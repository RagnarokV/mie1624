Link,Description,Course Title
https://www.classcentral.com/course/spatial-data-science-10168,"Spatial (map) is considered as a core infrastructure of modern IT world, which is substantiated by business transactions of major IT companies such as Apple, Google, Microsoft, Amazon, Intel, and Uber, and even motor companies such as Audi, BMW, and Mercedes. Consequently, they are bound to hire more and more spatial data scientists.  Based on such business trend, this course is designed to present a firm understanding of spatial data science to the learners, who would have a basic knowledge of data science and data analysis, and eventually to make their expertise differentiated from other nominal data scientists and data analysts.  Additionally, this course could make learners realize the value of spatial big data and the power of open source software's to deal with spatial data science problems.

This course will start with defining spatial data science and answering why spatial is special from three different perspectives - business, technology, and data in the first week.  In the second week, four disciplines related to spatial data science - GIS, DBMS, Data Analytics, and Big Data Systems, and the related open source software's - QGIS, PostgreSQL, PostGIS, R, and Hadoop tools are introduced together.  During the third, fourth, and fifth weeks, you will learn the four disciplines one by one from the principle to applications.  In the final week, five real world problems and the corresponding solutions are presented with step-by-step procedures in environment of open source software's.
      


            Read more
          



          Understanding Spatial Data Science
    -The first module of ""Spatial Data Science and Applications"" is entitled to ""Understanding of Spatial Data Science.""  This module is composed of four lectures.  The first lecture ""Introduction to spatial data  science"" was designed to give learners a solid concept of spatial data science in comparison with science, data science, and spatial data science. For Learner's better understanding, examples of spatial data science problems are also presented.  The second, third, and fourth lectures focuses on ""what is spatial special? - unique aspects of spatial data science from three perspectives of business, technology, and data, respectively.   In the second lecture, learners will learn five reasons why major IT companies are serious about spatial data, in other words, maps.   The third lecture will allow learners to understand four issues of dealing with spatial data, including DBMS problems, topology, spatial indexing, and spatial big data problems. The fourth lecture will allow learners to understand another four issues of spatial data including spatial autocorrelation, map projection, uncertainty, and modifiable areal unit problem.

Solution Structures of Spatial Data Science Problems
    -The second module is entitled to ""Solution Structures of Spatial Data Science Problems"", which is composed of four lectures and will give learners an overview of academic subjects, software tools, and their combinations for the solution structures of spatial data science problems. The first lecture, ""Four Disciplines for Spatial Data Science and Applications"" will introduce four academic disciplines related to spatial data science, which are Geographic Information System (GIS), Database Management System (DBMS), Data Analytics, and Big Data Systems.  The second lecture ""Open Source Software's"" will introduce open source software's in the four related disciplines, QGIS for GIS, PostgreSQL and PostGIS for DBMS, R for Data Analytics, Hadoop and Hadoop-based solutions for Big Data System, which will be used throughout this course.  The third lecture ""Spatial Data Science Problems"" will present six solution structures, which are different combinations of GIS, DBMS, Data Analytics, and Big Data Systems. The solution structures are related to the characteristics of given problems, which are the data size, the number of users, level of analysis, and main focus of problems.  The fourth lecture ""Spatial Data vs. Spatial Big Data"" will make learner have a solid understanding of spatial data and spatial big data in terms of similarity and differences.  Additionally, the value of spatial big data will be discussed.

Geographic Information System (GIS)
    -The third module is ""Geographic Information System (GIS)"", which is one of the four disciplines for spatial data science.  GIS has five layers, which are spatial reference framework, spatial data model, spatial data acquisition systems, spatial data analysis, and geo-visualization.  This module is composed of six lecture.  The first lecture ""Five Layers of GIS"" is an introduction to the third module.  The rest of the lectures will cover the five layers of GIS, one by one.  The second lecture  ""Spatial Reference Framework"" will make learners understand, first, a series of formulation steps of physical earth, geoid, ellipsoid, datum, and map projections, second, coordinate transformation between different map projections.  The third lecture ""Spatial Data Models"" will teach learners how to represent spatial reality in two spatial data models - vector model and raster model.  The fourth lecture ""Spatial Data Acquisition Systems"" will cover topics on how and where to acquire spatial data and how to produce your own spatial data. The fifth lecture ""Spatial Data Analysis"", will make learners to have brief taste of how to extract useful and valuable information from spatial data. More advanced algorithms for spatial analysis will be covered in the fifth module.  In the sixth lecture ""Geovisualization and Information Delivery"", learners will understand powerful aspects as well as negative potentials of cartographic representations as a communication media of spatial phenomenon.    

Spatial DBMS and Big Data Systems
    -The fourth module is entitled to ""Spatial DBMS and Big Data Systems"", which covers two disciplines related to spatial data science, and will make learners understand how to use DBMS and Big Data Systems to manage spatial data and spatial big data.  This module is composed of six lectures.  The first two lectures will cover DBMS and Spatial DBMS, and the rest of the lectures will cover Big Data Systems.  The first lecture ""Database Management System (DBMS)"" will introduce powerful functionalities of DBMS and related features, and limitations of conventional Relational DBMS for spatial data.  The second lecture ""Spatial DBMS"" focuses on the difference of spatial DBMS from conventional DBMS, and new features to manage spatial data.  The third lecture will give learners a brief overview of Big Data Systems and the current paradigm - MapReduce.  The fourth lecture will cover Hadoop MapReduce, Hadoop Distributed File System (HDFS), Hadoop YARN, as an implementation of MapReduce paradigm, and also will present the first example of spatial big data processing using Hadoop MapReduce. The fifth lecture will introduce Hadoop ecosystem and show how to utilize Hadoop tools such as Hive, Pig, Sqoop, and HBase for spatial big data processing.  The last lecture ""Spatial Big Data System"" will introduce two Hadoop tools for spatial big data - Spatial Hadoop and GIS Tools for Hadoop, and review their pros and cons for spatial big data management and processing. 

Spatial Data Analytics 
    -The fifth module is entitled to ""Spatial Data Analytics"", which is one of the four disciplines related to spatial data science.  Spatial Data Analytics could cover a wide spectrum of spatial analysis methods, however, in this module, only some portion of spatial data analysis methods will be covered.  The first lecture is an introduction, in which an overview of Spatial Data Analytics and a list of six topics are given and discussed.  The second lecture ""Proximity and Accessibility"" will make learners realize how spatial data science can be used for business applications, while trade area analysis, supply to demand ratio, Floating Catchment Analysis (FCA), and Gravity-based index of accessibility are introduced and applied to real world problems. The third lecture ""Spatial Autocorrelation"" will give an instruction on how to measure spatial autocorrelation and to apply hypothesis test with Moran's I.  The fourth lecture ""Spatial Interpolation"" will introduce trend surface analysis, inverse distance weighting, and Kriging. Particularly, in-depth explanations regarding Kriging, a de facto standard of spatial interpolation will be presented.  The fifth lecture ""Spatial Categorization"" will make learners understand classification algorithms such as Minimum Distance to Mean (MDM) and Decision Tree (DT), clustering algorithms such as K-Means and DBSCAN with real-world examples.  The sixth lecture ""Hotspot Analysis"" will introduce hotspot analysis and Getis-Ord GI* as the most popular method.  The seventh lecture ""Network Analysis"" will make learners explore the algorithms of geocoding, map matching, and shortest path finding, of which importance is increasing in spatial big data analysis.

Practical Applications of Spatial Data Science
    -The sixth module is entitled to ""Practical Applications of Spatial Data Science"", in which five real-world problems are introduced and corresponding solutions are presented with step-by-step procedures in the solution structures and related open source software's, discussed in Module 2.  The first lecture presents an example of Desktop GIS, in which only QGIS is used,  to find the top 5 counties for timberland investment in the southeastern states of the U.S, in which simple differencing of demand and supply is applied to figure out counties of large deficit of timber supply in comparison with timber demand.  In the second lecture, an example of sever GIS, in which QGIS and PostgreSQL/PostGIS are used, will be presented as a solution for a given problem of NYC spatial data center, which required multiple user access and different levels of privileges.  The third lecture presents an example of spatial data analytics, in which QGIS and R are used, to find out any regional factors which contribute to higher or lower disease prevalence in administrative districts, for which spatial autocorrelation analysis is conducted and decision tree analysis is applied.  The fourth lecture is another example of spatial data analytics, to find optimal infiltration routing with network analysis, in which cost surface is produced and Dijkstra's algorithm is used.  The fifth lecture is an example of spatial big data management and analytics, in which QGIS, PostGIS, R, and Hadoop MapReduce are all used, to provide a solution of ""Passenger Finder"", which can guide to the places where more passengers are waiting for taxi cabs.  For the solution, spatial big data, taxi trajectory, are collected, and noise removal and map matching are conducted in Hadoop environment.  Then, a series of spatial data processing and analysis such as spatial join in PostGIS, hotspot analysis in R are conducted in order to provide the solution.  All in all, learners will realize the value of spatial big data and power of the solution structure with combination of four disciplines.",Spatial Data Science and Applications
https://www.classcentral.com/course/process-mining-5419,"Learn to get a critical, process-centric perspective on data
Process mining combines business process management with data science. Using process mining, you can analyse and visualise business processes based on event data recorded in event logs.  For example, you could analyse how people use public transportation; verify whether a loan application is processed correctly by a bank; or predict when hardware parts are likely to fail.  This online course will give you an introduction to this new and exciting field.
This course is designed for anyone with an interest in business process management (BPM), data science and/or process analytics. No specific prior knowledge is required, only a healthy interest is required.
We do however require you to have a computer with internet access ready on which you can install and use ProM. Please refer to www.promtools.org for more information regarding ProM.",Introduction to Process Mining with ProM
https://www.classcentral.com/course/datamanagement-540,"This course presents critical concepts and practical methods to support planning, collection, storage, and dissemination of data in clinical research.

Understanding and implementing solid data management principles is critical for any scientific domain. Regardless of your current (or anticipated) role in the research enterprise, a strong working knowledge and skill set in data management principles and practice will increase your productivity and improve your science. Our goal is to use these modules to help you learn and practice this skill set. 

This course assumes very little current knowledge of technology other than how to operate a web browser. We will focus on practical lessons, short quizzes, and hands-on exercises as we explore together best practices for data management.
      


          Research Data Collection Strategy
    -This introductory module reviews the course structure and basic concepts in clinical research. We also discuss best practices for designing your clinical research data collection.

Electronic Data Capture Fundamentals
    -This module covers standards for study processes, concepts for regulatory compliance, and electronic data capture fundamentals.

Planning a Data Strategy for a Prospective Study
    -This module reviews the process of planning data elements for a real-world research study.

Practicing What We've Learned: Implementation
    -This week, we set up an Electronic Data Capture (EDC) instrument in REDCap for the Morphine vs. Marinol Study. We also review data processes that occur during the running of a study, including an overview of key data quality operations.

Post-Study Activities and Other Considerations
    -In this week, we cover activities to wrap up your study and share data and results, as well as two lectures on other electronic sources of data that can be used in research.  In response to learner requests, we've also added several lectures on clinical data management in resource-limited settings, in collaboration with research colleagues from Indiana University. This is a long week of videos, but next week will be short on videos in exchange!

Data Collection with Surveys
    -In the final week, we cover how to collect data using surveys and review an example together. This week's assignment includes designing, distributing, and reporting on your own survey.",Data Management for Clinical Research
https://www.classcentral.com/course/python-machine-learning-6673,"This course will introduce the learner to applied machine learning, focusing more on the techniques and methods than on the statistics behind these methods. The course will start with a discussion of how machine learning is different than descriptive statistics, and introduce the scikit learn toolkit through a tutorial. The issue of dimensionality of data will be discussed, and the task of clustering data, as well as evaluating those clusters, will be tackled. Supervised approaches for creating predictive models will be described, and learners will be able to apply the scikit learn predictive modelling methods while understanding process issues related to data generalizability (e.g. cross validation, overfitting). The course will end with a look at more advanced techniques, such as building ensembles, and practical limitations of predictive models. By the end of this course, students will be able to identify the difference between a supervised (classification) and unsupervised (clustering) technique, identify which technique they need to apply for a particular dataset and need, engineer features to meet that need, and write python code to carry out an analysis. 

This course should be taken after Introduction to Data Science in Python and Applied Plotting, Charting & Data Representation in Python and before Applied Text Mining in Python and Applied Social Analysis in Python.
      


          Module 1: Fundamentals of Machine Learning - Intro to SciKit Learn
    -This module introduces basic machine learning concepts, tasks, and workflow using an example classification problem based on the K-nearest neighbors method, and implemented using the scikit-learn library.

Module 2: Supervised Machine Learning - Part 1
    -This module delves into a wider variety of supervised learning methods for both classification and regression, learning about the connection between model complexity and generalization performance, the importance of proper feature scaling, and how to control model complexity by applying techniques like regularization to avoid overfitting.  In addition to k-nearest neighbors, this week covers linear regression (least-squares, ridge, lasso, and polynomial regression), logistic regression, support vector machines, the use of cross-validation for model evaluation, and decision trees. 

Module 3: Evaluation
    -This module covers evaluation and model selection methods that you can use to help understand and optimize the performance of your machine learning models. 

Module 4: Supervised Machine Learning - Part 2
    -This module covers more advanced supervised learning methods that include ensembles of trees (random forests, gradient boosted trees), and neural networks (with an optional summary on deep learning).  You will also learn about the critical problem of data leakage in machine learning and how to detect and avoid it.",Applied Machine Learning in Python
https://www.classcentral.com/course/coursera-dog-emotion-and-cognition-3627,"Dog Emotion and Cognition will introduce you to the exciting new study of dog psychology, what the latest discoveries tell us about how dogs think and feel about us, and how we can use this new knowledge to further strengthen our relationship with our best friends.
      


          Course Information 
    -Dog Emotion and Cognition is a course designed to introduce the exciting new science of dog psychology to any level of dog enthusiast. In learning about dogs you will be introduced to evolutionary and cognitive theory, learn about experimental methodology, see how dogs compare to other species, and even have the chance to try some of the cognitive games you learn about with your own dog. The course is a great introduction to the field of animal cognition and animal behavior but is also relevant to anyone interested in human evolution or even dog training. When you finish you will think about your dog in a new way, will be ready to apply your new knowledge, and will be prepared to take higher level classes in the evolutionary or cognitive sciences. 

The Paradox of a Best Friend That Evolved From Our Worst Enemy
    -This module will provide an introduction to cognitive psychology and evolution, while having direct application to your dog. At the beginning of each lecture, Dr. Hare will suggest an optional reading from his book The Genius of Dogs, as well as free Dognition games to play at www.dognition.com/mooc. Dr. Hare discusses how our evolutionary relationship with dogs is a puzzle. He describes the meaning of cognition and what it looks like with modern research on animals. Last, he discusses what Dognition is and how can be used like a laboratory for the class. 

How Biology Studies Cognitive Evolution
    -In this module, Dr. Hare describes how the internal processes of the mind are studied through experiments. He explains how animal problem solving is best explained as scientists work toward better understanding the topic. Next, he describes the ecological approach to cognition through an evolutionary lens, which involves Tinbergen's four levels of analysis. 

Dogs Are Cognitively Remarkable
    -In this module, Dr. Hare describes how dogs are cognitively remarkable. He begins by explaining theory of mind, which, when viewed through the ecological approach, suggests that social problem solving drove primate and human cognitive evolution. Next, he describes how good dogs are at understanding communicative intentions, especially compared to apes. Dr. Hare has three hypotheses to explain the remarkable communication found in domestic dogs. 

Evolutionary Accidents and Survival of the Friendliest
    -In this module, Dr. Hare explores three of his research studies he's done with foxes, New Guinea Singing Dogs, as well as research on wolves. He describes how early dog-wolves may actually be a product of natural selection rather than artificial selection, contrary to popular belief. He introduces a hypothesis called Survival of the Friendliest, which may explain how dogs, bonobos, and modern species evolved in contrast to close relatives, such as wolves and chimpanzees. Last, he relates the high level of social tolerance of these species to human by looking at human self-domestication.  

Problems That Dogs Can and Cannot Solve
    -In this module, you will learn about the genius of dogs. Brilliant examples of the canine mind will be explored. Dogs seem to be capable of inferential reasoning using the ""principle of exclusion"" as well as learning new words by imitating humans. Next, Dr. Hare discusses dog's abilities to understand physical problem solving compared to other species (hint, this isn't most dog's strong suit). Last, he will discuss how dogs are not cooperative breeders, do have a relaxed social system, and are excellent hunting companions for humans. 

Finding Your Dog's Genius
    -In this module, Dr. Hare will discuss the common myths of breed differences and what research (including citizen science Dognition data) has actually been done to understand potential differences between breeds. You will also listen to Dr. Hare debunk ""aggressive dog breed"" stereotypes by learning about the literature and studies that have been done on dog aggression. He poses an interesting question about the actual culprit for the dog aggression problem, which is not even a dog! Next, he will explain how important understanding dog cognition is to training strategies. Dr. Hare will discuss how, unfortunately, not all cultures love dogs, and some see them as food and pests. He suggests ways that humans can live with dogs for mutual benefit. Taking all that you've learned into account, Dr. Hare then discusses how Dognition is revolutionizing what we know about dogs and how beneficial it could be to your relationship with your dog as well as for science! 

Final Exam
    -The final exam covering topics from all modules.",Dog Emotion and Cognition
https://www.classcentral.com/course/edx-algorithms-5752,"Algorithms power the biggest web companies and the most promising startups. Interviews at tech companies start with questions that probe for good algorithm thinking.
In this computer science course, you will learn how to think about algorithms and create them using sorting techniques such as quick sort and merge sort, and searching algorithms, median finding, and order statistics.
The course progresses with Numerical, String, and Geometric algorithms like Polynomial Multiplication, Matrix Operations, GCD, Pattern Matching, Subsequences, Sweep, and Convex Hull. It concludes with graph algorithms like shortest path and spanning tree.
Topics covered:

Sorting and Searching
Numerical Algorithms
String Algorithms
Geometric Algorithms
Graph Algorithms

This course is part of the Fundamentals of Computer Science XSeries Program:

Programming Basics
Object-Oriented Programming
Foundations of Data Structures
Implementation of Data Structures",Algorithms
https://www.classcentral.com/course/sql-for-data-science-9725,"As data collection has increased exponentially, so has the need for people skilled at using and interacting with data; to be able to think critically, and provide insights to make better decisions and optimize their businesses. This is a data scientist, “part mathematician, part computer scientist, and part trend spotter” (SAS Institute, Inc.). According to Glassdoor, being a data scientist is the best job in America; with a median base salary of $110,000 and thousands of job openings at a time. The skills necessary to be a good data scientist include being able to retrieve and work with data, and to do that you need to be well versed in SQL, the standard language for communicating with database systems.

This course is designed to give you a primer in the fundamentals of SQL and working with data so that you can begin analyzing it for data science purposes. You will begin to ask the right questions and come up with good answers to deliver valuable insights for your organization. This course starts with the basics and assumes you do not have any knowledge or skills in SQL. It will build on that foundation and gradually have you write both simple and complex queries to help you select data from tables.  You'll start to work with different types of data like strings and numbers and discuss methods to filter and pare down your results. 

You will create new tables and be able to move data into them. You will learn common operators and how to combine the data. You will use case statements and concepts like data governance and profiling. You will discuss topics on data, and practice using real-world programming assignments. You will interpret the structure, meaning, and relationships in source data and use SQL as a professional to shape your data for targeted analysis purposes. 

Although we do not have any specific prerequisites or software requirements to take this course, a simple text editor is recommended for the final project. So what are you waiting for? This is your first step in landing a job in the best occupation in the US and soon the world!
      


            Read more
          



          Getting Started and Selecting & Retrieving Data with SQL
    -In this module, you will be able to define SQL and discuss how SQL differs from other computer languages. You will be able to compare and contrast the roles of a database administrator and a data scientist, and explain the differences between one-to-one, one-to-many, and many-to-many relationships with databases. You will be able to use the SELECT statement and talk about some basic syntax rules. You will be able to add comments in your code and synthesize its importance.

Filtering, Sorting, and Calculating Data with SQL
    -In this module, you will be able to use several more new clauses and operators including WHERE, BETWEEN, IN, OR, NOT, LIKE, ORDER BY, and GROUP BY. You will be able to use the wildcard function to search for more specific or parts of records, including their advantages and disadvantages, and how best to use them. You will be able to discuss how to use basic math operators, as well as aggregate functions like AVERAGE, COUNT, MAX, MIN, and others to begin analyzing our data.

Subqueries and Joins in SQL
    -In this module, you will be able to discuss subqueries, including their advantages and disadvantages, and when to use them. You will be able to recall the concept of a key field and discuss how these help us link data together with JOINs. You will be able to identify and define several types of JOINs, including the Cartesian join, an inner join, left and right joins, full outer joins, and a self join. You will be able to use aliases and pre-qualifiers to make your SQL code cleaner and efficient.

Modifying and Analyzing Data with SQL
    -In this module, you will be able to discuss how to modify strings by concatenating, trimming, changing the case, and using the substring function. You will be able to discuss the date and time strings specifically. You will be able to use case statements and finish this module by discussing data governance and profiling. You will also be able to apply fundamental principles when using SQL for data science. You'll be able to use tips and tricks to apply SQL in a data science context.",SQL for Data Science
https://www.classcentral.com/course/edx-data-science-r-basics-9253,"The first in our Professional Certificate Program in Data Science, this course will introduce you to the basics of R programming. You can better retain R when you learn it to solve a specific problem, so you'll use a real-world dataset about crime in the United States. You will learn the R skills needed to answer essential questions about differences in crime across the different states. 
We'll cover R's functions and data types, then tackle how to operate on vectors and when to use advanced functions like sorting. You'll learn how to apply general programming features like ""if-else,"" and ""for loop"" commands, and how to wrangle, analyze and visualize data. 
Rather than covering every R skill you might need, you'll build a strong foundation to prepare you for the more in-depth courses later in the series, where we cover concepts like probability, inference, regression, and machine learning. We help you develop a skill set that includes R programming, data wrangling with dplyr, data visualization with ggplot2, file organization with UNIX/Linux, version control with git and GitHub, and reproducible document preparation with RStudio. 
The demand for skilled data science practitioners is rapidly growing, and this series prepares you to tackle real-world data analysis challenges.",Data Science: R Basics
https://www.classcentral.com/course/data-science-for-business-innovation-14369,"The course is a compendium of the must-have expertise in data science for executive and middle-management to foster data-driven innovation. It consists of introductory lectures spanning big data, machine learning, data valorization and communication. Topics cover the essential concepts and intuitions on data needs, data analysis, machine learning methods, respective pros and cons, and practical applicability issues.	

The course covers terminology and concepts, tools and methods, use cases and success stories of data science applications. 
The course explains what is Data Science and why it is so hyped. It discusses the value that Data Science can create, the main classes of problems that Data Science can solve, the difference is between descriptive, predictive and prescriptive analytics, and the roles of machine learning and artificial intelligence.

From a more technical perspective, the course covers supervised, unsupervised and semi-supervised methods, and explains what can be obtained with classification, clustering, and regression techniques. It discusses the role of NoSQL data models and technologies, and the role and impact of scalable cloud-based computation platforms.
All topics are covered with example-based lectures, discussing use cases, success stories and realistic examples.
      


          Introduction to Data-driven Business 
    -This module introduces the course and offers some basic overview of the topics. It presents the crucial concepts related to data science and big data and provides an outlook on how to use them in real world settings for increasing business value.

Terminology and Foundational Concepts
    -In this module, you will learn the foundational concepts of machine learning and data science. You will understand how these techniques can be useful in terms of increased business value for organizations, thanks to the discussion of a very well known success story, namely Netflix, which can be deemed as a completely data-driven business. You will also understand how machine learning is different from programming.

Data Science Methods for Business
    -In this module, you will learn the concepts and intuitions about the basic approaches for data analysis, including linear regression, naive Bayes, decision trees, clustering, and logistic regression. All the methods are presented starting from typical business uses and are covered in an intuitive way through a guided explanation of how the approach works on simple examples.

Challenges and Conclusions
    -This module summarizes the concepts learned so far and introduces a set of challenges and risks that data-savvy managers must take into account when deciding for a data-driven strategy.",Data Science for Business Innovation
https://www.classcentral.com/course/python-text-mining-6672,"This course will introduce the learner to text mining and text manipulation basics. The course begins with an understanding of how text is handled by python, the structure of text both to the machine and to humans, and an overview of the nltk framework for manipulating text. The second week focuses on common manipulation needs, including regular expressions (searching for text), cleaning text, and preparing text for use by machine learning processes. The third week will apply basic natural language processing methods to text, and demonstrate how text classification is accomplished. The final week will explore more advanced methods for detecting the topics in documents and grouping them by similarity (topic modelling). 

This course should be taken after: Introduction to Data Science in Python, Applied Plotting, Charting & Data Representation in Python, and Applied Machine Learning in Python.
      


          Module 1: Working with Text in Python

Module 2: Basic Natural Language Processing

Module 3: Classification of Text

Module 4: Topic Modeling",Applied Text Mining in Python
https://www.classcentral.com/course/edx-cs50-s-computer-science-for-business-professionals-10143,"This is CS50’s introduction to computer science for business professionals, designed for managers, product managers, founders, and decision-makers more generally. Whereas CS50 itself takes a bottom-up approach, emphasizing mastery of low-level concepts and implementation details thereof, this course takes a top-down approach, emphasizing mastery of high-level concepts and design decisions related thereto. Through lectures on computational thinking, programming languages, internet technologies, web development, technology stacks, and cloud computing, this course empowers you to make technological decisions even if not a technologist yourself. You’ll emerge from this course with first-hand appreciation of how it all works and all the more confident in the factors that should guide your decision-making.",CS50's Computer Science for Business Professionals
https://www.classcentral.com/course/gencommand-3474,"Introduces to the commands that you need to manage and analyze directories, files, and large sets of genomic data. This is the fourth course in the Genomic Big Data Science Specialization from Johns Hopkins University.
      


          Basic Unix Commands
    -In this module, you will be introduced to command Line Tools for Genomic Data Science

Week Two
    -In this module, we'll be taking a look at Sequences and Genomic Features in a sequence of 10 presentations. 

Week Three
    -In this module, we'll be going over Alignment and Sequence Variation in another sequence of 8 presentations.

Week Four
    -In this module, we'll be going over Tools for Transcriptomics in a sequence of 6 presentations.",Command Line Tools for Genomic Data Science
https://www.classcentral.com/course/edx-programming-basics-1650,"Basic concepts of computer programming are introduced, starting with the notion of an algorithm. Emphasis is on developing the ability to write programs to solve practical computational problems.
Topics include:

Algorithms
Elements of C/C++ programming languages
Basic data types
Sequential and conditional execution
Iterative solutions
Arrays, matrices and their applications
Functions
Sorting and searching
Elements of string processing
Introduction to pointers
Basics of Software Engineering
Structures
File Processing

Learners will read and understand many sample programs, and will have to write several on their own. This course deals with basic programming, and sets the foundation for solid programming practices for beginners.
This course is part of the Fundamentals of Computer Science XSeries Program:

Object-Oriented Programming
Foundations of Data Structures
Implementation of Data Structures
Algorithms",Programming Basics
https://www.classcentral.com/course/social-science-research-chinese-society-8628,"This course is intended as a first step for learners who seek to become producers of social science research. It is organized as an introduction to the design and execution of a research study. It introduces the key elements of a proposal for a research study, and explains the role of each. It reviews the major types of qualitative and quantitative data used in social science research, and then introduces some of the most important sources of existing data available freely or by application, worldwide and for China. The course offers an overview of basic principles in the design of surveys, including a brief introduction to sampling. Basic techniques for quantitative analysis are also introduced, along with a review of common challenges that arise in the interpretation of results. Professional and ethical issues that often arise in the conduct of research are also discussed.  The course concludes with an introduction to the options for further study available to the interested student, and an overview of the key steps involved in selecting postgraduate programs and applying for admission. Learners who complete the course will be able to make an informed decision about whether to pursue advanced studies, and should be adequately prepared to write an application for postgraduate study that exhibits basic understanding of key aspects of social science research paradigms and methodologies.

Explore the big questions in social science and learn how you can be a producer of social science research. 

Course Overview video: https://youtu.be/QuMOAlwhpvU

Part 1 should be completed before taking this course:  https://www.coursera.org/learn/social-science-study-chinese-society
      


            Read more
          



          Designing a Study
    -Welcome to Social Science Approaches to the Study of Chinese Society Part 2! Part 2 focuses on being a PRODUCER of Social Science Research.  Take some time to review the course overview, assignments for this course and say hello in the discussion forum.  

Evidence
    -Week 2 will discuss the kind sources social scientists use for research. By the end of this week, you should be able to identify some of these major sources and perhaps pinpoint some sources that can be used in your own study.

Sampling
    -By the end of Week 3, you should be able to understand why RANDOM SAMPLING is important in a survey, outline the most common approaches to sampling and discuss key considerations when choosing a sampling strategy for your study.

Public Data for China
    -Week 4 discusses major sources of public data available to you.  By the end of this week you should be able to describe the opportunities as well as the challenges associated with using publicly available survey data. 

Quantitative Analysis
    -Week 5 will give you a taste of the basic methods for quantitative analysis.  From there you should be able to identify key issues when interpreting results and discuss implications for research.

Research and Professional Ethics
    -By the end of this week you should be able to describe major ethical and professional concerns in social science research.

Where to go from here
    -Welcome to the last week of Part 2!  By the end of this week you should be able to be aware of the options you have for further study in social science research and know the steps to move forward in the application process for advanced training.

Final exam
    -You've reached the final exam week!  Complete the final exam and the post-course survey. Your feedback can help us improve the course.  Thank you for being a part of this course and good luck for your pursuit of advanced studies in social science research!",Social Science Approaches to the Study of Chinese Society Part 2
https://www.classcentral.com/course/maps-676,"Learn how advances in geospatial technology and analytical methods have changed how we do everything, and discover how to make maps and analyze geographic patterns using the latest tools.

The past decade has seen an explosion of new mechanisms for understanding and using location information in widely-accessible technologies. This Geospatial Revolution has resulted in the development of consumer GPS tools, interactive web maps, and location-aware mobile devices. These radical advances are making it possible for people from all walks of life to use, collect, and understand spatial information like never before.

This course brings together core concepts in cartography, geographic information systems, and spatial thinking with real-world examples to provide the fundamentals necessary to engage with Geography beyond the surface-level. We will explore what makes spatial information special, how spatial data is created, how spatial analysis is conducted, and how to design maps so that they’re effective at telling the stories we wish to share. To gain experience using this knowledge, we will work with the latest mapping and analysis software to explore geographic problems.
      


          Getting Started
    -Watch a short video to learn how this class works (it's a bit different than other MOOCs) and help make a map with your classmates.

The Changing Nature of Place
    -Discover the Geospatial Revolution and its impact on the rapidly evolving science of Geography.

Spatial is Special
    -Explore what it means to think spatially and consider the impacts of scale and time.

Understanding Spatial Data
    -Examine the key elements of spatial datasets.

Doing Spatial Analysis
    -Learn how Geographers solve problems using spatial analysis techniques.

Making Great Maps
    -Explore the key elements of effective cartographic design.",Maps and the Geospatial Revolution
https://www.classcentral.com/course/big-data-ai-ethics-17300,"This course gives you context and first-hand experience with the two major catalyzers of the computational science revolution: big data and artificial intelligence. With more than 99% of all mediated information in digital format and with 98% of the world population using digital technology, humanity produces an impressive digital footprint. In theory, this provides unprecedented opportunities to understand and shape society. In practice, the only way this information deluge can be processed is through using the same digital technologies that produced it. Data is the fuel, but machine learning it the motor to extract remarkable new knowledge from vasts amounts of data. Since an important part of this data is about ourselves, using algorithms in order to learn more about ourselves naturally leads to ethical questions. Therefore, we cannot finish this course without also talking about research ethics and about some of the old and new lines computational social scientists have to keep in mind. As hands-on labs, you will use IBM Watson’s artificial intelligence to extract the personality of people from their digital text traces, and you will experience the power and limitations of machine learning by teaching two teachable machines from Google yourself.
      


          Getting Started and Big Data Opportunities
    -In this module, you will be able to define the idea of big data and digital footprint. You will be able to discuss how big data is represented in social science and identify the opportunities of big data.

Big Data Limitations
    -In this module, you will be able to explain the limitations of big data. You will work with an AI interface, IBM Watson, and discover how AI can identify personality through Natural Language Processing. You will analyze the personality of a person.

Artificial Intelligence
    -In this module, you will discover the history of artificial intelligence (AI) and its fields of study. You'll be able to examine how AI is used through case studies. You will be able to discuss the application of AI and you will use AI to create a unique artifact through a hands-on exercise.

Research Ethics 
    -In this module, you will be able to define the term research ethics. You will be able to examine the role ethics plays in conducting research. You will be able to discuss how ethics is applied when using AI and big data.","Big Data, Artificial Intelligence, and Ethics"
https://www.classcentral.com/course/functional-programming-haskell-6636,"##
Do you want to develop software using the latest programming language paradigm? Haskell is a functional programming language, based on formal mathematical principles. As such, it is easy to reason about and develop, and it executes efficiently on modern multicore machines. From investment banks to social networks, everyone is adopting Haskell.
Get an introduction to functional programming in Haskell
On this introductory course, you will discover the power, elegance and simplicity of functional programming in Haskell. By the end, you will be able to:

characterise the differences between imperative and functional programming paradigms;
implement small-scale functional programs in elementary Haskell;
apply standard combinators for operating on lists;
create new algebraic data types and use recursion to define functions that traverse recursive types;
and reason in a mathematical manner about data types, functions, recursion and similar functional constructs.

Learn with developers from the birthplace of Haskell
This course has been created by the School of Computing Science at the University of Glasgow – the virtual birthplace of the Haskell language, where many of its original developers worked. It will give you the opportunity to learn with these experts and join the growing, global community of Haskell programmers.
This course is intended for learners who already have experience of at least one programming language, such as Python or Java. You might be a computer science student, a software developer who wants to learn a new programming style, or somebody considering university study in computer science or information technology.



            Read more",Functional Programming in Haskell: Supercharge Your Coding
https://www.classcentral.com/course/case-studies-business-analytics-accentur-4369,"Who is this course for ?
This course is RESTRICTED TO LEARNERS ENROLLED IN  Strategic Business Analytics SPECIALIZATION as a preparation to the capstone project. During the first two MOOCs, we focused on specific techniques for specific applications. Instead, with this third MOOC, we provide you with different examples  to open your mind to different applications from different industries and sectors.
The objective is to give you an helicopter overview on what's happening in this field. You will see how the tools presented in the two previous courses of the Specialization are used in real life projects. 
We want to ignite your reflection process. Hence, you will best make use of the Accenture cases by watching first the MOOC and then investigate by yourself on the different concepts, industries, or challenges that are introduced during the videos.

At the end of this course learners will be able to: 
- identify the possible applications of business analytics,
- hence, reflect on the possible solutions and added-value applications that could be proposed for their capstone project.

The cases will be presented by senior practitioners from Accenture with different backgrounds in term of industry, function, and country.  Special attention will be paid to the ""value case"" of the issue raised to prepare you for the capstone project of the specialization.

About Accenture
Accenture is a leading global professional services company, providing a broad range of services and solutions in strategy, consulting, digital, technology and operations. Combining unmatched experience and specialized skills across more than 40 industries and all business functions—underpinned by the world’s largest delivery network—Accenture works at the intersection of business and technology to help clients improve their performance and create sustainable value for their stakeholders. With more than 358,000 people serving clients in more than 120 countries, Accenture drives innovation to improve the way the world works and lives. Visit us at www.accenture.com.
      


            Read more
          



          Introduction to case studies in business analytics with Accenture
    -In this introductory module, Fabrice Marque, Managing Director Customer Strategy Practice Lead for France, Belgium and the Netherlands, also in charge of the ESSEC-Accenture Strategic Business Analytics Chair, will first introduce the MOOC in general. Then Michael Svilar, Global Accenture Data Science Group Lead, will identify the general trends in this sector. In this module, we will cover three different real-life examples. First, Rohit Banerji, Accenture business lead responsible for big data analytics for the resource sector, will present an example from a water utilities company. Second, Cian O’Hare, Managing Director at Accenture Digital, will present a case study from a global communication provider. Finally, Christopher Gray, public service expert at Accenture, will discuss challenges arising in the public sector where Analytics and Big Data can provide effective solutions.   

At the end of each example there will be quiz questions. Note that those questions may require you to collect additional information from that which was delivered during the videos. Do not hesitate to consult additional books, websites and examples about this topic: some of the answers can actually be found directly thanks to open access research engines or online encyclopedias! The objective with this final MOOC in the Strategic Business Analytics specialization is to assess whether you now master the different concepts that are implemented within this field.

Digital Transformation in the Media, the Financial Services and the Retail Sector
    -During this module, different real-life examples will be discussed. Christine Removille, Digital Marketing Lead at the European Level, will present a data-centric digital transformation at a French TV company: Canal +. Edwin Van der Ouderaa, Financial Services Lead, will then explain how digital developments and data are disrupting the financial service sector.At the end of each video there will be  quiz questions. Do not hesitate to consult additional books, websites and examples about this topic! The objective with this final MOOC in the Strategic Business Analytics specialization is to assess whether you now master the different concepts that are implemented within this field.

Advanced Analytics in Healthcare and the Pharmaceutical industry / Wrap up and Introduction to capstone
    -During this module, two different real-life examples will be discussed. First, Paul Pierotti, Managing Director at Accenture Digital, will explain how Analytics can transform how health services are delivered. Second Xavier Cimino, Managing Director in charge of the Analytics Practice in the Life Science industry for Europe, will present an award-winning project in this sector. At the end of each video, there will be quiz questions. Do not hesitate to consult additional books, websites and examples about this topic! The objective with this final MOOC in the Strategic Business Analytics specialization is to assess whether you now master the different concepts that are implemented within this field.Finally, Michael Svilar, Global Accenture Data Science Group Lead, will conclude the MOOC.",Case studies in business analytics with ACCENTURE
https://www.classcentral.com/course/edx-data-science-and-machine-learning-essentials-3954,"Demand for Data science talent is exploding. Learn these essentials with experts from MIT and the industry, partnering with Microsoft to help develop your career as a data scientist. By the end of this course, you will know how to build and derive insights from data science and machine learning models. You will learn key concepts in data acquisition, preparation, exploration and visualization along with examples on how to build a cloud data science solution using Azure Machine Learning, R & Python.
Data Science is an essential skill for analyzing and deriving useful insights from data, big and small. McKinsey estimates that by 2018, a 500,000 strong workforce of data scientists will be needed in US alone. The resulting talent gap must be filled by a new generation of data scientists.
This course is organized into 5 weekly modules each concluding with a quiz. By achieving a passing grade in the final course assessment you will receive a certificate demonstrating that you have acquired data science skills and knowledge. Apart from answering your questions on the forum, faculty will host an office hour to address questions you may have while undertaking this course.
Get an ID verified certificate to demonstrate your data science knowledge and share on LinkedIn.



Module I Introduction

Introduction to Data Science
Overview of the Data Science process
Introduction to Data Science technologies
Introduction to Machine Learning
Regressions
Classification
Clustering
Recommendation

 
Module 2: Working with Data in Azure ML

Data Acquisition
Data Ingestion and Ingress
Data Sampling and Quantization
Data Cleaning and Transformation

 
Module 3: Building and Evaluation of Models

Data Exploration and Visualization
Business Metrics and Cost-Based Metrics
Model Evaluation, Comparison and Selection

 
Module 4: Models in Azure ML, Part 1

Regression Models
Classification Models
Unsupervised Learning Models

 
Module 5: Models in Azure ML, Part 2

Recommendation Models
Publishing AML Models
Course Exam",Data Science and Machine Learning Essentials
https://www.classcentral.com/course/data-science-k-means-clustering-python-13623,"Organisations all around the world are using data to predict behaviours and extract valuable real-world insights to inform decisions. Managing and analysing big data has become an essential part of modern finance, retail, marketing, social science, development and research, medicine and government.

This MOOC, designed by an academic team from Goldsmiths, University of London, will quickly introduce you to the core concepts of Data Science to prepare you for intermediate and advanced Data Science courses. It focuses on the basic mathematics, statistics and programming skills that are necessary for typical data analysis tasks. 

You will consider these fundamental concepts on an example data clustering task, and you will use this example to learn basic programming skills that are necessary for mastering Data Science techniques. During the course, you will be asked to do a series of mathematical and programming exercises and a small data clustering project for a given dataset.
      


          Week 1: Foundations of Data Science: K-Means Clustering in Python
    -This week we will introduce you to the course and to the team who will be guiding you through the course over the next 5 weeks. The aim of this week's material is to gently introduce you to Data Science through some real-world examples of where Data Science is used, and also by highlighting some of the main concepts involved.

Week 2: Means and Deviations in Mathematics and Python

Week 3: Moving from One to Two Dimensional Data

Week 4: Introducing Pandas and Using K-Means to Analyse Data

Week 5: A Data Clustering Project",Foundations of Data Science: K-Means Clustering in Python
https://www.classcentral.com/course/java-programming-arrays-lists-data-4362,"Build on the software engineering skills you learned in “Java Programming: Solving Problems with Software” by learning new data structures. Use these data structures to build more complex programs that use Java’s object-oriented features. At the end of the course you will write an encryption program and a program to break your encryption algorithm.

After completing this course, you will be able to:
1. Read and write data from/to files;
2. Solve problems involving data files;
3. Perform quantitative analyses of data (e.g., finding maximums, minimums, averages); 
4. Store and manipulate data in an array or ArrayList;
5. Combine multiple classes to solve larger problems;
6. Use iterables and collections (including maps) in Java.
      


          Welcome
    -Welcome to “Java Programming: Arrays, Lists, and Structured Data”! We are excited that you are starting our course to learn how to write programs in Java, one of the most popular programming languages in the world. In this introductory module, you will hear an overview of this course and be introduced to the supporting resources available.

Cryptography: Keeping Information Secret
    -In this module, you will learn about the basics of cryptography, the science of keeping information private and secure. You will learn about simpler cryptographic systems, which were used from the Roman Empire through the early 1900s. You will learn how to implement these ciphers, as well as how to break them. To solve these problems, you will work more with processing Strings, but also learn about arrays—a way to store an indexable sequence of elements. You will be able to: (1) combine Strings using concatenation; (2) build Strings within a Java program using StringBuilder; (3) use arrays to store and manipulate collections of data; (4) refactor your programs for improved organization using object-oriented principles; (5) and practice effective algorithm design.

GladLibs: Stories from Templates
    -After completing this module, you will be able (1) to program a word frequency counter to analyze any input text file, (2) to select and substitute words from a list into a document template using both ArrayList and HashMap, (3) to create new lists to use in templates, (4) to recognize brittle code, and (5) to improve code with flexible, object-oriented design. You will gain these skills in the framework of developing a randomly generated story that we call GladLibs. You may discover that bald lions change peoples’ lives, or that fluffy dinosaurs get things done in a jiffy. We hope you have fun developing your Java skills this week!

Web Server Logs: From Logs to Visits
    -In this module, you will learn about how web server logs store information about visitors to a website, and you will write programs to access information like user IP address, date and time of access, and more. Using Java programs you write in this module, you will be able (1) to read information from a web server log, (2) to count the number of unique visitors to your website, and (3) to count the number of times each visitor uses your website.

MiniProject: Vigenère Cipher
    -In this module, you will develop a program to break the Vigenère Cipher, a more complex version of the Caesar Cipher. You will improve your program in three stages: first decrypting messages where you know the language and key length, then adding the capability to handle messages with unknown key length, then extending the program to handle messages in a range of possible languages. Through this project, you will be able (1) to effectively use HashSet and HashMap, (2) to expand an algorithm from solving a simpler problem to handle broader, more complex problems, and (3) to design and modify program code involving a more complex collection of classes, methods, and data.","Java Programming: Arrays, Lists, and Structured Data"
https://www.classcentral.com/course/edx-computer-science-101-2175,"CS101 is a self-paced course that teaches the essential ideas of Computer Science for a zero-prior-experience audience. Computers can appear very complicated, but in reality, computers work within just a few, simple patterns. CS101 demystifies and brings those patterns to life, which is useful for anyone using computers today.
In CS101, participants play and experiment with short bits of ""computer code"" to bring to life to the power and limitations of computers. Everything works within the browser, so there is no extra software to download or install. CS101 also provides a general background on computers today: what is a computer, what is hardware, what is software, what is the internet. Anyone who has the ability to use a web browser may be successful in this course. No previous computer science experience is required.",Computer Science 101
https://www.classcentral.com/course/clustering-3556,"How do we infer which genes orchestrate various processes in the cell?  How did humans migrate out of Africa and spread around the world? In this class, we will see that these two seemingly different questions can be addressed using similar algorithmic and machine learning techniques arising from the general problem of dividing data points into distinct clusters.

In the first half of the course, we will introduce algorithms for clustering a group of objects into a collection of clusters based on their similarity, a classic problem in data science, and see how these algorithms can be applied to gene expression data.

In the second half of the course, we will introduce another classic tool in data science called principal components analysis that can be used to preprocess multidimensional data before clustering in an effort to greatly reduce the number dimensions without losing much of the ""signal"" in the data.

Finally, you will learn how to apply popular bioinformatics software tools to solve a real problem in clustering.
      


          Week 1: Introduction to Clustering Algorithms
    -Welcome to class!At the beginning of the class, we will see how algorithms for clustering a set of data points will help us determine how yeast became such good wine-makers. At the bottom of this email is the Bioinformatics Cartoon for this chapter, courtesy of Randall Christopher and serving as a chapter header in the Specialization's bestselling print companion. How did the monkey lose a wine-drinking contest to a tiny mammal?  Why have Pavel and Phillip become cavemen? And will flipping a coin help them escape their eternal boredom until they can return to the present? Start learning to find out!

Week 2: Advanced Clustering Techniques
    -Welcome to week 2 of class!

This week, we will see how we can move from a ""hard"" assignment of points to clusters toward a ""soft"" assignment that allows the boundaries of the clusters to blend. We will also see how to adapt the Lloyd algorithm that we encountered in the first week in order to produce an algorithm for soft clustering. We will also see another clustering algorithm called ""hierarchical clustering"" that groups objects into larger and larger clusters.

Week 3: Introductory Algorithms in Population Genetics",Genomic Data Science and Clustering (Bioinformatics V)
https://www.classcentral.com/course/complexity-explorer-tutorials-for-complex-systems-1194,"This course covers several mathematical techniques that are frequently used in complex systems science.   The techniques are covered in independent units, taught by different instructors.  Each unit has its own prerequisites.  Note that this course is meant to introduce students to various important techniques and to provide illustrations of their application in complex systems.  A given unit is not meant to offer complete coverage of its topic or substitute for an entire course on that topic.   
The units included during this offering of the course are:
(1) Introduction to differential equations (David Feldman)
(2) Ordinary differential equations (ODEs) and numerical ODE solvers (Liz Bradley)
(3) Functions and iteration (David Feldman)
(4) Maximum entropy methods  (Simon DeDeo)
(5) Random Walks (Sid Redner)
(6) Vector and matrix algebra (Anthony Rhodes)
(7) Introduction to information theory (Seth Lloyd)
(8) Game Theory I - Static Games (Justin Grana)
 
(9) Game Theory II - Dynamic Games (Justin Grana)
 
(10) Introduction to Renormalization (Simon DeDeo)
 

(11) Fundamentals of Machine Learning (Artemy Kolchinsky)
 
(12) Introduction to Computation Theory (Josh Grochow)
 
(13) Fundamentals of NetLogo (Bill Rand)
 
Other units to be developed over time. 



            Read more",Tutorials for Complex Systems
https://www.classcentral.com/course/sciwrite-464,"This course teaches scientists to become more effective writers, using practical examples and exercises. Topics include: principles of good writing, tricks for writing faster and with less anxiety, the format of a scientific manuscript, peer review, grant writing, ethical issues in scientific publication, and writing for general audiences.
      


          1
    -Unit 1 introduces the course and reviews key principles of effective writing. In particular, you will practice cutting clutter from writing.

2
    -Unit 2 focuses on writing with strong, active verbs. Lessons include how to: write in the active voice; avoid turning verbs into nouns; choose strong verbs; and get to the main verb of a sentence quickly.

3
    -Unit 3 reviews how to vary sentence structure and write strong paragraphs. You will practice using the dash, colon, semi-colon, and parentheses, as well as writing well-organized and concise paragraphs.

4
    -Unit 4 reviews the writing process. I will give you tips for making the writing process easier, more efficient, and more organized. 

5
    -Unit 5 reviews the sections of a scientific manuscript. You will learn how to format tables and figures, and how to write results, methods, introduction, and discussion sections.

6
    -Unit 6 discusses the peer review process, as well as ethical issues in scientific publishing. You will learn how to avoid plagiarism, determine authorship, submit a paper, write a peer review, and avoid predatory journals.

7
    -Unit 7 reviews types of writing beyond original research manuscripts. You will learn how to write review papers, grants, letters of recommendation, and personal essays.

8
    -Unit 8 reviews communication with broader audiences. You will learn how work with the media, be interviewed, conduct an interview, and write about science for general audiences.",Writing in the Sciences
https://www.classcentral.com/course/independent-cartography-8812,"Once, only cartographers made maps. Today anyone can. Still, cartographers can teach people to make better maps, just as chefs can show people how to cook better meals. With coaching from experienced cartographers and practical, hands-on exercises using ArcGIS Pro, you'll become a smarter mapmaker, ready to go beyond the defaults and make better maps.



Section 1
Getting Started: Let's Get Mapping
Consider the value and purpose of cartography as science and art. Get set up with ArcGIS Pro, ArcGIS Online, and exercise data. Use ArcGIS Pro to design a small-format, multiscale topographic map, using generalization tools and scale-dependent symbology. Use layouts for composition. Add contextual detail, insets, legends, and marginalia.
Section 2
Math for Mapmakers
Explore how coordinate systems, transformations, and projections affect your map's message. Deal with the effects of projections and data classification methods on thematic maps. Design and publish a custom basemap in a nonstandard projection to support thematic data. Build attribute-driven symbology. Publish a multiscale web map and app.
Section 3
Language of Graphics
See how generalization, symbology, and color affect your story. Explore generalization techniques that reduce feature complexity for smaller-scale displays. Create a variety of thematic maps, including choropleth, proportional symbol, value-by alpha, and multivariate maps. Change symbology and use transparency in creative ways.
Section 4
Labels and Composition
Learn a little about typography, label placement, and map composition. Set up a palette of label styles for different features and explore options for positioning them around other map details. Create a layout that includes a range of marginalia. Use ArcGIS expressions to define labels in innovative ways.
Section 5
Mapping in 3D
Consider how to best use the z dimension to represent data for both reference and thematic maps. Use 3D symbology and develop a sense of when 3D adds value to your map. Build 3D web scenes and vary the way features are represented using attributes and dynamic symbology.
Section 6
Mapping Change
Use the time-aware and animation controls in ArcGIS Pro to design maps that show temporal change. Direct an animated movie to map change; add captions and dynamic overlay information; and publish in a range of popular, shareable formats. Create a display of small multiples for an infographic poster.",Cartography
https://www.classcentral.com/course/methodological-biological-foundations-9522,"The ""Introduction to Psychology as a Science 1 – Methodological and Biological Foundations"" course will close to new enrollments on August 2nd. Learners who are enrolled prior to this date will still have 180 days to complete and earn a certificate. 

This course deals with an Introduction to Psychology as a Science. Psychology is the study of behavior and the mind.  But all of us have tried to understand and predict behavior throughout our lives, first with our parents, then with our peers and teachers, and finally with our friends and co-workers.  The difference is that psychological scientists conduct research that discovers the facts about behavior and our minds, so its principles are based on science and not just on intuition and experience.  The course covers all areas of Psychology, discussing scientific findings relevant to each area.  The content of the course has received approval from ""Quality Matters"", an organization that evaluates on-line courses.  The learning outcomes are:  (1) Students will be able to recognize and describe major psychological principles, theories and perspectives;  (2) Students will be able to distinguish between different methods used by psychological scientists to study the different areas of psychology;  (3) Students will be able to describe the ""nature-nurture"" controversy across different areas of psychology;  (4) Students will know that the basic principles of psychology are based on sound research; and (5) Students will know how the nervous system and other biological systems are involved in understanding behavior and the mind.
      


            Read more",Introduction to Psychology as a Science 1 – Methodological and Biological Foundations
https://www.classcentral.com/course/advanced-r-7174,"This course covers advanced topics in R programming that are necessary for developing powerful, robust, and reusable data science tools. Topics covered include functional programming in R, robust error handling, object oriented programming, profiling and benchmarking, debugging, and proper design of functions. Upon completing this course you will be able to identify and abstract common data analysis tasks and to encapsulate them in user-facing functions. Because every data science environment encounters unique data challenges, there is always a need to develop custom software specific to your organization’s mission. You will also be able to define new data types in R and to develop a universe of functionality specific to those data types to enable cleaner execution of data science tasks and stronger reusability within a team.
      


          Welcome to Advanced R Programming
    -This course covers advanced topics in R programming that are necessary for developing powerful, robust, and reusable data science tools. Topics covered include functional programming in R, robust error handling, object oriented programming, profiling and benchmarking, debugging, and proper design of functions. Upon completing this course you will be able to identify and abstract common data analysis tasks and to encapsulate them in user-facing functions. Because every data science environment encounters unique data challenges, there is always a need to develop custom software specific to your organization’s mission. You will also be able to define new data types in R and to develop a universe of functionality specific to those data types to enable cleaner execution of data science tasks and stronger reusability within a team.

Functions
    -This module begins with control structures in R for controlling the logical flow of an R program. We then move on to functions, their role in R programming, and some guidelines for writing good functions.

Functions: Lesson Choices

Functional Programming
    -Functional programming is a key aspect of R and is one of R's differentiating factors as a data analysis language. Understanding the concepts of functional programming will help you to become a better data science software developer. In addition, we cover error and exception handling in R for writing robust code.

Functional Programming: Lesson Choices

Debugging and Profiling
    -Debugging tools are useful for analyzing your code when it exhibits unexpected behavior. We go through the various debugging tools in R and how they can be used to identify problems in code. Profiling tools allow you to see where your code spends its time and to optimize your code for maximum efficiency.

Object-Oriented Programming
    -Object oriented programming allows you to define custom data types or classes and a set of functions for handling that data type in a way that you define. R has a three different methods for implementing object oriented programming and we will cover them in this section.",Advanced R Programming
https://www.classcentral.com/course/social-media-analytics-introduction-6916,"Social media not only provides marketers with a means of communicating with their customers, but also a way to better understand their customers. Viewing consumers’ social media activity as the “voice of the consumer,” this session exposes learners to the analytic methods that can be used to convert social media data to marketing insights. In Introduction to Social Media Analytics, learners will be exposed to both the benefits and limitations of relying on social media data compared to traditional methods of marketing research. Partnering with a leading social media listening platform, this course provides learners with the foundational skills of social media listening including the creation of monitors and common social media metrics. Moving beyond social media listening, this course shows learners how social media data can be used to provide insights into market structure and consumers’ perceptions of the brand.  Learners will have the opportunity to assess data and discern how to ""listen"" to the data by watching video lectures and completing activities, practice quizzes, discussion boards, and peer assessments.
      


          Basics of Social Media Listening 
    -This module will address how to evaluate social media messaging and data.

Opinion Science and Dynamics 
    -This module will discuss how to evaluate and judge social media contributions.  You will be able to better determine what data is useful or not.

Crimson Hexagon Walkthrough 
    -*Faculty has gotten permission from Crimson Hexagon to partner up for this course.  This module will address how to apply aspects of social media monitoring to business decisions.

Applying Analytics to Social Media Activity  
    -This module will teach learners how to examine multiple social media metrics to monitor and identify deviations from typical social media activity.",Introduction to Social Media Analytics
https://www.classcentral.com/course/edx-logic-and-computational-thinking-8725,"Understanding how a computer ""thinks"" is one of the first steps to becoming an excellent computer programmer. A foundation in logic is crucial in developing this understanding. Mastering logic is more than learning a set of rules. It involves learning how to break problems into smaller chunks, figuring out how repeatable processes can save time and improve quality, and understanding how to organize problems into the right size.
In this course, you'll learn how to do all those things and use computers to make them easier. After all, logical tasks are what computers are best at doing!
This is not a programming course, but it will teach you how to approach critical thinking as both a lifestyle and an aide to better programming and testing.



1. Module 0: Introduction to the course
a. What this course is about
i. Analytic logic and its relation to computer science
ii. Critical thinking as both a lifestyle and aide to better programming and testing
iii. Note: This is not a programming course
b. Let's get started: critical thinking and logical reasoning
i. What does it mean to think critically?
ii. An overview of definition, induction, and deduction
iii. Computer programming and logical thinking
2. Module 1: Deduction and Induction
a. Deduction and deductive syllogisms
i. Validity and invalidity
ii. Argument forms
iii. Deductive arguments and computer code
iv. Exercises
b. Induction and inductive syllogisms
i. Inductive arguments and critical thinking
ii. Exercises
c. Assessment
3. Module 2: Deductive Reasoning and Categorical Logic
a. Focus on how to discipline thinking to write better programs
b. The categorical statement
c. The categorical syllogism
d. Venn diagrams
e. Application to computer code
f. Exercises
g. Assessment
4. Module 3: Inductive Reasoning and Software Testing: How to think critically
a. The logic of science
b. Looking for the cause (Mill's Methods)
c. Critical thinking and modern science
d. Applying critical thinking skills to software testing
e. Assessment
5. Final Exam",Logic and Computational Thinking
https://www.classcentral.com/course/edx-big-data-analysis-with-apache-spark-3026,"Organizations use their data to support and influence decisions and build data-intensive products and services, such as recommendation, prediction, and diagnostic systems. The collection of skills required by organizations to support these functions has been grouped under the term ‘data science’.
This statistics and data analysis course will attempt to articulate the expected output of data scientists and then teach students how to use PySpark (part of Spark) to deliver against these expectations. The course assignments include log mining, textual entity recognition, and collaborative filtering exercises that teach students how to manipulate data sets using parallel processing with PySpark.
This course covers advanced undergraduate-level material. It requires a programming background and experience with Python (or the ability to learn it quickly). All exercises will use PySpark (the Python API for Spark), and previous experience with Spark equivalent to Introduction to Apache Spark, is required.",Big Data Analysis with Apache Spark
https://www.classcentral.com/course/edx-principles-of-machine-learning-6511,"This course is part of the Microsoft Professional Program Certificate in Data Science and Microsoft Professional Program in Artificial Intelligence.
Machine learning uses computers to run predictive models that learn from existing data in order to forecast future behaviors, outcomes, and trends.
In this data science course, you will be given clear explanations of machine learning theory combined with practical scenarios and hands-on experience building, validating, and deploying machine learning models. You will learn how to build and derive insights from these models using R, Python, and Azure Machine Learning.



Explore classification  • Understand the operation of classifiers • Use logistic regression as a classifier • Understand the metrics used to evaluate classifiers • Lab: Classification with logistic regression taught using Azure Machine Learning Regression in machine learning • Understand the operation of regression models • Use linear regression for prediction and forecasting • Understand the metrics used to evaluate regression models • Lab: Predicting bike demand with linear regression taught using Azure Machine Learning How to improve supervised models  • Process for feature selection • Understand the problems of over-parameterization and the curse of dimensionality • Use regularization on over-parameterized models • Methods of dimensionality reduction Apply cross validation to estimating model performance • Lab: Improving diabetes patient classification using Azure Machine Learning • Lab: Improving bike demand forecasting using Azure Machine Learning Details on non-linear modeling  • Understand how and when to use common supervised machine learning models Applying ML models to diabetes patient classification • Applying ML models to bike demand forecasting Clustering • Understand the principles of unsupervised learning models • Correctly apply and evaluate k-means clustering models • Correctly apply and evaluate hieratical clustering model • Lab: Cluster models with AML, R and Python Recommender systems  • Understand the operation of recommenders • Understand how to evaluate recommenders • Know how to use alternative to collaborative filtering for recommendations • Lab: Creating and evaluating recommendations",Principles of Machine Learning
https://www.classcentral.com/course/linear-models-2-7476,"Welcome to the Advanced Linear Models for Data Science Class 2: Statistical Linear Models. This class is an introduction to least squares from a linear algebraic and mathematical perspective. Before beginning the class make sure that you have the following:

- A basic understanding of linear algebra and multivariate calculus.
- A basic understanding of statistics and regression models.
- At least a little familiarity with proof based mathematics.
- Basic knowledge of the R programming language.

After taking this course, students will have a firm foundation in a linear algebraic treatment of regression modeling. This will greatly augment applied data scientists' general understanding of regression models.
      


          Introduction and expected values
    -In this module, we cover the basics of the course as well as the prerequisites. We then cover the basics of expected values for multivariate vectors. We conclude with the moment properties of the ordinary least squares estimates. 

The multivariate normal distribution
    -In this module, we build up the multivariate and singular normal distribution by starting with iid normals.

Distributional results
    -In this module, we build the basic distributional results that we see in multivariable regression.

Residuals
    -In this module we will revisit residuals and consider their distributional results. We also consider the so-called PRESS residuals and show how they can be calculated without re-fitting the model.",Advanced Linear Models for Data Science 2: Statistical Linear Models
https://www.classcentral.com/course/gengalaxy-3473,"Learn to use the tools that are available from the Galaxy Project. This is the second course in the Genomic Big Data Science Specialization.
      


          Introduction
    -This week, we will present some of the research challenges that motivated the development of the Galaxy framework. We will then introduce Galaxy, describe what the Galaxy framework is, and look at different ways you can use it.

Galaxy 101
    -In this module and the following modules we will start to use Galaxy to perform different types of analysis. 

Working with sequence data
    -In this module we will be studying sequence data quality control as well as ChIP-Sequence Analysis with MACS.

RNA-seq & Running your own Galaxy
    -In these final modules, we'll take a look at working with sequence data and RNA-seq and at installing and running your own Galaxy.",Genomic Data Science with Galaxy
https://www.classcentral.com/course/data-science-ethics-9630,"What are the ethical considerations regarding the privacy and control of consumer information and big data, especially in the aftermath of recent large-scale data breaches?

This course provides a framework to analyze these concerns as you examine the ethical and privacy implications of collecting and managing big data. Explore the broader impact of the data science field on modern society and the principles of fairness, accountability and transparency as you gain a deeper understanding of the importance of a shared set of ethical values. You will examine the need for voluntary disclosure when leveraging metadata to inform basic algorithms and/or complex artificial intelligence systems while also learning best practices for responsible data management, understanding the significance of the Fair Information Practices Principles Act and the laws concerning the ""right to be forgotten.""

This course will help you answer questions such as who owns data, how do we value privacy, how to receive informed consent and what it means to be fair.

Data scientists and anyone beginning to use or expand their use of data will benefit from this course. No particular previous knowledge needed.
      


          What are Ethics?
    -Module 1 of this course establishes a basic foundation in the notion of simple utilitarian ethics we use for this course. The lecture material and the quiz questions are designed to get most people to come to an agreement about right and wrong, using the utilitarian framework taught here. If you bring your own moral sense to bear, or think hard about possible counter-arguments, it is likely that you can arrive at a different conclusion. But that discussion is not what this course is about. So resist that temptation, so that we can jointly lay a common foundation for the rest of this course.

History, Concept of Informed Consent
    -Early experiments on human subjects were by scientists intent on advancing medicine, to the benefit of all humanity, disregard for welfare of individual human subjects. Often these were performed by white scientists, on black subject. In this module we will talk about the laws that govern the Principle of Informed Consent. We will also discuss why informed consent doesn’t work well for retrospective studies, or for the customers of electronic businesses.

Data Ownership
    -Who owns data about you? We'll explore that question in this module. A few examples of personal data include copyrights for biographies; ownership of photos posted online, Yelp, Trip Advisor, public data capture, and data sale. We'll also explore the limits on recording and use of data. 

Privacy
    -Privacy is a basic human need. Privacy means the ability to control information about yourself, not necessarily the ability to hide things. We have seen the rise different value systems with regards to privacy. Kids today are more likely to share personal information on social media, for example. So while values are changing, this doesn’t remove the fundamental need to be able to control personal information. In this module we'll examine the relationship between the services we are provided and the data we provide in exchange: for example, the location for a cell phone. We'll also compare and contrast ""data"" against ""metadata"".

Anonymity
    -Certain transactions can be performed anonymously. But many cannot, including where there is physical delivery of product. Two examples related to anonymous transactions we'll look at are ""block chains"" and ""bitcoin"". We'll also look at some of the drawbacks that come with anonymity.

Data Validity
    -Data validity is not a new concern. All too often, we see the inappropriate use of Data Science methods leading to erroneous conclusions. This module points out common errors, in language suited for a student with limited exposure to statistics. We'll focus on the notion of representative sample: opinionated customers, for example, are not necessarily representative of all customers.

Algorithmic Fairness
    -What could be fairer than a data-driven analysis? Surely the dumb computer cannot harbor prejudice or stereotypes. While indeed the analysis technique may be completely neutral, given the assumptions, the model, the training data, and so forth, all of these boundary conditions are set by humans, who may reflect their biases in the analysis result, possibly without even intending to do so. Only recently have people begun to think about how algorithmic decisions can be unfair. Consider this article, published in the New York Times. This module discusses this cutting edge issue.

Societal Consequences
    -In Module 8, we consider societal consequences of Data Science that we should be concerned about even if there are no issues with fairness, validity, anonymity, privacy, ownership or human subjects research. These “systemic” concerns are often the hardest to address, yet just as important as other issues discussed before. For example, we consider ossification, or the tendency of algorithmic methods to learn and codify the current state of the world and thereby make it harder to change. Information asymmetry has long been exploited for the advantage of some, to the disadvantage of others. Information technology makes spread of information easier, and hence generally decreases asymmetry. However, Big Data sets and sophisticated analyses increase asymmetry in favor of those with ability to acquire/access. 

Code of Ethics
    -Finally, in Module 9, we tie all the issues we have considered together into a simple, two-point code of ethics for the practitioner.

Attributions
    -This module contains lists of attributions for the external audio-visual resources used throughout the course.",Data Science Ethics
https://www.classcentral.com/course/datacamp-introduction-to-r-7630,"In this introduction to R, you will master the basics of this beautiful open source language, including factors, lists and data frames. With the knowledge gained in this course, you will be ready to undertake your first very own data analysis. With over 2 million users worldwide R is rapidly becoming the leading programming language in statistics and data science. Every year, the number of R users grows by 40% and an increasing number of organizations are using it in their day-to-day activities. Leverage the power of R by completing this free R online course today!



          Chapter One: learn how to use the console as a calculator and how to assign variables
Chapter Two: Learn how to create vectors in R, name them, select elements from them and compare different vectors.
Chapter Three: Learn how to work with matrices in R
Chapter Four: Learn how to create, subset and compare matrices.
Chapter Five: See how to create a data frame, select interesting parts of a data frame and order a data frame according to certain variables
Chapter Six: This final chapter will teach you how to create, name and subset these lists",Introduction to R
https://www.classcentral.com/course/data-visualization-science-communication-14502,"This course is an introduction to 3D scientific data visualization, with an emphasis on science communication and cinematic design for appealing to broad audiences. You will develop visualization literacy, through being able to interpret/analyze (read) visualizations and create (write) your own visualizations.

By the end of this course, you will:
-Develop visualization literacy.
-Learn the practicality of working with spatial data.
-Understand what makes a scientific visualization meaningful.
-Learn how to create educational visualizations that maintain scientific accuracy.
-Understand what makes a scientific visualization cinematic.
-Learn how to create visualizations that appeal to broad audiences.
-Learn how to work with image-making software. (for those completing the Honors track)
      


          Course Orientation
    -You will become familiar with the course, your classmates, and our learning environment.

Week 1: Introduction
    -Week 1 is an introduction to the field of data visualization, as well as related fields like computational science and computer graphics. You will learn about different types of data visualization, and visualization best practices.

Week 2: Data
    -Week 2 is all about data - how are spatial data represented in a computer? How is it formatted? Where can you find it, and how do you work with it?

Week 3: Meaningful Communication
    -Week 3 is all about the human side of things. How do people learn? How do we perceive visual information? What makes certain methods of communication and education more effective? How do you find a story in a dataset, and how do you tell that story clearly and concisely?

Week 4: Cinematic Presentation
    -Week 4 is about presenting your visualization in an engaging way to broad audiences with techniques like camera design, lighting, compositing, digital cosmetics, and other tricks from Hollywood. You’ll also learn how to package your visualization with sound, titles, and credits, and you’ll learn how to distribute it to various types of audiences.

Conclusion
    -Congratulations on reaching the end of the course!",3D Data Visualization for Science Communication
https://www.classcentral.com/course/foundations-marketing-analytics-4370,"Who is this course for?  
This course is designed for students, business analysts, and data scientists who want to apply statistical knowledge and techniques to business contexts. For example, it may be suited to experienced statisticians, analysts, engineers who want to move more into a business role, in particular in marketing.

You will find this course exciting and rewarding if you already have a background in statistics, can use R or another programming language and are familiar with databases and data analysis techniques such as regression, classification, and clustering.
However, it contains a number of recitals and R Studio tutorials which will consolidate your competences, enable you to play more freely with data and explore new features and statistical functions in R.

Business Analytics, Big Data and Data Science are very hot topics today, and for good reasons. Companies are sitting on a treasure trove of data, but usually lack the skills and people to analyze and exploit that data efficiently. Those companies who develop the skills and hire the right people to analyze and exploit that data will have a clear competitive advantage.

It's especially true in one domain: marketing. About 90% of the data collected by companies today are related to customer actions and marketing activities.The domain of Marketing Analytics is absolutely huge, and may cover fancy topics such as text mining, social network analysis, sentiment analysis, real-time bidding, online campaign optimization, and so on.

But at the heart of marketing lie a few basic questions that often remain unanswered: (1) who are my customers, (2) which customers should I target and spend most of my marketing budget on, and (3) what's the future value of my customers so I can concentrate on those who will be worth the most to the company in the future.

That's exactly what this course will cover: segmentation is all about understanding your customers, scorings models are about targeting the right ones, and customer lifetime value is about anticipating their future value. These are the foundations of Marketing Analytics. And that's what you'll learn to do in this course.
      


            Read more
          



          Module 0 : Introduction to Foundation of Marketing Analytics
    -
In this short module, we will introduce the field of marketing analytics, and layout the structure of this course.

We will also take that opportunity to explore a retailing data set that we’ll be using throughout this course. We will setup the environment, load the data in R (we’ll be using the RStudio environment), and explore it using simple SQL statements.


Module 1 : Statistical segmentation
    -
In this module, you will learn the inner workings of statistical segmentation, how to compute statistical indicators about customers such as recency or frequency, and how to identify homogeneous groups of customers within a database.

We will alternate lectures and R tutorials, making sure that, by the end of this module, you will be able to apply every concept we will cover.


Module 2 : Managerial segmentation
    -
Statistical segmentation is an invaluable tool, especially to explore, summarize, or make a snapshot of an existing database of customers. But what most academics will fail to tell you is that this kind of segmentation is not the method of choice for many companies, and for good reasons.

In this module, you will learn to perform managerial segmentations, which are not built upon statistical techniques, but are an essential addition to your toolbox of marketing analyst.

You will also learn how to segment a database now, but also at any point in time in the past, and why it is useful to managers to do so.


Module 3 : Targeting and scoring models
    -
How can Target predict which of its customers are pregnant? How can a bank predict the likelihood you will default on their loan, or crash your car within the next five years, and price accordingly? And if your firm only has the budget to reach a few customers during a marketing campaign, who should it target to maximize profit?

The answer to all these questions is… by building a scoring model, and targeting your customers accordingly.

In this module, you will learn how to build a customer score, which in marketing usually combines two predictions in one : what is the likelihood that a customer will buy something, and if he does, how much will he buy for?


Module 4 : Customer lifetime value
    -In this module, you will learn how to use R to execute lifetime value analyses. You will learn to estimate what is called a transition matrix -which measures how customers transition from one segment to another- and use that information to make invaluable predictions about how a customer database is likely to evolve over the next few years, and how much money it should be worth.",Foundations of marketing analytics
https://www.classcentral.com/course/edx-chinese-thought-ancient-wisdom-meets-modern-science-part-2-3709,"This course is designed to give students a thorough introduction to early (pre-221 BCE) Chinese thought, its contemporary implications, and the role of religion in human well-being. Important themes to be discussed include the ideal of wu-wei or “effortless action,” the paradox of how one can consciously try not to try, mindfulness techniques and self-cultivation, models of the self and society, rationality versus emotions, trust and human cooperation, and the structure and impact of different spiritual and political ideals.
This period of Chinese history witnessed the formation of all of the major indigenous schools of Chinese thought (Confucianism, Daoism, Mohism and Legalism), which in turn had an impact on the development of East Asian cultural history that is still felt today. We will also explore parallels with Western philosophical and religious traditions, the relevance of early Chinese thought for contemporary debates in ethics, moral education, and political philosophy, and the manner in which early Chinese models of the self anticipate recent developments in the evolutionary and cognitive sciences.
This course provides a full university semester’s worth of material broken into two parts. Each part of the course will last five weeks with a week-long break in between. For each part, there will be four weeks worth of new material. The fifth week will be reserved for review and completion of the final exam.
Part 2 builds upon Part 1 by exploring late Warring States thinkers such as the Confucian Mencius, the Daoist Zhuangzi, and the return to externalism in the form of Xunzi—who believed Mencius betrayed the original Confucian vision—and his former student Hanfeizi, a “Legalist” thinker who helped lay the foundations for the autocratic system that unified the Warring States into China’s first empire. We will conclude with some reflections on what it means to study religious thought, and the thought of other cultures, in a modern, globalized world. Part 2 can be taken as a stand-alone course, but will be more comprehensible and rewarding with the background provided in Part 1.
See also: Chinese Thought: Ancient Wisdom Meets Modern Science - Part 1



            Read more",Chinese Thought: Ancient Wisdom Meets Modern Science - Part 2
https://www.classcentral.com/course/logical-and-critical-thinking-3715,"##
We are constantly being given reasons to do and believe things: to believe that we should buy a product, support a cause, accept a job, judge someone innocent or guilty, that fairness requires us to do some household chore, and so on.  Assessing the reasons we are given to do or believe these things calls upon us to think critically and logically.
Improve your logical and critical thinking skills
Even though we’re called upon to use our critical and logical thinking skills all the time, most of us are not that good at it. This free online course aims to help you develop and improve these skills.
You’ll learn how to:

identify and avoid common thinking mistakes that lead to the formation of bad beliefs;
recognise, reconstruct and evaluate arguments;
use basic logical tools to analyse arguments;
and apply those tools in areas including science, moral theories and law.

Associate Professor Tim Dare and Dr Patrick Girard from the University of Auckland take us on an informative and engaging eight week journey through the worlds of logical and critical thinking helping us to avoid these common obstacles and fallacies and improve our logical and critical thinking skills.
Throughout the course, Tim and Patrick provide videos, articles, and assignments to lead us through the thickets of logical and critical thinking.
We will spend the first half of the course exploring key concepts in logical and critical thinking. In the second half of the course, we will apply those concepts in familiar areas, to help you develop practical and useful logical and critical thinking skills.
We begin, in the first week, with an introduction to logical and critical thinking and common obstacles and fallacies.
In week two Patrick introduces arguments.  We learn to identify premises and conclusions – components of a good argument – and by the end of this week we’ll be able to construct an argument in standard form.
In week three we will learn how to distinguish between deductive and non-deductive arguments and about validity, invalidity, strength and weakness.
In week four we examine good and bad arguments in more detail, learning how to tell when an argument is sound or cogent, and how to evaluate an argument.
Weeks five to seven examine three familiar areas – science, law, and morality – that call upon our logical and critical thinking skills in ways appropriate to the particular demands of those areas.
Finally in week eight we will apply the lessons of the course to an argument “in the wild”, seeing how the skills we have developed over our eight-week journey can be used in our own lives.
By the end of the course, you will have acquired the basic skills to assess arguments logically and critically, and so to be in a better situation to own the reasons for your beliefs.
You can find out more in Patrick’s post for the FutureLearn blog: “What can the New Zealand flag teach us about logical and critical thinking?”
This course is open to anyone with an interest in improving their logical and critical thinking skills. No previous knowledge or experience is required.



            Read more",Logical and Critical Thinking
https://www.classcentral.com/course/r-packages-7175,"Writing good code for data science is only part of the job. In order to maximizing the usefulness and reusability of data science software, code must be organized and distributed in a manner that adheres to community-based standards and provides a good user experience. This course covers the primary means by which R software is organized and distributed to others. We cover R package development, writing good documentation and vignettes, writing robust software, cross-platform development, continuous integration tools, and distributing packages via CRAN and GitHub. Learners will produce R packages that satisfy the criteria for submission to CRAN.
      


          Getting Started with R Packages

Documentation and Testing

Licensing, Version Control, and Software Design

Continuous Integration and Cross Platform Development",Building R Packages
https://www.classcentral.com/course/computational-social-science-methods-17299,"This course gives you an overview of the current opportunities and the omnipresent reach of computational social science. The results are all around us, every day, reaching from the services provided by the world’s most valuable companies, over the hidden influence of governmental agencies, to the power of social and political movements. All of them study human behavior in order to shape it. In short, all of them do social science by computational means.

In this course we answer three questions:
I.    Why Computational Social Science (CSS) now? 
II.    What does CSS cover?
III.    What are examples of CSS?

In this last part, we take a bird’s-eye view on four main applications of CSS. First, Prof. Blumenstock from UC Berkeley discusses how we can gain insights by studying the massive digital footprint left behind today’s social interactions, especially to foster international development. Second, Prof. Shelton from UC Riverside introduces us to the world of machine learning, including the basic concepts behind this current driver of much of today's computational landscape. Prof. Fowler, from UC San Diego introduces us to the power of social networks, and finally, Prof. Smaldino, from UC Merced, explains how computer simulation help us to untangle some of the mysteries of social emergence.
      


          Computational Social Science (CSS)
    -In this module, you will be able to examine the history and current challenges faced by social science through the digital revolution. You will be able to discuss the mystery at the core of society: social emergence. You will be able to recall the fundamental building blocks of the scientific method and how they apply to the new computational tools we now have available. You will be able to defend what people mean when they say that ‘social studies’ are currently maturing to become a ‘real science’.

Example of Computational Social Science: Data Science
    -In this module, you will be presented with an example of how computational social science is applied in the real world through a case study. You will be able to discuss examples of digital footprint and describe how computational social science is applied. You will practice an activity and be able to configure a machine to create a database that can later be used for analysis.

Examples of CSS: Machine Learning & AI
    -In this module, you will be able to discover how artificial intelligence can convert news stories into a real-time observatory of global unrest and potential terror attacks, and how brain scans can be used to reveal aspects of your moral values. You will be able to practice interacting with artificial intelligence that can interpret your art skills.

Examples of CSS: Social Networks and Computer Simulations
    -In this module, you will be able to discover how social networks and human dynamics create systems that are larger than you and me: social systems. You will be able to discuss how social networks and human dynamics follow recognizable patterns. You will be able to identify how social network analysis and computer simulations are currently quite successful in untangling some of the mysteries of social emergence.",Computational Social Science Methods
https://www.classcentral.com/course/how-computers-work-12188,"Computers are everywhere, they aren't just the desktops and laptops we use for work but the phones in our pockets and even the watches on our wrists are also computers. You probably use a computer every day and in fact you are reading this on a computer! 

Just because we use computers all the time, doesn't mean that we understand them, or find them easy to use. Computer Science is the science of computers, it is the field of knowledge that experts use to understand computer systems. Knowing a little computer science will help you understand the computers all around you. 

This isn't a how-to course for a particular piece of software, instead you will learn some fundamental concepts that you can apply to any software or computer system. You'll apply these concepts to the kind of computer systems we use every day, including word processing applications, e-commerce, the internet and web sites. You will learn how to apply computer science concepts to solve problems in daily computer use and generally be a better computer user. 

Taking this course could be the start of your career in computer science, and the course is an introduction to the Bachelors in Computer Science from University of London, but it is also for you if you just want to learn a little computer science to help you better understand the computers you use in your ordinary life.
      


          Abstraction
    -This week starts your journey into understanding computer science. You will think about how computer science can help you understand the technology you use every day and you will also learn one of the most important concepts in computer science: abstraction. 

State, modularity and applications
    -In this week you will learn about the computer science concepts of state and modularity and how they can help you understand the computer applications that you use every day. 

Networks
    -This week you will learn about how computers communicate with each other over networks, including the internet. You will also learn about some of the security threats that the internet entails and how they can be avoided.  

How the web works
    -In this week you will apply all of the computer science concepts you have learned in this course to understanding how modern websites work.",How Computers Work
https://www.classcentral.com/course/data-structures-optimizing-performance-4203,"How do Java programs deal with vast quantities of data? Many of the data structures and algorithms that work with introductory toy examples break when applications process real, large data sets.  Efficiency is critical, but how do we achieve it, and how do we even measure it?

This is an intermediate Java course. We recommend this course to learners who have previous experience in software development or a background in computer science, and in particular, we recommend that you have taken the first course in this specialization (which also requires some previous experience with Java).  

In this course, you will use and analyze data structures that are used in industry-level applications, such as linked lists, trees, and hashtables.  You will explain how these data structures make programs more efficient and flexible.  You will apply asymptotic Big-O analysis to describe the performance of algorithms and evaluate which strategy to use for efficient data retrieval, addition of new data, deletion of elements, and/or memory usage.

The program you will build throughout this course allows its user to manage, manipulate and reason about large sets of textual data.  This is an intermediate Java course, and we will build on your prior knowledge.  This course is designed around  the same video series as in our first course in this specialization, including explanations of core content, learner videos, student and engineer testimonials, and support videos -- to better allow you to choose your own path through the course!
      


            Read more
          



          Introduction to the Course
    -Welcome to the first module in the second course of our Intermediate Java Programming Specialization.  We'll start with introductions again: to ourselves, the Google engineers, and the structure of the course.  After the introduction we'll have a short warm up to get you comfortable with the code you will be building on to this class.  But don't worry--no graded programming assignments yet.  This week is all about getting comfortable and excited to learn.

Working with Strings
    -This week we're going to dive into the course programming project.  In the first lesson you'll learn about Strings and Regular Expressions, and in the programming assignment this week you'll apply that knowledge to adding functionality to your text editor so that it can measure the ""readability"" of text by calculating something called the ""Flesch Readability Score"".  This course is focused on building code that not only does interesting things, but also finishes them quickly.  So, let's get started building some code!

Efficiency Analysis and Benchmarking
    -Welcome to week 3!  The text-editor application you worked with last week does something, but it doesn't do it particularly fast.  This week we'll start talking about efficiency.  We'll introduce the concept of ""Big-O"" notation, which sounds a little silly, but is really a powerful (and extremely common) way of analyzing a program's efficiency, independent of the system that it's running on and the exact details of how it's implemented.  Then we'll go the other direction and dive into the details, talking about how to measure the actual running time of a piece of code to get an idea of how it really performs in practice. 

Interfaces, Linked Lists vs. Arrays, and Correctness
    -This week we'll start talking about some of the basic concepts that one expects to find in a data structures course: the idea of data abstraction, and a data structure called a Linked List.  Even though Linked Lists are not very efficient structures (for the most part), they do hit home the idea of ""linking"" pieces of data together in your computer's memory, rather than storing the data in one contiguous region.  This linking idea will be central to many of the more advanced data structures, namely trees and graphs, that are coming up later in this course and in the next course in this specialization.  In this module you'll also learn tools and procedures for unit testing your code, which is a way to make sure that what you've written is correct, and a staple practice of any sophisticated software developer.

Trees! (including Binary Search Trees and Tries)
    -Welcome to week 4!  We know you've been working hard.  We hope you tried that optional Markov Text Generation programming assignment last week, but if not, no worries.  You can always go back and do it later (spoiler alert: it's pretty amazing that such a simple algorithm can produce such realistic text).  This week there's more fun (and hard work) as we learn about trees.  Trees rely on the same linked structure idea as Linked Lists, only they're MUCH faster (usually...).  In the project this week you'll add auto-complete to your text editor.  Believe us when we say it's so cool when you get it working!  You'll see... and we bet you can't wait for the programming assignment now.  :)

Hash Maps and Edit Distance
    -You made it to the last week!  Congratulations on getting this far!  In this last week we'll be looking at a fundamental data structure called a Hash Table.  If you thought trees were fast, just wait until you see what Hash Tables can do!   Your last programming assignment will add spelling correction suggestions to your text editor, and there's an optional assignment that builds on the same ideas as the main assignment too, if you have the time and energy.",Data Structures and Performance
https://www.classcentral.com/course/big-data-integration-processing-6467,"At the end of the course, you will be able to:

*Retrieve data from example database and big data management systems 
*Describe the connections between data management operations and the big data processing patterns needed to utilize them in large-scale analytical applications
*Identify when a big data problem needs data integration
*Execute simple big data integration and processing on Hadoop and Spark platforms

This course is for those new to data science.  Completion of Intro to Big Data is recommended.  No prior programming experience is needed, although the ability to install applications and utilize a virtual machine is necessary to complete the hands-on assignments.  Refer to the specialization technical requirements for complete hardware and software specifications.

Hardware Requirements: 
(A) Quad Core Processor (VT-x or AMD-V support recommended), 64-bit; (B) 8 GB RAM; (C) 20 GB disk free. How to find your hardware information: (Windows): Open System by clicking the Start button, right-clicking Computer, and then clicking Properties; (Mac): Open Overview by clicking on the Apple menu and clicking “About This Mac.” Most computers with 8 GB RAM purchased in the last 3 years will meet the minimum requirements.You will need a high speed internet connection because you will be downloading files up to 4 Gb in size. 

Software Requirements: 
This course relies on several open-source software tools, including Apache Hadoop. All required software can be downloaded and installed free of charge (except for data charges from your internet provider). Software requirements include: Windows 7+, Mac OS X 10.10+, Ubuntu 14.04+ or CentOS 6+ VirtualBox 5+.
      


            Read more
          



          Welcome to Big Data Integration and Processing
    -Welcome to the third course in the Big Data Specialization. This week you will be introduced to basic concepts in big data integration and processing. You will be guided through installing the Cloudera VM, downloading the data sets to be used for this course, and learning how to run the Jupyter server. 

Retrieving Big Data (Part 1)
    -This module covers the various aspects of data retrieval and relational querying. You will also be introduced to the Postgres database. 

Retrieving Big Data (Part 2)
    -This module covers the various aspects of data retrieval for NoSQL data, as well as data aggregation and working with data frames. You will be introduced to MongoDB and Aerospike, and you will learn how to use Pandas to retrieve data from them.

Big Data Integration
    -In this module you will be introduced to data integration tools including Splunk and Datameer, and you will gain some practical insight into how information integration processes are carried out. 

Processing Big Data
    -This module introduces Learners to big data pipelines and workflows as well as processing and analysis of big data using Apache Spark. 

Big Data Analytics using Spark
    -In this module, you will go deeper into big data processing by learning the inner workings of the Spark Core. You will be introduced to two key tools in the Spark toolkit: Spark MLlib and GraphX. 

Learn By Doing: Putting MongoDB and Spark to Work
    -In this module you will get some practical hands-on experience applying what you learned about Spark and MongoDB to analyze Twitter data.",Big Data Integration and Processing
https://www.classcentral.com/course/edx-introduction-to-linear-models-and-matrix-algebra-2963,"Matrix Algebra underlies many of the current tools for experimental design and the analysis of high-dimensional data. In this introductory online course in data analysis, we will use matrix algebra to represent the linear models that commonly used to model differences between experimental units. We perform statistical inference on these differences. Throughout the course we will use the R programming language to perform matrix operations.
Given the diversity in educational background of our students we have divided the series into seven parts. You can take the entire series or individual courses that interest you. If you are a statistician you should consider skipping the first two or three courses, similarly, if you are biologists you should consider skipping some of the introductory biology lectures. Note that the statistics and programming aspects of the class ramp up in difficulty relatively quickly across the first three courses. You will need to know some basic stats for this course. By the third course will be teaching advanced statistical concepts such as hierarchical models and by the fourth advanced software engineering skills, such as parallel computing and reproducible research concepts.
These courses make up 2 XSeries and are self-paced:
PH525.1x: Statistics and R for the Life Sciences
PH525.2x: Introduction to Linear Models and Matrix Algebra
PH525.3x: Statistical Inference and Modeling for High-throughput Experiments
PH525.4x: High-Dimensional Data Analysis
PH525.5x: Introduction to Bioconductor: annotation and analysis of genomes and genomic assays 
PH525.6x: High-performance computing for reproducible genomics
PH525.7x: Case studies in functional genomics
This class was supported in part by NIH grant R25GM114818.



            Read more",Introduction to Linear Models and Matrix Algebra
https://www.classcentral.com/course/science-healthcare-delivery-8862,"The Mayo Clinic and Arizona State University Alliance for Health Care has developed innovative Science of Health Care Delivery training programs which introduce scientific approaches to quality improvement for patient care and population health, while also examining ways to reduce health costs. The full training, which explores key concepts in the Science of Health Care Delivery and why it is critically important to future patient care, can be used by health care professionals or as curriculum for aspiring care providers.

By the end of this introductory course, learners will recognize the how education in the Science of Health Care Delivery can improve and enhance the quality of provider care, health care systems and patient health. The overview course consists of a multimedia introduction to Science of Health Care Delivery domains, followed by video segments where learners meet a patient and caregivers who embody or apply new knowledge, skills and attitudes learned from the Science of Health Care Delivery. An expert reflection after each video presentation reinforces the domain’s concepts. Learners can seek more information into this dynamic field with the additional resources provided at the end of the course.
      


          The Science of Health Care Delivery: Transformation of Health Care Delivery Through Education & Research",The Science of Health Care Delivery
https://www.classcentral.com/course/relativism-13660,"Relativism is an ancient philosophical doctrine which has recurred time and again in the history of philosophy. It has also transcended the boundaries of that discipline, for it has shaped much of the methodology in anthropology and sociology, as well as in critical theory and literary studies. While often advocated for its supposed tolerance of differences, relativism has profound consequences for how we think of reality, for the possibility of knowledge, both in the factual and in the moral domain, and may engender the practice of double standard. 

If a wind is hot for me and cold for you and none of us is at fault, does this mean that reality is always perspectival, or that it admits of contradictory descriptions? If a belief turns out to be justified when evaluated within a certain epistemic system (such as religion, for instance), while it turns out to be unjustified if assessed from within a different one (science, say), does relativism undermine the very possibility of knowledge? If an action can be morally permissible within an ethical system and not so within a different one, does that challenge the idea that there are moral truths and moral progress? These are some of the questions we will engage in during the course, while considering examples taken from the history of science, such as the Bellarmine-Galileo dispute, and from everyday life.

This course is aimed at anyone who is interested in learning more about philosophy, along with those who are looking for strategies to combat extremism in their communities. Using these approaches, no matter what your skill levels in topics you would like to master, you can change your thinking and change your life.

In this course, learners will:

Explore the concept of Relativism
Discuss the role of Relativism in contemporary society
Identify common responses to Relativism
Compare/Contrast various forms of Relativism 
Recognize how epistemic relativism can be used to explain important events in the history of science and crucial discoveries in anthropology
Create a presentation with your personal perspective on one of the forms of relativism
      


            Read more
          



          Module 1
    -Welcome to Module 1: Introduction to Relativism. In this module, we will explore how current issues in public debate (climate change denial, fake news, vaccine skepticism, religious and political extremism) trade on relativism, and how relativism may be thought of as being a source of good by promoting pluralism and tolerance. We will begin by defining Relativism, and review the various forms, including faultless disagreement, relativism of difference, and local vs. global Relativism.


Module 2
    -Welcome to Module 2: Alethic Relativism. This week we will explore the structure of alethic relativism in Protagoras’ philosophy, examine the structure of contemporary alethic relativism, and identify the main objections to both forms of alethic relativism.

Module 3
    -Welcome to Module 3: Epistemic Relativism. In this module we will explore the structure of epistemic relativism and identify how epistemic relativism can be used to explain important events in the history of science and crucial discoveries in anthropology. We will also review the main objections to epistemic relativism and examine how the data provided by the history of science and anthropology could be understood without appealing to epistemic relativism.


Module 4
    -Welcome to Module 4: Moral Relativism. In this module we will explore the structure and framework of ethical relativism and review alethic relativism and relativism of distance as applied to ethics. We will identify the main objections to these forms of ethical relativism and recognize the difficulty of formulating a coherent relativist proposal. Finally, course participants are asked to apply their understanding of one of the forms of relativism and create a presentation to share their personal perspective.",Relativism
https://www.classcentral.com/course/normal-abnormal-behavior-9523,"The ""Introduction to Psychology as a Science 3 – Normal and Abnormal Behavior"" course will close to new enrollments on August 2nd. Learners who are enrolled prior to this date will still have 180 days to complete and earn a certificate. 

This course deals with complex normal and abnormal behavior patterns ad determined by Psychology as a Science. Psychology is the study of behavior and the mind.  But all of us have tried to understand and predict behavior throughout our lives, first with our parents, then with our peers and teachers, and finally with our friends and co-workers.  The difference is that psychological scientists conduct research that discovers the facts about behavior and our minds, so its principles are based on science and not just on intuition and experience.  The course covers personality psychology, social psychology, and abnormal psychology.  The content of the course has received approval from ""Quality Matters"", an organization that evaluates on-line courses.  The learning outcomes are:  (1) Students will be able to recognize and describe major psychological theories of personality and how personality is measured;  (2) Students will understand how behavior and our cognition is shaped by being with other people; and, (4) Students will be able to distinguish between different psychological disorders and be able to describe how they are both diagnosed and treated.",Introduction to Psychology as a Science 3 – Normal and Abnormal Behavior
https://www.classcentral.com/course/qualitative-methods-4176,"In this course you will be introduced to the basic ideas behind the qualitative research in social science. You will learn about data collection, description, analysis and interpretation in qualitative research. Qualitative research often involves an iterative process. We will focus on the ingredients required for this process: data collection and analysis.
You won't learn how to use qualitative methods by just watching video's, so we put much stress on collecting data through observation and interviewing and on analysing and interpreting the collected data in other assignments.
Obviously, the most important concepts in qualitative research will be discussed, just as we will discuss quality criteria, good practices, ethics, writing some methods of analysis, and mixing methods.
We hope to take away some prejudice, and enthuse many students for qualitative research.
      


          Philosophy of Qualitative Research
    -Welcome to the first week of the course. We start with an introduction, followed by two lessons on the  Philosophy of Qualitative Research.

Observation
    -In the first module we discussed the philosophy of qualitative research, explaining some basic notions and general philosophical approaches. In this second module we'll discuss observation as an important method within qualitative research. What types of observation are there? How do we observe? And how do we analyse and describe our data? 

Good Practices & Criteria
    -What makes qualitative research 'good' is a rather difficult question. Different criteria are suggested, but within the field of qualitative research there is not much agreement on these criteria. However, there is quite some agreement on what good practices of qualitative research are. In this module we will start in lesson 1 with a  discussion of  good practices of qualitative research.

Qualitative Interviewing
    -In this module we'll look at what a qualitative interview entails by trying to define it and by discussing different forms of interviewing behaviour. 

Qualitative Analysis
    -In previous modules we discussed how you should observe a social situation or conduct a qualitative interview. Now we will focus on what to do with your data, by discussing qualitative analysis. In this module you will try to do a qualitative analysis by interpreting your observed data and try to code it. 

Writing, mixing & ethics
    -In this module I will discuss ideas on writing in qualitative research, I will discuss mixing methods  and talk about the ethical issues you should consider. 

Catch up week
    -In this module there's no new material. The only requirement in this module is that you finish up the final peer review assignment.

Exam week
    -This is the final module, where you can apply everything you've learned up until now in the final exam. Please note that you can only take the final exam once every day, so make sure you are fully prepared to take the test. Please follow the honor code and do not communicate or confer with others taking this exam. Good luck! Once you've taken the exam, please consider doing the other courses in our specialisation track. I hope it was an enjoyable experience. If it was, please consider joining in with the Massive Open Online Research by my colleague Christian Bröer. Thanks for all your hard work, feedback and interpretations, the course team and your fellow learners really appreciate it!",Qualitative Research Methods
https://www.classcentral.com/course/industrial-iot-project-planning-machine--12284,"This course can also be taken for academic credit as ECEA 5386, part of CU Boulder’s Master of Science in Electrical Engineering degree.

This is part 2 of the specialization. In this course students will learn :
  * How to staff, plan and execute a project
  * How to build a bill of materials for a product
  * How to calibrate sensors and validate sensor measurements
  * How hard drives and solid state drives operate
  * How basic file systems operate, and types of file systems used to store big data
  * How machine learning algorithms work - a basic introduction
  * Why we want to study big data and how to prepare data for machine learning algorithms
      


          Project Planning and Staffing
    -In this module I share with you my experience in product planning, staffing and execution. You will perform a product tear down, write a paper about your tear down and build a bill of materials (BOM) for that product.

Sensors and File Systems
    -In this module you will learn about sensors, and in this case, a temperature sensor. You will learn how to calibrate and then validate that a temperature sensor is producing accurate results. We will study how data is stored on hard drives and solid state drives. We will take a brief look at file systems used to store large data sets.

Machine Learning
    -In this module we look at machine learning (ML), what it is and how it works. We take a look at a couple supervised learning algorithms and 1 unsupervised learning algorithm. No coding is required of you. Instead I provide working source code to you so you can play around with these algorithms. I wrap up by providing some examples of how ML can be used in the IIoT space.

Big Data Analytics
    -In this module you will learn about big data and why we want to study it. You will learn about issues that can arise with a data set and the importance of properly preparing data prior to a ML exercise.",Project Planning and Machine Learning
https://www.classcentral.com/course/qualitative-methods-4176,"In this course you will be introduced to the basic ideas behind the qualitative research in social science. You will learn about data collection, description, analysis and interpretation in qualitative research. Qualitative research often involves an iterative process. We will focus on the ingredients required for this process: data collection and analysis.
You won't learn how to use qualitative methods by just watching video's, so we put much stress on collecting data through observation and interviewing and on analysing and interpreting the collected data in other assignments.
Obviously, the most important concepts in qualitative research will be discussed, just as we will discuss quality criteria, good practices, ethics, writing some methods of analysis, and mixing methods.
We hope to take away some prejudice, and enthuse many students for qualitative research.
      


          Philosophy of Qualitative Research
    -Welcome to the first week of the course. We start with an introduction, followed by two lessons on the  Philosophy of Qualitative Research.

Observation
    -In the first module we discussed the philosophy of qualitative research, explaining some basic notions and general philosophical approaches. In this second module we'll discuss observation as an important method within qualitative research. What types of observation are there? How do we observe? And how do we analyse and describe our data? 

Good Practices & Criteria
    -What makes qualitative research 'good' is a rather difficult question. Different criteria are suggested, but within the field of qualitative research there is not much agreement on these criteria. However, there is quite some agreement on what good practices of qualitative research are. In this module we will start in lesson 1 with a  discussion of  good practices of qualitative research.

Qualitative Interviewing
    -In this module we'll look at what a qualitative interview entails by trying to define it and by discussing different forms of interviewing behaviour. 

Qualitative Analysis
    -In previous modules we discussed how you should observe a social situation or conduct a qualitative interview. Now we will focus on what to do with your data, by discussing qualitative analysis. In this module you will try to do a qualitative analysis by interpreting your observed data and try to code it. 

Writing, mixing & ethics
    -In this module I will discuss ideas on writing in qualitative research, I will discuss mixing methods  and talk about the ethical issues you should consider. 

Catch up week
    -In this module there's no new material. The only requirement in this module is that you finish up the final peer review assignment.

Exam week
    -This is the final module, where you can apply everything you've learned up until now in the final exam. Please note that you can only take the final exam once every day, so make sure you are fully prepared to take the test. Please follow the honor code and do not communicate or confer with others taking this exam. Good luck! Once you've taken the exam, please consider doing the other courses in our specialisation track. I hope it was an enjoyable experience. If it was, please consider joining in with the Massive Open Online Research by my colleague Christian Bröer. Thanks for all your hard work, feedback and interpretations, the course team and your fellow learners really appreciate it!",Qualitative Research Methods
https://www.classcentral.com/course/normal-abnormal-behavior-9523,"The ""Introduction to Psychology as a Science 3 – Normal and Abnormal Behavior"" course will close to new enrollments on August 2nd. Learners who are enrolled prior to this date will still have 180 days to complete and earn a certificate. 

This course deals with complex normal and abnormal behavior patterns ad determined by Psychology as a Science. Psychology is the study of behavior and the mind.  But all of us have tried to understand and predict behavior throughout our lives, first with our parents, then with our peers and teachers, and finally with our friends and co-workers.  The difference is that psychological scientists conduct research that discovers the facts about behavior and our minds, so its principles are based on science and not just on intuition and experience.  The course covers personality psychology, social psychology, and abnormal psychology.  The content of the course has received approval from ""Quality Matters"", an organization that evaluates on-line courses.  The learning outcomes are:  (1) Students will be able to recognize and describe major psychological theories of personality and how personality is measured;  (2) Students will understand how behavior and our cognition is shaped by being with other people; and, (4) Students will be able to distinguish between different psychological disorders and be able to describe how they are both diagnosed and treated.",Introduction to Psychology as a Science 3 – Normal and Abnormal Behavior
https://www.classcentral.com/course/edx-data-science-research-methods-python-edition-11606,"Data scientists are often trained in the analysis of data. However, the goal of data science is to produce a good understanding of some problem or idea and build useful models on this understanding. Because of the principle of ""garbage in, garbage out,"" it is vital thata data scientist know how to evaluate the quality of information that comes into a data analysis. This is especially the case when data are collected specifically for some analysis (e.g., a survey). 
In this course, you will learn the fundamentals of the research process--from developing a good question to designing good data collection strategies to putting results in context. Althougha data scientist may often play a key part in data analysis, the entire research process must work cohesively for valid insights to be gleaned. 
Developed as a powerful and flexible language used in everything from Data Science to cutting-edge and scalable Artificial Intelligence solutions, Python has become an essential tool for doing Data Science and Machine Learning. With this edition of Data Science Research Methods, all of the labs are done with Python, while the videos are language-agnostic. If you prefer your Data Science to be done with R, please see Data Science Research Methods: R Edition. 
edX offers financial assistance for learners who want to earn Verified Certificates but who may not be able to pay the fee. To apply for financial assistance, enroll in the course, then follow this link to complete an application for assistance.



            Read more
          




The Research Process
Planning for Analysis
Research Claims
Measurement
Correlational and Experimental Design

Note: This syllabus is preliminary and subject to change.",Data Science Research Methods: Python Edition
https://www.classcentral.com/course/neuroec-1387,"Economics, psychology, and neuroscience are converging today into a unified discipline of Neuroeconomics with the ultimate aim of creating a single, general theory of human decision-making. 

Neuroeconomics provides biologists, economists, psychologists and social scientists with a deeper understanding of how they make their own decisions and how others decide. Neuroscience, when allied with psychology and economics, creates powerful new models to explain why we make decisions. Neurobiological mechanisms of decision-making, decisions under risk, trust and cooperation will be central issues in this course. You will be provided with the most recent evidence from brain-imaging techniques (fMRI, TMS, etc.) and introduced to the explanatory models behind them.

The course does not require any prior study of economics and neuroscience; however, it might require you to study novel interdisciplinary materials. The course provides an introduction to the methodology, assumptions, and main findings of  Neuroeconomics. Our students have different backgrounds; therefore, I have adapted and simplified the course to allow all students to understand the interdisciplinary content. This course will help you to start your progress in the field of Neuroeconomics and to further develop your skills during other more advanced courses and trainings in the future. For some topics, the course will also provide supplementary videos to reveal the opinions of leading experts in the field. Each module provides optional reading material.

The course structure is as follows: During each video, you will have to answer some relevant questions. Your answers will not affect your final grade. At the end of each module, you must complete a quiz consisting of 15 questions. To pass the course, you must reach a satisfactory standard in all the course modules by completing all graded quizzes and the final exam. In addition to watching video lectures and taking quizzes, you will receive an invitation to join our forum. We plan to join the discussions in the forum on a weekly basis.

Welcome to Neuroeconomics World!

Do you have technical problems? Write to us: coursera@hse.ru
      


            Read more
          



           Introduction to the Course
    -Welcome to the new field of Neuroeconomics!

I hope you have an opportunity to reserve some time to explore the course content, course logic and our grading policy. The course consists of nine lectures covering main topics of Neuroeconomics. This class is completely self-paced: You can learn as fast as you like.The course does not require any prior study of economics and neuroscience; however, it might require you to study novel interdisciplinary materials. The course provides an introduction to the methodology, assumptions, and main findings of Neuroeconomics. Our students have different backgrounds; therefore, I have adapted and simplified the course to allow all students to understand the interdisciplinary content. This course will help you to start your progress in the field of Neuroeconomics and to further develop your skills during other more advanced courses and trainings in the future.Have a good time with this new field of science!

Best regards,
Vasily Klucharev

Introduction and Scope of Neuroeconomics
    -This lecture will provide an introduction to the course and a historical overview of the field and will explore major assumptions of Neuroeconomics. We'll discuss the need for Neuroeconomics and the limitations of the traditional fields of economics, psychology, and neuroscience. Can we predict decisions based on neural activity? Can we change human decisions using brain stimulation techniques? Does Neuroeconomics change views on free will and free decisions? This lecture will deal with these and other questions. Overall, I'll try to convince you that Neuroeconomics radically transforms the way we normally think about human behavior. Have a good time with a new field of science!

Neuroanatomy, Neurophysiology, and Neuroimaging: Tools of Neuroeconomics 
    -We will start with a short introduction to cognitive neuroscience, brain anatomy, and brain functions and continue with a discussion of various methods of measuring brain activity, including brain imaging methods (EEG, MEG, fMRI), transcranial brain stimulation (TMS), cell recording, and data visualization, and interpretation of the results. The main goal of this lecture is to help you read and understand results of Neuroeconomics papers. I will introduce terminology and experimental methods that we will use throughout the whole course.

Introducing Brain Models of Decision-Making and Choice 
    -Now we will start our journey in Neuroeconomic theories and findings. You will learn the main features of the Diffusion Model, the most popular theoretical model of decision-making in Neuroeconomics. We will apply this model to single-neuron activity in a monkey cortex and to the human brain in order to understand how brains program decisions. For advanced students, I recommend a guest lecture provided by Dr. Sebastian Horn (Max Planck Institute for Human Development, Berlin), who gives a more fundamental explanation of the drift diffusion model. Enjoy Neuroeconomics!

Neural Representation of Subjective Value
    -Why do we make decisions? Perhaps we do so to activate our neurons. During this lecture, we will discuss how neurons assign values to different options during the decision-making process. We will also discuss the central role of the nucleus accumbens and orbitofrontal cortex in the valuation process. To make adaptive decisions, we must evaluate the costs and benefits of available options. Neuroeconomics has set itself the ambitious goal of understanding the brain mechanisms that are responsible for these evaluative processes. Neuroeconomics has also focused on describing the neural signals related to learning the value of stimuli and actions. Overall, this lecture will present some key ideas of Neuroeconomics. 

Affective Mechanisms of Decision-Making 
    -The influence of emotions on decision-making is largely ignored in decision theories. Our objective in this lecture is to explore the role of emotion in decision-making and to introduce theories and basic findings of Neuroeconomics in this context. For example, the neuroeconomic studies of decision-making in neurological patients who can no longer process emotional information normally suggest that people make judgments based not only on evaluations of the values of options and probabilities of outcomes but often primarily on emotions.

Dual Process Theory of Decision-Making: Toward a Neuroeconomics Perspective
    -Studies in Neuroeconomics have found evidence suggesting that the brain may employ multiple levels of processing when making decisions, and this conclusion is consistent with dual-processing theories that have received extensive theoretical consideration in the field of cognitive psychology. During this lecture, we will discuss the classic and cutting-edge research studies supporting dual process theory. Additionally, I recommend you to attend the guest lecture provided by Dr. Samuel McClure (Arizona State University), who is a leading neuroeconomist investigating dual-process mechanisms.

Decision-Making under Risk: Toward a Neuroeconomics Mechanism
    -Many of our decisions involve uncertainty or imperfect knowledge about how our choices lead to outcomes. The important aspect of uncertainty most commonly considered by economists and neuroeconomists is risk, which refers to situations in which we know the probabilities of possible outcomes. For example, if you play roulette in Monte Carlo, you are making a decision under risk since you know the probability of winning and thus how much you should expect to lose. Here I will introduce a neuroeconomic approach to studying decisions under risk and an anticipatory affect model suggesting that the balance of activity in the set brain areas (insular cortex and nucleus accumbens) promotes either approach toward or avoidance of risk. Additionally, Dr. Brian Knutson (Stanford University) provides his comments on the functional role of the nucleus accumbens in a guest lecture.

The Social Brain: Games in the Brain
    -Ancient Greek philosophers observed that we are fundamentally a social species. Indeed, the human brain has evolved to deal with complex social interactions. Day by day, we collectively analyze problems or situations and evaluate alternative courses of action within social groups. Game theory has proven useful in the investigation of the neural basis of social interactions and social decision-making. In particular, researchers have investigated what happens in the brains of subjects involved in games where each player can choose between cooperative and non-cooperative behaviors or between altruistic and selfish behaviors. Here we will apply game theory to studying the neural mechanism of decisions to cooperate or to defect. I will also introduce the mirror neurons mechanism of social interaction.

 Evolutionary Perspective of Decision-Making 
    -Neuroeconomics investigates the origins of human decision-making by examining whether similar choice biases are seen in nonhuman primates, our closest phylogenetic relatives. Comparative studies can identify shared versus human-unique tendencies in decision-making. Here we will compare animal and human decision-making mechanisms. I will also introduce the theory of biological markets. At the beginning of the lecture, we will discuss the ontogenetic origin of human cooperation.

Final Exam
    -This is the final quiz. To pass, you must answer at least 24 out of 30 questions correctly. Good luck with your exams!",Introduction to Neuroeconomics: How the Brain Makes Decisions
https://www.classcentral.com/course/philosophy-science-religion-3-10623,"Philosophy, Science and Religion mark three of the most fundamental modes of thinking about the world and our place in it. Are these modes incompatible? Put another way: is the intellectually responsible thing to do to ‘pick sides’ and identify with one of these approaches at the exclusion of others? Or, are they complementary or mutually supportive? As is typical of questions of such magnitude, the devil is in the details. For example, it is important to work out what is really distinctive about each of these ways of inquiring about the world. In order to gain some clarity here, we’ll be investigating what some of the current leading thinkers in philosophy, science and religion are actually doing.

This course, entitled ‘Religion and Science’, is the third of three related courses in our Philosophy, Science and Religion Online series. The course will address five themes, each presented by an expert in the area. 

1. Science, Religion, and the Origin of the Universe (Professor Tim Maudlin, NYU )
2. Buddhism and Science (Professor Graham Priest, CUNY)
3. Evolution and Design (Dr Kevin Scharp, St Andrews)
4. Sin Suffering and Salvation: Evolutions Thorny Issues (Dr Bethany Sollereder, Oxford)
5. Human Uniqueness in Science, Theology, and Ethics (Professor David Clough, Chester)

The first and second courses in the Philosophy, Science and Religion series, 'Science and Philosophy' and 'Philosophy and Religion' were launched in 2017 and you can sign up to these at any time. It is not necessary to have completed these courses to follow this course. However, completing all three courses will give you a broader understanding of this fascinating topic. Look for: 

• Philosophy, Science and Religion I: Science and Philosophy - https://www.coursera.org/learn/philosophy-science-religion-1
• Philosophy, Science and Religion II: Philosophy and Religion - https://www.coursera.org/learn/philosophy-science-religion-2

Upon successful completion of all three courses, students will:

(1) Understand the main parameters at stake in the current debate between science and religion.
(2) Have some familiarity with the relevant areas of science that feature in the debate—including cosmology, evolution, and the neurosciences—and will have begun to engage with them conceptually.
(3) Have encountered key philosophical approaches to the interface between science and religion, and will have had the opportunity to engage them in practice.
(4) Have embarked constructively in cross-disciplinary conversations.
(5) Have demonstrated an openness to personal growth through a commitment to dialogue across intellectual and spiritual boundaries.

You can also follow us on Twitter at https://twitter.com/EdiPhilOnline and you can follow the hashtag #psrmooc
      


            Read more
          



          Introduction to the Course

Science, Religion and the Origins of the Universe
    -In this module Tim Maudlin, Professor of the Foundations of Physics at New York University (NYU) discusses stories and theories of the origins of the cosmos from the perspectives of various religions,  philosophy, and Science. He then explains what our physics tells us and compares this to the origins stories.

BUDDHISM AND SCIENCE
    -In this module Graham Priest, Distinguished Professor of Philosophy at City University of New York (CUNY) outlines the background and basic ideas of Buddhism. After considering whether Buddhism is compatible with science, he goes on to explain how some aspects of Buddhist thought are relevant to contemporary logic and science.

EVOLUTION AND DESIGN
    -In this module Kevin Scharp, Reader in Philosophy at the University of St Andrews introduces one of the most common arguments for Intelligent Design and considers whether it is a genuine scientific competitor to, or can even be made compatible with, evolutionary theory. He then presents the Fine-Tuning Argument for the existence of God and its criticisms.

SIN, SUFFERING AND SALVATION: EVOLUTION’S THORNY ISSUES
    -In this module Bethany Sollereder, Postdoctoral Fellow in Science and Religion at the University of Oxford considers questions that arise in Christian Theology as a result of accepting evolutionary theory.

HUMAN UNIQUENESS IN SCIENCE, THEOLOGY AND ETHICS
    -In this module David Clough, Professor of Theological Ethics at Chester University investigates three ways in which the question of human uniqueness prompt questions at the interface of theology and science. It asks ‘Are we alone in the Universe?’, ‘Where did we come from?’ and ‘Are we just animals?’ before going on to consider the ethical implications of a theological approach that engages these questions seriously.","Philosophy, Science and Religion: Religion and Science"
https://www.classcentral.com/course/edx-data-science-research-methods-r-edition-11640,"Data scientists are often trained in the analysis of data. However, the goal of data science is to produce good understanding of some problem or idea and build useful models on this understanding. Because of the principle of ""garbage in, garbage out,"" it is vital that the data scientist know how to evaluate the quality of information that comes into a data analysis. This is especially the case when data are collected specifically for some analysis (e.g., a survey). 
In this course, you will learn the fundamentals of the research process--from developing a good question to designing good data collection strategies to putting results in context. Although the data scientist may often play a key part in data analysis, the entire research process must work cohesively for valid insights to be gleaned. 
Developed as a language with statistical analysis and modeling in mind, R has become an essential tool for doing real-world Data Science. With this edition of Data Science Research Methods, all of the labs are done with R, while the videos are tool-agnostic. If you prefer your Data Science to be done with Python, please see Data Science Research Methods: Python Edition. 
edX offers financial assistance for learners who want to earn Verified Certificates but who may not be able to pay the fee. To apply for financial assistance, enroll in the course, then follow this link to complete an application for assistance.




The Research Process
Planning for Analysis
Research Claims
Measurement
Correlational and Experimental Design

Note: This syllabus is preliminary and subject to change.",Data Science Research Methods: R Edition
https://www.classcentral.com/course/statistics-1349,"The Coursera course, Data Analysis and Statistical Inference has 
been revised and is now offered as part of Coursera Specialization “Statistics with R”. This Specialization consists of 4 courses and a capstone project. The courses can be taken separately:Introduction to Probability and Data (began in April 2016)Inferential Statistics (begins in May 2016)Linear Regression and Modeling (begins in June 2016)Bayesian Statistics (begins in July 2016) A completely new course, with additional faculty!Statistics Capstone Project (August 2016) (for learners who have passed the 4 previous courses, and earned certificate)You
 may enroll in a single course, or all of them, but each requires the 
knowledge and techniques from the previous courses. The assignments in 
these courses have suggested but not required deadlines, so you can work
 at your own schedule. Please check the Specialization page for other 
answers to your questions, and peek at the first course. We hope to see you in our new courses. The Statistics with R team.___________________________________________________The goals of this course are as follows:Recognize the importance of data collection, identify limitations in data collection methods, and determine how they affect the scope of inference.Use statistical software (R) to summarize data numerically and visually, and to perform data analysis.Have a conceptual understanding of the unified nature of statistical inference.Apply estimation and testing methods (confidence intervals and hypothesis tests) to analyze single variables and the relationship between two variables in order to understand natural phenomena and make data-based decisions.Model and investigate relationships between two or more variables within a regression framework.Interpret results correctly, effectively, and in context without relying on statistical jargon.Critique data-based claims and evaluate data-based decisions.Complete a research project that employs simple statistical inference and modeling techniques.



            Read more
          



Week 1: Unit 1 - Introduction to dataPart 1 – Designing studiesPart 2 – Exploratory data analysisPart 3 – Introduction to inference via simulationWeek 2: Unit 2 - Probability and distributionsPart 1 – Defining probabilityPart 2 – Conditional probabilityPart 3 – Normal distributionPart 4 – Binomial distributionWeek 3: Unit 3 - Foundations for inferencePart 1 – Variability in estimates and the Central Limit TheoremPart 2 – Confidence intervalsPart 3 – Hypothesis testsWeek 4: Finish up Unit 3 + MidtermPart 4 – Inference for other estimatorsPart 5 - Decision errors, significance, and confidenceWeek 5: Unit 4 - Inference for numerical variablesPart 1 – t-inferencePart 2 – PowerPart 3 – Comparing three or more means (ANOVA)Part 4 – Simulation based inference for meansWeek 6: Unit 5 - Inference for categorical variablesPart 1 – Single proportionPart 2 – Comparing two proportionsPart 3 – Inference for proportions via simulationPart 4 – Comparing three or more proportions (Chi-square)Week 7: Unit 6 - Introduction to linear regressionPart 1 – Relationship between two numerical variablesPart 2 – Linear regression with a single predictorPart 3 – Outliers in linear regressionPart 4 – Inference for linear regressionWeek 8: Unit 7 - Multiple linear regressionPart 1 – Regression with multiple predictorsPart 2 – Inference for multiple linear regressionPart 3 – Model selectionPart 4 – Model diagnosticsWeek 9: Review / catch-up weekBayesian vs. frequentist inferenceWeek 10: Final exam",Data Analysis and Statistical Inference
https://www.classcentral.com/course/philosophy-science-religion-1-8024,"Philosophy, Science and Religion mark three of the most fundamental modes of thinking about the world and our place in it. Are these modes incompatible? Put another way: is the intellectually responsible thing to do to ‘pick sides’ and identify with one of these approaches at the exclusion of others? Or, are they complementary or mutually supportive? As is typical of questions of such magnitude, the devil is in the details. For example, it is important to work out what is really distinctive about each of these ways of inquiring about the world. In order to gain some clarity here, we’ll be investigating what some of the current leading thinkers in philosophy, science and religion are actually doing.

This course, entitled ‘Science and Philosophy’, is the first of three related courses in our Philosophy, Science and Religion Online series. The first launch is now closed to enrolments. We will launch a new version of the course in July 2018. The course will address four themes each presented by guest lecturers:

1. Are Science and Religion in conflict? (Professor Michael Murray, Franklin & Marshall)
2. Neuroscience and Free Will (Professor Al Mele, Florida State)
3. Creationism and Evolutionary Biology--Science or Pseudo-science? (Dr. Mark Harris and Dr. David de Pomerai, University of Edinburgh)
4. Do Scientific claims constitute absolute truths? (Professor Martin Kusch, University of Vienna)

The second and third courses in the Philosophy, Science and Religion series are ‘Philosophy and Religion’ and ‘Religion and Science’. They may be taken in any order and completing all three courses will give you a broader understanding of this fascinating topic. Look for: 

• Philosophy, Science and Religion II: Philosophy and Religion
• Philosophy, Science and Religion III: Religion and Science

Check out our trailer to hear more: https://youtu.be/OifqTI5VKek
You can also follow us on Twitter at https://twitter.com/EdiPhilOnline and you can follow the hashtag #psrmooc
      


            Read more
          



          Philosophy, Science and Religion: Introduction and Overview
    -In this module, Dr Orestis Palermos provides a short introduction and overview of the key themes that will be discussed in the ‘Science and Philosophy’ course. 

Neuroscience and Free Will
    -In this module Professor Al Mele presents experiments that purport to show that there is no such thing as free will. He then presents three criticisms of this interpretation of the evidence.

Are Science and Religion in Conflict?
    -Guest lecturer: Dr Michael Murray. Are science and religion compatible with one another? Are they incompatible? What do these questions even mean, and how do we go about answering them? Philosophical tools are helpful to make progress with these very important questions. In this module, Dr Michael Murray offers a philosophical analysis of the complex and easily misunderstood issue of the relationship between science and religion. 

Do Scientific Claims Constitute Absolute Truths?
    -Guest lecturer: Professor Martin Kusch. This module will focus on a central challenge for scientific knowledge: Are there any scientific claims that are absolutely true, or are they all true relative to the system of thought that generated them? If we accept the latter, does this also hold true of any claims we might make, including within the domains of philosophy and religion? 

Evolution and Creationism
    -This module starts with Dr. Mark Harris presenting the history of creationist views and what is claimed about evolution by different creationist approaches. Professor David de Pomerai then goes on to explain what evolutionary biology is.","Philosophy, Science and Religion: Science and Philosophy"
https://www.classcentral.com/course/edx-python-basics-for-data-science-12115,"Kickstart your learning of Python for data science, as well as programming in general with this introduction to Python course. This beginner-friendly Python course will quickly take you from zero to programming in Python in a matter of hours. 
Upon its completion, you'll be able to write your own Python scripts and perform basic hands-on data analysis using our Jupyter-based lab environment. If you want to learn Python from scratch, this course is for you. 
You can start creating your own data science projects and collaborating with other data scientists using IBM Watson Studio. When you sign up, you will receive free access to Watson Studio. Start now and take advantage of this platform and learn the basics of programming, machine learning and data visualization with this introductory course.



Module 1 - Python Basics
Your first program
Types
Expressions and Variables
String Operations 
Module 2 - Python Data Structures
Lists and Tuples
Sets
Dictionaries 
Module 3 - Python Programming Fundamentals
Conditions and Branching
Loops
Functions
Objects and Classes 
Module 4 - Working with Data in Python
Reading files with open
Writing files with open
Loading data with Pandas
Working with and Saving data with Pandas 
Module 5 - Working with Numpy Arrays
Numpy 1d Arrays
Numpy 2d Arrays",Python Basics for Data Science
https://www.classcentral.com/course/ai-for-everyone-12502,"AI is not only for engineers. If you want your organization to become better at using AI, this is the course to tell everyone--especially your non-technical colleagues--to take. 

In this course, you will learn:

- The meaning behind common AI terminology, including neural networks, machine learning, deep learning, and data science
- What AI realistically can--and cannot--do
- How to spot opportunities to apply AI to problems in your own organization
- What it feels like to build machine learning and data science projects
- How to work with an AI team and build an AI strategy in your company
- How to navigate ethical and societal discussions surrounding AI

Though this course is largely non-technical, engineers can also take this course to learn the business aspects of AI.
      


          What is AI?

Building AI Projects

Building AI In Your Company

AI and Society",AI For Everyone
https://www.classcentral.com/course/material-informatics-6534,"This course aims to provide a succinct overview of the emerging discipline of Materials Informatics at the intersection of materials science, computational science, and information science. Attention is drawn to specific opportunities afforded by this new field in accelerating materials development and deployment efforts. A particular emphasis is placed on materials exhibiting hierarchical internal structures spanning multiple length/structure scales and the impediments involved in establishing invertible process-structure-property (PSP) linkages for these materials. More specifically, it is argued that modern data sciences (including advanced statistics, dimensionality reduction, and formulation of metamodels) and innovative cyberinfrastructure tools (including integration platforms, databases, and customized tools for enhancement of collaborations among cross-disciplinary team members) are likely to play a critical and pivotal role in addressing the above challenges.
      


          Welcome
    -What you should know before you start the course

Accelerating Materials Development and Deployment 
    -•	Learn and appreciate historical paradigms of advanced materials development while emphasizing the critical need for new approaches that employ data sciences and informatics as the glue to connect computational simulation and experiments to speed up the processes of materials discovery and development.
•	Learn about the emergence of key national and international 21st century initiatives in accelerated materials discovery and development and how they are expected to bring about a disruptive transformation of new product capabilities and time to market.

Materials Knowledge and Materials Data Science 
    -•	Understand property, structure and process spaces
•	Learn about Process-Structure-Property Linkages 
•	Learn what does Materials Knowledge mean
•	Learn about a role of Data Science in Materials Knowledge System
•	Overview approaches and main components of Data Science
•	Learn about a new discipline - Materials Data Sciences

Materials Knowledge Improvement Cycles
    -•	Learn material structure and its digital representation
•	Learn how to calculate 2-point statistics 
•	Learn how Principal Component Analysis can be used to reduce dimensionality
•	Understand Homogenization and Localization concepts


Case Study in Homogenization: Plastic Properties of Two-Phase Composites
    -This module demonstrates a homogenization problem based on an example of two-phase composites

Materials Innovation Cyberinfrastructure and Integrated Workflows
    -•	Learn about materials innovation system and cyberinfrastructure
•	Review Materials Databases, e-collaboration platforms and code repositories
•	Learn why integrated workflows are needed
•	Define Metadata, Structured and Unstructured data
•	Learn about available services for e-collaborations",Materials Data Sciences and Informatics
https://www.classcentral.com/course/udacity-statistics-631,"NOTE: This course has been divided into two courses: Descriptive and Inferential Statistics. If you are new to statistics, we recommend taking these courses instead.We live in a time of unprecedented access to information...data.  Whether researching the best school, job, or relationship, the Internet has thrown open the doors to vast pools of data.  Statistics are simply objective and systematic methods for describing and interpreting information so that you may make the most informed decisions about life.Why Take This Course?The applications of statistics to everyday lifeMethods for acquiring data through observation and experimentationTo organize and describe quantitative and categorical forms of dataAnticipating patterns using basic probability and samplingStatistical inference through estimation and hypothesis testingCorrelation and simple regressionWays of describing the strength of relationships between variables



Module 1: Introduction to Statistics and MethodsLesson 1: Intro to statistical research methods Lesson 2: Frequency Distributions & Visualizing data Module 2: Describing DataLesson 3: Central Tendency Lesson 4: Variability Midterm 1  on Lessons 1-4 Module 3: Normal Distribution AnalysisLesson 5: Standardized Scores (z-scores) Lesson 6: Probability and the Normal Distribution Lesson 7: Sampling Distributions Module 4: Foundations of Inferential StatisticsLesson 8: Estimation Lesson 9: Hypothesis Testing Midterm 2  on Lessons 5-9 Module 5: Comparing MeansLesson 10-11: t-tests Lesson 12-13: One-way ANOVA Module 6: Correlation, Regression, and Non-ParametricsLesson 14: Correlation Lesson 15: RegressionLesson 16: Chi-Squared TestsFinal Exam on Lessons 10-16 (available soon)",Statistics
https://www.classcentral.com/course/udacity-introduction-to-artificial-intelligence-301,"Artificial Intelligence (AI) is a field that has a long history but is still constantly and actively growing and changing. In this course, you’ll learn the basics of modern AI as well as some of the representative applications of AI. Along the way, we also hope to excite you about the numerous applications and huge possibilities in the field of AI, which continues to expand human capability beyond our imagination. ***Note: Parts of this course are featured in the Machine Learning Engineer Nanodegree and the Data Analyst Nanodegree programs. If you are interested in AI, be sure to check out those programs as well!***Why Take This Course?Artificial Intelligence (AI) technology is increasingly prevalent in our everyday lives. It has uses in a variety of industries from gaming, journalism/media, to finance, as well as in the state-of-the-art research fields from robotics, medical diagnosis, and quantum science. In this course you’ll learn the basics and applications of AI, including: machine learning, probabilistic reasoning, robotics, computer vision, and natural language processing.



### Part I: Fundamentals of AI  - Overview of AI - Statistics, Uncertainty, and Bayes networks - Machine Learning - Logic and Planning - Markov Decision Processes and Reinforcement Learning - Hidden Markov Models and Filters - Adversarial and Advanced Planning  ### Part II: Applications of AI  - Image Processing and Computer Vision - Robotics and robot motion planning - Natural Language Processing and Information Retrieval",Introduction to Artificial Intelligence
https://www.classcentral.com/course/discrete-math-and-analyzing-social-graphs-17336,"The main goal of this course is to introduce topics in Discrete Mathematics relevant to Data Analysis.

We will start with a brief introduction to combinatorics, the branch of mathematics that studies how to count. Basics of this topic are critical for anyone working in Data Analysis or Computer Science. We will illustrate new knowledge, for example, by counting the number of features in data or by estimating the time required for a Python program to run.

Next, we will apply our knowledge in combinatorics to study basic Probability Theory. Probability is everywhere in Data Analysis and we will study it in much more details later. Our goals for probability section in this course will be to give initial flavor of this field.

Finally, we will study the combinatorial structure that is the most relevant for Data Analysis, namely graphs. Graphs can be found everywhere around us and we will provide you with numerous examples. We will mainly concentrate in this course on the graphs of social networks. We will provide you with relevant notions from the graph theory, illustrate them on the graphs of social networks and will study their basic properties. In the end of the course we will have a project related to social network graphs.

As prerequisites we assume only basic math (e.g., we expect you to know what is a square or how to add fractions), basic programming in Python (functions, loops, recursion), common sense and curiosity. Our intended audience are all people that work or plan to work in Data Analysis, starting from motivated high school students.
      


            Read more
          



          Basic Combinatorics
    -Suppose we need to count certain objects. Can we do anything better than just list all the objects? Do we need to create a list of all our data entries to check whether we have enough data to teach our ML model? Is there a way to tell whether our algorithm will run in a reasonable time before implementing and actually running it? All these questions are addressed by a mathematical field called Combinatorics. In this module we will give an introduction to this field that will help us to answer basic versions of the above questions.

Advanced Combinatorics
    -In the first week we have already considered most of the standard settings in Combinatorics, that allow us to address many counting problems. However, successful application of this knowledge on practice requires considerable experience in this kind of problems. The goal of this module is twofold. First, we study extensively more advanced combinatorial settings. We discuss in more details binomial coefficients. Also, we address one more standard setting, combinations with repetitions. The second gaol of the course is to practice counting. We will gain some experience in this by discussing various problems in Combinatorics.

Discrete Probability
    -Probability theory is a mathematical foundation of Statistics, the core of Data Science. During this week we study discrete probability, the first chapter of the probability theory, closely related to combinatorics. We discuss random experiments, their outcomes and events, introduce the notion of probability and some basic rules that follow immediately from the combinatorial results studied before. We also study simple probabilistic models like coin-tossing that will be used later.

Introduction to Graphs
    -Graphs represent objects and relations between them in a compact geometric form. Objects are represented by vertices of a graph and relations correspond to edges. Applications of graphs include geoinformational systems (vertices are cities, edges are roads), social network analysis (people and friendship relations), chemistry (graphs of molecular structure), computer network topology, and many more. During this week, we introduce basic notions of graph theory and discuss basic algorithms on graphs.

Basic Graph Parameters
    -Graph parameters, also called graph properties and graph invariants, are values (usually numerical), which are calculated for a given graph and depend only on its abstract structure (not, say, on a particular way of drawing the graph on a plane). Graph parameters are useful in data science, since they reduce a big amount of data (the graph) to a small one (the parameter), while conveying important information about the graph. We discuss some of the basic graph parameters in this module.

Graphs of Social Networks
    -In this final part of the course we discuss a Python library for working with graphs, called NetworkX. In NetworkX, one can create and modify graphs, compute graph parameters, visualize graphs, etc. We shall show how NetworkX is used to operate on graphs coming from a real-world dataset.",Discrete Math and Analyzing Social Graphs
https://www.classcentral.com/course/edx-data-science-and-machine-learning-capstone-project-12606,"About this course
Now that you've taken several courses on data science and machine learning, it’s time to put your learning to work on a data problem involving a real life scenario. Employers really care about how well you can apply your knowledge and skills to solve real world problems, and the work you do in this capstone project will make you stand out in the job market. 
In this capstone project, you’ll explore data sets in New York’s 311 system, which is used by New Yorkers to report complaints for the non-emergency problems they face. Upon being reported, various agencies in New York get assigned to resolve these problems. The data related to these complaints is available in the New York City Open Dataset. On investigation, one can see that in the last few years the 311 complaints coming to the Department of Housing Preservation and Development in New York City have increased significantly. 
Your task is to find out the answers to some of the questions that would help the Department of Housing Preservation and Development in New York City effectively tackle the 311 complaints coming to them. You will need to use the techniques you learned in your previous Python, data science, and machine learning courses, including data ingestion, data exploration, data visualization, feature engineering, probabilistic modeling, model validation, and more. 
By the end of this course, you will have used real world data science tools to create a showcase project and demonstrate to employers that you are job ready and a worthy candidate in the field of data science.



            Read more",Data Science and Machine Learning Capstone Project
https://www.classcentral.com/course/exploratory-data-analysis-matlab-17125,"In this course, you will learn to think like a data scientist and ask questions of your data.  You will use interactive features in MATLAB to extract subsets of data and to compute statistics on groups of related data. You will learn to use  MATLAB to automatically generate code so you can learn syntax as you explore.  You will also use interactive documents, called live scripts,  to capture the steps of your analysis, communicate the results, and provide interactive controls allowing others to experiment by selecting groups of data.

These skills are valuable for those who have domain knowledge and some exposure to computational tools, but no programming background is required. To be successful in this course, you should have some knowledge of basic statistics (e.g., histograms, averages, standard deviation, curve fitting, interpolation). 

By the end of this course, you will be able to load data into MATLAB, prepare it for analysis, visualize it, perform basic computations, and communicate your results to others. In your last assignment, you will combine these skills to assess damages following a severe weather event and communicate a polished recommendation based on your analysis of the data.  You will be able to visualize the location of these events on a geographic map and create sliding controls allowing you to quickly visualize how a phenomenon changes over time.
      


          Introduction to the Data Science Workflow
    -In this module you’ll learn about the key steps in a data science workflow and begin exploring a data set using a script provided for you. As you work with the file, take note of the different elements in the script. As you progress through the course, you’ll create a similar script yourself.

Importing Data
    -In this module you’ll import data into MATLAB, customize the import options, and generate code to automate the process. You’ll also work with different types of data, such as numeric, dates, and text.

Visualizing and Filtering Data
    -In this module you’ll create visualizations and learn how to customize figures. You’ll also filter your data to select only what is needed for your analysis. You’ll create new tables and save them to use in the future or share with others outside of MATLAB.

Performing Calculations
    -In this module you’ll write small pieces of code to extend your analysis. You’ll calculate summary statistics on groups of data and determine if variables are correlated. You’ll extend your ability to filter data to defining conditions across multiple variables. You’ll also modify categorical data to remove, combine, or create new categories to use for defining groups.

Documenting Your Work
    -In this module you’ll create live scripts with interactive controls. Then you’ll create your own analysis of a weather event to submit as a peer-reviewed assignment.",Exploratory Data Analysis with MATLAB
https://www.classcentral.com/course/edx-statistics-and-r-2960,"This course teaches the R programming language in the context of statistical data and statistical analysis in the life sciences.
We will learn the basics of statistical inference in order to understand and compute p-values and confidence intervals, all while analyzing data with R code. We provide R programming examples in a way that will help make the connection between concepts and implementation. Problem sets requiring R programming will be used to test understanding and ability to implement basic data analyses. We will use visualization techniques to explore new data sets and determine the most appropriate approach. We will describe robust statistical techniques as alternatives when data do not fit assumptions required by the standard approaches. By using R scripts to analyze data, you will learn the basics of conducting reproducible research.
Given the diversity in educational background of our students we have divided the course materials into seven parts. You can take the entire series or individual courses that interest you. If you are a statistician you should consider skipping the first two or three courses, similarly, if you are biologists you should consider skipping some of the introductory biology lectures. Note that the statistics and programming aspects of the class ramp up in difficulty relatively quickly across the first three courses. We start with simple calculations and descriptive statistics. By the third course will be teaching advanced statistical concepts such as hierarchical models and by the fourth advanced software engineering skills, such as parallel computing and reproducible research concepts.
These courses make up 2 XSeries and are self-paced:
PH525.1x: Statistics and R for the Life Sciences
PH525.2x: Introduction to Linear Models and Matrix Algebra
PH525.3x: Statistical Inference and Modeling for High-throughput Experiments
PH525.4x: High-Dimensional Data Analysis
PH525.5x: Introduction to Bioconductor: annotation and analysis of genomes and genomic assays 
PH525.6x: High-performance computing for reproducible genomics
PH525.7x: Case studies in functional genomics
This class was supported in part by NIH grant R25GM114818.



            Read more",Statistics and R
https://www.classcentral.com/course/edx-data-analytics-in-health-from-basics-to-business-7160,"Many people talk about the promise of “big data” to health care. But how can the application of data analytics to big data actually improve health and health care? We will show that novel data analytics based solutions can result in better diagnosis, better care and better curing. This provides fertile ground for entrepreneurship and the development of new businesses.
In our course we’ll start from the very basics of data analytics, look at different real world approaches and help you to see entrepreneurial opportunities and develop a business plan.
We will cover three important fields:

Health care expertise: We will present medical approaches to data and give an overview of challenges where big data based solutions have been developed to improve the efficiency and effectiveness in medicine.
Data analytics: We’ll explain the basics of data mining within the context of a wide variety of health care settings, and the types of data and data analysis challenges that you will likely encounter in each. We’ll start with gathering the data, move on to classifying, analyzing and finally visualizing it.
Entrepreneurship: You will learn how to assess when data sciences based improvements in health care represent entrepreneurial opportunities. The development of a rigorous business plan is used to help you make that assessment.

Participants with prior experience in the medical field will learn how novel data science applications can improve healthcare, create societal value and how to spot entrepreneurial opportunities.
Participants with experience in data science or mathematics will learn about medical approaches to data and why healthcare is an exciting area to apply and develop data analytics.
Participants interested in launching their startup will learn how big data solutions in health care can provide a solid basis to build great ventures.
Whatever your motivation to enrol in this course, we care about your project and your success - that’s why we will guide you through all parts of this learning journey step by step!
Enter now to see how you can engage in data driven innovation and make an impact on improving care, outcomes and the quality of life.



            Read more
          



Week 1: Module 1: Diabetes
Health data expenditure, machine learning, data transformation, deriving patterns, opportunities.
Week 2: Module 2: PCR Analysis
Introduction to PCR, data mining, competitive analysis, industry analysis.
Week 3: Module 3: Genomic Data Analysis
Data sharing, data reliability, association rules, market research, marketing, solution optimization.
Week 4: Module 4: Diagnostic Model Research
Workflow, data missing values, density maps, business modelling, requirements and planning, investment needs.",Data Analytics in Health – From Basics to Business
https://www.classcentral.com/course/what-is-datascience-10616,"The art of uncovering the insights and trends in data has been around since ancient times. The ancient Egyptians used census data to increase efficiency in tax collection and they accurately predicted the flooding of the Nile river every year. Since then, people working in data science have carved out a unique and distinct field for the work they do. This field is data science. In this course, we will meet some data science practitioners and we will get an overview of what data science is today.

LIMITED TIME OFFER: Subscription is only $39 USD per month for access to graded materials and a certificate.
      


          Defining Data Science and What Data Scientists Do
    -In this module, you will view the course syllabus to learn what will be taught in this course. You will hear from data science professionals to discover what data science is, what data scientists do, and what tools and algorithms data scientists use on a daily basis. Finally, you will complete a reading assignment to find out why data science is considered the sexiest job in the 21st century.

Data Science Topics
    -In this module, you will hear from Norman White, the Faculty Director of the Stern Centre for Research Computing at New York University, as he talks about data science and the skills required for anyone interested in pursuing a career in this field. He also advises those looking to start a career in data science. Finally, you will complete reading assignments to learn about the process of mining a given dataset and about regression analysis.

Data Science in Business
    -In this module, you will learn about the approaches companies can take to start working with data science. You will learn about some of the qualities that differentiate data scientists from other professionals. You will also learn about analytics, story-telling, and the pivotal role data scientists play in creating an effective final deliverable. Finally, you will apply what you learned about data science by answering open-ended questions.",What is Data Science?
https://www.classcentral.com/course/positive-psychology-visionary-science-8337,"Dr. Martin E.P.  Seligman—renowned worldwide as the “father of Positive Psychology”—has led visionary leaps in the scientific research, empirical data and personal understandings of human flourishing. This course explores the past, present and future of positive psychology as a journey through the key scientific leaps led by Dr. Seligman and his colleagues at the University of Pennsylvania's Positive Psychology Center and Master of Applied Positive Psychology program. 

There are no prerequisites.
      


          Positive Psychology Introduction by Dr. Martin Seligman
    -In this module, Dr. Martin Seligman introduces the scientific foundations of positive psychology and key research findings that led to a revolutionary understanding of what makes people flourish.  Participants will learn about research-based skills and exercises to increase well-being and begin to practice these skills in their own lives. 

The Skills of Well-being Can Be Learned, Taught, and Transformative
    -In this module, Dr. Martin Seligman shares the great leaps in scientific understanding that created the foundation for a science of well-being at individual, communal, and global levels. 

Being Whole: Mind/Body Flourishing Throughout Life
    -In this module, Dr. Martin Seligman shares key research questions from the field of Positive Psychology, and the answers turn some conventional assumptions on their head. Are we shaped by the future vs. the past? And what does science tell us about mind/body flourishing? What gets better as we age?

Future Directions in Positive Psychology
    -In this module, Dr. Martin Seligman discusses some of the most inspiring recent and future developments in the field of Positive Psychology, in particular those that transcend individual experience and have the potential to transform our world.",Positive Psychology: Martin E. P. Seligman’s Visionary Science
https://www.classcentral.com/course/julia-programming-7092,"This four-module course introduces users to Julia as a first language.  Julia is a high-level, high-performance dynamic programming language developed specifically for scientific computing. This language will be particularly useful for applications in physics, chemistry, astronomy, engineering, data science, bioinformatics and many more. As open source software, you will always have it available throughout your working life. It can also be used from the command line, program files or a new type of interface known as a Jupyter notebook (which is freely available as a service from JuliaBox.com).

Julia is designed to address the requirements of high-performance numerical and scientific computing while also being effective for general-purpose programming. You will be able to access all the available processors and memory, scrape data from anywhere on the web, and have it always accessible through any device you care to use as long as it has a browser.  Join us to discover new computing possibilities. Let's get started on learning Julia.

By the end of the course you will be able to:
- Programme using the Julia language by practising through assignments
- Write your own simple Julia programs from scratch
- Understand the advantages and capacities of Julia as a computing language
- Work in Jupyter notebooks using the Julia language
- Use various Julia packages such as  Plots, DataFrames and Stats

The course is delivered through video lectures, on-screen demonstrations, quizzes and practical peer-reviewed projects designed to give you an opportunity to work with the packages.
      


            Read more
          



          Welcome to the course
    -A warm welcome to Julia Scientific Programming. Over the next four weeks, we will provide you with an introduction to what Julia can offer. This will allow you to learn the basics of the language, and stimulate your imagination about how you can use Julia in your own context. This is all about you exploring Julia - we can only demonstrate some of the capacity and encourage you to take the first steps. For those of you with a programming background, the course is intended to offer a jumpstart into using this language. If you are a novice or beginner programmer, you should follow along the simple coding but recognising that working through the material will not be sufficient to make you a proficient programmer in four weeks. You could see this as the ‘first date’ at the beginning of a long and beautiful new relationship. There is so much you will need to learn and discover. Good luck and we hope you enjoy the course! Best wishes, Henri and Juan

A context for exploring Julia: Working with data
    -In our case study we use Julia to store, plot, select and slice data from the Ebola epidemic. Taking real data, we explain how to work in Julia using arrays, and for loops to work with the structures. By the end of this module, you will be able to: create an array from data;  learn to use the logical structures IF  and FOR ; conduct basic array slicing, getting the incidence data and generating total number of cases; use Plots to generate graphs and plot data; and combine the Ebola data outputs to show a plot of disease incidence in several countries.

Notebooks as Julia Programs
    -in this week, we demonstrate how it is possible to use Julia in the notebook environment to interpret a model and its fit to the data from the Ebola outbreak. For this, we apply the well-known SIR compartmental model in epidemiology. The SIR model labels three compartments, namely S = number susceptible, I =number infectious, and R =number recovered. By the end of this module, you will be able to: understand the SIR models; describe the basic parameters of an SIR model; plot the model-predicted curve and the data on the same diagram; adjust the parameters of the model so the model-predicted curve is close (or rather as close as you can make it) to the data.

Structuring data and functions in Julia
    -As a scientific computing language, Julia has many applications and is particularly well suited to the task of working with data.  In this last module, we will use descriptive statistics as our topic to explore the power of Julia. You should see this week as offering you a chance to further explore concepts introduced in week one and two. You will also be introduced to more efficient ways of managing and visualizing your data. We have also included additional, honors material for those who want to explore further with Julia around functions and collections.   By the end of this module, you will be able to:  1. Practice basic functions in Julia  2.Creating random variables from data point values 3. Build your own  Dataframes 4. Create a variety of data visualisations 5. Conduct statistical tests 6. learn how to export your data.",Julia Scientific Programming
https://www.classcentral.com/course/breast-cancer-causes-prevention-6044,"Welcome to an Introduction to Breast Cancer!  In this course, we’ll learn a bit about the leading cause of cancer in women worldwide – from the basic biology of the disease, to risk factors and prevention, to treatment modalities to survivorship.  We’ll talk to leading experts, explore some of the milestone studies that have pushed this field forward, and have interactive discussions on discussion boards and social media.  You’ll even have an opportunity to let us know what topics you want to cover on tweetchats, so we can try to make the content fit your interests.  

There is something in this course for everyone – if you’re a breast cancer survivor or the friend/family member of someone with this disease, this course will help you to better understand this disease, and give you ideas for questions you may want to ask your doctor.  Maybe you’re a healthcare provider or studying to be the same, this course is a great refresher on where the state of the science is.  If you’re a healthcare administrator wondering about how the interdisciplinary components of breast cancer care fit together, or an entrepreneur thinking about unmet needs in this space, or someone in public health interested in prevention, this course is also for you!

Are you ready to learn a lot, and have some fun while we’re at it?  If so, I hope you’ll join us!  Let’s get started!!!
      


          Welcome to the Course!

Risks and Prevention
    -Join me as we start to learn about what breast cancer is, the epidemiology of this disease and the risks associated with it. In these lectures, we’ll talk about genetic mutations that predispose us to developing breast cancer.  As you’ll find out, this goes far beyond just BRCA!

Under the Microscope
    -What is cancer and how does it work? Want to learn the fundamentals of what breast cancer is?  The different “types” – what is in situ vs. invasive?  What is lobular vs. ductal?  What is grade vs. stage?  And what do molecular subtypes refer to?  Well, tune in! Learn about the hallmarks of cancer – what are the processes that actually lead to this disease?  Maybe this will give you some ideas about how we can stop cancers in their tracks!

Making the Diagnosis 
    -Want to learn more about how to find breast cancers early, when they’re most treatable?  This is the lecture for you! “Tissue is the issue” – learn how we actually do the biopsies to make the diagnosis of breast cancer. How do we stage breast cancer?  Learn what tests we need to do and in whom in order to get this information!

All About Surgery
    -How do we actually remove breast cancer?  Is a lumpectomy just as good as a mastectomy?  Find out in this session. There are many different options for reconstructing a breast after a mastectomy – from tissue expanders and implants, to using your own tissue.  In this talk, we’ll explore some of these options. Why do we take out lymph nodes, and how?  What are the side effects?  Learn more about this in this session! Do you have questions about lymphedema?  How do you prevent it?  Can/should you lift weights after a lymph node dissection?  Should you wear a sleeve if you are going on a plane?  What about shaving, hand surgery, and having an iv placed?  We’ll answer all of these questions in this session.

Beyond the Knife 
    -Learn all about radiation therapy – who needs it, when, what are the different types, and how do we minimize side effects. Who needs chemotherapy?  What about hormonal therapy?  What is targeted therapy?  We’ll learn all about the drugs we use to treat breast cancer in this session.

Potpurri
    -Not all breast cancers are the same.  Let’s learn a bit more about inflammatory breast cancer, Paget’s disease, Male breast cancer, breast cancer in pregnancy and metastatic disease. Let’s talk all about clinical trials – what they are, how they are monitored, and some of the trials that have really moved the field forward. So, you or your patients have gotten through diagnosis and active treatment, and you’re now in the survivorship period.  Great!  But this poses a whole new set of issues as people adjust to their “new normal”.  Learn about what these issues are, and a bit about survivorship care plans as well.",Introduction to Breast Cancer
https://www.classcentral.com/course/python-social-network-analysis-6674,"This course will introduce the learner to network analysis through tutorials using the NetworkX library. The course begins with an understanding of what network analysis is and motivations for why we might model phenomena as networks. The second week introduces the concept of connectivity and network robustness. The third week will explore ways of measuring the importance or centrality of a node in a network. The final week will explore the evolution of networks over time and cover models of network generation and the link prediction problem. 

This course should be taken after: Introduction to Data Science in Python, Applied Plotting, Charting & Data Representation in Python, and Applied Machine Learning in Python.
      


          Why Study Networks and Basics on NetworkX
    -Module One introduces you to different types of networks in the real world and why we study them. You'll learn about the basic elements of networks, as well as different types of networks. You'll also learn how to represent and manipulate networked data using the NetworkX library. The assignment will give you an opportunity to use NetworkX to analyze a networked dataset of employees in a small company.

Network Connectivity
    -In Module Two you'll learn how to analyze the connectivity of a network based on measures of distance, reachability, and redundancy of paths between nodes. In the assignment, you will practice using NetworkX to compute measures of connectivity of a network of email communication among the employees of a mid-size manufacturing company. 

Influence Measures and Network Centralization
    -In Module Three, you'll explore ways of measuring the importance or centrality of a node in a network, using measures such as Degree, Closeness, and Betweenness centrality, Page Rank, and Hubs and Authorities. You'll learn about the assumptions each measure makes, the algorithms we can use to compute them, and the different functions available on NetworkX to measure centrality. In the assignment, you'll practice choosing the most appropriate centrality measure on a real-world setting.

Network Evolution
    -In Module Four, you'll explore the evolution of networks over time, including the different models that generate networks with realistic features, such as the Preferential Attachment Model and Small World Networks. You will also explore the link prediction problem, where you will learn useful features that can predict whether a pair of disconnected nodes will be connected in the future. In the assignment, you will be challenged to identify which model generated a given network. Additionally, you will have the opportunity to combine different concepts of the course by predicting the salary, position, and future connections of the employees of a company using their logs of email exchanges.",Applied Social Network Analysis in Python
https://www.classcentral.com/course/futurelearn-the-science-of-nutrition-3822,"Explore the nutritional science behind what you eat
Have you ever looked at a food label and wondered what kilocalories really mean? Would you like to know more about fat, protein or carbohydrates, and how our bodies process them?
This online nutrition course provides the answers. You’ll explore biology, finding out how our digestive system and bloodstream process and transport food. You’ll use physics to work out how much energy food contains. And through chemistry, you’ll discover the role that acid and enzymes play in digestion.
Finally, you’ll consider the science behind dietary advice and why we’re facing an obesity epidemic worldwide.
This course is intended for anyone with a general interest in science or nutrition and does not require any prior experience of studying this subject.",The Science of Nutrition
https://www.classcentral.com/course/edx-introduction-to-data-wise-a-collaborative-process-to-improve-learning-teaching-3395,"Educators have an ever-increasing stream of data at their fingertips, but knowing how to use this data to improve learning and teaching — how to make it less overwhelming, more useful, and part of an effective collaborative process — can be challenging.
Based on the book Data Wise: A Step-by-Step Guide to Using Assessment Results to Improve Teaching and Learning, this course describes a clear, 8-step process for using a wide range of data sources to improve instruction. You will see what this disciplined way of working with colleagues can look and feel like in a school setting. You will also have the opportunity to share insights and experiences about school improvement with educators from around the world.
Introduction to Data Wise is open to all but is especially valuable for teachers and school and district leaders, as well as policymakers, and educational entrepreneurs who are dedicated to improving outcomes for students. There are several ways you could take this course:

Participate on your own.
Enroll with a few colleagues as part of a study group.
Formally integrate it into professional development in your workplace.

It is a self-paced course. You can go through the essential materials in a day or take several weeks to allow for reflection. There will be one month of active course facilitation, which will include discussion board moderation, office hours, and other live events.
This course provides an introduction to a rich portfolio of books, resources, training, and support developed by the Data Wise Project at the Harvard Graduate School of Education. The Data Wise Project works in partnership with teachers and school and system leaders to develop and field-test resources that support collaborative school improvement. We encourage you to explore these resources as you chart a course for using data to improve learning and teaching for all students.



            Read more",Introduction to Data Wise: A Collaborative Process to Improve Learning & Teaching
https://www.classcentral.com/course/principlescomputing2-3198,"This two-part course introduces the basic mathematical and programming principles that underlie much of Computer Science. Understanding these principles is crucial to the process of creating efficient and well-structured solutions for computational problems.  To get hands-on experience working with these concepts, we will use the Python programming language. The main focus of the class will be weekly mini-projects that build upon the mathematical and programming principles that are taught in the class. To keep the class fun and engaging, many of the projects will involve working with strategy-based games.

In part 2 of this course,  the programming portion of the class will focus on concepts such as recursion, assertions, and invariants. The mathematical portion of the class will focus on searching, sorting, and recursive data structures.  Upon completing this course, you will have a solid foundation in the principles of computation and programming.  This will prepare you for the next course in the specialization, which will begin to introduce a structured approach to developing and analyzing algorithms.  Developing such algorithmic thinking skills will be critical to writing large scale software and solving real world computational problems.
      


          Searching and Data Structures
    -This week, we will explain the importance of searching.  We will also explore various data structures and learn about inheritance.

Recursion
    -This week, we will explain the importance of recursion.

Trees
    -This week, we will explain the importance of trees.  We will also explore how to set up game trees so that we can efficiently search them.

Modeling, Assertions, and Invariants
    -This week, we will explain the importance of modeling.  We will also explore how to use assertions and invariants to ensure that our models are always consistent and correct.",Principles of Computing (Part 2)
https://www.classcentral.com/course/data-driven-astronomy-8140,"Science is undergoing a data explosion, and astronomy is leading the way. Modern telescopes produce terabytes of data per observation, and the simulations required to model our observable Universe push supercomputers to their limits. To analyse this data scientists need to be able to think computationally to solve problems. In this course you will investigate the challenges of working with large datasets: how to implement algorithms that work; how to use databases to manage your data; and how to learn from your data with machine learning tools. The focus is on practical skills - all the activities will be done in Python 3, a modern programming language used throughout astronomy.

Regardless of whether you’re already a scientist, studying to become one, or just interested in how modern astronomy works ‘under the bonnet’, this course will help you explore astronomy: from planets, to pulsars to black holes.

Course outline:
Week 1: Thinking about data
- Principles of computational thinking
- Discovering pulsars in radio images

Week 2: Big data makes things slow
- How to work out the time complexity of algorithms
- Exploring the black holes at the centres of massive galaxies

Week 3: Querying data using SQL
- How to use databases to analyse your data
- Investigating exoplanets in other solar systems

Week 4: Managing your data
- How to set up databases to manage your data
- Exploring the lifecycle of stars in our Galaxy

Week 5: Learning from data: regression
- Using machine learning tools to investigate your data
- Calculating the redshifts of distant galaxies

Week 6: Learning from data: classification
- Using machine learning tools to classify your data
- Investigating different types of galaxies

Each week will also have an interview with a data-driven astronomy expert.

Note that some knowledge of Python is assumed, including variables, control structures, data structures, functions, and working with files.
      


            Read more
          



          Thinking about data
    -This module introduces the idea of computational thinking, and how big data can make simple problems quite challenging to solve. We use the example of calculating the median and mean stack of a set of radio astronomy images to illustrate some of the issues you encounter when working with large datasets. 

Big data makes things slow
    -In this module we explore the idea of scaling your code. Some algorithms scale well as your dataset increases, but others become impossibly slow. We look at some of the reason for this, and use the example of cross-matching astronomical catalogues to demonstrate what kind of improvements you can make. 

Querying your data
    -Most large astronomy projects use databases to manage their data. In this module we introduce SQL - the language most commonly used to query databases. We use SQL to query the NASA Exoplanet database and investigate the habitability of planets in other solar systems.

Managing your data
    -This module introduces the basic principles of setting up databases. We look at how to set up new tables, and then how to combine Python and SQL to get the best out of both approaches. We use these tools to explore the life of stars in a stellar cluster.


Learning from data: regression
    -This module introduces the idea of machine learning. We look at standard methodology for running machine learning experiments, and then apply this to calculating redshifts of distant galaxies using decision trees for regression. 

Learning from data: classification
    -In this final module we explore the limitations of decision tree classifiers. We then look at ensemble classifiers, using the random forest algorithm to classify images of galaxies into different types.",Data-driven Astronomy
https://www.classcentral.com/course/biosphere-science-future-10470,"Are you ready to take an incredible journey around Planet Earth and beyond? In this course, you will delve into a world of innovative science and learn from a team of Biosphere 2 and University of Arizona researchers. From plants and soils, to oceans and rainforests, the Moon, Mars, and more, this course is an exciting opportunity for anyone interested in science and Earth stewardship. 

Learn how a unique research station in the Arizona desert is used to investigate big ideas, such as how Earth systems interact, the effects of climate change, and what our future holds. Go back in time thousands of years with information locked in ancient trees, and travel into an imagined future where humans become Martians. Collect and analyze your own scientific data, discuss big questions with participants from around the world, and gain novel insights and understanding about our wonderfully unique planet.
      


          Biosphere 2, an Icon of Possibilities
    -Why would anyone build an enormous glass structure in the Arizona desert? In Module 1, you will get a virtual introduction to the engineering marvel that is Biosphere 2. Learn about the fascinating history of Biosphere 2 and how it is currently used as the world’s best research instrument for earth systems science. Discover how the ocean, rainforest, and desert can be studied in one enclosed, three-acre structure in the Arizona desert. With Dr. Joaquin Ruiz, University of Arizona (UA) Vice President for Innovation, Director of Biosphere 2, Dean of UA Science, Geoscientist, and John Adams, Deputy Director, UA Biosphere 2.

Climate Disruption 
    -How do we know that human activity is changing the climate? In Module 2, you will hear from scientists who reconstruct past climates by unlocking information held in ancient trees. Discover how tree rings help us understand drought and wildfire patterns across time and space. Learn what global warming is, exactly, and how it is accelerated by carbon emissions. With Dr. Kevin Anchukaitis, Geography and UA Laboratory of Tree-Ring Research, and Dr. David Frank, UA Laboratory of Tree-Ring Research.

The Science of Water Availability 
    -Where is Earth’s water? In Module 3, you will learn about the global water cycle and discover how much water exists, where it exists, and how it moves around the environment. Learn how Biosphere 2 and Critical Zone research are used to study the water cycle. With Dr. Peter Troch, Director of Science at Biosphere 2, UA Hydrology.

Desert Plants, Climate, and Changing Landscapes 
    -How can many different species coexist in once place? In Module 4, go beyond Biosphere 2 to UA Tumamoc Hill—the world’s oldest long-term desert ecology research site near the University of Arizona. Learn how living and nonliving components of the environment are related, how different species coexist, and how climate variation affects Sonoran Desert plants. With Dr. Larry Venable, UA Ecology & Evolutionary Biology.

Rainforests in an Altered World 
    -What can the Biosphere 2 rainforest tell us about the future? Module 5 focuses on tropical rainforests in the Amazon Basin of South America, and the controlled rainforest inside Biosphere 2. Learn about the fascinating activity of tropical forests, the major roles they play in global climate, and the potential impacts of deforestation and climate change. With Dr. Joost Van Haren, Biosphere 2, UA Honors, and Dr. Scott Saleska, UA Ecology & Evolutionary Biology.

Sea Changes in our Marine Environment 
    -Why are coral reefs in peril, and what can we do about it? In Module 6, discover the immense role that oceans play in global climate, heat distribution, and human livelihoods. Learn why global warming is sometimes called ocean warming, how ocean acidification affects marine life, and innovative ways in which the ocean is studied. With Dr. Julia Cole, U. of Michigan, UA Biosphere 2 Marine Research.

Soil Science - Foundations & Implications 
    -How can soil be alive? In Module 7, discover the fascinating, microscopic world within soils and their critical role in Earth systems. Learn how soils provide functions and services that make them vital to our health and wellbeing. With Dr. Rachel Gallery, UA School of Natural Resources and the Environment, and Dr. Katerina Dontsova, UA Soil Water & Environmental Science, Biosphere 2.

Feeding the Future
    -Can a Mars or Lunar greenhouse help feed people on Earth? In Module 8, learn how space-farming models can be applied on Earth as we move towards a global population of 10 billion people. Discover innovative controlled agricultural systems, learn more about how plants grow, and get a chance to produce your own hydroponically grown vegetables at home! With Dr. Gene Giacomelli, UA Controlled Environment Agriculture Center.

Life and Resources in Space - Should We Go There?
    -When will humans live beyond Earth’s gravity? Module 9 is a fascinating and inspiring journey into space. Ignite your imagination as you learn about space tourism, asteroid-mining, moon elevators, robotic space explorers, and Mars colonization. While focusing on space, this module is sure to reaffirm your appreciation of Planet Earth. With Dr. Chris Impey, Associate Dean UA College of Science, UA Astronomy.",Biosphere 2 Science for the Future of Our Planet
https://www.classcentral.com/course/teach-impacts-technology-workplace-futur-11235,"In this course you’ll focus on how the Internet has enabled new careers and changed expectations in traditional work settings, creating a new vision for the workplace of the future. This will be done through a series of paired teaching sections, exploring a specific “Impact of Computing” in your typical day and the “Technologies and Computing Concepts” that enable that impact, all at a K12-appropriate level. 

This course is part of a larger Specialization through which you’ll learn impacts of computing concepts you need to know, organized into 5 distinct digital “worlds”, as well as learn pedagogical techniques and evaluate lesson plans and resources to utilize in your classroom. By the end, you’ll be prepared to teach pre-college learners to be both savvy and effective participants in their digital world.

In this particular digital world (careers and work), you’ll explore the following Impacts & Technology pairs --

Impacts (Getting jobs in new ways): technology based freelancing, Linkedin and how it changed the way we work  
Technology and Computing Concepts: Data retrieval, data vs metadata, SQL, Boolean logic (AND, OR, NOT)

Impacts (Physical ties to work restricts people and businesses): work communication, the cloud, cloud computing, companies affected by ransomware attacks 
Technology and Computing Concepts: how the cloud works, FTP, cloud storage, clients and servers, scalability basics, fault tolerance, AWS, devops

Impacts (Advancing your career in the fast moving technical world): digital technology changing jobs, online classes, machines replacing jobs, data science and artificial intelligence

In the pedagogy section for this course, in which best practices for teaching computing concepts are explored, you’ll learn how to effectively explore and critique curricular material you find and practice reviewing lesson plans, with a focus on material aimed at learning HTML.

In terms of CSTA K-12 computer science standards, we’ll primarily cover learning objectives within the “impacts of computing” concept, while also including some within the “networks and the Internet” concepts and the “data and analysis” concept.  Practices we cover include “fostering and inclusive computing culture”, “recognizing and defining computational problems”, and “communicating about computing”.
      


            Read more
          



          Course Orientation
    -Welcome!  Are you ready to explore the impacts of the technology on the workplace and new types careers available to us?  To learn more about the computation and computing concepts that underlie those technologies?  We'll be using a problem-based approach to explore interesting ways to teach concepts of networks and the internet, data and analysis, and even algorithms and data representation.  Additionally, this course features a series called ""Career Explorations"" -- resources you can use to help students broaden their ideas of future career opportunities. Finally, we'll explore several lesson plans supporting online learning resources around data science and html programming (don't worry -- not prior programming experience is required!).

Getting a Job in New Ways
    -How has getting a job changed due to the Internet and ever growing amounts of information we choose to make available online?  What new opportunities or flexibility are available because of the digital nature of much of our work?  We'll explore this and some of fundamentals behind database storage and access that helps match us to possible jobs!

Physical Ties to Work
    -How have cheap computers and ""always available"" Internet connectivity changed how and when we can work?  What about the cloud -- is it  just for storage?  Finally, we'll look at two impacts on careers -- working in a truly ""global"" company and managing the updates of software that we seem to get all the time!

Advancing your career in the technical world
    -How will the workplace of the future be different?  Will workers be expected to constantly learn new things just to stay employable?  How might that happen?  Will machines be taking over our jobs?  This is currently the subject of a LOT of discussion.  Although exploring the technology behind machine learning and artificial intelligence is appropriate, we have already covered that in another course (Course 2 - Data).  Instead here we'll look at the new ""career"" of data science and explore a tool you can use with students to give them a first introduction -- no programming needed!

Impacts of Computing and Pedagogy
    -Technology and the Internet is changing not only what kinds of jobs we can get, but how we can stay trained and train for new jobs our entire life.  This week you will find a resource for exploring the impacts of computing on career or work -- that you think would be useful with YOUR students.   Additionally we'll reflect on how cognitive load can cause challenges when teaching computing and explore and critique a code.org lesson on learning HTML.",Teaching Impacts of Technology: Workplace of the Future
https://www.classcentral.com/course/data-wrangling-analysis-abtesting-14375,"This course allows you to apply the SQL skills taught in “SQL for Data Science” to four increasingly complex and authentic data science inquiry case studies. We'll learn how to convert timestamps of all types to common formats and perform date/time calculations. We'll select and perform the optimal JOIN for a data science inquiry and clean data within an analysis dataset by deduping, running quality checks, backfilling, and handling nulls. We'll learn how to segment and analyze data per segment using windowing functions and use case statements to execute conditional logic to address a data science inquiry. We'll also describe how to convert a query into a scheduled job and how to insert data into a date partition. Finally, given a predictive analysis need, we'll engineer a feature from raw data using the tools and skills we've built over the course. The real-world application of these skills will give you the framework for performing the analysis of an AB test.
      


          Data of Unknown Quality
    -In this module, you will be able to create trustworthy analysis from a new set of data. You will be able  to coalesce some nulls and identify unreliable data and discover reasons why data might be missing. You will also be able to answer ambiguous questions by defining new metrics.

Creating Clean Datasets
    -In this module, you will be able to name the main the categories of data types. You will be able to explain how the unfiltered data can be manipulated into a table where you can conduct data analysis. You will be able to discuss why a data warehouse is separate from a production database, and you will be able to use the tools you learned to create your own trustworthy tables. 

SQL Problem Solving
    -In this module, you will be able to map out your joins and be able to highlight the level of detail needed for different kinds of questions. You will be able to practice answering data questions, which should help you feel ready to get asked a whole slough of questions, vague questions, ambiguous questions, or even poorly worded questions. Finally, you will develop a strategy for answering all those questions using data.

Case Study: AB Testing
    -In this module, you will be able to use your SQL skills to set up a basic AB testing system. You will be able to apply hypothesis testing to prove or disprove a hypothesis about how user behavior changed. You will be able to test and interpret the results using a metric or metrics that are tied directly to some business metrics. You will be able to test your SQL skills and give you the base experience you need to learn anything more complicated in terms of AB testing in the future.","Data Wrangling, Analysis and AB Testing with SQL"
https://www.classcentral.com/course/edx-introduction-to-genomic-data-science-8962,"In the first half of this course, we'll investigate DNA replication, and ask the question, where in the genome does DNA replication begin? You will learn how to answer this question for many bacteria using straightforward algorithms to look for hidden messages in the genome.  
In the second half of the course, we'll examine a different biological question, and ask which DNA patterns play the role of molecular clocks. The cells in your body manage to maintain a circadian rhythm, but how is this achieved on the level of DNA? Once again, we will see that by knowing which hidden messages to look for, we can start to understand the amazingly complex language of DNA. Perhaps surprisingly, we will apply randomized algorithms to solve problems.  
Finally, you will get your hands dirty and apply existing software tools to find recurring biological motifs within genes that are responsible for helping Mycobacterium tuberculosis go ""dormant"" within a host for many years before causing an active infection.  
This course begins a series of classes illustrating the power of computing in modern biology.



Welcome! A brief introduction to the course and its logistics.
Week 1: A Journey of a Thousand Miles
What does a cryptic message leading to buried treasure have to do with biology? Many cellular processes are encoded as ""secret messages"" within an organism's DNA. But how do we decipher these messages?
Week 2: Finding Replication Origins.
We examine the details of DNA replication and apply these details to design an intelligent algorithmic approach to find the replication origin in a bacterial genome.
Week 3: Hunting for Regulatory Motifs.
Your cells ""tell time"" and maintain your circadian clock by turning genes on and off during the day in set patterns. This brings us to a different kind of ""secret message"" problem in biology: how do we find the motifs hidden in DNA that switch on genes? We develop introductory algorithms for motif-finding in genes.
Week 4: How Rolling Dice Helps Us Find Regulatory Motifs.
We see how to improve upon these motif-finding approaches by designing randomized algorithms that can ""roll dice"" to find motifs and perform quite well in practice.
Week 5: Finishing Up
Bioinformatics Application Challenge: Motif-Finding. We use popular software built on the motif-finding algorithms that we learned to hunt for motifs in a real biological dataset.
End-of-the-Course Assessment. 
In an end-of-the course assessment, we will ask you to answer Course Review questions. This will give you the opportunity to let us know how the course went for you. This assessment will provide data for our research study and will help us improve our courses for future learners.",Introduction to Genomic Data Science
https://www.classcentral.com/course/resilienceinchildren-1768,"How do children overcome hazardous experiences to succeed in life? What can be done to protect young people at risk from trauma, war, disasters, and other adversities? Learn about the importance of fostering resilience in children at risk. 

During this course, participants will: learn how trauma can affect children and the systems they depend on, gain insight into core concepts, research methods and lessons learned in last 50 years of resilience research, learn how research is being applied in the real world through interventions that promote resilience, and engage in discussions with others who are working with children at risk around the world

Participants are welcome to take the MOOC at no cost or to register for a Course Certificate ($49). Those who register and earn a Course Certificate from Coursera also are eligible to sign up for continuing education clock hours through the University of Minnesota. 

Participants can earn 10 clock hours of continuing education credit (added cost $99) from the College of Education and Human Development at the University of Minnesota. Go here http://z.umn.edu/1a5q to register for continuing education clock hours for completing this course.
      


          Week 1: Origins and Landmark Studies in the Science of Resilience in Children 
    -The first module of this course provides an introduction to the course and to the science of resilience. Video lectures discuss the meaning of resilience and the origins of resilience science. Participants will begin to think about case examples of resilience from their own experience and plan for a resilience interview. In the forum discussions, participants will introduce themselves, discuss the meaning of resilience and its importance in their work. Participants also will nominate favorite films and books about true stories of resilience:


Week 2: Methods and Models of Research on Resilience (including case studies)
    -This module highlights the models and methods used in resilience science, including person-focused methods and variable-focused methods. The case study of Dr. Maddaus continues and the case of resilience in early childhood is presented. 

Week 3: Effects on Children of Natural and Technological Disasters 
    -This module focuses on what has been learned from research on children who experience disasters, including the effects on children and patterns of recovery. Participants will watch a video interview with an expert on children in disaster and additional videos on damage and recovery following the F5 Joplin tornado. Participants will also complete a survey on disaster experiences.

Week 4: Resilience in Children Exposed to War and Political Violence 
    -This module highlights what has been learned about the effects of war, terror, and political violence on children and youth. What are the effects of these violent experiences on young people? What has been learned about resilience? We will examine the provocative literature on youth who voluntarily get involved in political conflicts or war. The concluding lecture considers new approaches to peace-building and what might be done to promote peace through interventions with children.

This week also features 4 special topics on resilience in young people who experienced the trauma of war and conflict. Choose one or more of the special topics and watch these moving stories of survival. Post your thoughts in the special topics discussion forums on each of these options. If you have time, watch them all. These accounts of resilience are very compelling. 

Week 5: Roles of Families, Schools, Culture, and Community in Promoting Resilience of Children
    -This module summarizes the findings on protective factors for resilience in children. Professor Masten presents her ideas about the adaptive systems that account for most of the capacity for resilience in children, what she has called “ordinary magic.” The roles of families, schools, and culture in resilience are discussed.

Week 6: A Resilience Framework for Action, Enduring Controversies, and New Horizons in the Study of Resilience 
    -In video lectures this final week of the course, Professor Masten presents a general resilience framework for designing interventions and programs to promote resilience. She also discusses enduring controversies in the study of resilience and new frontiers, including the neurobiology of resilience and growing research on the role of culture in resilience. The course concludes with highlights about growing global work on resilience and final “take home” messages from the course.","Resilience in Children Exposed to Trauma, Disaster and War: Global Perspectives"
https://www.classcentral.com/course/wharton-introduction-spreadsheets-models-5451,"The simple spreadsheet is one of the most powerful data analysis tools that exists, and it’s available to almost anyone. Major corporations and small businesses alike use spreadsheet models to determine where key measures of their success are now, and where they are likely to be in the future. But in order to get the most out of a spreadsheet, you have the know-how to use it. This course is designed to give you an introduction to basic spreadsheet tools and formulas so that you can begin harness the power of spreadsheets to map the data you have now and to predict the data you may have in the future. Through short, easy-to-follow demonstrations, you’ll learn how to use Excel or Sheets so that you can begin to build models and decision trees in future courses in this Specialization. 
Basic familiarity with, and access to, Excel or Sheets is required.
      


          Spreadsheets: A Tool for Thinking with Numbers
    -This module was designed to introduce you to the history of spreadsheets, their basic capabilities, and how they can be used to create models. You'll learn the different types of data used in spreadsheets, spreadsheet notations for mathematical operations, common built-in formulas and functions, conditional expressions, relative and absolute references, and how to identify and correct circular references. By the end of this module, you'll understand the context of spreadsheets, be able to navigate a spreadsheet, use built-in formulas and functions in spreadsheets, create your own simple formulas, and identify and correct common errors so you can put spreadsheets to work for you.

From Spreadsheet to Model
    -In this module, you'll move from spreadsheet to model, so you can begin to create your own models that reflect real-world events. You'll learn how to organize and lay out model elements, as well as the types of objective functions and their use. You'll also learn what-if analysis and scenarios, sensitivity analysis, and other classic models. By the end of this module, you'll be able to design a spreadsheet reflecting assumptions, decision variables, and outcomes, create a basic cashflow model, evaluate a small business opportunity, conduct what-if analysis, identify key variables using sensitivity analysis, and linear programming models and deterministic models.

Addressing Uncertainty and Probability in Models
    -This module was designed to introduce you to how you can use spreadsheets to address uncertainty and probability. You'll learn about random variables, probability distributions, power, exponential, and log functions in model formulas, models for calculating probability trees and decision trees, how to use regression tools to make predictions, as well as multiple regression. By the end of this module, you'll be able to measure correlations between variables using spreadsheet statistical functions, understand the results of functions that calculate correlations, use regression tools to make predictions, and improve forecasts with multiple regression.

 Simulation and Optimization
    -In this module, you'll learn to use spreadsheets to implement Monte Carlo simulations as well as linear programs for optimization. You'll examine the purpose of Monte Carlo simulations, how to implement Monte Carlo simulations in spreadsheets, the types of problems you can address with linear programs and how to implement those linear programs in spreadsheets. By the end of this module, you'll be able to model uncertainty and risk in spreadsheets, and use Excel's solver to optimize resources to reach a desired outcome.  You'll also be able to identify the similarities and differences between Excel and Sheets, and be prepared for the next course in the Business and Financial Modeling Specialization.",Introduction to Spreadsheets and Models
https://www.classcentral.com/course/guitar-522,"Grasp the essentials needed to begin playing acoustic or electric guitar. You'll learn an easy approach to get you playing quickly, through a combination of exploring the instrument, performance technique, and basic music theory.

For students who have long thought about picking up the acoustic or electric guitar, this course will provide an easy-access foundation that will get you playing. When first learning guitar, it is important to have the material presented in stages, in an enjoyable way that allows you to grasp the basics of the instrument and music. The course begins simply with the parts of the guitar, the names of the strings, tuning, and technique—whether finger-style or pick. It then explores the basics of music theory with such topics as scales, triads, power chords, and fingering and shapes.

At the end of this course, students will understand the structure, parts, and accessories of the instrument, in addition to an understanding of its basic maintenance. Electric guitar players will learn the operation of their instrument along with basic options for amplification, effect pedals, and sounds. Students will also learn to develop correct technique and apply theory concepts to their playing. They will have the foundational knowledge necessary to pursue most intermediate guitar courses.
      


          Welcome to Introduction to Guitar
    -Welcome to Guitar for Beginners! Before you begin the course, we will cover all the details about the course and what you'll need to know to get the most out of your Berklee MOOC.

Acoustic / Electric Guitar and the Basics
    -In this first lesson, we will take things slow. We will focus on how to choose the right guitar for you and what accessories are essential for any guitar player. We'll also learn the parts of the guitar and get you comfortable with your instrument.

Getting Started: Fundamental Guitar Skills
    -In this lesson, you will learn how to tune and you will start playing your instrument from the ground up! Be patient and remember: focus on being accurate and play in consistent time with your metronome. These things are far more important than playing with speed.

The Twelve Half Steps and Basic Notation
    -While you don’t need to be an expert on music theory to play guitar, it is important to know the basic building blocks of music. With this understanding, music will no longer be shrouded in mystery or complexity. This lesson presents fundamental musical ideas in a fun, non-intimidating way.

Scales: Construction and Fingerings
    -In this lesson, you will dig into scales. Don’t be intimidated. Some of you may have heard of, or practiced, scales. It might have been during piano lessons. Most likely it wasn’t very exciting for you. Hopefully you'll find the approach to scales in lesson 4 much easier and even fun. 

Chords: Building Easy Triads and Power Chords
    -In this lesson, you will use all of the skills you’ve gained from the previous lessons to build the foundation of harmony. You will play certain scale notes at the same time to create chords. Let's look at why chords sound like they do, how to build them, how to easily play chords in open position, and how to play chords that you can move all around the neck.

Putting it All Together: The Pentatonic Scale and Songs
    -Now that you have the ""science"" of the guitar in your fingers, you will learn a couple of songs. You will do this by using melody (from the scales) and harmony (from the chords) we have learned. You will also learn an essential scale for playing melodies and soloing.",Guitar for Beginners
https://www.classcentral.com/course/edx-microsoft-professional-capstone-data-science-6422,"Showcase the knowledge and skills you've acquired during the Microsoft Professional Program for Data Science, and solve a real-world data science problem in this program capstone project. The project takes the form of a challenge in which you will explore a dataset and develop a machine learning solution that is tested and scored to determine your grade.

edX offers financial assistance for learners who want to earn Verified Certificates but who may not be able to pay the fee. To apply for financial assistance, enroll in the course, then follow this link to complete an application for assistance.[ 
](https://www.edx.org/microsoft-professional-program-data-science)",Microsoft Professional Capstone : Data Science
https://www.classcentral.com/course/edx-introduction-to-health-and-wellness-4069,"This course is part of Global Freshman Academy (GFA), which means you can earn transferable ASU credit toward your college degree.
This 3 credit health and wellness course focuses on the latest trends in health, nutrition, physical activity, and wellness. From stress management and sleep to overall wellbeing, we will explore personal health, health related attitudes and beliefs, and individual health behaviors.
Topics include:

Assessment of one’s personal health
Introduction to population health and national and global health goals
Dietary choices for lifelong health
Improving personal fitness
Achieving and maintaining a healthy weight
Assessing health information
Managing stress
Sleep hygiene
Lowering risk of infectious diseases
Chronic disease risk reduction

This course satisfies the Social-Behavioral Sciences (SB) general studies requirement at Arizona State University. This course may satisfy a general education requirement at other institutions; however, it is strongly encouraged that you consult with your institution of choice to determine how these credits will be applied to their degree requirements prior to transferring the credit.Student Testimonials“Excellent course, well organized, very useful information. I have been very impressed with ASU courses and this one is no exception. It is an important topic, relevant to everyone and presents good science to base decisions on. I am happy to be taking this course.” -Abeer Kazi“The Course content is detailed and very useful towards my line of work especially in terms of nutrition and personal assessment.” -Winnie NakiyingiMore reviews on CourseTalk



            Read more
          



          Click to view the complete course syllabus here.",Introduction to Health and Wellness
https://www.classcentral.com/course/stanford-openedx-writing-in-the-sciences-1183,"This course teaches scientists to become more effective writers, using practical examples and exercises. Topics include: principles of good writing, tricks for writing faster and with less anxiety, the format of a scientific manuscript, and issues in publication and peer review. Students from non-science disciplines can benefit from the training provided in the first four weeks (on general principles of effective writing).



In the first four weeks, we will review principles of effective writing, examples of good and bad writing, and tips for making the writing process easier. In the second four weeks, we will examine issues specific to scientific writing, including: authorship, peer review, the format of an original manuscript, and communicating science for lay audiences. Students will watch video lectures, complete quizzes and editing exercises, write two short papers, and edit each others’ work.
Week 1 - Introduction; principles of effective writing (cutting unnecessary clutter)Week 2 - Principles of effective writing (verbs)Week 3 - Crafting better sentences and paragraphsWeek 4 - Organization; and streamlining the writing processWeek 5 - The format of an original manuscriptWeek 6 - Reviews, commentaries, and opinion pieces; and the publication processWeek 7 - Issues in scientific writing (plagiarism, authorship, ghostwriting, reproducible research)Week 8 - How to do a peer review; and how to communicate with the lay public",Writing in the Sciences
https://www.classcentral.com/course/problem-solving-programming-video-games-11500,"This course is an introduction to computer science and programming in Python.  Upon successful completion of this course, you will be able to:

1.  Take a new computational problem and develop a plan to solve it through problem understanding and decomposition.
2.  Follow a design creation process that includes specifications, algorithms, and testing.
3.  Code, test, and debug a program in Python, based on your design.

Important computer science concepts such as problem solving (computational thinking), problem decomposition, algorithms, abstraction, and software quality are emphasized throughout.  The Python programming language and video games are used to demonstrate computer science concepts in a concrete and fun manner.  However, a learner can take the knowledge and skills from this course and apply them to non-game problems, other programming languages, and other computer science courses.

You do not need any previous programming, Python, or video game experience.  However, some computer skills (e.g., mouse, keyboard, document editing), knowledge of algebra, attention to detail (as with many technical subjects), and a “just give it a try” spirit will be keys to your success.  Despite the use of video games for all the programming examples, PVG is not about computer games.  PVG will still provide valuable knowledge and skills for non-game computational problems.

The interactive learning objects (ILO) of the course provide automatic, context-specific guidance and feedback, like a virtual teaching assistant, as you develop problem descriptions, algorithms, and functional test plans.  The course forums will be supported by the creators of the course, to help you succeed.

All videos, assessments, and ILOs are available free of charge.  There is an optional certificate available for a fee.
      


            Read more
          



          Module 0: Introduction
    -In Module 0, you will meet the instructional team and be introduced to the four themes of this course: computer science, problem solving, Python programming, and how to create video games.

Module 1: Design Hacking Version 1
    -In Module 1, you will explore the game creation process that is used in this course. You will use this process to design Version 1 of the first game, Hacking. You will use two problem-solving techniques: problem decomposition and algorithms. You will explore five criteria for problem decomposition: experiential decomposition, feature selection, problem refinement, spatial decomposition, and temporal decomposition. To create your design for Hacking Version 1, you will use three interactive learning objects: the description builder, functional test plan builder, and algorithm builder.

Module 2: Program Hacking Version 1
    -In Module 2, you will discover how lexics, syntax, and semantics can be used to understand and describe programming languages. You will use these concepts to understand your first Python statement (expression statement), first three Python expressions (literal, identifier, function call), and first five Python types (int, str, float, function, NoneType). You will use these Python constructs to write, test, and debug Hacking Version 1, a text-based game version. You will then reflect on your game version by using a third problem-solving technique called abstraction, including the specific technique of solution generalization, to solve similar problems.

Module 3: Hacking Version 2
    -In Module 3, you will identify solution issues in your game. You will apply a second form of the abstraction problem-solving technique, called using templates, to solve a solution issue by using a graphics library. You will then use lexics, syntax, and semantics to learn two new Python statements (assignment, import), two new Python expressions (binary expression, attribute reference), and one new Python type (module). You will employ these Python constructs and a simple graphics library to write, test, and debug Hacking Version 2.

Module 4: Hacking Version 3
    -In Module 4, you will modify your game design to support multiple gameplay paths using a new problem decomposition criteria called case-based decomposition, which utilizes a selection control structure. You will learn one new Python statement (if), one new Python expression (unary expression), and one new Python type (bool). You will employ these Python constructs to write, test, and debug Hacking Version 3.

Module 5: Hacking Version 4 & 5
    -
In Module 5, you will modify your game design using two new abstraction techniques, called control abstraction and data abstraction. You will explore two different control abstractions, called definite and indefinite repetition. You will learn two new Python statements (for, while), four new Python expressions (subscription expression, expression list, parenthesized expression, list display), and three new Python types (tuple, list, range). You will employ these Python constructs to write, test, and debug Hacking Version 4 and Hacking Version 5.


Module 6: Hacking Version 6
    -In Module 6, you will learn a new control abstraction called a user-defined function. You will learn how to implement user-defined functions using two new Python statements (function definition, return). You will employ these Python constructs to significantly improve the quality of your code in Hacking Version 6.

Module 7: Hacking Version 7
    -In Module 7, you will not learn any new problem-solving techniques or Python language features. Instead you will exercise your problem-solving skills and practice the language constructs you already know to improve your proficiency. You will add some fun features to the Hacking game by designing, coding, testing, and debugging Hacking Version 7.

Module 8: Poke the Dots Version 1 & 2
    -In Module 8, you will design and implement Version 1 of a new graphical game called Poke the Dots. You will then modify your game design using data abstraction to create user-defined classes. You will learn two new Python statements (class definition, pass) that will allow you to construct your own Python types. You will employ these Python constructs to implement Poke the Dots Version 2.

Module 9: Poke the Dots Version 3
    -In Module 9, you will not learn any new problem-solving techniques or Python language features. Instead you will exercise your problem-solving skills and practice the language constructs you already know to improve your proficiency. You will add some fun features to the Poke the Dots game by designing, coding, testing, and debugging Poke the Dots Version 3.

Module 10: Poke the Dots Version 4
    -In Module 10, you will modify your game design using a new form of control abstraction called user-defined methods. User-defined methods allow you to restrict access to the attributes of a class to improve data abstraction. You will employ user-defined methods to implement Poke the Dots Version 4.

Module 11: Poke the Dots Version 5
    -In Module 11, you will not learn any new problem-solving techniques or Python language features. Instead you will exercise your problem-solving skills and practice the language constructs you already know to improve your proficiency. You will add some fun features to the Poke the Dots game by designing, coding, testing, and debugging Poke the Dots Version 5.","Problem Solving, Python Programming, and Video Games"
https://www.classcentral.com/course/ml-classification-4219,"Case Studies: Analyzing Sentiment & Loan Default Prediction

In our case study on analyzing sentiment, you will create models that predict a class (positive/negative sentiment) from input features (text of the reviews, user profile information,...).  In our second case study for this course, loan default prediction, you will tackle financial data, and predict when a loan is likely to be risky or safe for the bank. These tasks are an examples of classification, one of the most widely used areas of machine learning, with a broad array of applications, including ad targeting, spam detection, medical diagnosis and image classification. 

In this course, you will create classifiers that provide state-of-the-art performance on a variety of tasks.  You will become familiar with  the most successful techniques, which are most widely used in practice, including logistic regression, decision trees and boosting.  In addition, you will be able to design and implement the underlying algorithms that can learn these models at scale, using stochastic gradient ascent.  You will implement these technique on real-world, large-scale machine learning tasks.  You will also address significant tasks you will face in real-world applications of ML, including handling missing data and measuring precision and recall to evaluate a classifier.  This course is hands-on, action-packed, and full of visualizations and illustrations of how these techniques will behave on real data.  We've also included optional content in every module, covering advanced topics for those who want to go even deeper! 

Learning Objectives: By the end of this course, you will be able to:
   -Describe the input and output of a classification model.
   -Tackle both binary and multiclass classification problems.
   -Implement a logistic regression model for large-scale classification.  
   -Create a non-linear model using decision trees.
   -Improve the performance of any model using boosting.
   -Scale your methods with stochastic gradient ascent.
   -Describe the underlying decision boundaries.  
   -Build a classification model to predict sentiment in a product review dataset.  
   -Analyze financial data to predict loan defaults.
   -Use techniques for handling missing data.
   -Evaluate your models using precision-recall metrics.
   -Implement these techniques in Python (or in the language of your choice, though Python is highly recommended).
      


            Read more
          



          Welcome!
    -Classification is one of the most widely used techniques in machine learning, with a broad array of applications, including sentiment analysis, ad targeting, spam detection, risk assessment, medical diagnosis and image classification. The core goal of classification is to predict a category or class y from some inputs x. Through this course, you will become familiar with the fundamental models and algorithms used in classification, as well as a number of core machine learning concepts. Rather than covering all aspects of classification, you will focus on a few core techniques, which are widely used in the real-world to get state-of-the-art performance. By following our hands-on approach, you will implement your own algorithms on multiple real-world tasks, and deeply grasp the core techniques needed to be successful with these approaches in practice. This introduction to the course provides you with an overview of the topics we will cover and the background knowledge and resources we assume you have.

Linear Classifiers & Logistic Regression
    -Linear classifiers are amongst the most practical classification methods. For example, in our sentiment analysis case-study, a linear classifier associates a coefficient with the counts of each word in the sentence. In this module, you will become proficient in this type of representation. You will focus on a particularly useful type of linear classifier called logistic regression, which, in addition to allowing you to predict a class, provides a probability associated with the prediction. These probabilities are extremely useful, since they provide a degree of confidence in the predictions. In this module, you will also be able to construct features from categorical inputs, and to tackle classification problems with more than two class (multiclass problems). You will examine the results of these techniques on a real-world product sentiment analysis task.

Learning Linear Classifiers
    -Once familiar with linear classifiers and logistic regression, you can now dive in and write your first learning algorithm for classification. In particular, you will use gradient ascent to learn the coefficients of your classifier from data. You first will need to define the quality metric for these tasks using an approach called maximum likelihood estimation (MLE). You will also become familiar with a simple technique for selecting the step size for gradient ascent. An optional, advanced part of this module will cover the derivation of the gradient for logistic regression.  You will implement your own learning algorithm for logistic regression from scratch, and use it to learn a sentiment analysis classifier.

Overfitting & Regularization in Logistic Regression
    -As we saw in the regression course, overfitting is perhaps the most significant challenge you will face as you apply machine learning approaches in practice. This challenge can be particularly significant for logistic regression, as you will discover in this module, since we not only risk getting an overly complex decision boundary, but your classifier can also become overly confident about the probabilities it predicts. In this module, you will investigate overfitting in classification in significant detail, and obtain broad practical insights from some interesting visualizations of the classifiers' outputs. You will then add a regularization term to your optimization to mitigate overfitting. You will investigate both L2 regularization to penalize large coefficient values, and L1 regularization to obtain additional sparsity in the coefficients. Finally, you will modify your gradient ascent algorithm to learn regularized logistic regression classifiers. You will implement your own regularized logistic regression classifier from scratch, and investigate the impact of the L2 penalty on real-world sentiment analysis data.

Decision Trees
    -Along with linear classifiers, decision trees are amongst the most widely used classification techniques in the real world. This method is extremely intuitive, simple to implement and provides interpretable predictions. In this module, you will become familiar with the core decision trees representation. You will then design a simple, recursive greedy algorithm to learn decision trees from data. Finally, you will extend this approach to deal with continuous inputs, a fundamental requirement for practical problems. In this module, you will investigate a brand new case-study in the financial sector: predicting the risk associated with a bank loan. You will implement your own decision tree learning algorithm on real loan data.

Preventing Overfitting in Decision Trees
    -Out of all machine learning techniques, decision trees are amongst the most prone to overfitting. No practical implementation is possible without including approaches that mitigate this challenge. In this module, through various visualizations and investigations, you will investigate why decision trees suffer from significant overfitting problems. Using the principle of Occam's razor, you will mitigate overfitting by learning simpler trees. At first, you will design algorithms that stop the learning process before the decision trees become overly complex. In an optional segment, you will design a very practical approach that learns an overly-complex tree, and then simplifies it with pruning. Your implementation will investigate the effect of these techniques on mitigating overfitting on our real-world loan data set. 

Handling Missing Data
    -Real-world machine learning problems are fraught with missing data. That is, very often, some of the inputs are not observed for all data points. This challenge is very significant, happens in most cases, and needs to be addressed carefully to obtain great performance. And, this issue is rarely discussed in machine learning courses. In this module, you will tackle the missing data challenge head on. You will start with the two most basic techniques to convert a dataset with missing data into a clean dataset, namely skipping missing values and inputing missing values. In an advanced section, you will also design a modification of the decision tree learning algorithm that builds decisions about missing data right into the model. You will also explore these techniques in your real-data implementation.  

Boosting
    -One of the most exciting theoretical questions that have been asked about machine learning is whether simple classifiers can be combined into a highly accurate ensemble. This question lead to the developing of boosting, one of the most important and practical techniques in machine learning today. This simple approach can boost the accuracy of any classifier, and is widely used in practice, e.g., it's used by more than half of the teams who win the Kaggle machine learning competitions. In this module, you will first define the ensemble classifier, where multiple models vote on the best prediction. You will then explore a boosting algorithm called  AdaBoost, which provides a great approach for boosting classifiers. Through visualizations, you will become familiar with many of the practical aspects of this techniques. You will create your very own implementation of AdaBoost, from scratch, and use it to boost the performance of your loan risk predictor on real data. 

Precision-Recall
    -In many real-world settings, accuracy or error are not the best quality metrics for classification. You will explore a case-study that significantly highlights this issue: using sentiment analysis to display positive reviews on a restaurant website. Instead of accuracy, you will define two metrics: precision and recall, which are widely used in real-world applications to measure the quality of classifiers. You will explore how the probabilities output by your classifier can be used to trade-off precision with recall, and dive into this spectrum, using precision-recall curves. In your hands-on implementation, you will compute these metrics with your learned classifier on real-world sentiment analysis data.

Scaling to Huge Datasets & Online Learning
    -With the advent of the internet, the growth of social media, and the embedding of sensors in the world, the magnitudes of data that our machine learning algorithms must handle have grown tremendously over the last decade. This effect is sometimes called ""Big Data"". Thus, our learning algorithms must scale to bigger and bigger datasets. In this module, you will develop a small modification of gradient ascent called stochastic gradient, which provides significant speedups in the running time of our algorithms. This simple change can drastically improve scaling, but makes the algorithm less stable and harder to use in practice. In this module, you will investigate the practical techniques needed to make stochastic gradient viable, and to thus to obtain learning algorithms that scale to huge datasets. You will also address a new kind of machine learning problem, online learning, where the data streams in over time, and we must learn the coefficients as the data arrives. This task can also be solved with stochastic gradient. You will implement your very own stochastic gradient ascent algorithm for logistic regression from scratch, and evaluate it on sentiment analysis data.",Machine Learning: Classification
https://www.classcentral.com/course/material-behavior-5944,"Have you ever wondered why ceramics are hard and brittle while metals tend to be ductile?  Why some materials conduct heat or electricity while others are insulators?  Why adding just a small amount of carbon to iron results in an alloy that is so much stronger than the base metal?  In this course, you will learn how a material’s properties are determined by the microstructure of the material, which is in turn determined by composition and the processing that the material has undergone.

This is the first of three Coursera courses that mirror the Introduction to Materials Science class that is taken by most engineering undergrads at Georgia Tech.  The aim of the course is to help students better understand the engineering materials that are used in the world around them.  This first section covers the fundamentals of materials science including atomic structure and bonding, crystal structure, atomic and microscopic defects, and noncrystalline materials such as glasses, rubbers, and polymers.
      


          Introduction [Difficulty: Easy || Student Effort: 1hr 30mins]
    -This module will introduce the core principles of materials science.  Topics that will be covered include the different general material types (metal, ceramic, polymer, etc.) and the properties associated with each type, some methods that are used to experimentally determine and quantify a material's properties, and how a materials engineer might go about choosing a suitable material for a simple application.  This module also introduces the concept of the microstructure-processing-properties relationship which is at the heart of all materials science. 

Atomic Structure and Bonding [Difficulty: Easy || Student Effort: 2hrs]
    -In this module, we will discuss the structure of the atom, how atoms interact with each other, and how those interactions affect material properties.  We will explore how the types of atoms present in a material determine what kind of bonding occurs, what differentiates the three types of primary bonds - metallic, ionic, and covalent, and the implications of the type of bonding on the material microstructure.  You will learn how atoms arrange themselves as a natural result of their size and bonding.  This knowledge will provide you with a foundation for understanding the relationship between a material's microstructure and its properties. 

Crystalline Structure [Level of Difficulty: Medium || Student Effort: 2hrs 30mins]
    -This module covers how atoms are arranged in crystalline materials.  Many of the materials that we deal with on a daily basis are crystalline, meaning that they are made up of a regularly repeating array of atoms.  The ""building block"" of a crystal, which is called the Bravais lattice, dtermines some of the physical properties of a material.  An understanding of these crystallographic principles will be vital to discussions of defects and diffusion, which are covered in the next module. 

Point Defects and Diffusion [Level of Difficulty: Medium || Student Effort: 2hrs 30mins]
    -In the previous module, we learned how the lattice structure of a crystalline material in part determines the properties of that material.  In this module, we will begin to learn how defects - deviations from the expected microstructure - also have a large effect on properties.  This module covers one-dimensional, or point, defects which can be missing atoms (vacancies) or excess atoms (interstitial solution) or the wrong type of atom at a lattice point (substitutional solution).  Building on these concepts, part of this module will cover diffusion - the movement of atoms through the crystal structure. 

Linear, Planar, and Volumetric Defects [Level of Difficulty: Medium || Student Effort: 2hrs 40mins]
    -This module covers two- and three-dimensional defects such as dislocations, grain boundaries, and precipitates.  The discussion extends to explain how deformation of a material is accommodated at the microscopic level.  We will finish by addressing how the presence and properties of defects can increase or decrease the strength of a material.

Noncrystalline and Semicrystalline Materials [Level of Difficulty: Medium || Student Effort: 2hrs 30mins]
    -In this module, we discuss materials that are not fully crystalline, such as polymers, rubbers, and glasses.  You will learn how the absence of crystallinity affects the behavior of these materials and what factors affect their formation and properties.  Lessons include discussions of the microstructure and defects in amorphous materials, partial cystallinity in polymers, and demonstrations of materials exhibiting ductile and brittle behavior at different temperatures.",Material Behavior
https://www.classcentral.com/course/edx-programming-in-scratch-2954,"“Although many of the programs designed to teach kids to code are very simplistic, many of them, like Scratch, are suitable for all ages. It doesn't matter how old you are…Get started with the basics of programming!” -Lifehacker
Want to learn computer programming, but unsure where to begin? This is the course for you! Scratch is the computer programming language that makes it easy and fun to create interactive stories, games and animations and share them online.
This course is an introduction to computer science using the programming language Scratch, developed by MIT. Starting with the basics of using Scratch, the course will stretch your mind and challenge you. You will learn how to create amazing games, animated images and songs in just minutes with a simple “drag and drop” interface.
No previous programming knowledge needed. Join us as you start your computer science journey.
This material is based upon work supported by the National Science Foundation under Grant No. 1044106. Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation (NSF).",Programming in Scratch
https://www.classcentral.com/course/qualitativemethods-2739,"In this course you will be introduced to the origin and philosophies behind the qualitative approach to empirical science. You will learn about data collection, description, analysis and interpretation in qualitative research. The qualitative approach often involves an iterative process. We will focus on the basic ingredients required for this process: data collection and analysis. A good qualitative analysis consists of a general strategy of analysis, clear analytic 'actions' and documentation of all the steps taken. An important analytical action is coding parts of the material. This forms the basis for the categorisation and interpretation of the data. In this course you will learn to use statistical software to perform the qualitative analysis. We will also discuss and compare different types of analysis and interpretation. The most important concepts in qualitative analysis will be discussed in light of these different types.



          The qualitative approach to empirical science has its own origin story and is associated with a different philosophy of science than the quantitative approach. In this course you will learn about the qualitative way of thinking, but also about data collection, description, analysis and interpretation in qualitative research. You will gain hands on experience with interviewing and observation and practice analysis of this type of data using statistical software.Week 1: Introduction •	introduction to qualitative methods •	philosophy of science •	differences between qualitative versus quantitative approaches•	mixed-methods•	warm-up assignments (not graded)Week 2: Qualitative traditions •	history of qualitative methods •	introduction to ethnography•	research design in ethnography•	quiz and small assignment (graded)Week 3: Observation and field notes •	access and role of the researcher•	field notes•	sampling •	quiz and paper on week 1 & 2 (graded)Week 4: Organization and analysis•	recording data•	organzing data •	analysis of observational data•	quiz and small assignment (graded)Week 5: Interviewing•	difference between structured and qualitative interview •	interviewing versus observation•	asking questions•	quiz and paper on week 3 & 4 (graded)Week 6: Data analysis•	content analysis•	analytical induction•	grounded theory•	quiz and small assignment (graded)Week 7: Study week•	time to ask your final questions•	time to work on last paperWeek 8: Exam week•	paper on week 5 & 6 (graded), final exam (graded) and course evaluation",Qualitative Research Methods
https://www.classcentral.com/course/clinical-data-models-and-data-quality-as-12839,"This course aims to teach the concepts of clinical data models and common data models. Upon completion of this course, learners will be able to interpret and evaluate data model designs using Entity-Relationship Diagrams (ERDs), differentiate between data models and articulate how each are used to support clinical care and data science, and create SQL statements in Google BigQuery to query the MIMIC3 clinical data model and the OMOP common data model.
      


          Introduction: Clinical Data Models and Common Data Models
    -This week describes clinical data models and explains the need for and use of common data models in national and international data networks.  We will also cover the features of Entity-Relationship Diagrams (ERDs) to describe the key technical features of data models. 

Tools: Querying Clinical Data Models
    -We take a deep dive into the technical features of clinical data models using MIMIC3 as our example and research common data models using OMOP as our example.

Techniques: Extract-Transform-Load and Terminology Mapping
    -This module teaches learners about the processes and challenges with extracting, transforming and loading (ETL) data with real-world examples in data and terminology mapping. 


Techniques: Data Quality Assessments
    -We explore the dimensions of data quality by reviewing its challenges, data quality measurements used to measure it, and data quality rules to assess its acceptability for use.

Practical Application: Create an ETL Process to Transform a MIMIC-III Table to OMOP
    -In this module, you gather everything you’ve learned to complete a real-world hands-on exercise using ETL methods to convert MIMIC3 data into the OMOP common data model.",Clinical Data Models and Data Quality Assessments
https://www.classcentral.com/course/canvas-network-python-programming-for-everybody-8869,"This course is an introduction to programming in Python using the textbook Python for Everybody. This course assumes no previous programming, math, or other experience. The course covers the first 10 chapters of the textbook and included basics of program logic and simple data structures. The focus on the course is simple data analysis. When students complete the course, they will be well prepared to take other more challenging introductory programming courses.",Python Programming for Everybody
https://www.classcentral.com/course/data-public-health-8921,"Epidemiology is often described as the cornerstone science in public health. Epidemiology in public health practice uses study design and analyses to identify causes in an outbreak situation, guides interventions to improve population health, and evaluates programs and policies.

In this course, we'll define the role of the professional epidemiologist as it relates to public health services, functions, and competencies. With that foundation in mind, we'll introduce you to the problem solving methodology and demonstrate how it can be used in a wide variety of settings to identify problems, propose solutions, and evaluate interventions. This methodology depends on the use of reliable data, so we'll take a deep dive into the routine and public health data systems that lie at the heart of epidemiology and then conclude with how you can use that data to calculate measures of disease burden in populations.
      


          Introduction and Problem-Solving Methodology
    -In this module, we will introduce the problem solving methodology. This methodology is a powerful tool that can useful when identifying a public health problem, building the case that there truly is a problem, suggesting interventions, and suggestions ways to evaluate the interventions and disseminate the findings of the evaluation.

Data Sources in Public Health
    -In this module, we dive deeper into what lies at the heart of epidemiology: data! More specifically, we will look at routine and public health data systems. 

Measures of Disease Burden
    -In this module we will use data from routine and public health information systems to measure the burden of disease in the population. We will calculate crude mortality rates, and then apply direct and indirect age standardization methods. 

Health Indicators 
    -In this module, we'll discuss health indicators, which are important measurements of the health of a population. There are numerous health indicators that help us paint the picture of a populations health. We'll talk about characteristics of good health indicators to provide a little guidance on how to choose health indicators for the public health problem of interest. Then, we'll use the example of the health indicator of liver cancer incidence to explore descriptive epidemiology. We will stratify liver cancer incidence by person, place, and time, to build our skills in descriptive epidemiology.",Data and Health Indicators in Public Health Practice
https://www.classcentral.com/course/causal-inference-2-13095,"This course offers a rigorous mathematical survey of advanced topics in causal inference at the Master’s level.

Inferences about causation are of great importance in science, medicine, policy, and business.  This course provides an introduction to the statistical literature on causal inference that has emerged in the last 35-40 years and that has revolutionized the way in which statisticians and applied researchers in many disciplines use data to make inferences about causal relationships.  

We will study advanced topics in causal inference, including mediation, principal stratification, longitudinal causal inference, regression discontinuity, interference, and fixed effects models.
      


          Module 7: Introduction to Mediation

Module 8: More on Mediation

Module 9: Instrumental Variables, Principal Stratification, and Regression Discontinuity																										

Module 10: Longitudinal Causal Inference																										

Module 11: Interference and Fixed Effects",Causal Inference  2
https://www.classcentral.com/course/edx-quantitative-biology-workshop-1984,"Do you have an interest in biology and quantitative tools? Do you know computational methods but do not realize how they apply to biological problems? Do you know biology but do not understand how scientists really analyze complicated data? 7.QBWx: Quantitative Biology Workshop is designed to give learners exposure to the application of quantitative tools to analyze biological data at an introductory level. The Biology Department of MIT has run this workshop-style course as part of a one-week outreach program for students from other universities. With 7.QBWx, we can give more learners from around the world the chance to discover quantitative biology. We hope that this series of workshops encourages learners to explore new interests and take more biology and computational courses.
We expect that learners from 7.00x Introduction to Biology - The Secret of Life or an equivalent course can complete this workshop-based course without a background in programming. The course content will introduce programming languages but will not teach any one language in a comprehensive manner. The content of each week varies. We want learners to have an introduction to multiple languages and tools to find a topic that they would want to explore more. We recommend that learners try to complete each week to find what interests them the most. 
This workshop includes activities on the following biological topics: population biology, biochemical equilibrium and kinetics, molecular modeling of enzymes, visual neuroscience, global and single-cell gene expression, development, and genomics. The tools and programming languages include MATLAB, PyMOL, Python, and R. This course does not require learners to download MATLAB. All MATLAB activities run and are graded within the edX platform. We do recommend that participants download a few other free tools for the activities so that they learn how to use the same tools and programs that scientists use.
Workshop Content Creators and Residential Leaders
Gregory Hale, Michael Goard, Ben Stinson, Kunle Demuren, Sara Gosline, Glenna Foight, Leyla Isik, Samir El-Boustani, Gerald Pho, and Rajeev Rikhye
Residential Outreach Workshop Organizer and Creator
Mandana Sassanfar



            Read more",Quantitative Biology Workshop
https://www.classcentral.com/course/css-capstone-17985,"CONGRATULATIONS! Not only did you accomplish to finish our intellectual tour de force, but, by now, you also already have all required skills to execute a comprehensive multi-method workflow of computational social science. We will put these skills to work in this final integrative lab, where we are bringing it all together. We scrape data from a social media site (drawing on the skills obtained in the 1st course of this specialization). We then analyze the collected data by visualizing the resulting networks (building on the skills obtained in the 3rd course). We analyze some key aspects of it in depth, using machine learning powered natural language processing (putting to work the insights obtained during the 2nd course). Finally, we use a computer simulation model to explore possible generative mechanism and scrutinize aspects that we did not find in our empirical reality, but that help us to improve this aspect of society (drawing on the skills obtained during the 4th course of this specialization). The result is the first glimpse at a new way of doing social science in a digital age: computational social science. Congratulations! Having done all of this yourself, you can consider yourself a fledgling computational social scientist!
      


          Getting Started and Milestone 1
    -For this milestone, you will again web scrape videos from two YouTube channels. You will be assigned two channels to scrape. In contrast to the previous version of this exercise, you will NOT scrape the featured videos of the specified news channel, but the search results of the name of the news channel in combination with your name.

Milestone 2: Social Network Analysis
    -In this milestone, you will analyze a social network with help of the software Gephi.

Milestone 3: Natural Language Processing
    -In this milestone of our Integrative Lab, you will select two of the key videos identified with help of our SNA, and analyze the sentiment and emotions contained in the comment sections of the videos. We use NLP from IBM Watson for this.

Milestone 4: Agent-Based Computer Simulations
    -In this milestone, you will take all the data you created in the previous milestones and use a two-step flow model and discover how ideas can diffuse into society. Through this exercise you will grow your own artificial society from the bottom-up.",Computational Social Science Capstone Project
https://www.classcentral.com/course/nand2tetris2-8025,"In this project-centered course you will build a modern software hierarchy, designed to enable the translation and execution of object-based, high-level languages on a bare-bone computer hardware platform. In particular, you will implement a virtual machine and a compiler for a simple, Java-like programming language, and you will develop a basic operating system that closes gaps between the high-level language and the underlying hardware platform. In the process, you will gain a deep, hands-on understanding of numerous topics in applied computer science, e.g. stack processing, parsing, code generation, and classical algorithms and data structures for memory management, vector graphics, input-output handling, and various other topics that lie at the very core of every modern computer system.

This is a self-contained course: all the knowledge necessary to succeed in the course and build the various systems will be given as part of the learning experience. The only prerequisite is knowledge of programming at the level acquired in introduction to computer science courses. All the software tools and materials that are necessary to complete the course will be supplied freely after you enrol in the course.

This course is accompanied by the textbook ""The Elements of Computing Systems"" (Nisan and Schocken, MIT Press). While not required for taking the course, the book provides a convenient coverage of all the course topics. The book is available in either hardcopy or ebook form, and MIT Press is offering a 30% discount off the cover price by using the discount code MNTT30 at https://mitpress.mit.edu/books/elements-computing-systems. 

The course consists of six modules, each comprising a series of video lectures, and a project. You will need about 2-3 hours to watch each module's lectures, and about 15 hours to complete each one of the six projects. The course can be completed in six weeks, but you are welcome to take it at your own pace. You can watch a TED talk about this course by Googling ""nand2tetris TED talk"". 

*About Project-Centered Courses: Project-centered courses are designed to help you complete a personally meaningful real-world project, with your instructor and a community of learners with similar goals providing guidance and suggestions along the way. By actively applying new concepts as you learn, you’ll master the course content more efficiently; you’ll also get a head start on using the skills you gain to make positive changes in your life and career. When you complete the course, you’ll have a finished project that you’ll be proud to use and share.
      


            Read more
          



          Getting Started

Machine Language

Virtual Machine I: Stack Arithmetic

Virtual Machine II: Program Control

High-Level Language

Compiler I: Syntax Analysis

Compiler II: Code Generation

Operating System

Postscript: More Fun to Go",Build a Modern Computer from First Principles: Nand to Tetris Part II (project-centered course)
https://www.classcentral.com/course/canvas-network-earth-s-environment-soil-water-and-air-9467,"This course is part of the Introduction to Environmental Science open course series. ""Earth's Environment: Soil, Water, and Air"" provides an introduction to environmental science, environmental literacy and the scientific process.  It explores the challenges of many of the environmental problems that we face today and examines potential solutions.","Earth's Environment: Soil, Water, and Air"
https://www.classcentral.com/course/nand2tetris2-8025,"In this project-centered course you will build a modern software hierarchy, designed to enable the translation and execution of object-based, high-level languages on a bare-bone computer hardware platform. In particular, you will implement a virtual machine and a compiler for a simple, Java-like programming language, and you will develop a basic operating system that closes gaps between the high-level language and the underlying hardware platform. In the process, you will gain a deep, hands-on understanding of numerous topics in applied computer science, e.g. stack processing, parsing, code generation, and classical algorithms and data structures for memory management, vector graphics, input-output handling, and various other topics that lie at the very core of every modern computer system.

This is a self-contained course: all the knowledge necessary to succeed in the course and build the various systems will be given as part of the learning experience. The only prerequisite is knowledge of programming at the level acquired in introduction to computer science courses. All the software tools and materials that are necessary to complete the course will be supplied freely after you enrol in the course.

This course is accompanied by the textbook ""The Elements of Computing Systems"" (Nisan and Schocken, MIT Press). While not required for taking the course, the book provides a convenient coverage of all the course topics. The book is available in either hardcopy or ebook form, and MIT Press is offering a 30% discount off the cover price by using the discount code MNTT30 at https://mitpress.mit.edu/books/elements-computing-systems. 

The course consists of six modules, each comprising a series of video lectures, and a project. You will need about 2-3 hours to watch each module's lectures, and about 15 hours to complete each one of the six projects. The course can be completed in six weeks, but you are welcome to take it at your own pace. You can watch a TED talk about this course by Googling ""nand2tetris TED talk"". 

*About Project-Centered Courses: Project-centered courses are designed to help you complete a personally meaningful real-world project, with your instructor and a community of learners with similar goals providing guidance and suggestions along the way. By actively applying new concepts as you learn, you’ll master the course content more efficiently; you’ll also get a head start on using the skills you gain to make positive changes in your life and career. When you complete the course, you’ll have a finished project that you’ll be proud to use and share.
      


            Read more
          



          Getting Started

Machine Language

Virtual Machine I: Stack Arithmetic

Virtual Machine II: Program Control

High-Level Language

Compiler I: Syntax Analysis

Compiler II: Code Generation

Operating System

Postscript: More Fun to Go",Build a Modern Computer from First Principles: Nand to Tetris Part II (project-centered course)
https://www.classcentral.com/course/edx-machine-learning-for-data-science-and-analytics-4912,"Machine Learning is a growing field that is used when searching the web, placing ads, credit scoring, stock trading and for many other applications.
This data science course is an introduction to machine learning and algorithms. You will develop a basic understanding of the principles of machine learning and derive practical solutions using predictive analytics. We will also examine why algorithms play an essential role in Big Data analysis.",Machine Learning for Data Science and Analytics
https://www.classcentral.com/course/accounting-data-analytics-python-17297,"This course focuses on developing Python skills for assembling business data. It will cover some of the same material from Introduction to Accounting Data Analytics and Visualization, but in a more general purpose programming environment (Jupyter Notebook for Python), rather than in Excel and the Visual Basic Editor. These concepts are taught within the context of one or more accounting data domains (e.g., financial statement data from EDGAR, stock data, loan data, point-of-sale data).
The first half of the course picks up where Introduction to Accounting Data Analytics and Visualization left off: using in an integrated development environment to automate data analytic tasks. We discuss how to manage code and share results within Jupyter Notebook, a popular development environment for data analytic software like Python and R. We then review some fundamental programming skills, such as mathematical operators, functions, conditional statements and loops using Python software. 
The second half of the course focuses on assembling data for machine learning purposes.  We introduce students to Pandas dataframes and Numpy for structuring and manipulating data. We then analyze the data using visualizations and linear regression. Finally, we explain how to use Python for interacting with SQL data.
      


          INTRODUCTION TO THE COURSE
    -In this module, you will become familiar with the course, your instructor and your classmates, and our learning environment. This orientation module will also help you obtain the technical skills required to navigate and be successful in this course.

MODULE 1: FOUNDATIONS
    -This module serves as the introduction to the course content and the course Jupyter server, where you will run your analytics scripts. First, you will read about specific examples of how analytics is being employed by Accounting firms. Next, you will learn about the capabilities of the course Jupyter server, and how to create, edit, and run notebooks on the course server. After this, you will learn how to write Markdown formatted documents, which is an easy way to quickly write formatted text, including descriptive text inside a course notebook.

MODULE 2: INTRODUCTION TO PYTHON
    -This module focuses on the basic features in the Python programming language that underlie most data analytics programs (or scripts). First, you will read about why accounting students should learn to write computer programs. In the first lesson, you will also learn the basic concepts of the Python programming language, including how to create variables, basic data types and mathematical operators, and how to document your programs with comments. Next, you will learn about Boolean and logical operators in Python and how they can be used to control the flow of a Python program by using conditional statements. Finally, you will learn about functions and how they can simplify developing and maintaining programs. You will also learn how to create and call functions in Python.

MODULE 3: INTRODUCTION TO PYTHON PROGRAMMING
    -In this module you will learn about working with fundamental data structures in Python: strings, tuples, lists, and dictionaries. You will also learn about how to write loops for performing repetitive tasks.

MODULE 4: PYTHON PROGRAMMING
    -In this module you will learn about creating and using modules, which is a group of functions. You will then learn about two of the most important modules for data analytics: NumPy and Pandas. NumPy performs numerical calculations on large data arrays. Pandas simplifies procedures for working with panel data, also known as dataframes.

MODULE 5: DATA ANALYSIS WITH PYTHON
    -This module focuses on using the Pandas dataframe to do some fundamental dataframe tasks including saving and reading dataframes, pivot table functions, filtering functions, and calculating descriptive statistics.


MODULE 6: INTRODUCTION TO VISUALIZATION IN PYTHON
    -In this module you will learn some basic elements of creating data visualizations in Python. You will then learn how to use the Matplotlib and Seaborn modules to help create some of the most commonly used one- and two-dimensional data visualizations.

MODULE 7: PRODUCTION DATA ANALYTICS
    -In this module you'll learn about the CRISP decision making framework to approach real-world problems. You'll also learn how to use linear regression to find and quantify relationships.

MODULE 8: INTRODUCTION TO DATABASES IN PYTHON
    -This module focuses on relational database management systems (RDBMS) and how to interact with those using Python.",Accounting Data Analytics with Python
https://www.classcentral.com/course/machine-learning-duke-12086,"This course will provide you a foundational understanding of machine learning models (logistic regression, multilayer perceptrons, convolutional neural networks, natural language processing, etc.) as well as demonstrate how these models can solve complex problems in a variety of industries, from medical diagnostics to image recognition to text prediction. In addition, we have designed practice exercises that will give you hands-on experience implementing these data science models on data sets. These practice exercises will teach you how to implement machine learning algorithms with TensorFlow, open source libraries used by leading tech companies in the machine learning field (e.g., Google, NVIDIA, CocaCola, eBay, Snapchat, Uber and many more).
      


          Simple Introduction to Machine Learning
    -The focus of this module is to introduce the concepts of machine learning with as little mathematics as possible. We will introduce basic concepts in machine learning, including logistic regression, a simple but widely employed machine learning (ML) method.  Also covered is multilayered perceptron (MLP), a fundamental neural network. The concept of deep learning is discussed, and also related to simpler models. 

Basics of Model Learning
    -In this module we will be discussing the mathematical basis of learning deep networks. We’ll first work through how we define the issue of learning deep networks as a minimization problem of a mathematical function. After defining our mathematical goal, we will introduce validation methods to estimate real-world performance of the learned deep networks. We will then discuss how gradient descent, a classical technique in optimization, can be used to achieve this mathematical goal. Finally, we will discuss both why and how stochastic gradient descent is used in practice to learn deep networks.

Image Analysis with Convolutional Neural Networks
    -This week will cover model training, as well as transfer learning and fine-tuning. In addition to learning the fundamentals of a CNN and how it is applied, careful discussion is provided on the intuition of the CNN, with the goal of providing a conceptual understanding.

Introduction to Natural Language Processing
    -This week will cover the application of neural networks to natural language processing (NLP), from simple neural models to the more complex. The fundamental concept of word embeddings is discussed, as well as how such methods are employed within model learning and usage for several NLP applications. A wide range of neural NLP models are also discussed, including recurrent neural networks, and specifically long short-term memory (LSTM) models.

Introduction to Reinforcement Learning
    -This week will cover Reinforcement Learning, a fundamental concept in machine learning  that is concerned with taking suitable actions to maximize rewards in a particular situation. After learning the initial  steps of Reinforcement Learning, we'll move to Q Learning, as well as Deep Q Learning. We'll discuss the difference between the concepts of Exploration and Exploitation and why they are important.",Introduction to Machine Learning
https://www.classcentral.com/course/youth-sports-6208,"Seventy percent of kids drop out of sports before their high school graduation. Only 15% leave because they feel they are not good enough. Almost 70% leave because they were not having fun, or due to problems with the coach. Injuries cause 30% to give up sports. This course is packed full of practical sports science information that provide youth coaches and parents with the practical pediatric sports science insights to successfully retain young athletes and develop their sport potential while avoiding injury and overtraining. We begin by examining the multidimensional nature of coaching, the relevant sport motor performance abilities, the impact of growth and development on motor skills, the gene versus practice controversy, and briefly overview the body structures strengthened through training. Then we explore the athlete's energy supply, where this energy comes from, and how it matures along with the athlete. Finally, we examine the development of strength, power, anaerobic capacity, coordination and flexibility through the life span.

The optional text manual for this course is available at: http://www.learnitez.com/HighPerformanceScience/manuals/
      


          Week 1: Introduction to the young athlete
    -Youth coaches who have a sound understanding of pediatric sports science are essential to the successful development of a young athlete’s sport potential. In this section you are introduced to the multidimensional nature of coaching, and how an athlete’s motor abilities of endurance, strength, speed, coordination and flexibility are affected by growth and maturation.The optional text manual for this course is available at:       http://www.learnitez.com/HighPerformanceScience/manuals/

Week 2: Strategies for maximizing the athlete’s potential 
    -Many factors can positively and negatively impact the young athlete’s ability to optimize their sports potential.  In this section we examine strategies for ensuring the athlete’s systematic long-term sports development and how to mold the correct sport-specific phenotype.

Week 3: How the body works
    -The coach is a microbiologist who designs training so it stimulates the body’s cells and structures to become stronger and more efficient. In this section you are introduced to key organ systems, and the energy these organ systems use to run the chemical reactions needed for a sports performance. You will also learn how diet can positively enhance an athlete’s ability to train and compete.

 Week 4: Enhancing the athlete’s physical work capacity
    -The level of expertise with which an athlete is able to perform sports skill depends on how well the coach molds the correct ratio of endurance, strength, power and speed to meet the demands of the sport. In this section you will learn the science behind developing these important motor performance abilities as the young athlete moves through puberty.

Week 5: Enhancing the fluidity of movement
    -Coordination and flexibility permit movements that are precise, fluid and spatially controlled. In this section we examine current knowledge about coordination and flexibility as the young child moves through early childhood and into adolescence.",The Science of Training Young Athletes
https://www.classcentral.com/course/scientist-9969,"On Being a Scientist  will provide you with an overview of scientific practice, what it means to be a scientist and allows you to become acquainted with academic conduct, thus meeting a demand for increased awareness in scientific integrity.

This course is designed to inform you on topics as scientific integrity and social responsibilities of scientists. 
Broad questions, which are inseparably linked to these topics are discussed: namely regarding the nature of science and the societal role it fulfills. 

Course objectives:
After this course you will:

1) Understand the basic principles of science, and know what is ""not done"".

2) Have a realistic image of science and scientists.

3) Recognize integrity dilemmas, know how to respond in clear cases, and have the skills to respond prudently in unclear cases.

4) Know and understand the differences and similarities of various disciplines.

5) Have a basic understanding of the role of science in society, realise your own societal responsibilities, and are able to take a position in societal issues where science plays a role. 


The course consists of a feature film, supported by short lectures, set to serve as a starting point for the discussions and assignments.
      


          Introduction
    -Welcome! Before you start we invite you to first go through our introduction module and introduce yourself in the forum to meet your fellow learners. If you encounter any difficulties while studying, please let us know in the forum. For technical difficulties or questions regarding the course certificate, you can always contact the Coursera Learner Helpdesk. Good luck & we hope you will enjoy this course! 

What is Science?
    -This module discusses the nature of science, in particular the attempt by the philosopher Karl Popper to demarcate science from other kinds of knowledge. It also raises the question whether history is a science.

Scientific questions
    -This module discusses the importance of posing the right scientific questions, as well as the nature of a good question. It also queries whether al scientific questions or research topics are allowable for an ethical point of view.

Scientific results
    -This module discusses the scientific publication culture. It focuses on issues like authorship, choice of journal, the review process and citation scores as markers of scientific quality.

Scientific activities
    -This module questions the notion of a single scientific method. It also discusses such issues as publication bias, confirmation bias and questionable research practices.

Academic differences
    -This module discusses some differences between different academic disciplines. Apart from studying different subjects, using different methods, disciplines are also characterised by specific cultures (e.g. values, presuppositions and habits).

Academic careers
    -This module discusses the different stages of an academic career and some of the major hurdles an aspiring academic may encounter.

Scientific misconduct
    -This module discusses the three main types of scientific misconduct or fraud: plagiarism, and the falsification and fabrication of research data.

Science & the industry
    -This module discusses the benefits and dangers of collaborations between science and industry.

  Science & society
    -This module discusses the social responsibilities of scientists, as well as the question whether in certain cases social activism is a possible or even proper stance for scientists.",On Being a Scientist
https://www.classcentral.com/course/edx-software-construction-in-java-6469,"This computer science course is the first of a two-course sequence about writing good software using modern software engineering techniques.
In this course, you will learn what software engineers mean by ""good"" code -- safe from bugs, easy to understand, and ready for change. You will also learn ways to make your code better, including testing, specifications, code review, exceptions, immutability, abstract data types, and interfaces.
This is a challenging and rigorous course that will help you take the next step on your way to becoming a skilled software engineer.
Photo by Wizou on Flickr. (CC BY) 2.0",Software Construction in Java
https://www.classcentral.com/course/netsysbio-491,"An introduction to data integration and statistical methods used in contemporary Systems Biology, Bioinformatics and Systems Pharmacology research. The course covers methods to process raw data from genome-wide mRNA expression studies (microarrays and RNA-seq) including data normalization, differential expression, clustering, enrichment analysis and network construction. The course contains practical tutorials for using tools and setting up pipelines, but it also covers the mathematics behind the methods applied within the tools. The course is mostly appropriate for beginning graduate students and advanced undergraduates majoring in fields such as biology, math, physics, chemistry, computer science, biomedical and electrical engineering. The course should be useful for researchers who encounter large datasets in their own research. The course presents software tools developed by the Ma’ayan Laboratory (http://labs.icahn.mssm.edu/maayanlab/) from the Icahn School of Medicine at Mount Sinai, but also other freely available data analysis and visualization tools. The ultimate aim of the course is to enable participants to utilize the methods presented in this course for analyzing their own data for their own projects. For those participants that do not work in the field, the course introduces the current research challenges faced in the field of computational systems biology.
      


          Course Overview and Introductions
    -The 'Introduction to Complex Systems' module discusses complex systems and leads to the idea that a cell can be considered a complex system or a complex agent living in a complex environment just like us. The 'Introduction to Biology for Engineers' module provides an introduction to some central topics in cell and molecular biology for those who do not have the background in the field. This is not a comprehensive coverage of cell and molecular biology. The goal is to provide an entry point to motivate those who are interested in this field, coming from other disciplines, to begin studying biology.

Topological and Network Evolution Models
    -In the 'Topological and Network Evolution Models' module, we provide several lectures about a historical perspective of network analysis in systems biology. The focus is on in-silico network evolution models. These are simple computational models that, based of few rules, can create networks that have a similar topology to the molecular networks observed in biological systems. 

Types of Biological Networks
    -The 'Types of Biological Networks' module is about the various types of networks that are typically constructed and analyzed in systems biology and systems pharmacology. This lecture ends with the idea of functional association networks (FANs). Following this lecture are lectures that discuss how to construct FANs and how to use these networks for analyzing gene lists.  

Data Processing and Identifying Differentially Expressed Genes
    -This set of lectures in the 'Data Processing and Identifying Differentially Expressed Genes' module first discusses data normalization methods, and then several lectures are devoted to explaining the problem of identifying differentially expressed genes with the focus on understanding the inner workings of a new method developed by the Ma'ayan Laboratory called the Characteristic Direction. 

Gene Set Enrichment and Network Analyses
    -In the 'Gene Set Enrichment and Network Analyses' module the emphasis is on tools developed by the Ma'ayan Laboratory to analyze gene sets. Several tools will be discussed including: Enrichr, GEO2Enrichr, Expression2Kinases and DrugPairSeeker. In addition, one lecture will be devoted to a method we call enrichment vector clustering we developed, and two lectures will describe the popular gene set enrichment analysis (GSEA) method and an improved method we developed called principal angle enrichment analysis (PAEA).

Deep Sequencing Data Processing and Analysis
    -A set of lectures in the 'Deep Sequencing Data Processing and Analysis' module will cover the basic steps and popular pipelines to analyze RNA-seq and ChIP-seq data going from the raw data to gene lists to figures. These lectures also cover UNIX/Linux commands and some programming elements of R, a popular freely available statistical software. Note that since these lectures were developed and recorded during the Fall of 2013, it is possible that there are better tools that should be used now since the field is rapidly advancing.  

Principal Component Analysis, Self-Organizing Maps, Network-Based Clustering and Hierarchical Clustering
    -This module is devoted to various method of clustering: principal component analysis, self-organizing maps, network-based clustering and hierarchical clustering. The theory behind these methods of analysis are covered in detail, and this is followed by some practical demonstration of the methods for applications using R and MATLAB.

Resources for Data Integration
    -The lectures in the 'Resources for Data Integration' module are about the various types of networks that are typically constructed and analyzed in systems biology and systems pharmacology. These lectures start with the idea of functional association networks (FANs). Following this lecture are several lectures that discuss how to construct FANs from various resources and how to use these networks for analyzing gene lists as well as to construct a puzzle that can be used to connect genomic data with phenotypic data. 

Crowdsourcing: Microtasks and Megatasks
    -The final set of lectures presents the idea of crowdsourcing. MOOCs provide the opportunity to work together on projects that are difficult to complete alone (microtasks) or compete for implementing the best algorithms to solve hard problems (megatasks). You will have the opportunity to participate in various crowdsourcing projects: microtasks and megatasks. These projects are designed specifically for this course.

Final Exam
    -The final exam consists of multiple choice questions from topics covered in all of modules of the course. Some of the questions may require you to perform some of the analysis methods you learned throughout the course on new datasets.",Network Analysis in Systems Biology
https://www.classcentral.com/course/data-manipulation-4473,"Data analysis has replaced data acquisition as the bottleneck to evidence-based decision making --- we are drowning in it.  Extracting knowledge from large, heterogeneous, and noisy datasets requires not only powerful computing resources, but the programming abstractions to use them effectively.  The abstractions that emerged in the last decade blend ideas from parallel databases, distributed systems, and programming languages to create a new class of scalable data analytics platforms that form the foundation for data science at realistic scales.

In this course, you will learn the landscape of relevant systems, the principles on which they rely, their tradeoffs, and how to evaluate their utility against your requirements. You will learn how practical systems were derived from the frontier of research in computer science and what systems are coming on the horizon.   Cloud computing, SQL and NoSQL databases, MapReduce and the ecosystem it spawned, Spark and its contemporaries, and specialized systems for graphs and arrays will be covered.

You will also learn the history and context of data science, the skills, challenges, and methodologies the term implies, and how to structure a data science project.  At the end of this course, you will be able to:

Learning Goals: 
1. Describe common patterns, challenges, and approaches associated with data science projects, and what makes them different from projects in related fields.
2. Identify and use the programming models associated with scalable data manipulation, including relational algebra, mapreduce, and other data flow models.
3. Use database technology adapted for large-scale analytics, including the concepts driving parallel databases, parallel query processing, and in-database analytics
4. Evaluate key-value stores and NoSQL systems, describe their tradeoffs with comparable systems, the details of important examples in the space, and future trends.
5. “Think” in MapReduce to effectively write algorithms for systems including Hadoop and Spark.  You will understand their limitations, design details, their relationship to databases, and their associated ecosystem of algorithms, extensions, and languages.
write programs in Spark
6. Describe the landscape of specialized Big Data systems for graphs, arrays, and streams
      


            Read more
          



          Data Science Context and Concepts
    -Understand the terminology and recurring principles associated with data science, and understand the structure of data science projects and emerging methodologies to approach them.    Why does this emerging field exist?  How does it relate to other fields?  How does this course distinguish itself?  What do data science projects look like, and how should they be approached?  What are some examples of data science projects?  

Relational Databases and the Relational Algebra
    -Relational Databases are the workhouse of large-scale data management.  Although originally motivated by problems in enterprise operations, they have proven remarkably capable for analytics as well.  But most importantly, the principles underlying relational databases are universal in managing, manipulating, and analyzing data at scale.  Even as the landscape of large-scale data systems has expanded dramatically in the last decade, relational models and languages have remained a unifying concept.  For working with large-scale data, there is no more important programming model to learn.

MapReduce and Parallel Dataflow Programming
    -The MapReduce programming model (as distinct from its implementations) was proposed as a simplifying abstraction for parallel manipulation of massive datasets, and remains an important concept to know when using and evaluating modern big data platforms.  

NoSQL: Systems and Concepts
    -NoSQL systems are purely about scale rather than analytics, and are arguably less relevant for the practicing data scientist.  However, they occupy an important place in many practical big data platform architectures, and data scientists need to understand their limitations and strengths to use them effectively.

Graph Analytics
    -Graph-structured data are increasingly common in data science contexts due to their ubiquity in modeling the communication between entities: people (social networks), computers (Internet communication), cities and countries (transportation networks), or corporations (financial transactions).  Learn the common algorithms for extracting information from graph data and how to scale them up.",Data Manipulation at Scale: Systems and Algorithms
https://www.classcentral.com/course/edx-statistical-inference-and-modeling-for-high-throughput-experiments-2967,"In this course you’ll learn various statistics topics including multiple testing problem, error rates, error rate controlling procedures, false discovery rates, q-values and exploratory data analysis. We then introduce statistical modeling and how it is applied to high-throughput data. In particular, we will discuss parametric distributions, including binomial, exponential, and gamma, and describe maximum likelihood estimation. We provide several examples of how these concepts are applied in next generation sequencing and microarray data. Finally, we will discuss hierarchical models and empirical bayes along with some examples of how these are used in practice. We provide R programming examples in a way that will help make the connection between concepts and implementation.
Given the diversity in educational background of our students we have divided the series into seven parts. You can take the entire series or individual courses that interest you. If you are a statistician you should consider skipping the first two or three courses, similarly, if you are biologists you should consider skipping some of the introductory biology lectures. Note that the statistics and programming aspects of the class ramp up in difficulty relatively quickly across the first three courses. By the third course will be teaching advanced statistical concepts such as hierarchical models and by the fourth advanced software engineering skills, such as parallel computing and reproducible research concepts.
These courses make up 2 XSeries and are self-paced:
PH525.1x: Statistics and R for the Life Sciences
PH525.2x: Introduction to Linear Models and Matrix Algebra
PH525.3x: Statistical Inference and Modeling for High-throughput Experiments
PH525.4x: High-Dimensional Data Analysis
PH525.5x: Introduction to Bioconductor: annotation and analysis of genomes and genomic assays 
PH525.6x: High-performance computing for reproducible genomics
PH525.7x: Case studies in functional genomics
This class was supported in part by NIH grant R25GM114818.



            Read more",Statistical Inference and Modeling for High-throughput Experiments
https://www.classcentral.com/course/ml-clustering-and-retrieval-4313,"Case Studies: Finding Similar Documents

A reader is interested in a specific news article and you want to find similar articles to recommend.  What is the right notion of similarity?  Moreover, what if there are millions of other documents?  Each time you want to a retrieve a new document, do you need to search through all other documents?  How do you group similar documents together?  How do you discover new, emerging topics that the documents cover?   

In this third case study, finding similar documents, you will examine similarity-based algorithms for retrieval.  In this course, you will also examine structured representations for describing the documents in the corpus, including clustering and mixed membership models, such as latent Dirichlet allocation (LDA).  You will implement expectation maximization (EM) to learn the document clusterings, and see how to scale the methods using MapReduce.

Learning Outcomes:  By the end of this course, you will be able to:
   -Create a document retrieval system using k-nearest neighbors.
   -Identify various similarity metrics for text data.
   -Reduce computations in k-nearest neighbor search by using KD-trees.
   -Produce approximate nearest neighbors using locality sensitive hashing.
   -Compare and contrast supervised and unsupervised learning tasks.
   -Cluster documents by topic using k-means.
   -Describe how to parallelize k-means using MapReduce.
   -Examine probabilistic clustering approaches using mixtures models.
   -Fit a mixture of Gaussian model using expectation maximization (EM).
   -Perform mixed membership modeling using latent Dirichlet allocation (LDA).
   -Describe the steps of a Gibbs sampler and how to use its output to draw inferences.
   -Compare and contrast initialization techniques for non-convex optimization objectives.
   -Implement these techniques in Python.
      


            Read more
          



          Welcome
    -Clustering and retrieval are some of the most high-impact machine learning tools out there.  Retrieval is used in almost every applications and device we interact with, like in providing a set of products related to one a shopper is currently considering, or a list of people you might want to connect with on a social media platform.  Clustering can be used to aid retrieval, but is a more broadly useful tool for automatically discovering structure in data, like uncovering groups of similar patients.This introduction to the course provides you with an overview of the topics we will cover and the background knowledge and resources we assume you have.

Nearest Neighbor Search
    -We start the course by considering a retrieval task of fetching a document similar to one someone is currently reading.  We cast this problem as one of nearest neighbor search, which is a concept we have seen in the Foundations and Regression courses.  However, here, you will take a deep dive into two critical components of the algorithms: the data representation and metric for measuring similarity between pairs of datapoints.  You will examine the computational burden of the naive nearest neighbor search algorithm, and instead implement scalable alternatives using KD-trees for handling large datasets and locality sensitive hashing (LSH) for providing approximate nearest neighbors, even in high-dimensional spaces.  You will explore all of these ideas on a Wikipedia dataset, comparing and contrasting the impact of the various choices you can make on the nearest neighbor results produced.

Clustering with k-means
    -In clustering, our goal is to group the datapoints in our dataset into disjoint sets.  Motivated by our document analysis case study, you will use clustering to discover thematic groups of articles by ""topic"".  These topics are not provided in this unsupervised learning task; rather, the idea is to output such cluster labels that can be post-facto associated with known topics like ""Science"", ""World News"", etc.  Even without such post-facto labels, you will examine how the clustering output can provide insights into the relationships between datapoints in the dataset.  The first clustering algorithm you will implement is k-means, which is the most widely used clustering algorithm out there.  To scale up k-means, you will learn about the general MapReduce framework for parallelizing and distributing computations, and then how the iterates of k-means can utilize this framework.  You will show that k-means can provide an interpretable grouping of Wikipedia articles when appropriately tuned.

Mixture Models
    -In k-means, observations are each hard-assigned to a single cluster, and these assignments are based just on the cluster centers, rather than also incorporating shape information.  In our second module on clustering, you will perform probabilistic model-based clustering that provides (1) a more descriptive notion of a ""cluster"" and (2) accounts for uncertainty in assignments of datapoints to clusters via ""soft assignments"".  You will explore and implement a broadly useful algorithm called expectation maximization (EM) for inferring these soft assignments, as well as the model parameters.  To gain intuition, you will first consider a visually appealing image clustering task.  You will then cluster Wikipedia articles, handling the high-dimensionality of the tf-idf document representation considered.

Mixed Membership Modeling via Latent Dirichlet Allocation
    -The clustering model inherently assumes that data divide into disjoint sets, e.g., documents by topic.  But, often our data objects are better described via memberships in a collection of sets, e.g., multiple topics.  In our fourth module, you will explore latent Dirichlet allocation (LDA) as an example of such a mixed membership model particularly useful in document analysis.  You will interpret the output of LDA, and various ways the output can be utilized, like as a set of learned document features.  The mixed membership modeling ideas you learn about through LDA for document analysis carry over to many other interesting models and applications, like social network models where people have multiple affiliations.Throughout this module, we introduce aspects of Bayesian modeling and a Bayesian inference algorithm called Gibbs sampling.  You will be able to implement a Gibbs sampler for LDA by the end of the module.

Hierarchical Clustering & Closing Remarks
    -In the conclusion of the course, we will recap what we have covered.  This represents both techniques specific to clustering and retrieval, as well as foundational machine learning concepts that are more broadly useful.We provide a quick tour into an alternative clustering approach called hierarchical clustering, which you will experiment with on the Wikipedia dataset.  Following this exploration, we discuss how clustering-type ideas can be applied in other areas like segmenting time series.  We then briefly outline some important clustering and retrieval ideas that we did not cover in this course. We conclude with an overview of what's in store for you in the rest of the specialization.",Machine Learning: Clustering & Retrieval
https://www.classcentral.com/course/edx-foundations-of-data-science-computational-thinking-with-python-10319,"We live in an era of unprecedented access to data. Understanding how to organize and leverage the vast amounts of information at our disposal are critical skills that allow us to infer upon the world and make informed decisions. This course will introduce you to such skills. 
To work with large amounts of data, you will need to harness the power of computation through programming. This course teaches you basic programming skills for manipulating data. You will learn how to use Python to organize and manipulate data in tables, and to visualize data effectively. No prior experience with programming or Python is needed, nor is any statistics background necessary.
The examples given in the course involve real world data from diverse settings. Not all data is numerical – you will work with different types of data from a variety of domains. Though the term “data science” is relatively new, the fundamental ideas of data science are not. The course includes powerful examples that span the centuries from the Victorian era to the present day. 
This course emphasizes learning through doing: you will work on large real-world data sets through interactive assignments to apply the skills you learn. Throughout, the underlying thread is that data science is a way of thinking, not just an assortment of methods. You will also hone your interpretation and communication skills, which are essential skills for data scientists.",Foundations of Data Science: Computational Thinking with Python
https://www.classcentral.com/course/edx-introduction-to-python-absolute-beginner-8671,"Brand new to text-based programming? Check out this hands-on course for an in-depth look at the details of Python layers and concepts. Get ample practice drills and projects, using Jupyter Notebooks on Azure, which require only a browser and an Internet connection. Learn best practices and begin coding almost immediately.
After you explore data types and variables, take a look at strings, input, testing, and formatting. From there, learn about arguments and parameters, along with conditionals and nested conditionals. By the end of the course, you'll be able to create programs that prompt users for input and use conditional (True/False) logic and Python methods to manipulate numbers and text to provide responses to the users, in addition to requesting further input. Plus, learn basic troubleshooting for your code. Sign up, and get started coding right away!
Ready for next steps? Take the Introduction to Python: Fundamentals course.",Introduction to Python: Absolute Beginner
https://www.classcentral.com/course/analytics-tableau-4297,"One of the skills that characterizes great business data analysts is the ability to communicate practical implications of quantitative analyses to any kind of audience member.  Even the most sophisticated statistical analyses are not useful to a business if they do not lead to actionable advice, or if the answers to those business questions are not conveyed in a way that non-technical people can understand.  

In this course you will learn how to become a master at communicating business-relevant implications of data analyses.  By the end, you will know how to structure your data analysis projects to ensure the fruits of your hard labor yield results for your stakeholders.  You will also know how to streamline your analyses and highlight their implications efficiently using visualizations in Tableau, the most popular visualization program in the business world.  Using other Tableau features, you will be able to make effective visualizations that harness the human brain’s innate perceptual and cognitive tendencies to convey conclusions directly and clearly.  Finally, you will be practiced in designing and persuasively presenting business “data stories” that use these visualizations, capitalizing on business-tested methods and design principles.
      


          About this Specialization and Course
    -The Coursera Specialization: Excel to MySQL: Analytic Techniques for Business, is about how 'Big Data' interacts with business, and how to use data analytics to create value for businesses. This specialization consists of four courses and a final Capstone Project, where you will apply your skills to a real-world business process. You will learn to perform sophisticated data-analysis functions using powerful software tools such as Microsoft Excel, Tableau, and MySQL. To learn more, watch the video and review the specialization overview document we provided.In the third course of the specialization: Data Visualization and Communication with Tableau, you will learn how to communicate business-relevant implications of data analyses.  Specifically, you will:craft the right questions to ensure your analysis projects succeed; leverage questions to design logical and structured analysis plans; create the most important graphs used in business analysis and transform data in Tableau;design business dashboards with Tableau; tell stories with data;design effective slide presentations to showcase your data story; and deliver compelling business presentations. By the end of this course, you will know how to structure your data analysis projects to ensure the fruits of your hard labor yield results for your stakeholders.  You will also know how to streamline your analyses and highlight their implications efficiently using visualizations in Tableau, the most popular visualization program in the business world.  Using other Tableau features, you will be able to make effective visualizations that harness the human brain’s innate perceptual and cognitive tendencies to convey conclusions directly and clearly.  Finally, you will be practiced in designing and persuasively presenting business “data stories” that use these visualizations, capitalizing on business-tested methods and design principles by completing a final peer assessed project recommending a business process change. To get started, please begin with the video 'About This Specialization.'I hope you enjoy this week's materials!

Asking The ""Right Questions""
    -Welcome! This week, you will learn how data analysts ask the right questions to ensure project success. By the end of this week, you will be able to: Craft the right questions to ensure your analysis projects succeed Leverage questions to design logical and structured analysis plans",Data Visualization and Communication with Tableau
https://www.classcentral.com/course/stanford-openedx-openknowledge-changing-the-global-course-of-learning-2176,"Open source, open science, open data, open access, open education, open learning -- this free, online course provides an introduction to the important concept of openness from a variety of perspectives, including education, publishing, librarianship, economics, politics, and more, and asks you to discover what it means to you. Open Knowledge is international and multi-institutional, bringing together instructors and students from Canada, Ghana, Mexico, the United States, and the rest of the world. It will challenge you take control of your own learning, to determine your own personal learning objectives, to contribute to the development of the curriculum, to reflect on your progress, to learn new digital skills, and to take a leadership role in the virtual classroom. It will also provide you with the opportunity to connect with colleagues from different countries and professions, and to better understand areas where your interests overlap and where unexpected distinctions exist. We hope you’ll consider taking this journey with us.



Week 1: Introduction to Open KnowledgeWeek 2: Technological Change, Digital Identity, and Connected LearningWeek 3: Participatory Culture, Citizen Journalism, Citizen ScienceWeek 4: Intellectual Property, Copyright, and the Economics of OpenWeek 5: Historical Perspectives: Learned Publishing from Medieval to Modern TimesWeek 6: Open Science, Data, Access, Source, ReviewWeek 7: Open Educational Resources: From Lesson Plans to Instructional VideosWeek 8: Archives, Databases, Encyclopedia: Evaluating Open Collections and Reference SourcesWeek 9: Scholarly Publishing and Communications: Journals, Books, and Publication of ResearchWeek 10: Information Literacy: Overload, Filters, and Developing a Critical LensWeek 11: Global Perspectives on Equity, Development, and Open KnowledgeWeek 12: Student Publishing: Lessons in Publishing, Peer Review, and Knowledge SharingWeek 13: The Future of Open Knowledge",OpenKnowledge: Changing the global course of learning
https://www.classcentral.com/course/calculus-and-optimization-for-machine-learning-17335,"Hi! Our course aims to provide necessary background in Calculus sufficient for up-following Data Science courses. 

Course starts with basic introduction to concepts concerning functional mappings. Later students are assumed to study limits (in case of sequences, single- and multivariate functions), differentiability (once again starting from single variable up to multiple cases), integration, thus sequentially building up a base for the basic optimisation. To provide an understanding of the practical skills set being taught, the course introduces the final programming project considering the usage of optimisation routine in machine learning. 

Additional materials provided during the course include interactive plots in GeoGebra environment used during lectures, bonus reading materials with more general methods and more complicated basis for discussed themes.
      


          Introduction: Numerical Sets, Functions, Limits
    -Here we introduce basic concept the calculus course could not be imagine without: function. In order to properly do it, one should say that the function is a mapping from one set to another. Thus, we start with the ideas of numerical sets and mapping, then proceeding with functions itself. Since we are particularly interested in functions' graph, we spend a lot of time discussing simplest ways to produce a complex function graph from elementary case. In the second part of the week we start our calculus journey with a discrete limit, the limit of sequences, and master skills needed to calculate them.

Limits and Multivariate Functions
    -Now it is time to move from discrete limits to continuous ones: in other words, in the current module we are going to discuss limits of functions. We start with the basic question: does this case sufficiently differ from the sequences? Turns out, yes, it does thanks to significant structural differences between natural and real numbers. One of those differences - the continuousness - allows us to define and calculate limits at finite  moments. We spend some time specifically on the famous important limits, then we proceed with the idea of asymptotic comparison of functions, Big- and little-o notations. To top our module with, we introduce functions of several variables and spend some time getting used to conveniently plot and interpret them, finishing up with discussion of its limits.

Derivatives and Linear Approximations: Singlevariate Functions
    -Since we now know limits, let us use them in order to define some instantaneous characteristics of functions starting with its slope. Thus we define function's derivative and discuss all the machinery to calculate it. Since it is a purely technical issue, you are expected to be able to do it: in order to make sure that you can find a derivative we provide a drill. This skills could be used for finding approximate values via linear approximation or during the search for extremal values. To provide an understanding of the sufficient condition of the extremum, we introduce the concept of convexity.

Derivatives and Linear Approximations: Multivariate Functions
    -Whilst we have discussed all linear related concepts for single variate functions, it is essential to try and generalise it for the multivariate case. Since the derivative concept is hard to stretch directly, we start with the idea of linear approximation and tangent plane; thus we introduce partial derivatives and the differentiability. We separately spend sometime discussing neural network inspired composite multivariate functions and all-mighty chain rule. Our generalisation attempt finalised with the idea of convexity in terms of the second partial derivatives.

Integrals: Anti-derivative, Area under Curve
    -As we introduced the operation of differentiation, it is essential to think about the inverse procedure - the integration. We start the module with basic definition of the integration and, as usual, all techniques required to calculate wide range of the indefinite integrals, stressing out that the result is not guaranteed now. Then we proceed with the idea and formal definition of area under curve and its relation to the indefinite case - the fundamental theorem of calculus. We finish our week with the discussion of the areas of infinite figures (improper integrals) and numerical methods to assess the value of the definite integral.

Optimization: Directional derivative, Extrema and Gradient Descent
    -As we built up impressive base by introducing various estimations of change and overall function's behaviour, it is essential to speak about general idea of the optimisation procedure. Since we already tackled it in a single variate case, we try to generalise our principles of necessary and sufficient conditions to the case of multivariate functions. Whilst it provides theoretical understanding, one should seek for faster iterative way to find an extremal point. In order to do it, we start our week with the concept of the directional derivative in order to provide and understanding of the desired direction of iterative search. Thus we produce the idea and motivation of the gradient descent, the last  and final concept in our course you are asked to master.",Calculus and Optimization for Machine Learning
https://www.classcentral.com/course/open-source-tools-for-data-science-10620,"What are some of the most popular data science tools, how do you use them, and what are their features? In this course, you'll learn about Jupyter Notebooks, RStudio IDE, Apache Zeppelin and Data Science Experience. You will learn about what each tool is used for, what programming languages they can execute, their features and limitations. With the tools hosted in the cloud on Cognitive Class Labs, you will be able to test each tool and follow instructions to run simple code in Python, R or Scala. To end the course, you will create a final project with a Jupyter Notebook on IBM Data Science Experience and demonstrate your proficiency preparing a notebook, writing Markdown, and sharing your work with your peers.

LIMITED TIME OFFER: Subscription is only $39 USD per month for access to graded materials and a certificate.
      


          Introducing Skills Network Labs
    -This week, you will get an overview of the various data science tools available to you, hosted on Skills Network Labs. You will create an account and start exploring some of the features.

Jupyter Notebooks
    -This week, you will learn about a popular data science tool, Jupyter Notebooks, its features, and why they are so popular among data scientists today.

Apache Zeppelin Notebooks
    -This week, you will learn about Apache Zeppelin Notebooks, its feature, and how they are different from Jupyter Notebooks.

RStudio IDE
    -This week, you will learn about a popular data science tool used by R programmers. You'll learn about the user interface and how to use its various features.

IBM Watson Studio
    -This week, you will learn about an enterprise-ready data science platform by IBM, called Watson Studio (formerley known as Data Science Experience). You'll learn about some of the features and capabilities of what data scientists use in the industry.

Project: Create and share a Jupyter Notebook",Open Source tools for Data Science
https://www.classcentral.com/course/tipping-points-climate-change-and-society-10580,"Explore the possible future of Earth
A tipping point occurs when there’s a shift in the state of a system towards a new equilibrium. We’re now facing tipping points in our climate system that could accelerate the dangerous effects of climate change. Natural systems will change, as will human systems. In future we could see the collapse of the West Antarctic Ice Sheet, dieback of the Amazon or droughts across the Sahel but also behavioural changes and regional warfare.
On this course you will explore the concept of tipping points from an interdisciplinary perspective, discovering their role in climate change and the future.
This course is for people with a basic knowledge of climate change science (to get an introduction join the course Climate Change: The Science).",Tipping Points: Climate Change and Society
https://www.classcentral.com/course/interest-rate-models-7662,"This course gives you an easy introduction to interest rates and related contracts. These include the LIBOR, bonds, forward rate agreements, swaps, interest rate futures, caps, floors, and swaptions. We will learn how to apply the basic tools duration and convexity for managing the interest rate risk of a bond portfolio. We will gain practice in estimating the term structure from market data. We will learn the basic facts from stochastic calculus that will enable you to engineer a large variety of stochastic interest rate models. In this context, we will also review the arbitrage pricing theorem that provides the foundation for pricing financial derivatives. We will also cover the industry standard Black and Bachelier formulas for pricing caps, floors, and swaptions.

At the end of this course you will know how to calibrate an interest rate model to market data and how to price interest rate derivatives.
      


          Introduction

Interest Rates and Related Contracts
    -We learn various notions of interest rates and some related contracts. Interest is the rent paid on a loan. A bond is the securitized form of a loan. There exist coupon paying bonds and zero-coupon bonds. The latter are also called discount bonds. Interest rates and bond prices depend on their maturity. The term structure is the function that maps the maturity to the corresponding interest rate or bond price. An important reference rate for many interest rate contracts is the LIBOR (London Interbank Offered Rate). Loans can be borrowed over future time intervals at rates that are agreed upon today. These rates are called forward or futures rates, depending on the type of the agreement. In an interest rate swap, counterparties exchange a stream of fixed-rate payments for a stream of floating-rate payments typically indexed to LIBOR. Duration and convexity are the basic tools for managing the interest rate risk inherent in a bond portfolio. We also review some of the most common market conventions that come along with interest rate market data. 

Estimating the Term Structure
    -We learn how to estimate the term structure from market data. There are two types of methods. Exact methods produce term structures that exactly match the market data. This comes at the cost of somewhat irregular shapes. Smooth methods penalize irregular shapes and trade off exactness of fit versus regularity of the term structure. We will also see what principal component analysis tells us about the basic shapes of the term structure.

Stochastic Models
    -Models for the evolution of the term structure of interest rates build on stochastic calculus. We start with a crash course in stochastic calculus, which introduces Brownian motion, stochastic integration, and stochastic processes without going into mathematical details. This provides the necessary tools to engineer a large variety of stochastic interest rate models. We then study some of the most prevalent so-called short rate models and Heath-Jarrow-Morton models. We also review the arbitrage pricing theorem from finance that provides the foundation for pricing financial derivatives. As an application we price options on bonds.

Interest Rate Derivatives
    -We apply what we learnt to price interest rate derivatives. Specifically, we focus on the standard derivatives: interest rate futures, caps and floors, and swaptions. We derive the industry standard Black and Bachelier formulas for cap, floor, and swaption prices. In a case study we learn how to calibrate a stochastic interest rate model to market data.

Final Quiz",Interest Rate Models
https://www.classcentral.com/course/edx-introduction-to-python-fundamentals-8650,"Ready for more hands-on, step-by-step Python fundamentals? Add to the foundational experience you got in the Introduction to Python: Absolute Beginner, and explore data structures. Get lots of practice working with sample code in Jupyter Notebooks on Azure, which require only a browser and an Internet connection.
Focus on Python data structures, and work with string, list, and range sequences. Discover the power of list iteration, and learn about string and list methods. From there, get the details on file input and output--open files, read them, add to them, close them, and more. At the end of the course, you'll be able to slice strings into substrings, create lists, iterate through them, import files, and use file append mode, along with a lot of other practical Python tasks, as you get started coding.



Module 1 - Sequences: String Indexing
Module 2 - Sequences: List Manipulation
Module 3 - Sequences: Iteration
Module 4 - Files: Input and Output",Introduction to Python: Fundamentals
https://www.classcentral.com/course/intro-practical-deep-learning-10449,"This course provides an introduction to Deep Learning, a field that aims to harness the enormous amounts of data that we are surrounded by with artificial neural networks, allowing for the development of self-driving cars, speech interfaces, genomic sequence analysis and algorithmic trading. 

You will explore important concepts in Deep Learning, train deep networks using Intel Nervana Neon, apply Deep Learning to various applications and explore new and emerging Deep Learning topics.
      


          Introduction to Deep Learning and Deep Learning Basics

Convolutional Neural Networks (CNN), Fine-Tuning and Detection

Recurrent Neural Networks (RNN)

Training Tips and Multinode Distributed Training

Hot Research and Intel's Roadmap

Final Quiz",An Introduction to Practical Deep Learning
https://www.classcentral.com/course/sql-data-science-11067,"Much of the world's data resides in databases. SQL (or Structured Query Language) is a powerful language which is used for communicating with and extracting data from databases. A working knowledge of databases and SQL is a must if you want to become a data scientist.

The purpose of this course is to introduce relational database concepts and help you learn and apply foundational knowledge of the SQL language. It is also intended to get you started with performing SQL access in a data science environment.  

The emphasis in this course is on hands-on and practical learning . As such, you will work with real databases, real data science tools, and real-world datasets. You will create a database instance in the cloud. Through a series of hands-on labs you will practice building and running SQL queries. You will also learn how to access databases from Jupyter notebooks using SQL and Python.

No prior knowledge of databases, SQL, Python, or programming is required.

Anyone can audit this course at no-charge. If you choose to take this course and earn the Coursera course certificate, you can also earn an IBM digital badge upon successful completion of the course.

LIMITED TIME OFFER: Subscription is only $39 USD per month for access to graded materials and a certificate.
      


          Week 1 - Introduction to Databases and Basic SQL
    -In Week 1 you will be introduced to databases. You will create a database instance on the cloud.  You will learn some of the basic SQL statements. You will also write and practice basic SQL hands-on on a live database.

Week 2 - Advanced SQL
    -By the end of this module, you will learn the following: (1) Learn how to use string patterns and ranges to search data and how to sort and group data in result sets.  (2) Learn how to work with multiple tables in a relational database using  join operations.

Week 3 - Accessing Databases using Python
    -After completing the lessons in this week, you will learn how to explain the basic concepts related to using Python to connect to databases and then create tables, load data, query data using SQL, and analyze data using Python 

Week 4: Course Assignment
    -As a hands-on Data Science assignment, you will be working with multiple real world datasets for the city of Chicago. You will be asked questions that will help you understand the data just like a data scientist would. You will be assessed both on the correctness of your SQL queries and results.",Databases and SQL for Data Science
https://www.classcentral.com/course/causal-inference-12136,"This course offers a rigorous mathematical survey of causal inference at the Master’s level.

Inferences about causation are of great importance in science, medicine, policy, and business.  This course provides an introduction to the statistical literature on causal inference that has emerged in the last 35-40 years and that has revolutionized the way in which statisticians and applied researchers in many disciplines use data to make inferences about causal relationships.  

We will study methods for collecting data to estimate causal relationships. Students will learn how to distinguish between relationships that are causal and non-causal; this is not always obvious. We shall then study and evaluate the various methods students can use — such as matching, sub-classification on the propensity score, inverse probability of treatment weighting, and machine learning — to estimate a variety of effects — such as the average treatment effect and the effect of treatment on the treated. At the end, we discuss methods for evaluating some of the assumptions we have made, and we offer a look forward to the extensions we take up in the sequel to this course.
      


          MODULE 1: Key Ideas

Module 2: Randomization Inference 

MODULE 3: Regression

Module 4: Propensity Score

Module 5: Matching

Module 6: Special Topics",Causal Inference
https://www.classcentral.com/course/edx-statistical-learning-1579,"This is an introductory-level course in supervised learning, with a focus on regression and classification methods. The syllabus includes: linear and polynomial regression, logistic regression and linear discriminant analysis; cross-validation and the bootstrap, model selection and regularization methods (ridge and lasso); nonlinear models, splines and generalized additive models; tree-based methods, random forests and boosting; support-vector machines. Some unsupervised learning methods are discussed: principal components and clustering (k-means and hierarchical).
This is not a math-heavy class, so we try and describe the methods without heavy reliance on formulas and complex mathematics. We focus on what we consider to be the important elements of modern data analysis. Computing is done in R. There are lectures devoted to R, giving tutorials from the ground up, and progressing with more detailed sessions that implement the techniques in each chapter.
The lectures cover all the material in An Introduction to Statistical Learning, with Applications in R by James, Witten, Hastie and Tibshirani (Springer, 2013). The pdf for this book is available for free on the book website.",Statistical Learning
https://www.classcentral.com/course/edx-cs50-s-ap-computer-science-principles-7017,"This is CS50 AP, Harvard University's introduction to the intellectual enterprises of computer science and the art of programming for students in high school, which satisfies the College Board's new AP CS Principles curriculum framework.
An entry-level course taught by David J. Malan, CS50 AP teaches students how to think algorithmically and solve problems efficiently. Topics include abstraction, algorithms, data structures, encapsulation, resource management, security, software engineering, and web development. Languages include C, PHP, and JavaScript plus SQL, CSS, and HTML. Problem sets inspired by real-world domains of biology, cryptography, finance, forensics, and gaming. As of Fall 2015, the on-campus version of CS50 was Harvard's largest course.
Students in high school may receive AP credit for this course provided their school approves the credit and administers the College Board's end-of-year exam. Students who earn a satisfactory score on 9 problem sets (i.e., programming assignments) and a final project are also eligible to receive a verified certificate from HarvardX.",CS50's AP® Computer Science Principles
https://www.classcentral.com/course/geneticsevolution-381,"Introduction to Genetics and Evolution is a college-level class being offered simultaneously to new students at Duke University. The course gives interested people a very basic overview of some principles behind these very fundamental areas of biology.  We often hear about new ""genome sequences,"" commercial kits that can tell you about your ancestry (including pre-human) from your DNA or disease predispositions, debates about the truth of evolution, why animals behave the way they do, and how people found ""genetic evidence for natural selection.""  This course provides the basic biology you need to understand all of these issues better, tries to clarify some misconceptions, and tries to prepare students for future, more advanced coursework in Biology (and especially evolutionary genetics).  No prior coursework is assumed.
      


          Welcome to Genetics and Evolution
    -General introduction to this MOOC, including coverage and expectations.

Evidence for Evolution
    -This module discusses the definition of the word ""evolution"" in a biological context, evidence for the truth of evolution and common ancestry of species, and public thoughts and misconceptions about biological evolution. This module is optional and will not be included in the course assessments. There are not class discussion forums for this section, as we feel such discussion can happen on other, non-course-related, sites on this topic (of which there are a great many on the internet).

Genetics I
    -An introduction to basic transmission genetics and inheritance. This module reflects what is often covered in high school biology courses in the USA.

Genetics II
    -This module delves somewhat more deeply into genetics and specifically the concept of ""recombination."" It begins to discuss how recombination is leveraged in classic genetic works as well as mapping simple genetic traits using crosses or data from natural populations. 

Genetics III
    -This module delves even more deeply into the complexities of the genetics underlying traits,the origin of genetic variation, and how ""complex"" traits (ones controlled by multiple genes) are studied genetically.

Heritability and Population Growth
    -This module begins the transition to evolutionary genetics by looking at the relative contributions of genetics and environment to traits, and also introduces how population growth is studied.

Population Genetics I
    -Rather than looking at individuals, this module discusses how multiple individuals from natural populations can be studied genetically to begin to understand the evolutionary forces acting upon the populations.

Population Genetics II
    -This module extends the previous one to specifically examine the effects of natural selection and genetic drift on genetic variation in natural populations.

Molecular Evolution
    -This advanced module explains why sexual reproduction (involving recombination) is evolutionarily advantageous, and discusses how the analysis of DNA sequences can be used to understand the evolutionary forces acting on populations or species, either in general or at specific genes.

 Adaptive Behaviors and Sexual Selection
    -This module changes gears a bit to look at the exciting field of animal behavior-- specifically, how particular behaviors are or may be adaptive, and why individuals choose particular others as mates.

Speciation and Phylogenetics
    -This module gets into the nitty gritty of what causes the formation of new species, and how evolutionary relationships between species are inferred.

Applied Evolution
    -This final module talks about applications and misapplications of many of the concepts discussed in the course to human health, understanding, and well-being. This module is optional and not included in the assessments.",Introduction to Genetics and Evolution
https://www.classcentral.com/course/bd2klincs-3024,"The Library of Integrative Network-based Cellular Signatures (LINCS) is an NIH Common Fund program. The idea is to perturb different types of human cells with many different types of perturbations such as: drugs and other small molecules; genetic manipulations such as knockdown or overexpression of single genes; manipulation of the extracellular microenvironment conditions, for example, growing cells on different surfaces, and more. These perturbations are applied to various types of human cells including induced pluripotent stem cells from patients, differentiated into various lineages such as neurons or cardiomyocytes. Then, to better understand the molecular networks that are affected by these perturbations, changes in level of many different variables are measured including: mRNAs, proteins, and metabolites, as well as cellular phenotypic changes such as changes in cell morphology. The BD2K-LINCS Data Coordination and Integration Center (DCIC) is commissioned to organize, analyze, visualize and integrate this data with other publicly available relevant resources. In this course we briefly introduce the DCIC and the various Centers that collect data for LINCS. We then cover metadata and how metadata is linked to ontologies. We then present data processing and normalization methods to clean and harmonize LINCS data. This follow discussions about how data is served as RESTful APIs. Most importantly, the course covers computational methods including: data clustering, gene-set enrichment analysis, interactive data visualization, and supervised learning. Finally, we introduce crowdsourcing/citizen-science projects where students can work together in teams to extract expression signatures from public databases and then query such collections of signatures against LINCS data for predicting small molecules as potential therapeutics.
      


            Read more
          



          The Library of Integrated Network-based Cellular Signatures (LINCS) Program Overview
    -This module provides an overview of the concept behind the LINCS program; and tutorials on how to get started with using the LINCS L1000 dataset.

Metadata and Ontologies
    -This module includes a broad high level description of the concepts behind metadata and ontologies and how these are applied to LINCS datasets.

Serving Data with APIs
    -In this module we explain the concept of accessing data through an application programming interface (API).

Bioinformatics Pipelines
    -This module describes the important concept of a Bioinformatics pipeline.

The Harmonizome
    -This module describes a project that integrates many resources that contain knowledge about genes and proteins. The project is called the Harmonizome, and it is implemented as a web-server application available at: http://amp.pharm.mssm.edu/Harmonizome/ 

Data Normalization
    -This module describes the mathematical concepts behind data normalization.

Data Clustering
    -This module describes the mathematical concepts behind data clustering, or in other words unsupervised learning - the identification of patterns within data without considering the labels associated with the data. 

Midterm Exam
    -The Midterm Exam consists of 45 multiple choice questions which covers modules 1-7. Some of the questions may require you to perform some analysis with the methods you learned throughout the course on new datasets. 

Enrichment Analysis
    -This module introduces the important concept of performing gene set enrichment analyses. Enrichment analysis is the process of querying gene sets from genomics and proteomics studies against annotated gene sets collected from prior biological knowledge.

Machine Learning
    -This module describes the mathematical concepts of supervised machine learning, the process of making predictions from examples that associate observations/features/attribute with one or more properties that we wish to learn/predict.

Benchmarking
    -This module discusses how Bioinformatics pipelines can be compared and evaluated.

Interactive Data Visualization
    -This module provides programming examples on how to get started with creating interactive web-based data visualization elements/figures.

Crowdsourcing Projects
    -This final module describes opportunities to work on LINCS related projects that go beyond the course.

Final Exam
    -The Final Exam consists of 60 multiple choice questions which covers all of the modules of the course. Some of the questions may require you to perform some analysis with the methods you learned throughout the course on new datasets.",Big Data Science with the BD2K-LINCS Data Coordination and Integration Center
https://www.classcentral.com/course/independent-introduction-to-machine-learning-for-coders-12175,"Welcome to Introduction to Machine Learning for Coders! taught by Jeremy Howard (Kaggle's #1 competitor 2 years running, and founder of Enlitic). Learn the most important machine learning models, including how to create them yourself from scratch, as well as key skills in data preparation, model validation, and building data products.There are around 24 hours of lessons, and you should plan to spend around 8 hours a week for 12 weeks to complete the material. The course is based on lessons recorded at the University of San Francisco for the Masters of Science in Data Science program. We assume that you have at least one year of coding experience, and either remember what you learned in high school math, or are prepared to do some independent study to refresh your knowledge.
 



1—INTRODUCTION TO RANDOM FORESTS
2—RANDOM FOREST DEEP DIVE
3—PERFORMANCE, VALIDATION AND MODEL INTERPRETATION
4—FEATURE IMPORTANCE, TREE INTERPRETER
5—EXTRAPOLATION AND RF FROM SCRATCH
6—DATA PRODUCTS AND LIVE CODING
7—RF FROM SCRATCH AND GRADIENT DESCENT
8—GRADIENT DESCENT AND LOGISTIC REGRESSION
9—REGULARIZATION, LEARNING RATES AND NLP
10— MORE NLP AND COLUMNAR DATA
11—EMBEDDINGS
12— COMPLETE ROSSMANN, ETHICAL ISSUES",Introduction to Machine Learning for Coders!
https://www.classcentral.com/course/gis-1-13293,"This course is organized into two parts presenting the theoretical and practical foundations of geographic information systems (GIS).
- Together theses courses constitute an introduction to GIS and require no prior knowledge.
- By following this introduction to GIS you will quickly acquire the basic knowledge required to create spatial databases and produce high-quality maps and cartographic representations.
- This is a practical course and is based on free, open-source software, including QGIS.
If you study or work in the fields of land management or the analysis of geographically distributed objects such as land use planning, biology, public health, ecology, or energy, then this course is for you!

In this first part of the course, we will focus on the digitization and the storage of geodata. In particular, you will learn:
- To characterize spatial objects and/or phenomena (territory modeling) with respect to their position in space (through coordinate systems, projections, and spatial relationships) and according to their intrinsic nature (object/vector mode vs. Image/raster mode); 
- About the different means used to acquire spatial data; including direct measurement, georeferencing images, digitization, existing data source, etc.);
- About the different ways in which geodata can be stored - notably, files and relational databases;
- How to use data modeling tools to describe and create a spatial database;
- To query and analyze data using SQL, a common data manipulation language.

The second part of this course will focus on methods of spatial analysis and geodata representation. In this section, you will learn:
- How to describe and quantify the spatial properties of discrete variables, for example through spatial autocorrelation;
- To work with continuous variables. In particular, we will look at sampling strategies, how to construct contour lines and isovalue curves, and we will explore different interpolation methods;
- To use digital elevation models and create their derivative products (i.e. slope, orientation);
- How to evaluate the interaction between different types of geodata through overlay and interaction techniques;
- How to create effective maps based around the rules of graphic semiology;
- Finally, we will also explore other, increasingly common, forms of spatial representation such as interactive web-mapping and 3D representations.

You can find an interactive forum for course participants on our Facebook page: https://www.facebook.com/moocsig
      


            Read more
          



          Digitization – Territorial Modeling: Spatial elements and the characteristics
    -This first week deals with the first step in digitizing terrain, namely territorial modeling. In this week, we will consider factors such as the scale and theme of interest in order to determine which objects or spatial phenomena should included in the model, and we will also see how the geographic positioning and intrinsic nature (e.g. raster or vector) of these elements factors into how they are characterized in a terrain model. 

Digitization - Geodata Capture and Documentation
    -Digital data acquisition involves various techniques including the direct measurement of primary data, the semi-automated vectorization and digitization of spatial objects, or the georeferencing of digital images. In this week’s module we will begin with a lesson on metadata in which we will discuss the processes and rules for documenting a dataset, which are essential for data sustainability, and we will also introduce a case study on participatory GIS in Senegal and Seychelles.

Digitization - Automated Capture and Use of Existing Geodata
    -In this week we will continue to build on the topic introduced last week with automatic vectorization, and we will also review a non-exhaustive list of some important pre-existent data sources that are available for you to access. We will finish with a case study of a Senegal-Mauritania biodiversity project before you will test your knowledge in the first quiz of the module.  

Storage - Geodata Structure and Organization 
    -In this 4th week, which marks the beginning of the second module of the course devoted to data storage, we begin by reviewing the fundamental aspects of geodata storage and the most common data formats, before tackling the theme of relational databases and data modeling. The week concludes with a lesson on creating databases in the QGIS environment and a case study on the role of GIS in a transport and urban planning project in Senegal.

Storage - Data Management with SQL
    -The SQL language is the preferred vector for access to relational databases, and can be used to search for data meeting certain criteria (conditional queries), to aggregate and calculate statistics on subsets of data (aggregation queries), to combine the results of several queries (nesting and merging), to edit and modify data, or even to manipulate data structure (DDL, DML).

Storage - Spatial SQL and NoSQL Databases
    -While the previous week's lessons dealt with various general aspects of the SQL language, in this week we will learn about SQL queries specifically related to the spatial dimensions and the relationships that characterize geodata (geometric and topological spatial queries). We will also present a brief introduction into the rapidly expanding field of noSQL databases and finish the lesson portion of this module with a case study devoted to bushfire management in sub-Saharan Africa. Finally, this first MOOC on an introduction to geographic information systems will conclude with a second quiz to test your knowledge.",Geographical Information Systems - Part 1
https://www.classcentral.com/course/mind-behavior-fundamentals-9524,"The ""Introduction to Psychology as a Science 2 – Fundamentals of the Mind and Behavior"" course will close to new enrollments on August 2nd. Learners who are enrolled prior to this date will still have 180 days to complete and earn a certificate. 

This course deals with the fundamentals important in Psychology as a science. Psychology is the study of behavior and the mind.  But all of us have tried to understand and predict behavior throughout our lives, first with our parents, then with our peers and teachers, and finally with our friends and co-workers.  The difference is that psychological scientists conduct research that discovers the facts about behavior and our minds, so its principles are based on science and not just on intuition and experience.  The course covers the fundamentals of learning, memory, motivation, emotion, and how behavior changes as we age.  The content of the course has received approval from ""Quality Matters"", an organization that evaluates on-line courses.  The learning outcomes are:  (1) Students will be able to recognize and describe major psychological principles of learning;  (2) Students will be able to distinguish between different types of memory;  (3) Students will be able to describe how motivation and emotion can affect how we behave; and (4) Students will know how cognitive behavior and social behavior develops as we age.",Introduction to Psychology as a Science 2 – Fundamentals of the Mind and Behavior
https://www.classcentral.com/course/introduction-portfolio-construction-pyth-16875,"The practice of investment management has been transformed in recent years by computational methods. This course provides an introduction to the underlying science, with the aim of giving you a thorough understanding of that scientific basis. However, instead of merely explaining the science, we help you build on that foundation in a practical manner, with an emphasis on the hands-on implementation of those ideas in the Python programming language. 

This course is the first in a four course specialization in Data Science and Machine Learning in Asset Management but can be taken independently. In this course, we cover the basics of Investment Science, and we'll build practical implementations of each of the concepts along the way. We'll start with the very basics of risk and return and quickly progress to cover a range of topics including several Nobel Prize winning concepts. We'll cover some of the most popular practical techniques in modern, state of the art investment management and portfolio construction. 

As we cover the theory and math in lecture videos, we'll also implement the concepts in Python, and you'll be able to code along with us so that you have a deep and practical understanding of how those methods work. By the time you are done, not only will you have a foundational understanding of modern computational methods in investment management, you'll have practical mastery in the implementation of those methods.
      


          Analysing returns

An Introduction to Portfolio Optimization

Beyond Diversification

Introduction to Asset-Liability Management",Introduction to Portfolio Construction and Analysis with Python
https://www.classcentral.com/course/stem-cells-10745,"What promise do stem cells hold for the treatment of medical conditions? In this five-part online course you will explore the history and basic biology of stem cells, learn about new research techniques, and find out how stem cells could lead to cures for diseases and to individualized medicine. You will hear from Museum scientists, medical researchers at the frontiers of the field, and a panel of bioethics experts who will address the ethical implications of stem cell research and therapy.  Learn what has already been accomplished, what challenges remain, and what medical breakthroughs may lie ahead.
      


          Introduction to Stem Cells
    -Welcome to The Science of Stem Cells! You will begin with a basic overview of stem cells--what they are, the history of stem cell research, and the potential for stem cell therapies. You will also learn from AMNH biologist Julia Zichello that stem cells are found throughout the tree of life.

How Do Stem Cells Work?
    -This week, New York University’s Dr. Esteban Mazzoni will discuss how scientists can coax stem cells to differentiate into particular cell types. Dr. Mazzoni will also talk about new stem cell-assisted technologies such as mitochondrial replacement therapy and generating chimeras for organ transplantation. You will also get some background information on the science and ethics of cloning. 

Using Stem Cells to Study Disease
    -We have covered the process by which scientists can differentiate cells in a culture dish. Now you will look at how scientists can use these cell to model diseases in a culture dish. Dr. Andrew Sproul from Columbia University explains how cultured cells can be used to understand the cause of diseases and to look for drugs that will potentially cure them. His research is on Alzheimer’s disease. You will also explore how how stem cells have the potential to help with the study of diabetes.

Using Stem Cells to Treat Disease
    -In addition to the great potential of stem cells to be used in the study of disease, stem cells can also be used to actually treat disease. Neural stem cell pioneer Dr. Sally Temple will explain the potential for using stem cells in our own bodies (adult stem cells) to treat age-related macular degeneration, an increasingly common and debilitating disease. Dr. Temple will also give you some tools for evaluating potential stem cell treatments.

The Bioethics of Stem Cell Research and Therapy
    -To complete the course, a panel of bioethics experts will discuss some of the controversies surrounding human embryonic stem cells and the legal, policy, and ethical challenges associated with the use of stem cells in basic and clinical research. You will have an opportunity to discuss and ask questions about the future of reproductive technology and stem cell research.",The Science of Stem Cells
https://www.classcentral.com/course/systems-science-obesity-6398,"Systems science has been instrumental in breaking new scientific ground in diverse fields such as meteorology, engineering and decision analysis.   However, it is just beginning to impact public health.   This seminar is designed to introduce students to basic tools of theory building and data analysis in systems science and to apply those tools to better understand the obesity epidemic in human populations. There will also be a lab in which students will use a simple demonstration model of food acquisition behavior using agent-based modeling on standard (free) software (netlogo).   The central organizing idea of the course is to examine the obesity epidemic at a population level as an emergent properties of complex, nested systems, with attention to feedback processes, multilevel interactions, and the phenomenon of emergence.   While the emphasis will be on obesity, the goal will be to explore ways in which the systems approach can be applied to other non-communicable diseases both nationally and internationally.  

Topics will include:
a) the epidemiology of obesity across time and place,
b) theories to explain population obesity,
c) the role of environments and economic resources in obesity
c) basic concepts and tools of systems science,
d) modeling energy-balance related behaviors in context,
e) agent-based models, systems dynamic models, and social network models
      


          Module 1
    -Obesity, the facts of the case, and human populations through a systems science lens.

Module 2
    -Complex systems, system dynamic models, and developing a stock and flow. This module includes a lab lesson.

Module 3
    -Social networks and obesity, neighborhoods and noshing, and prices and poverty.

Module 4
    -Agent based modeling and conceptual motivation for agent based modeling. This module includes a lab lesson.",Systems Science and Obesity
https://www.classcentral.com/course/edx-statistical-thinking-for-data-science-and-analytics-4913,"This statistics and data analysis course will pave the statistical foundation for our discussion on data science.
You will learn how data scientists exercise statistical thinking in designing data collection, derive insights from visualizing data, obtain supporting evidence for data-based decisions and construct models for predicting future trends from data.



Week 1 – Introduction to Data Science
Week 2 – Statistical Thinking

Examples of Statistical Thinking
Numerical Data, Summary Statistics
From Population to Sampled Data
Different Types of Biases
Introduction to Probability
Introduction to Statistical Inference 

Week 3 – Statistical Thinking 2

Association and Dependence
Association and Causation
Conditional Probability and Bayes Rule
Simpsons Paradox, Confounding
Introduction to Linear Regression
Special Regression Models

Week 4 – Exploratory Data Analysis and Visualization

Goals of statistical graphics and data visualization
Graphs of Data
Graphs of Fitted Models
Graphs to Check Fitted Models
What makes a good graph?
Principles of graphics

Week 5 – Introduction to Bayesian Modeling

Bayesian inference: combining models and data in a forecasting problem
Bayesian hierarchical modeling for studying public opinion
Bayesian modeling for Big Data",Statistical Thinking for Data Science and Analytics
https://www.classcentral.com/course/python-statistics-financial-analysis-12648,"Course Overview: https://youtu.be/JgFV5qzAYno

Python is now becoming the number 1 programming language for data science. Due to python’s simplicity and high readability, it is gaining its importance in the financial industry.  The course combines both python coding and statistical concepts and applies into analyzing financial data, such as stock data.

By the end of the course, you can achieve the following using python:

- Import, pre-process, save and visualize financial data into pandas Dataframe

- Manipulate the existing financial data by generating new variables using multiple columns

- Recall and apply the important statistical concepts (random variable, frequency, distribution, population and sample, confidence interval, linear regression, etc. ) into financial contexts

- Build a trading model using multiple linear regression model 

- Evaluate the performance of the trading model using different investment indicators

Jupyter Notebook environment is configured in the course platform for practicing python coding without installing any client applications.
      


          Visualizing and Munging Stock Data
    -Why do investment banks and consumer banks use Python to build quantitative models to predict returns and evaluate risks? What makes Python one of the most popular tools for financial analysis? You are going to learn basic python to import, manipulate and visualize stock data in this module. As Python is highly readable and simple enough, you can build one of the most popular trading models - Trend following strategy by the end of this module!

Random variables and distribution
    -In the previous module, we built a simple trading strategy base on Moving Average 10 and 50, which are ""random variables"" in statistics. In this module, we are going to explore basic concepts of random variables. By understanding the frequency and distribution of random variables, we extend further to the discussion of probability. In the later part of the module, we apply the probability concept in measuring the risk of investing a stock by looking at the distribution of log daily return using python. Learners are expected to have basic knowledge of probability before taking this module.

Sampling and Inference 
    -In financial analysis, we always infer the real mean return of stocks, or equity funds, based on the  historical data of a couple years. This situation is in line with a core part of statistics - Statistical Inference - which we also base on sample data to infer the population of a target variable.In this module, you are going to understand the basic concept of statistical inference such as population, samples and random sampling. In the second part of the module, we shall estimate the range of mean return of a stock using a concept called confidence interval, after we understand the distribution of sample mean.We will also testify the claim of investment return using another statistical concept - hypothesis testing.

Linear Regression Models for Financial Analysis
    -In this module, we will explore the most often used prediction method - linear regression. From learning the association of random variables to simple and multiple linear regression model, we finally come to the most interesting part of this course: we will build a model using multiple indices from the global markets and predict the price change of an ETF of S&P500. In addition to building a stock trading model, it is also great fun to test the performance of your own models, which I will also show you how to evaluate them!",Python and Statistics for Financial Analysis
https://www.classcentral.com/course/the-outcomes-and-interventions-of-health-12855,"For clinical data science to be effective in healthcare—to achieve the outcomes desired—it must translate into decision support of some sort, either at the patient, clinician, or manager level. By the end of this course, students will be able to articulate the need for an intervention, to right size it, to choose the appropriate technology, to describe how knowledge should be obtained, and to design a monitoring plan.
      


          Knowing Where to Intervene
    -In this module, you will be introduced to the course through a range of decision support interventions used in health care. We will examine the Five Rights of decision support and go on to discuss the basics for deciding whether to build an intervention and, having done so, how to evaluate it.

Defining Decision Support
    -In this module, we will focus on issues of design, both for decision support and as they apply more broadly across multiple environments.

Using Transactional and Summative Data and Knowledge for Decision Support
    -In this module, we return to decision support, focusing on rules-- the key structure in most decision support. We'll provide a key framework for making sure you have all the minimum components for ensuring a successful implementation. We'll also address issues of languages used by rules and how to keep rules consistent within and between institutions. 

Eliciting and Creating Knowledge for Decision Support
    -In this module, we will go behind the scenes of decision support, examining where and how we get the knowledge that drives decision support --including data science-- for generating knowledge from data.",The Outcomes and Interventions of Health Informatics
https://www.classcentral.com/course/introstats-646,"We live in a world where data are increasingly available, in ever larger quantities, and are increasingly expected to form the basis for decisions by governments, businesses, and other organizations, as well as by individuals in their daily lives. To cope effectively, every informed citizen must be statistically literate.  This course will provide an intuitive introduction to applied statistical reasoning,  introducing fundamental statistical skills and acquainting students with the full process of inquiry and evaluation used in investigations in a wide range of fields.  In particular, the course will cover methods of data collection, constructing effective graphical and numerical displays to understand the data, how to estimate and describe the error in estimates of some important quantities, and the key ideas in how statistical tests can be used to separate significant differences from those that are only a reflection of the natural variability in data.



A first look at data
Weeks 1-2: Summary statistics and graphical displays for a single categorical or quantitative variable and for relationships between two variables.
Collecting data
Week 2:  Sampling.  Observational studies and experiments.  The effect of confounding and concluding causation.
Probability
Week 3:  Probability models, the normal distribution, the Law of Large Numbers, the Central Limit Theorem, sampling distributions.
Confidence Intervals Week 4: Confidence intervals and sample size estimation for proportions and means.
Tests of significance Week 5: Tests of significance, power and sample size estimation for proportions and meansTwo samplesWeek 6: Tests of significance and confidence intervals for proportions and means in the two sample case.
Simple linear regression
Week 7: Method of least squares, evaluating model fit, the effects of outliers and influential observations.
The process of statistical inquiry
Week 8: Capstone case study.",Statistics: Making Sense of Data
https://www.classcentral.com/course/advanced-clinical-data-science-12841,This course prepares you to deal with advanced clinical data science topics and techniques including temporal and research quality analysis.,Advanced Clinical Data Science
https://www.classcentral.com/course/edx-food-for-thought-1485,"Eating well and understanding the nuances of food has become a complicated and often confusing experience. Virtually every day brings news about some “miracle food” that we should be consuming or some ""poison"" we should be avoiding. One day it's tomatoes to prevent cancer, then flaxseed against heart disease or soybeans for reducing menopause symptoms. At the same time, we are warned about trans fats, genetically modified foods, aspartame or MSG. Dietary supplements may be touted as the key to health or a factor in morbidity. According to some, dairy products are indispensable while others urge us to avoid them. The same goes for meat, wheat and soy; the list goes on.This course will shed light on the molecules that constitute our macro and micronutrients and will attempt to clarify a number of the food issues using tthe best evidence available. 



Week 1: Introduction This introductory week covers topics such as the link between food and health, historical views of food and food movements. Week 2: Micronutrients – VitaminsA comprehensive look at vitamins. Topics to be discussed include deficiency diseases and recommended daily allowances. Week 3: Micronutrients – Minerals This week you will be presented a selection of minerals that are important in the human diet with a key focus on calcium and osteoporosis. Week 4: Macronutrients How does the body breakdown carbohydrates? What are the different types of fats? Why are some amino acids essential? These questions and more will be answered this week.Week 5: Agriculture This week you will learn how farming has changed from the discovery of the key ingredients for fertilizer in the 1800’s to the introduction of genetically modified crops in the 1990’s. Week 6: Food Additives What chemicals are added to preserve food and extend its shelf life? What ingredients are added to enhance the taste and look of food? This week you will explore the world of food additives. Week 7: Adverse Food Reactions This week focuses on adverse food reactions including different types of toxins, food allergies and microbial contamination that results in food poisoning. Week 8: Weight Control This week looks at the science and non-science behind weight control, especially as it relates to developed countries where obesity is rapidly becoming an epidemic.Week 9: Diet & Health This week you will learn about the risk factors for cancer and heart disease, as well as how diet and lifestyle play a key role in the development and prevention of these diseases.Week 10: Wrap UpThe course wraps up with a look at the history of the natural food business, as well as the science and “non-science” of eating nutritious food.",Food for Thought
https://www.classcentral.com/course/edx-deep-learning-explained-8746,"Machine learning uses computers to run predictive models that learn from existing data to forecast future behaviors, outcomes, and trends. Deep learning is a sub-field of machine learning, where models inspired by how our brain works are expressed mathematically, and the parameters defining the mathematical models, which can be in the order of few thousands to 100+ million, are learned automatically from the data.
Deep learning is a key enabler of AI powered technologies being developed across the globe. In this deep learning course, you will learn an intuitive approach to building complex models that help machines solve real-world problems with human-like intelligence. The intuitive approaches will be translated into working code with practical problems and hands-on experience. You will learn how to build and derive insights from these models using Python Jupyter notebooks running on your local Windows or Linux machine, or on a virtual machine running on Azure. Alternatively, you can leverage the Microsoft Azure Notebooks platform for free.
This course provides the level of detail needed to enable engineers / data scientists / technology managers to develop an intuitive understanding of the key concepts behind this game changing technology. At the same time, you will learn simple yet powerful ""motifs"" that can be used with lego-like flexibility to build an end-to-end deep learning model. You will learn how to use the Microsoft Cognitive Toolkit -- previously known as CNTK -- to harness the intelligence within massive datasets through deep learning with uncompromised scaling, speed, and accuracy. 
edX offers financial assistance for learners who want to earn Verified Certificates but who may not be able to pay the fee. To apply for financial assistance, enroll in the course, then follow this link to complete an application for assistance.



            Read more
          



Week 1: Introduction to deep learning and a quick recap of machine learning concepts.
Week 2: Building a simple multi-class classification model using logistic regression
Week 3: Detecting digits in hand-written digit image, starting by a simple end-to-end model, to a deep neural network
Week 4: Improving the hand-written digit recognition with convolutional network
Week 5: Building a model to forecast time data using a recurrent network
Week 6: Building text data application using recurrent LSTM (long short term memory) units",Deep Learning Explained
https://www.classcentral.com/course/ibm-ai-workflow-machine-learning-model-deployment-17100,"This is the fifth course in the IBM AI Enterprise Workflow Certification specialization.   You are STRONGLY encouraged to complete these courses in order as they are not individual independent courses, but part of a workflow where each course builds on the previous ones.

This course introduces you to an area that few data scientists are able to experience: Deploying models for use in large enterprises.  Apache Spark is a very commonly used framework for running machine learning models.  Best practices for using Spark will be covered in this course.  Best practices for data manipulation, model training, and model tuning will also be covered.  The use case will call for the creation and deployment of a recommender system. The course wraps up with an introduction to model deployment technologies.
 
By the end of this course you will be able to:
1.  Use Apache Spark's RDDs, dataframes, and a pipeline
2.  Employ spark-submit scripts to interface with Spark environments
3.  Explain how collaborative filtering and content-based filtering work
4.  Build a data ingestion pipeline using Apache Spark and Apache Spark streaming
5.  Analyze hyperparameters in machine learning models on Apache Spark
6.  Deploy machine learning algorithms using the Apache Spark machine learning interface
7.  Deploy a machine learning model from Watson Studio to Watson Machine Learning

Who should take this course?
This course targets existing data science practitioners that have expertise building machine learning models, who want to deepen their skills on building and deploying AI in large enterprises. If you are an aspiring Data Scientist, this course is NOT for you as you need real world expertise to benefit from the content of these courses.

What skills should you have?
It is assumed that you have completed Courses 1 through 4 of the IBM AI Enterprise Workflow specialization and you have a solid understanding of the following topics prior to starting this course: Fundamental understanding of Linear Algebra; Understand sampling, probability theory, and probability distributions; Knowledge of descriptive and inferential statistical concepts; General understanding of machine learning techniques and best practices; Practiced understanding of Python and the packages commonly used in data science: NumPy, Pandas, matplotlib, scikit-learn; Familiarity with IBM Watson Studio; Familiarity with the design thinking process.
      


            Read more
          



          Deploying Models
    -Today data scientists have more tooling than ever before to create model-driven or algorithmic solutions, and it is important to know when to take the time to make code optimizations.  This week we spend a lot of time performing hands on activities.  We start this week by interacting with Apache Spark then progressing to a tutorial with Docker.  We’ll wrap up the week working through a tutorial on Watson Machine Learning.

Deploying Models using Spark
    -This week is primarily focused on deploying models using Spark.  The rationale to move to Spark almost always has to do with scale, either at the level of model training or at the level of prediction. Although the resources available to build Spark applications are fewer than those for scikit-learn, Spark gives us the ability to build in an entirely scaleable environment.  We will also look at recommendation systems.  Most recommender systems today are able to leverage both explicit (e.g. numerical ratings) and implicit (e.g. likes, purchases, skipped, bookmarked) patterns in a ratings matrix.  The majority of modern recommender systems embrace either a collaborative filtering or a content-based approach. A number of other approaches and hybrids exist making some implemented systems difficult to categorize.  We wrap the week up with our hands-on case study on Model Deployment.",AI Workflow: Enterprise Model Deployment
https://www.classcentral.com/course/the-data-science-of-health-informatics-12856,"Health data are notable for how many types there are, how complex they are, and how serious it is to get them straight. These data are used for treatment of the patient from whom they derive, but also for other uses. Examples of such secondary use of health data include population health (e.g., who requires more attention), research (e.g., which drug is more effective in practice), quality (e.g., is the institution meeting benchmarks), and translational research (e.g., are new technologies being applied appropriately). By the end of this course, students will recognize the different types of health and healthcare data, will articulate a coherent and complete question, will interpret queries designed for secondary use of EHR data, and will interpret the results of those queries.
      


          Introduction to Databases and Data Types
    -In this module, we will begin by introducing and defining databases, and placing the role of databases within the context of clinical informatics. We will continue by introducing the common health data types such as demographics, diagnosis, medications, procedures, and utilization data. We will finish this module by reviewing the emerging health data such as lab orders/results, vital signs, social data, and patient-generated data.

Data Sources and Data Challenges
    -In this module, we review the data specifications extracted from insurance claims and electronic health records. We will then discuss the common challenges in using health data, specifically issues with data quality, data interoperability, and data system architectures. Finally, we will describe the “Big Data” challenges of health data and explain some of the data problems that may hinder analytical efforts.

Formulating Data Questions
    -With this understanding of the data available, it’s time to see how to turn questions you and your colleagues will have into queries the database can understand. Besides getting rules of thumb for doing this translation, you will also be introduced to three online tools available to test some of these skills. You will also watch an interview with Sam Meiselman, course instructor and the data manager in charge of the Johns Hopkins Enterprise Data Warehouse, who has to use these skills on a daily basis. 

Real World Applications of Data Science in Health Informatics
    -To send home the recurring message on the challenges and art of translating questions into queries, you will see interviews with two professionals: One who comes from the data management side of the equation, and one who comes from the domain. They will give you perspectives that are both similar (the need to understand the problem for which the data are being retrieved) and different (the multiplicity of data available vs the richness of the domain problem).",The Data Science of Health Informatics
https://www.classcentral.com/course/edx-data-structures-an-active-learning-approach-10436,"This interactive text used in this course was written with the intention of teaching Computer Science students about various data structures as well as the applications in which each data structure would be appropriate to use. It is currently being taught at the University of California, San Diego (UCSD), the University of San Diego (USD), and the University of Puerto Rico (UPR). This coursework utilizes the Active Learning approach to instruction, meaning it has various activities embedded throughout to help stimulate your learning and improve your understanding of the materials we will cover. You will encounter ""STOP and Think"" questions that will help you reflect on the material, ""Exercise Breaks"" that will test your knowledge and understanding of the concepts discussed, and ""Code Challenges"" that will allow you to actually implement some of the algorithms we will cover. Currently, all code challenges are in C++ or Python, but the vast majority of the content is language-agnostic theory of complexity and algorithm analysis. In other words, even without C++ or Python knowledge, the key takeaways can still be obtained.
      


          Module 1: Introduction and Review

1.1 Welcome to Data Structures!
1.2 Tick Tock, Tick Tock
1.3 Classes of Computational Complexity
1.4 The Fuss of C++
1.5 Random Numbers
1.6 Bit-by-Bit
1.7 The Terminal-ator
1.8 Git: the ""Undo"" Button of Software Development

Module 2: Introductory Data Structures

2.1 Array Lists
2.2 Linked Lists
2.3 Skip Lists
2.4 Circular Arrays
2.5 Abstract Data Types
2.6 Deques
2.7 Queues
2.8 Stacks
2.9 And the Iterators Gonna Iterate-ate-ate

Module 3: Tree Structures

3.1 Lost in a Forest of Trees
3.2 Heaps
3.3 Binary Search Trees
3.4 BST Average-Case Time Complexity
3.5 Randomized Search Trees
3.6 AVL Trees
3.7 Red-Black Trees
3.8 B- Trees
3.9 B+ Trees

Module 4: Introduction to Graphs

4.1 Introduction to Graphs
4.2 Graph Representations
4.3 Algorithms on Graphs: Breadth-First Search
4.4 Algorithms on Graphs: Depth-First Search
4.5 Dijkstra's Algorithm
4.6 Minimum Spanning Trees: Prim's and Kruskal's Algorithms
4.7 Disjoint Sets

Module 5: Hashing

5.1 The Unquenched Need for Speed
5.2 Hash Functions
5.3 Introduction to Hash Tables
5.4 Probability of Collisions
5.5 Collision Resolution: Open Addressing
5.6 Collision Resolution: Closed Addressing (Separate Chaining)
5.7 Collision Resolution: Cuckoo Hashing
5.8 Hash Maps

Module 6: Implementing a Lexicon

6.1 Creating a Lexicon
6.2 Using Linked Lists
6.3 Using Arrays
6.4 Using Binary Search Trees
6.5 Using Hash Tables and Hash Maps
6.6 Using Multiway Tries
6.7 Using Ternary Search Trees

Module 7: Coding and Information Compression

7.1 Return of the (Coding) Trees
7.2 Entropy and Information Theory
7.3 Honey, I Shrunk the File
7.4 Bitwise I/O

Module 8: Conclusions

8.1 Summaries of Data Structures",Data Structures: An Active Learning Approach
https://www.classcentral.com/course/panprevention-3059,"What can we do to prevent outbreaks of infectious diseases from becoming epidemics or pandemic? In this course, you’ll learn the facts about infectious diseases and medical responses. We'll focus on the public health laws and policies that provide the framework for effective prevention, like quarantine laws, drug development policies, and bioterrorism and biodefense.
      


          Week 1: Introduction
    -Welcome to Week One! This week’s lesson immerses you in the world of epidemics, pandemics and outbreaks and our efforts to prevent and respond to them. It will prepare you to engage in depth with the lessons that are coming up in weeks 2-4: ""Understanding Infectious Diseases,"" ""Global Health Security,"" and ""Local Countermeasures.""

Week 2: Understanding Infectious Diseases
    -Welcome to Week Two! This week’s lesson provides you with the tools needed to understand the world of infectious disease. It will allow you to develop a context of knowledge and familiarity with the concepts that inform legal and public health response strategies to outbreaks, epidemics and pandemics. What you learn here will be drawn upon in weeks 3-4: “Global Health Security” and “Local Countermeasures.”


Week 3: Global Health Security
    -Welcome to Week 3! Now that you are more familiar with the nature and history of infectious disease, consider the following quote from Natalie Angier, American nonfiction writer and a science journalist for The New York Times: “Today, diseases as common as the cold and as rare as Ebola are circling the globe with near telephonic speed, making long-distance connections and intercontinental infections almost as if by satellite. You needn't even bother to reach out and touch someone. If you live, if you're homeothermic biomass, you will be reached and touched. Microbes are, after all, members of the most ancient, zealous and Darwinically gilded 24-7 delivery consortium. They travel by land, sea, air, nose, blows, glove, love, sewage, steerage, rat backs, hat racks, uncooked burritos, overlooked mosquitoes. And, oh, how they love the global village.” Indeed, the same forces of globalization that have lowered barriers to global communication, travel, and commerce have amplified the ability for infectious diseases to spread internationally. In many ways, defense against this common threat is only as strong as each nation’s ability to prevent, detect, and respond to infectious disease threats, and the collective ability of the international community to coordinate these capacities multilaterally.

Week 4: Local Countermeasures
    -Welcome to Week Four! This week’s lesson introduces you to the legal interventions available to state and local public health practitioners to combat epidemics, pandemics and outbreaks. In addition to the law, we will look at some of the ethical and practical issues associated with disease reporting requirements, the effect of a declaration of an emergency, travel restrictions, quarantine and isolation.","Epidemics, Pandemics and Outbreaks"
https://www.classcentral.com/course/meteor-development-4328,"In this course, you will learn how to create a complete, multi-user web site using the Meteor.js framework and MongoDB. You will implement user authentication, security features, reactive templates and routing using iron router. You will carry out key database operations such as inserting, removing and updating data as well as sorting and filtering. You will see how a complete application can be built, line by line. 

At the end of the course, you will be able to:
1. Install the Meteor.js system and create a web application
2. Work with the Meteor.js packaging system
3. Write Meteor.js templates that can reactively display data
4. Use insert, remove and update operations on MongoDB
5. Write MongoDB data filters to search for and sort data
6 .Add  user authentication functionality to a website
7. Control what is displayed on the page using iron:router 
8. Implement basic security features 

In this course, you will complete:
1 server install assignment taking ~1 hour to complete
1 programming assignment taking ~8 hours to complete
4 quizzes, each taking ~20 minutes to complete
multiple practice quizzes, each taking ~5 minutes to complete

Prerequisites

This course is designed to build on top of the material delivered in the previous two courses in this specialisation. Therefore, we recommend that if you find this course too technically challenging that you first complete the previous courses before re-commencing this one. Specifically, we expect you to be able to code basic HTML, CSS and Javascript before you take this course. 

Participation in or completion of this online course will not confer academic credit for University of London programmes.
      


            Read more
          



          Introduction to Meteor.js Development course overview
    -Welcome to 'Introduction to Meteor.js Development'! In this course, you will learn how to create a complete, multi-user web site using the Meteor.js framework and MongoDB. You will implement user authentication, security features, reactive templates and routing using iron router. You will also carry out key database operations such as inserting, removing and updating data as well as sorting and filtering. Finally, you will see how a complete application can be built, line by line. I hope you enjoy the course!  

Introduction to Meteor 
    -Welcome to the first module of 'Introduction to Meteor.js Development'! In this module we'll be installing Meteor tools, editing a template and learning how to define a template helper and template event listeners. I hope you enjoy this module! 

Databases and collections
    -Welcome to the second module of 'Introduction to Meteor.js Development'! In this course we will be creating Mongo Collections and using Mongo find and insert operations. In addition, we will be looking at how to control a Bootstrap modal from Meteor and we will be using third party Meteor packages to add functionality. Enjoy!

User authentication
    -Welcome to the third module of 'Introduction to Meteor.js Development!'. In this module we will be looking at adding a user authentication to your Meteor app and learning how to use Mongo filters. Finally, we will be using the Meteor reactive Session variable and we will implement an infinite scroll. Enjoy!

Security and routing
    -Welcome to the final module of 'Introduction to Meteor.js Development!'. In this module we will show you how to perform basic security testing on your app and how to implement basic data security features. In addition, we will look at how to organise Meteor application code and how to implement multiple routes using iron:router. Enjoy!",Introduction to Meteor.js Development
https://www.classcentral.com/course/wharton-people-analytics-4264,"People analytics is a data-driven approach to managing people at work. For the first time in history, business leaders can make decisions about their people based on deep analysis of data rather than the traditional methods of personal relationships, decision making based on experience, and risk avoidance. In this brand new course, three of Wharton’s top professors, all pioneers in the field of people analytics, will explore the state-of-the-art techniques used to recruit and retain great people, and demonstrate how these techniques are used at cutting-edge companies. They’ll explain how data and sophisticated analysis is brought to bear on people-related issues, such as recruiting, performance evaluation, leadership, hiring and promotion, job design, compensation, and collaboration. This course is an introduction to the theory of people analytics, and is not intended to prepare learners to perform complex talent management data analysis. By the end of this course, you’ll understand how and when hard data is used to make soft-skill decisions about hiring and talent development, so that you can position yourself as a strategic partner in your company’s talent management decisions. This course is intended to introduced you to Organizations flourish when the people who work in them flourish. Analytics can help make both happen. This course in People Analytics is designed to help you flourish in your career, too.
      


          Introduction to People Analytics, and Performance Evaluation
    -In this module, you'll meet Professors Massey, Bidwell, and Haas, cover the structore and scope of the course, and dive into the first topic: Performance Evaluation. Performance evaluation plays an influential role in our work lives, whether it is used to reward or punish and/or to gather feedback. Yet its fundamental challenge is that the measures we used to evaluate performance are imperfect: we can't infer how hard or smart an employee is working based solely on outcomes. In this module, you’ll learn the four key issues in measuring performance: regression to the mean, sample size, signal independence, and process vs. outcome, and see them at work in current companies, including an extended example from the NFL. By the end of this module, you’ll understand how to separate skill from luck and learn to read noisy performance measures, so that you can go into your next performance evaluation sensitive to the role of chance, knowing your environment, and aware of the four most common biases, so that you can make more informed data-driven decisions about your company's most valuable asset: its employees.

Staffing
    -In this module, you'll learn how to use data to better analyze the key components of the staffing cycle: hiring, internal mobility and career development, and attrition. You'll explore different analytic approaches to predicting performance for hiring and for optimizing internal mobility, to understanding and reducing turnover, and to predicting attrition. You'll also learn the critical skill of understanding causality so that you can avoid using data incorrectly. By the end of this module, you'll be able to use data to improve the quality of the decisions you make in getting the right people into the right jobs and helping them stay there, to benefit not only your organization but also employee's individual careers. 

Collaboration
    -In this module, you'll learn the basic principles behind using people analytics to improve collaboration between employees inside an organization so they can work together more successfully. You'll explore how data is used to describe, map, and evaluate collaboration networks, as well as how to intervene in collaboration networks to improve collaboration using examples from real-world companies. By the end of this module, you'll know how to deploy the tools and techniques of organizational network analysis to understand and improve collaboration patterns inside your organization to make your organization, and the people working within in it, more productive, effective, and successful. 

Talent Management and Future Directions
    -In this module, you explore talent analytics: how data may be used in talent assessment and development to maximize employee ability. You'll learn how to use data to move from performance evaluation to a more deeper analysis of employee evaluation so that you may be able to improve the both the effectiveness and the equitability of the promotion process at your firm. By the end of this module, you'll will understand the four major challenges of talent analytics: context, interdependence, self-fulfilling prophecies, and reverse causality, the challenges of working with algorithms, and some practical tips for incorporating data sensitively, fairly, and effectively into your own talent assessment and development processes to make your employees and your organization more successful. In the course conclusion, you'll also learn the current challenges and future directions of the field of people analytics, so that you may begin putting employee data to work in a ways that are smarter, practical and more powerful.",People Analytics
https://www.classcentral.com/course/canvas-network-energy-and-earth-fossil-fuels-alternative-and-renewable-energy-9468,"This course is part of the Introduction to Environmental Science open course series. ""Energy and Earth: Fossil Fuels, Alternative, and Renewable Energy"" explores the production and use of energy by humans and its impact on the environment, human health and Earth’s ecosystems. We will discuss some of the consequences of using fossil fuels and explore alternative and renewable energy sources.","Energy and Earth: Fossil Fuels, Alternative, and Renewable Energy"
https://www.classcentral.com/course/edx-principles-of-machine-learning-r-edition-11602,"Machine learning uses computers to run predictive models that learn from existing data in order to forecast future behaviors, outcomes, and trends. 
In this data science course, you will be given clear explanations of machine learning theory combined with practical scenarios and hands-on experience building, validating, and deploying machine learning models. You will learn how to build and derive insights from these models using R, and Azure Notebooks. 
edX offers financial assistance for learners who want to earn Verified Certificates but who may not be able to pay the fee. To apply for financial assistance, enroll in the course, then follow this link to complete an application for assistance.




Introduction to Machine Learning
Exploring Data
Data Preparation and Cleaning
Getting Started with Supervised Learning
Improving Model Performance
Machine Learning Algorithms
Unsupervised Learning

Note: This syllabus is preliminary and subject to change.",Principles of Machine Learning: R Edition
https://www.classcentral.com/course/linear-algebra-machine-learning-10453,"In this course on Linear Algebra we look at what linear algebra is and how it relates to vectors and matrices. Then we look through what vectors and matrices are and how to work with them, including the knotty problem of eigenvalues and eigenvectors, and how to use these to solve problems. Finally  we look at how to use these to do fun things with datasets - like how to rotate images of faces and how to extract eigenvectors to look at how the Pagerank algorithm works.
Since we're aiming at data-driven applications, we'll be implementing some of these ideas in code, not just on pencil and paper. Towards the end of the course, you'll write code blocks and encounter Jupyter notebooks in Python, but don't worry, these will be quite short, focussed on the concepts, and will guide you through if you’ve not coded before.

At the end of this course you will have an intuitive understanding of vectors and matrices that will help you bridge the gap into linear algebra problems, and how to apply these concepts to machine learning.
      


          Introduction to Linear Algebra and to Mathematics for Machine Learning
    -In this first module we look at how linear algebra is relevant to machine learning and data science. Then we'll wind up the module with an initial introduction to vectors. Throughout, we're focussing on developing your mathematical intuition, not of crunching through algebra or doing long pen-and-paper examples. For many of these operations, there are callable functions in Python that can do the adding up - the point is to appreciate what they do and how they work so that, when things go wrong or there are special cases, you can understand why and what to do.

Vectors are objects that move around space
    -In this module, we look at operations we can do with vectors - finding the modulus (size), angle between vectors (dot or inner product) and projections of one vector onto another. We can then examine how the entries describing a vector will depend on what vectors we use to define the axes - the basis. That will then let us determine whether a proposed set of basis vectors are what's called 'linearly independent.' This will complete our examination of vectors, allowing us to move on to matrices in module 3 and then start to solve linear algebra problems.

Matrices in Linear Algebra: Objects that operate on Vectors
    -Now that we've looked at vectors, we can turn to matrices.  First we look at how to use matrices as tools to solve linear algebra problems, and as objects that transform vectors. Then we look at how to solve systems of linear equations using matrices, which will then take us on to look at inverse matrices and determinants, and to think about what the determinant really is, intuitively speaking. Finally, we'll look at cases of special matrices that mean that the determinant is zero or where the matrix isn't invertible - cases where algorithms that need to invert a matrix will fail.

Matrices make linear mappings
    -In Module 4, we continue our discussion of matrices; first we think about how to code up matrix multiplication and matrix operations using the Einstein Summation Convention, which is a widely used notation in more advanced linear algebra courses. Then, we look at how matrices can transform a description of a vector from one basis (set of axes) to another. This will allow us to, for example, figure out how to apply a reflection to an image and manipulate images. We'll also look at how to construct a convenient basis vector set in order to do such transformations. Then, we'll write some code to do these transformations and apply this work computationally.

Eigenvalues and Eigenvectors: Application to Data Problems
    -Eigenvectors are particular vectors that are unrotated by a transformation matrix, and eigenvalues are the amount by which the eigenvectors are stretched. These special 'eigen-things' are very useful in linear algebra and will let us examine Google's famous PageRank algorithm for presenting web search results. Then we'll apply this in code, which will wrap up the course.",Mathematics for Machine Learning: Linear Algebra
https://www.classcentral.com/course/what-is-a-proof-9212,"Mathematical thinking is crucial in all areas of computer science: algorithms, bioinformatics, computer graphics, data science, machine learning, etc. In this course, we will learn the most important tools used in discrete mathematics: induction, recursion, logic, invariants, examples, optimality. We will use these tools to answer typical programming questions like: How can we be certain a solution exists? Am I sure my program computes the optimal answer? Do each of these objects meet the given requirements?

In the course, we use a try-this-before-we-explain-everything approach: you will be solving many interactive (and mobile friendly) puzzles that were carefully designed to allow you to invent many of the important ideas and concepts yourself.

Prerequisites: 
1. We assume only basic math (e.g., we expect you to know what is a square or how to add fractions), common sense and curiosity. 
2. Basic programming knowledge is necessary as some quizzes require programming in Python.
      


          Making Convincing Arguments
    -Why some arguments are convincing and some are not? What makes an argument convincing? How to establish your argument in such a way that there is no possible room for doubt left? How mathematical thinking can help with this? In this week we will start digging into these questions. We will see how a small remark or a simple observation can turn a seemingly non-trivial question into an obvious one. Through various examples we will observe a parallel between constructing a rigorous argument and mathematical reasoning.

How to Find an Example?
    -How can we be certain that an object with certain requirements exist? One way to show this, is to go through all objects and check whether at least one of them meets the requirements. However, in many cases, the search space is enormous. A computer may help, but some reasoning that narrows the search space is important both for computer search and for ""bare hands"" work. In this module, we will learn various techniques for showing that an object exists and that an object is optimal among all other objects. As usual, we'll practice solving many interactive puzzles. We'll show also some computer programs that help us to construct an example.

Recursion and Induction
    -We'll discover two powerful methods of defining objects, proving concepts, and implementing programs — recursion and induction. These two methods are heavily used, in particular, in algorithms — for analysing correctness and running time of algorithms as well as for implementing efficient solutions. You will see that induction is as simple as falling dominos, but allows to make convincing arguments for arbitrarily large and complex problems by decomposing them and moving step by step. You will learn how famous Gauss unexpectedly solved his teacher's problem intended to keep him busy the whole lesson in just two minutes, and in the end you will be able to prove his formula using induction. You will be able to generalize scary arithmetic exercises and then solve them easily using induction.

Logic
    -We have already invoked mathematical logic when we discussed how to make convincing arguments by giving examples. This week we will turn mathematical logic full on. We will discuss its basic operations and rules. We will see how logic can play a crucial and indispensable role in creating convincing arguments. We will discuss how to construct a negation to the statement, and you will see  how to win an argument by showing your opponent is wrong with just one example called counterexample!. We will see tricky and seemingly counterintuitive, but yet (an unintentional pun) logical aspects of mathematical logic. We will see one of the oldest approaches to making convincing arguments: Reductio ad Absurdum.

Invariants
    -""There are things that never change"". Apart from being just a philosophical statement, this phrase turns out to be an important idea that can actually help. In this module we will see how it can help in problem solving. Things that do not change are called invariants in mathematics. They form an important tool of proving with numerous applications, including estimating running time of programs and algorithms. We will get some intuition of what they are, see how they can look like, and get some practice in using them.

Solving a 15-Puzzle
    -In this module, we consider a well known 15-puzzle where one needs to restore order among 15 square pieces in a square box. It turns out that the behavior of this puzzle is determined by mathematics: it is solvable if and only if the corresponding permutation is even. We will learn the basic properties of even and odd permutations. The task is to write a program that determines whether a permutation is even or odd. There is also a more difficult bonus task: to write a program that actually computes a solution (sequence of moves) for a given position assuming that this position is solvable.",Mathematical Thinking in Computer Science
https://www.classcentral.com/course/python-for-applied-data-science-11194,"This introduction to Python will kickstart your learning of Python for data science, as well as programming in general. This beginner-friendly Python course will take you from zero to programming in Python in a matter of hours.

Module 1 - Python Basics
o	Your first program
o	Types
o	Expressions and Variables
o	String Operations

Module 2 - Python Data Structures
o	Lists and Tuples
o	Sets
o	Dictionaries

Module 3 - Python Programming Fundamentals
o	Conditions and Branching
o	Loops
o	Functions
o	Objects and Classes

Module 4 - Working with Data in Python
o	Reading files with open
o	Writing files with open
o	Loading data with Pandas
o	Numpy 

Finally, you will create a project to test your skills.

LIMITED TIME OFFER: Subscription is only $39 USD per month for access to graded materials and a certificate.
      


          Python Basics 

Python Data Structures 

Python Programming Fundamentals 

Working with Data in Python 

Analyzing US Economic Data and Building a Dashboard",Python for Data Science
https://www.classcentral.com/course/kadenze-creative-applications-of-deep-learning-with-tensorflow-6679,"This first course in the two-part program, Creative Applications of Deep Learning with TensorFlow, introduces you to deep learning: the state-of-the-art approach to building artificial intelligence algorithms. We cover the basic components of deep learning, what it means, how it works, and develop code necessary to build various algorithms such as deep convolutional networks, variational autoencoders, generative adversarial networks, and recurrent neural networks. A major focus of this course will be to not only understand how to build the necessary components of these algorithms, but also how to apply them for exploring creative applications. We'll see how to train a computer to recognize objects in an image and use this knowledge to drive new and interesting behaviors, from understanding the similarities and differences in large datasets and using them to self-organize, to understanding how to infinitely generate entirely new content or match the aesthetics or contents of another image.Deep learning offers enormous potential for creative applications and in this course we interrogate what's possible. Through practical applications and guided homework assignments, you'll be expected to create datasets, develop and train neural networks, explore your own media collections using existing state-of-the-art deep nets, synthesize new content from generative algorithms, and understand deep learning's potential for creating entirely new aesthetics and new ways of interacting with large amounts of data.What students are saying:""It was a fantastic course and I want to say ""super big thank you"" to the instructor Parag Mital. His lectures were highly valuable and inspiring. It not only gave me inspiration in how to apply ML for art, it gave me deeper insights in Deep Learning in general.""""After taking several courses in Machine Learning, I came across this course and it immediately caught my attention due to the the speed of delivery, content topics and it's pace when talking about concepts such as gradient descent and convolutions. Honestly, the course truly is EXCELLENT. Parag really is great a presenting the materials in an easy-to-understand manner, and perhaps more importantly, he has you focus on the RIGHT concepts and not going down rabbit-holes.""



            Read more
          



          Session 1: Introduction To Tensorflow We'll cover the importance of data with machine and deep learning algorithms, the basics of creating a dataset, how to preprocess datasets, then jump into Tensorflow, a library for creating computational graphs built by Google Research. We'll learn the basic components of Tensorflow and see how to use it to filter images.
 
Session 2: Training A Network W/ Tensorflow We'll see how neural networks work, how they are ""trained"", and see the basic components of training a neural network. We'll then build our first neural network and use it for a fun application of teaching a neural network how to paint an image.
 
Session 3: Unsupervised And Supervised Learning This session goes deep. We create deep neural networks capable of encoding a large dataset, and see how we can use this encoding to explore ""latent"" dimensions of a dataset or for generating entirely new content. We'll see what this means, how ""autoencoders"" can be built, and learn a lot of state-of-the-art extensions that make them incredibly powerful. We'll also learn about another type of model that performs discriminative learning and see how this can be used to predict labels of an image.
 
Session 4: Visualizing And Hallucinating Representations This sessions works with state of the art networks and sees how to understand what ""representations"" they learn. We'll see how this process actually allows us to perform some really fun visualizations including ""Deep Dream"" which can produce infinite generative fractals, or ""Style Net"" which allows us to combine the content of one image and the style of another to produce widely different painterly aesthetics automatically.
 
Session 5: Generative Models The last session offers a teaser into some of the future directions of generative modeling, including some state of the art models such as the ""generative adversarial network"", and its implementation within a ""variational autoencoder"", which allows for some of the best encodings and generative modeling of datasets that currently exist. We also see how to begin to model time, and give neural networks memory by creating ""recurrent neural networks"" and see how to use such networks to create entirely generative text.",Creative Applications of Deep Learning with TensorFlow
https://www.classcentral.com/course/climatechange-495,"What is Climate Change? How should we respond to
Climate Change? These questions are complex, not least because the responses
available to us depend upon who is providing the answers and the particular
perspective they take. The economist sees the economic challenges and
opportunities of Climate Change; the scientist sees the need to describe and
explain Climate Change; the policy-maker and social scientist
see Climate Change as a social problem. Therefore, the first step to
understanding Climate Change and what we do about it is to see how experts from
different disciplines engage with the issue. The second step is to appreciate how
our response to Climate Change depends upon the interplay between these
different approaches.
This course offers you an introduction to different
disciplinary perspectives on Climate Change to help you think about how Climate Change
affects you as an individual, as a member of your local community, as a citizen
of your country and as a member of the global community. We have designed the
presentations, discussions, activities and assessment tasks in this course to
help you understand what Climate Change is and what you – and we – should do about it.




The overall aim of this subject is to provide an introduction to the socio-political, scientific, and economic aspects of the phenomenon known as Climate Change. In doing so it is hoped that the student will emerge with an enhanced ability to analyse claims both about the science itself and the responses that can be made by humanity at present and for the future, based on current scientific data and its predictions over the next decades. You will emerge with a broad understanding of the science underpinning the claim that human activity has played a role in causing the current rise in global temperature. You will also develop an awareness of the present and future impact on global communities, the political response to such impacts, and consider basic economic concepts and models that describe a framework in which changes to our use of resources can occur.",Climate Change
https://www.classcentral.com/course/edx-ethics-and-law-in-data-and-analytics-9354,"Corporations, governments, and individuals have powerful tools in Analytics and AI to create real-world outcomes, for good or for ill. 
Data professionals today need both the frameworks and the methods in their job to achieve optimal results while being good stewards of their critical role in society today. 
In this course, you'll learn to apply ethical and legal frameworks to initiatives in the data profession. You'll explore practical approaches to data and analytics problems posed by work in Big Data, Data Science, and AI. You'll also investigate applied data methods for ethical and legal work in Analytics and AI. 
edX offers financial assistance for learners who want to earn Verified Certificates but who may not be able to pay the fee. To apply for financial assistance, enroll in the course, then follow this link to complete an application for assistance.",Ethics and Law in Data and Analytics
https://www.classcentral.com/course/edx-american-government-3828,"American politics has all the aspects of drama, but it has real meaning for people’s everyday lives.
What are the foundations of the U.S. political system? How do leading institutions such as the presidency and Congress operate? Where do public opinion, political parties, groups, and the media fit in? What explains America’s economic, social, and foreign policies?
If exploring these questions interests you, then this is the course for you. This course is an introduction to the U.S. government that draws on political science and cases—such as the Iraq invasion and health care reform—to explain how the U.S. government system works.
No previous study of American politics needed. Join us on a journey into the heart of the U.S. governing system. This course is ideal for:

College and advanced placement high school students looking for an introduction to American government.
U.S.-based political science and government teachers looking for a way to augment their own courses.
Global teachers and educators looking to explain the American political system to their students and citizens.
Citizens in the U.S. and abroad who want to understand the workings of the U.S. political system.

HarvardX requires individuals who enroll in its courses on edX to abide by the terms of the edX honor code. HarvardX will take appropriate corrective action in response to violations of the edX honor code, which may include dismissal from the HarvardX course; revocation of any certificates received for the HarvardX course; or other remedies as circumstances warrant. No refunds will be issued in the case of corrective action for such violations. Enrollees who are taking HarvardX courses as part of another program will also be governed by the academic policies of those programs.
HarvardX pursues the science of learning. By registering as an online learner in an HX course, you will also participate in research about learning. Read our research statement to learn more.
Harvard University and HarvardX are committed to maintaining a safe and healthy educational and work environment in which no member of the community is excluded from participation in, denied the benefits of, or subjected to discrimination or harassment in our program. All members of the HarvardX community are expected to abide by Harvard policies on nondiscrimination, including sexual harassment, and the edX Terms of Service. If you have any questions or concerns, please contact harvardx@harvard.edu and/or report your experience through the edX contact form.



            Read more
          



I. Foundations

Political culture
Limited government
Representative government
Federalism
Civil liberties
Civil rights

II. Institutions

Congress & constituency
Congress & party
Presidents & domestic policy
Presidents & foreign policy
Federal bureaucracy
Judiciary & Supreme Court

III. Mass Politics

Public opinion
Political parties
Campaigns & elections
Political movements
Interest groups
News media

IV. Public Policy

Social policy
Fiscal & monetary policy
Welfare & income policy
Regulatory policy
Foreign policy
Dynamics of American politics",American Government
https://www.classcentral.com/course/edx-computing-in-python-iv-objects-algorithms-11472,"Complete your introductory knowledge of computer science with this final course on objects and algorithms. Now that you've learned about complex control structures and data structures, learn to develop programs that more intuitively leverage your natural understanding of problems through object-oriented programming. Then, learn to analyze the complexity and efficiency of these programs through algorithms. In addition, certify your broader knowledge of Introduction to Computing with a comprehensive exam.By the end of this course, you'll be able to write programs in Python that leverage your more natural understanding of data structures by creating objects to represent the structures you work with most often. For example, if you were creating a class roster application, you'll learn how to create an object representing a student's name, ID number, and attendance record. Then, you'll be able to create applications that leverage sorting and searching algorithms to sort that roster alphabetically, search for a particular student, and evaluate the efficiency of both those operations.Structurally, the course is comprised of several parts. Instruction is delivered via a series of short (2-3 minute) videos. In between those videos, you'll complete both multiple choice questions and coding problems to demonstrate your knowledge of the material that was just covered. These exercises count for 20% of your grade. Then, after each major chapter, you'll complete a problem set of collected, more challenging problems. These count for 40% of your grade. Finally, you'll complete a final course exam, which counts for the remaining 40% of your grade.
      


            Read more
          



          Chapter 1. Objects. Working with instances of complex data types or defining your own, like creating a class to represent a video game character, a class syllabus, or an item for sale. Chapter 2. Algorithms. Creating complex code for searching in large lists or sorting lists of data, and analyzing code for its complexity. Chapter 3. Course Recap. A comprehensive review of the Xseries as a whole, leading into the final exam.",Computing in Python IV: Objects & Algorithms
https://www.classcentral.com/course/social-media-5792,"##
Social networks have emerged over the past 10 years in various forms to play a fundamental role in our lives.
But do we actually understand these networks? And are we using them in the right ways?
This course will teach you not just about the qualities and differences between social networks but also the impact they can have on our lives.
Understand different social networks
On this course you will explore the various properties of networks in order to understand more about how we can measure online power and influence.
Through doing this you will discover that networks such as Twitter, Facebook and LinkedIn have very distinct qualities. You’ll learn how organisations can use these qualities to learn more about the people participating in the network, and the communities they represent, and will be encouraged to reflect on what your participation in online social networks tells the world about you.
Explore how social media can be used positively
The media are quick to report on negative aspects of social networking such as cyberbullying or identity theft, but we hear less about the benefits that occur when networks are used to enhance employability or raise awareness of good causes.  On this course you’ll explore how social media can be used for good, not just at a personal level but at a societal level.
Learn how to manage your own social networks
Throughout the course you’ll learn different ways for managing your own networks in a professional way to help your own career development.
In fact the course itself is a social network. We encourage you to interact with other learners from all around the world to directly put into practice the lessons of the course and build your own online networks for learning and professional purposes.
Learn with well-known experts in Web Science
You’ll learn with well-known experts from the University of Southampton’s Web Science Institute, including lead educators, Associate Professors Lisa Harris and David Millard, and contributors, Professors Dame Wendy Hall and Sir Nigel Shadbolt.
Other University of Southampton Web Science courses are Web Science: How the Web is Changing the World and an Introduction to Linked Data and the Semantic Web.
The course is intended for existing users of social networks, who want to understand a bit more about how their social network activity might be used by others, and also how it can be made to work more effectively for them.
It will appeal to computer science, web science, business studies or marketing graduates, students and practitioners wishing to expand their knowledge.



            Read more",The Power of Social Media
https://www.classcentral.com/course/opensap-driving-business-results-with-big-data-3513,"Big Data is an extraordinary knowledge revolution that is sweeping almost invisibly through business, academia, government, healthcare, and everyday life. It already enables us to provide a healthier life for our children, ensure safety and independence for older people, conserve precious resources like water and energy, and peer into our own individual genetic makeup.The term “Big Data” describes the accumulation and analysis of vast amounts of information. But Big Data is much more than big data. It’s also the ability to extract meaning: to sort through masses of numbers and find the hidden patterns, unexpected correlations, and surprising connections.One of the biggest impacts of Big Data is in business. Companies that adopt “data-driven decision making” enjoy significantly greater productivity than those that do not.In this course, you’ll learn from real life use cases what it takes to extract that value from Big Data, and which solutions are available to acquire, store, analyze, and act on Big Data. We will also introduce SAP Rapid Deployment solutions, which help businesses adopt Big Data solutions and related technology. We will demonstrate how all this is done in a live system and provide course participants with access to the system to perform the steps themselves.During the first week of the course we will talk about the value behind Big Data. We will look at real use cases where enterprises managed to drive success based on information hidden in Big Data. We will also feature segments of the documentary about “The Human Face of Big Data”, a global media project focusing on the new ability to collect, analyze, triangulate, and visualize vast amounts of data in real time.In the second week we take a deep dive into SAP’s Big Data solutions. You’ll learn which technologies are used to collect, integrate, and store Big Data. We also cover a range of applications and analytical tools we have at our disposal to extract the hidden secrets from massive amounts of data and drive business success.The last three weeks are dedicated to SAP Rapid Deployment solutions, which help customers to quickly adopt key innovations in SAP Big Data solutions and technologies. You’ll learn how best practices, proven methodologies, and pre-configured content make adopting innovations simple and predictable. You will see how the SAP Big Data rapid-deployment solutions lower the complexity of implementation projects, and hence project risks, while accelerating time to value.



            Read more
          



Week 1: Introduction to Big DataWeek 2: Big Data SolutionsWeek 3: Big Data IntelligenceWeek 4: Predictive Analytics on Big DataWeek 5: Marketing with Big DataWeek 6: Final Exam",Driving Business Results with Big Data
https://www.classcentral.com/course/photography-5682,"Although taking, sharing, and viewing photographs has become second nature for many of us, our regular engagement with images does not necessarily make us visually literate. This course aims to address the gap between seeing and truly understanding photographs by introducing a diversity of ideas, approaches, and technologies that inform their making. In this course you will look closely at photographs from the collection of The Museum of Modern Art and hear a variety of perspectives on what a photograph is and the ways that photography has been used throughout its nearly 180 year history: as a means of artistic expression, as a tool for science and exploration; as an instrument of documentation; to tell stories and record histories; and as a mode of communication and critique in our ever increasingly visual culture.


Learning Objectives

•	Develop skills to better examine and understand the differences between photographs and photographic images.
•	Discover how context influences the production, circulation, and reception of photographic images.
•	Learn about different modes of artistic and technological experimentation and innovation in photography.
•	Investigate photography’s role in our increasingly visual culture.
      


          Introduction to Seeing Through Photographs
    -“Photography is a foreign language everyone thinks he speaks.”—Philip-Lorca di Corcia

One Subject, Many Perspectives
    -Discover photography's roots in both art and science by observing the diverse ways the medium has been used across time to capture a single subject familiar to us all. 

Documentary Photography
    -Explore a variety of approaches to documentary photography, from those that aim to produce objective records to those that critique the reliability of photographs as evidence.

Pictures of People
    -Examine pictures of people—as individuals or as representatives of a type, posed or captured unaware—and discover how the choices made by both photographer and subject inform our assumptions about those depicted.

Constructing Narratives & Challenging Histories
    -Learn to look critically at the way photographs have been used to construct narratives that shape our understanding of ourselves and the world around us.

Ocean of Images: Photography & Contemporary Culture
    -Many artists are turning to our image-saturated world as both a source for and subject of their work. Explore how they examine—and frequently disrupt—current methods of image production, presentation, and circulation.

Ocean of Images: Photography & Contemporary Culture: Lesson Choices",Seeing Through Photographs
https://www.classcentral.com/course/schizophrenia-9387,"The main goal of this class are to gain an introductory exposure to the nature of the psychiatric disorder known as schizophrenia as revealed by the scientific method. We will discuss a broad range of findings from the scientific investigation of biological and psychological factors related to schizophrenia and its treatment. More specifically we will learn about: (1)  key symptomatic features through discussion and enactments of interviews with actors portraying many of the cardinal features of the illness, (2) what brain imaging studies (MRI and fMRI) and neurochemistry have taught us about the neuroscience of the disorder, (3) scientific psychological data and theories concerning cognition, emotion and behavior in schizophrenia, and (4) current, evidence-based somatic and psychosocial approaches to treatment. A brief historical overview of the recent emergence of the psychiatric category of schizophrenia will be presented as well.
      


          An Introduction to the Disorder
    -The first module is focused on introducing key symptom characteristics of the psychiatric diagnosis known as schizophrenia, and describes current thinking around potential causes and biological correlates of the disorder. 

Symptom Assessment and History
    -The second module is focused on a continuing exploration of symptoms in the disorder through simulated client-clinician interactions. Lectures in this unit also focus on the history of the treatment of schizophrenia in Western culture. 

Neuroanatomy and Neuroimaging
    -In the third module we begin to discuss the neurochemistry of the disorder as well as common manifestations of those diagnosed with schizophrenia on structural and functional brain MRI scans. First, though, we look at two more client-clinician simulations to explore symptoms and recovery.


Psychological Science
    -In the fourth module we discuss common cognitive deficits, disruptions in social cognition and cognitive models of the disorder. 

Intervention
    -In the fifth module we discuss approaches to treatment with a focus on both pharmacologic and psychosocial approaches.",Schizophrenia
https://www.classcentral.com/course/introduction-trading-machine-learning-gcp-17910,"This course is for finance professionals, investment management professionals, and traders. Alternatively, this course can be for machine learning professionals who seek to apply their craft to trading strategies. 

At the end of the course you will be able to do the following: 

- Understand the fundamentals of trading, including the concept of trend, returns, stop-loss and volatility
- Understand the differences between supervised/unsupervised and regression/classification machine learning models
- Identify the profit source and structure of basic quantitative trading strategies 
- Gauge how well the model generalizes its learning
- Explain the differences between regression and forecasting
- Identify the steps needed to create development and implementation backtesters
- Use Google Cloud Platform to build basic machine learning models in Jupyter Notebooks 

To be successful in this course, you should have a basic competency in Python programming and familiarity with pertinent libraries for machine learning, such as Scikit-Learn, StatsModels, and Pandas. Experience with SQL will be helpful. You should have a background in statistics (expected values and standard deviation, Gaussian distributions, higher moments, probability, linear regressions) and foundational knowledge of financial markets (equities, bonds, derivatives, market structure, hedging).
      


          Introduction to Trading, Machine Learning and GCP
    -In this module you will be introduced to the fundamentals of trading. You will also be introduced to machine learning. Machine Learning is both an art that involves knowledge of the right mix of parameters that yields accurate, generalized models and a science that involves knowledge of the theory to solve specific types of problems.

Supervised Learning and Forecasting
    -In this module you will be introduced to supervised machine learning and some relevant algorithms commonly applied to trading problems. You will get some hands-on experience building a regression model using BigQuery Machine Learning

Time Series and ARIMA Modeling
    -In this module you will learn about ARIMA modeling and how it is applied to time series data. You will get hands-on experience building an ARIMA model for a financial dataset.

Introduction to Neural Networks and Deep Learning
    -In this module you'll learn about neural networks and how they relate to deep learning. You'll also learn how to gauge model generalization using regularization, and cross-validation. Also, you'll be introduced to Google Cloud Platform (GCP). Specifically, you'll be shown how to leverage GCP for implementing trading techniques.","Introduction to Trading, Machine Learning & GCP"
https://www.classcentral.com/course/edx-high-dimensional-data-analysis-2949,"If you’re interested in data analysis and interpretation, then this is the data science course for you. We start by learning the mathematical definition of distance and use this to motivate the use of the singular value decomposition (SVD) for dimension reduction of high-dimensional data sets, and multi-dimensional scaling and its connection to principle component analysis. We will learn about the batch effect, the most challenging data analytical problem in genomics today, and describe how the techniques can be used to detect and adjust for batch effects. Specifically, we will describe the principal component analysis and factor analysis and demonstrate how these concepts are applied to data visualization and data analysis of high-throughput experimental data.
Finally, we give a brief introduction to machine learning and apply it to high-throughput, large-scale data. We describe the general idea behind clustering analysis and descript K-means and hierarchical clustering and demonstrate how these are used in genomics and describe prediction algorithms such as k-nearest neighbors along with the concepts of training sets, test sets, error rates and cross-validation.
Given the diversity in educational background of our students we have divided the series into seven parts. You can take the entire series or individual courses that interest you. If you are a statistician you should consider skipping the first two or three courses, similarly, if you are biologists you should consider skipping some of the introductory biology lectures. Note that the statistics and programming aspects of the class ramp up in difficulty relatively quickly across the first three courses. By the third course will be teaching advanced statistical concepts such as hierarchical models and by the fourth advanced software engineering skills, such as parallel computing and reproducible research concepts.
These courses make up 2 XSeries and are self-paced:
PH525.1x: Statistics and R for the Life Sciences
PH525.2x: Introduction to Linear Models and Matrix Algebra
PH525.3x: Statistical Inference and Modeling for High-throughput Experiments
PH525.4x: High-Dimensional Data Analysis
PH525.5x: Introduction to Bioconductor: annotation and analysis of genomes and genomic assays 
PH525.6x: High-performance computing for reproducible genomics
PH525.7x: Case studies in functional genomics
This class was supported in part by NIH grant R25GM114818.



            Read more",High-Dimensional Data Analysis
https://www.classcentral.com/course/stanford-openedx-statistics-in-medicine-918,"This course aims to provide a firm grounding in the foundations of probability and statistics. Specific topics include:
1. Describing data (types of data, data visualization, descriptive statistics)2. Statistical inference (probability, probability distributions, sampling theory, hypothesis testing, confidence intervals, pitfalls of p-values)3. Specific statistical tests (ttest, ANOVA, linear correlation, non-parametric tests, relative risks, Chi-square test, exact tests, linear regression, logistic regression, survival analysis; how to choose the right statistical test)
The course focuses on real examples from the medical literature and popular press. Each week starts with ""teasers,"" such as: Should I be worried about lead in lipstick? Should I play the lottery when the jackpot reaches half-a-billion dollars? Does eating red meat increase my risk of being in a traffic accident? We will work our way back from the news coverage to the original study and then to the underlying data. In the process, participants will learn how to read, interpret, and critically evaluate the statistics in medical studies.
The course also prepares participants to be able to analyze their own data, guiding them on how to choose the correct statistical test and how to avoid common statistical pitfalls. Optional modules cover advanced math topics and basic data analysis in R.
PREREQUISITES
There are no prerequisites for this course.
Participants will need to be familiar with a few basic math tools: summation sign, factorial, natural log, exponential, and the equation of a line; a brief tutorial is available on the course website for participants who need a refresher on these topics.



            Read more
          



Week 1 - Descriptive statistics and looking at dataWeek 2 - Review of study designs; measures of disease risk and associationWeek 3 - Probability, Bayes' Rule, Diagnostic TestingWeek 4 - Probability distributionsWeek 5 - Statistical inference (confidence intervals and hypothesis testing)Week 6 - P-value pitfalls; types I and type II error; statistical power; overview of statistical testsWeek 7 - Tests for comparing groups (unadjusted); introduction to survival analysisWeek 8 - Regression analysis; linear correlation and regressionWeek 9 - Logistic regression and Cox regression",Statistics in Medicine
https://www.classcentral.com/course/mathematics-for-computer-science-12817,"“Welcome to Introduction to Numerical Mathematics. This is designed to give you part of the mathematical foundations needed to work in computer science in any of its strands, from business to visual digital arts, music, games. At any stage of the problem solving and modelling stage you will require numerical and computational tools. We get you started in binary and other number bases, some tools to make sense of sequences of numbers, how to represent space numerical using coordinates, how to study variations of quantities via functions and their graphs. For this we prepared computing and everyday life problems for you to solve using these tools, from sending secret messages to designing computer graphics. 
If you wish to take it further you can join the BSc Computer Science degree and complete the full module ‘Numerical Mathematics’. 
Enjoy!”
      


          Number bases - binary
    -In this week, we will cover the key concepts: Place value and Number systems. You will learn about the notion of number bases, how to do operate in binary.

Number bases - other bases
    -In this week, we will extend the place value and number systems to Octal, Hexadecimal and any other bases. You will also be introduced to the usefulness of hexadecimal in computer science.

Modular arithmetic
    -In this week, we will cover the key concept of congruence modulo an integer. You will also be introduced to the usefulness of congruence and modular arithmetic operations in computer science.

Sequences
    -In this week, we will cover the key concept of number sequences. You will look into more detail at a special family of sequences, called progressions, and study arithmetic and geometric progressions.

Series
    -In this week, we will cover the key concept of number series, building on number sequences. You will look into more detail at a special family of series arising from arithmetic and geometric progressions. You will look at expression summations of sequences using a compact form with a summation symbol.

Introduction to Graph Sketching and Kinematics 
    -In this week, we will cover the key concept of coordinate system, functions and graphical representation of functions, and kinematics. You will look at the example of modelling motion.",Mathematics for Computer Science
https://www.classcentral.com/course/digital-footprint-8277,"If I Googled you, what would I find?

As we move around the online world we leave tracks and traces of our activity all the time: social media accounts, tagged images, professional presences, scraps of text, but also many artefacts we don't always realise we are leaving behind, or that others leave about us.  

In this course you will hear from a range of experts and you will have an opportunity to explore and reflect on your own online tracks and traces, to understand why your digital footprint is important. We will introduce you to some of the tools and approaches to effectively manage your online presence (or digital footprint).  

The course will focus on the different dimensions of a digital footprint, including developing an effective online presence, managing your privacy, creating opportunities for networking, balancing and managing professional and personal presences (eprofessionalism). By the end of this course (MOOC) you should be equipped to ensure that your digital footprint works for you, whether you want to be more private online, or are looking to create a more effective and impactful presence.  

You can also join the conversation on Twitter using the hashtag #DFMOOC and follow us @DFMOOC

We hope you enjoy the course!
      


          What makes an online presence effective?
    -In week 1 we provide information on how to engage with the course as well as our Twitter account, using #DFMOOC.  This week, we will introduce you to the topic of Digital Footprint. There are a range of activities, videos and resources for you to work through. By the end of week 1, you will have the opportunity to critically reflect on your own online presence and consider how you can make better informed choices as well as setting appropriate personal goals around your digital footprint. 

Why does your digital footprint matter?
    -This week, there is a range of experts who focus on why a digital footprint matters and how to create an effective online presence. The themes explored include data after death, privacy online and managing your online data. The activity and quizzes will help you to consider your own online presence and what you might do to make it more effective and work for you!

What does it mean to be an effective online professional?
    -This week, we examine the idea of a professional online presence and what this might mean for different people and professions. Understanding whether your personal and professional online presence should blur or be kept separate can be a challenge. We will hear from experts in Business, Nursing, Science, Education, and a Careers Consultant. They will provide useful advice on what you can do to make your online presence more professional and potentially help you with finding a job,  standing out from the crowd, complying with professional bodies' guidelines, and much more. The activities, including the quizzes and peer assessment will help you to reflect on your own online presence. There will also be an opportunity to get advice from your peers and consider putting into action what you have learned during this course.",Digital Footprint
https://www.classcentral.com/course/success-8087,"This engaging course is designed to help you achieve the success that you desire. Drawing on decades of scientific research, you will learn what the most successful people do differently than others, why IQ is not the most significant predictor of success (and can sometimes backfire), and why many commonly held beliefs hold people back from achieving their goals.

Although this course is based on the science of success, you will learn many practical ideas that you can apply to your own life immediately, particularly in three main areas:

•	Getting better results at work (and school) 
•	Achieving career success (however you define success) 
•	Enjoying a meaningful, happy, and healthy life

By the time you finish this course you will know more than most people know about what predicts success in life. One of the most important lessons you’ll learn is that success is earned day-by-day through small wins - small, achievable actions that together can help you achieve your goals sooner and exceed even your own expectations. Therefore, you will have an opportunity to complete a detailed action plan through which you can turn what you learned into specific steps for achieving your most treasured life goals.
      


          Introduction to the Science of Success: What Researchers Know that You Should Know
    -This course is designed to help you achieve the success in life that you desire and deserve.  This module sets the foundation for the course and introduces you to the course objectives, as well as to four strategies that successful people use to achieve their life goals.  In the first video, you’ll learn about the goals of the course and how a scientifically-based approach to success can help you achieve your life goals.  In the second video, you’ll have the opportunity to think carefully about what success means to you, particularly in the areas of achieving better and more meaningful results at work, achieving the career success that you desire, and enjoying a happy, healthy life.  In the third video, you’ll learn about the most common myths about success that can distract you from achieving your life goals, as well as what researchers have found really predicts success in life.  Happy learning!


The Power of Beliefs 
    -In this module, you’ll learn how some beliefs can hold you back from achieving your goals, while others – such as having a growth mindset and positive core self-evaluations - can propel you forward toward your goals.  You will also learn how having a growth mindset can protect people against the harmful effects of bias and prejudice and why people with positive core self-evaluations tend to earn significantly more money, regardless of their grades in school and family background. By the end of this module, you’ll have specific strategies for creating beliefs that will help you set high goals and succeed in achieving them.  


The Power of Expertise 
    -In this module, you’ll learn about the importance of having an expertise that is meaningful to you and contributes to others. In the first video, you’ll learn about the role that expertise played in Pilot Chesley “Sully” Sullenberger’s successful emergency landing of a United Airlines flight with 155 people on board into the Hudson River after both engines failed.  You’ll learn how Sullenberger developed his expertise and how you can apply these lessons to your own pursuit of expertise.  In the second video, you’ll learn about what sets experts apart from non-experts, as well as the essential role that mental representations and chunks play in the development of expertise.  You’ll also learn what birds, squirrels, and elite London cab drivers have in common and what this means for you.  Hint: It has to do with how the brain develops in experts.  In the third video, you’ll learn a step-by-step strategy for engaging in the same type of practice that experts use to develop their expertise. 


The Power of Self-Motivation 
    -In this module, you’ll learn about two types of self-motivation that predict success: Conscientiousness and Grit.  The first video focuses on conscientiousness – what it is, how it can pay off for you in school and at work, and the benefits conscientiousness has on your health.  You’ll also discover researchers have learned about success from a famous series of studies about children, marshmallows, and delayed gratification. The second video focuses on grit – what it is, how it differs from conscientiousness, how it leads to success, what specific techniques you can use to become grittier, and how to avoid some of the downsides to being gritty.  You will also have the opportunity to assess your own conscientiousness and grit.  


The Power of Relationships 
    -In this module, you’ll learn about the power of developing mutually supportive relationships in predicting success and well-being in life.  You’ll learn what social capital is, why it is a competitive advantage, and how it contributes to your success, as well as to the success of organizations and societies.  You’ll learn to avoid several myths associated with relationship building, as well as four skills that are essential to developing relationships and social capital: developing self-awareness, creating your brand, being an energizer, and building your network of relationships.  You’ll also have an opportunity to think about your brand, as well as map out and assess the effectiveness of your own network based on four criteria: size, structure, diversity, and strength of relationships.


The Power of a Plan: Creating Your Action Plan
    -By the time you reach this module, you will know more than most people know about what predicts success in life.  You will now have the opportunity to turn what you know into actions that will help you achieve your life goals.  You will develop an action plan that will have three parts: The heart (identifying what is most important to you in life), head (identifying the one area that you will work on in the short-term to move you toward achieving your goals), and hands (creating the steps you will take in the short-term to make progress in that specific area). You’ll learn about the power of small wins in achieving your life goals, as well as the importance of resilience and self-compassion when faced with setbacks. 


Your Personalized Action Plan
    -Once you have watched all the videos, successfully completed the four quizzes, and created your personalized action plan, you will have successfully completed the course!  You can use the Personalized Action Plan Template (found in the submissions area of the assignment) to create your action plan.  Your action plan will be reviewed and graded by another course participant.  If needed, you can resubmit your action plan until you achieve a passing grade.  Of course, you should continue to refine your action plan throughout the different stages of your life.  I wish you the very best on your journey to the life you desire and deserve.",The Science of Success: What Researchers Know that You Should Know
https://www.classcentral.com/course/python-for-applied-data-science-ai-14403,"This introduction to Python will kickstart your learning of Python for data science, as well as programming in general. This beginner-friendly Python course will take you from zero to programming in Python in a matter of hours.

Module 1 - Python Basics
o	Your first program
o	Types
o	Expressions and Variables
o	String Operations

Module 2 - Python Data Structures
o	Lists and Tuples
o	Sets
o	Dictionaries

Module 3 - Python Programming Fundamentals
o	Conditions and Branching
o	Loops
o	Functions
o	Objects and Classes

Module 4 - Working with Data in Python
o	Reading files with open
o	Writing files with open
o	Loading data with Pandas
o	Numpy 

Finally, you will create a project to test your skills.
      


          Python Basics 

Python Data Structures 

Python Programming Fundamentals 

Working with Data in Python 

Analyzing US Economic Data and Building a Dashboard",Python for Data Science and AI
https://www.classcentral.com/course/applying-data-analytics-business-in-fina-15161,"This course introduces an overview of financial analytics. You will learn why, when, and how to apply financial analytics in real-world situations. You will explore techniques to analyze time series data and how to evaluate the risk-reward trade off expounded in modern portfolio theory. While most of the focus will be on the prices, returns, and risk of corporate stocks, the analytical techniques can be leverages in other domains. Finally, a short introduction to algorithmic trading concludes the course.

After completing this course, you should be able to understand time series data, create forecasts, and determine the efficacy of the estimates. Also, you will be able to create a portfolio of assets using actual stock price data while optimizing risk and reward. Understanding financial data is an important skill as an analyst, manager, or consultant.
      


          Course Introduction
    -In this course, we will introduce a number of financial analytic techniques. You will learn why, when, and how to apply financial analytics in real-world situations. We will explore techniques to analyze time series data and how to evaluate the risk-reward trade off expounded in modern portfolio theory. While most of the focus will be on the prices, returns, and risks of corporate stocks, the analytical techniques can be leveraged in other domains. Finally, a short introduction to algorithmic trading concludes the course.

Module 1: Introduction to Financial Analytics and Time Series Data
    -In this module, we will introduce an overview of financial analytics. Students will learn why, when, and how to apply financial analytics in real-world situations. We will explore techniques to analyze time series data and how to evaluate the risk-reward trade off expounded in modern portfolio theory. While most of our focus will be on the prices, returns, and risks of corporate stocks, the analytical techniques can be leveraged in other domains. Finally, a short introduction to algorithmic trading concludes the course.

Module 2: Performance Measures and Holt-Winters Model
    -We will introduce analytical methods to analyze time series data to build forecasting models and support decision-making. Students will learn how to analyze financial data that is usually presented as time series data. Topics include forecasting performance  measures, moving average, exponential smoothing methods, and the Holt-Winters method.

Module 3: Stationarity and ARIMA Model
    -In this module, we will begin with stationarity, the first and necessary step in analyzing time series data. Students will learn how to identify if a time series is stationary or not and know how to make nonstationary data become stationary. Next, we will study a basic forecasting model: ARIMA. Students will learn how to build an ARIMA forecasting model using R.

Module 4: Modern Portfolio Theory and Intro to Algorithmic Trading
    -We will introduce some basic measurements of modern portfolio theory. Students will understand about risk and returns, how to balance them, and how to evaluate an investment portfolio.",Applying Data Analytics in Finance
https://www.classcentral.com/course/javascript-4295,"If you want to take your website to the next level, the ability to incorporate interactivity is a must.    But adding some of these types of capabilities requires a stronger programming language than HTML5 or CSS3, and JavaScript can provide just what you need.  With just a basic understanding of the language, you can create a page that will react to common events such as page loads, mouse clicks & movements, and even keyboard input.      

This course will introduce you to the basics of the JavaScript language.  We will cover concepts such as variables, looping, functions, and even a little bit about debugging tools.  You will understand how the Document Object Model (DOM) is used by JavaScript to identify and modify specific parts of your page.  After the course, learners will be able to react to DOM Events and dynamically alter the contents and style of their page.   The class will culminate in a  final project - the creation of an interactive HTML5 form that accepts and verifies input.

This is the third course in the Web Design For Everybody specialization.  A basic understanding of HTML and CSS is expected when you enroll in this class.    Additional courses focus on enhancing the styling with responsive design and completing a capstone project.
      


          Week One: Introduction to JavaScript
    -If you haven't use a traditional programming language before, this first week is key.  Before we begin with the how, we will talk about the why, mainly why we want to use JavaScript.  The main reason is that it is very easy for JavaScript to work with the DOM.  And easy is always a great way to start.  Speaking of starting out, it is also always more fun when our code actually does something we can see, so we will jump quickly into different ways we can generate output.  It won't be flashy yet, but it will be a great way to get your feet wet with traditional programming.  After that we go back to the basics of how a computer uses data.  We begin with variables, expressions, and operators.  

Week Two: Reacting to Your Audience
    -If you have written HTML code in the past, hopefully you have fallen into the great habit of validating your code -- making sure that you close all of your open tags.  There are other rules that you may or may not have been following as well, for instance the importance of using each id attribute only once per page. This is called writing ""clean"" code.  The reasoning and importance of following these rules becomes clear as we begin to manipulate the different components of your webpage based on the the actions of the person interacting with your page.  In particular you will learn about the JavaScript Mouse Events and Touch Events.  This week's materials will end with a photo gallery example that you can create along with me.

Week Three: Arrays and Looping
    -This week we will delve into more complex programming concepts: arrays and looping.  Arrays allow you to represent groups of related information.  Looping provides efficiency and flexibility to your programs.  Using both we will expand upon the photo gallery example.

Week Four: Validating Form Data
    -This week we will put a number of the concepts from this course together to tackle a new project - creating and validating input entered into an HTML5 form.  Forms are extremely common elements used to input and send data to via a webpage.  We will look at how you can use JavaScript to add options to your forms, to pre-fill data based on previous input, and even to check that passwords match.",Interactivity with JavaScript
https://www.classcentral.com/course/swayam-data-science-for-engineers-10096,"Learning Objectives :Introduce R as a programming languageIntroduce the mathematical foundations required for data scienceIntroduce the first level data science algorithmsIntroduce a data analytics problem solving frameworkIntroduce a practical capstone case studyLearning Outcomes:Describe a flow process for data science problems (Remembering)Classify data science problems into standard typology (Comprehension)Develop R codes for data science solutions (Application)Correlate results to the solution approach followed (Analysis)Assess the solution approach (Evaluation)Construct use cases to validate approach and identify modifications required (Creating)INTENDED AUDIENCE:  Any interested learnerPREREQUISITES: 10 hrs of pre-course material will be provided, learners need to practise this to be ready to take the course.INDUSTRY SUPPORT: HONEYWELL, ABB, FORD, GYAN DATA PVT. LTD. 
      


COURSE LAYOUT Week 1: Course philosophy and introduction to RWeek 2: Linear algebra for data science 1. Algebraic view - vectors, matrices, product of matrix & vector, rank, null space, solution of over-determined  set of equations and pseudo-inverse) 2. Geometric view - vectors, distance, projections, eigenvalue decompositionWeek 3:Statistics (descriptive statistics, notion of probability, distributions, mean, variance, covariance, covariance  matrix, understanding univariate and multivariate normal distributions, introduction to hypothesis testing, confidence  interval for estimates)Week 4: OptimizationWeek 5: 1. Optimization 2. Typology of data science problems and a solution frameworkWeek 6: 1. Simple linear regression and verifying assumptions used in linear regression 2. Multivariate linear regression, model assessment, assessing importance of different variables, subset selectionWeek 7: Classification using logistic regressionWeek 8: Classification using kNN and k-means clustering",Data Science for Engineers
https://www.classcentral.com/course/server-side-nodejs-8888,"This course deals with all things server-side. We base the entire course around the NodeJS platform. We start with a brief overview of the Web protocols: HTTP and HTTPS. We examine NodeJS and NodeJS modules: Express for building web servers. On the database side, we review basic CRUD operations, NoSQL databases, in particular MongoDB and Mongoose for accessing MongoDB from NodeJS. We examine the REST concepts and building a RESTful API. We touch upon authentication and security. Finally we review backend as a service (BaaS) approaches, including mobile BaaS, both open-source and commercial BaaS services.

At the end of this course, you will be able to:

- Demonstrate an understanding of server-side concepts, CRUD and REST
- Build and configure a backend server using NodeJS framework
- Build a RESTful API for the front-end to access backend services
      


          Introduction to Server-side Development
    -In this module you will be introduced to Node, Node modules and the Node HTTP server. You will learn about the Express framework and how to set up a REST API using Express.

Data, Data, Where art Thou Data?
    -This module looks in detail at data storage with MongoDB, the popular NoSQL database. You will learn first about Express generator for scaffolding an Express application. Then you will learn about MongoDB. You will learn how to interact with MongoDB from a Node application. Then you will learn the Mongoose ODM to create schemas and models, and interact with MongoDB server.

Halt! Who goes there?
    -This module is dedicated to user authentication. We first develop a full-fledged REST API server with Express, Mongo and Mongoose. Thereafter we examine basic authentication and session-based authentication briefly. We then develop token-based authentication with the support of JSON web tokens and the Passport module.

Backend as a Service (BaaS)
    -In this module we learn about Mongoose population, a way of cross-referencing documents and populating the documents from other documents. We then review secure communication using HTTPS. We look at Backend as a Service (BaaS) and take a brief look at Loopback.","Server-side Development with NodeJS, Express and MongoDB"
https://www.classcentral.com/course/probability-theory-statistics-18167,"Exploration of Data Science requires certain background in probability and statistics. This course introduces you to the necessary sections of probability theory and statistics, guiding you from the very basics all way up to the level required for jump starting your ascent in Data Science. 

The core concept of the course is random variable — i.e. variable whose values are determined by random experiment. Random variables are used as a model for data generation processes we want to study. Properties of the data are deeply linked to the corresponding properties of random variables, such as expected value, variance and correlations. Dependencies between random variables are crucial factor that allows us to predict unknown quantities based on known values, which forms the basis of supervised machine learning. We begin with the notion of independent events and conditional probability, then introduce two main classes of random variables: discrete and continuous and study their properties. Finally, we learn different types of data and their connection with random variables.

While introducing you to the theory, we'll pay special attention to practical aspects for working with probabilities, sampling, data analysis, and data visualization in Python.

This course requires basic knowledge in Discrete mathematics (combinatorics) and calculus (derivatives, integrals).
      


          Conditional probability and Independence
    -During this week we discuss conditional probability and independence of events. Sometimes we can use this definition to find probabilities. Sometimes we check that this definition fulfills to assure whether events are independent. We discuss important law of total probability, which allows us to find probability of some event when we know its conditional probabilities provided some hypotheses and probabilities of the hypotheses. We also discuss Bayes's rule which allows us to find probability of hypothesis provided that some event occurred. We demonstrate how Python can be used for calculating conditional probabilities and checking independence of events.

Random variables
    -Random variable denotes a value that depends on the result of some random experiment. Some natural examples of random variables come from gambling and lotteries. There are two main classes of random variables that we will consider in this course. This week we'll learn discrete random variables that take finite or countable number of values. Discrete random variables can be described by their distribution. We'll consider various discrete distributions, introduce notions of expected value and variance and learn to generate and visualize discrete random variables with Python.

Systems of random variables; properties of expectation and variance, covariance and correlation.
    -Several random variables associated with the same random experiment constitute a system of random variables. To describe system of discrete random variables one can use joint distribution, which takes into account all possible combinations of values that random variables may take. We'll find some joint distributions, research their properties and introduce independence of random variables. Then we'll discuss properties of expected value and variance with respect to arithmetic operations and introduce measures of independence between random variables.

Continuous random variables
    -This week we'll study continuous random variables that constitute important data type in statistics and data analysis. For continuous random variables we'll define probability density function (PDF) and cumulative distribution function (CDF), see how they are linked and how sampling from random variable may be used to approximate its PDF. We'll introduce expected value, variance, covariance and correlation for continuous random variables and discuss their properties. Finally, we'll use Python to generate independent and correlated continuous random variables.

From random variables to statistical data. Data summarization and descriptive statistics.
    -This week we'll introduce types of statistical data and discuss models that are used to pass from statistical data to random variables. We'll introduce descriptive statistics of sample data, such as various measures of central tendency and statistical dispersion, and find correspondences between properties of random variables (population) and the sample descriptive statistics, which are essential for statistical predictions. We’ll talk about visualization of statistical data and learn to work with them in Python.

Correlations and visualizations
    -This week we’ll consider correlation in statistical data and find out how its' related to the level of dependance  within the data and what it means for scatter plots. We’ll consider several types of correlation suitable for different types of data and discuss difference between correlation and causation. Finally, we’ll learn to visualize dependence between numeric variables and calculate correlation with Python.","Probability Theory, Statistics and Exploratory Data Analysis"
https://www.classcentral.com/course/edx-web-security-fundamentals-8726,"Web applications are inherently insecure, as aptly illustrated by a pile of recent events. Insecurity is however not fundamental to the web platform. As a matter of fact, the modern web offers a variety of powerful security features that help stop a hacker. Unfortunately, not many developers have the knowledge and skills to leverage these security features to their full potential.
This course is imperative for understanding the fundamental security principles of the web. The course provides an overview of the most common attacks, and illustrates fundamental countermeasures that every web application should implement. In essence, this course offers you the knowledge and skills to build better and more secure applications.
This MOOC will introduce you to the web security landscape. Throughout the course, you will gain insights into the threats that modern web applications face. You’ll build an understanding of common attacks and their countermeasures; not only in theory, but also in practice. You’ll be provided with an overview of current best practices to secure web applications
Although no previous security knowledge is necessary to join this course, it will help to be familiar with the basic concepts behind web applications, including HTTP, HTML, and JavaScript.



Week 1: Is security an illusion?
Introduction to the web security landscape, and an overview of the most relevant threats. Understanding the security model of the web, and the recent evolution towards client-centric security.
Week 2: Securing the communication channel
Understanding the dangers of an insecure communication channel. Practical advice on deploying HTTPS, and dealing with the impact on your application. Insights into the latest evolutions for HTTPS deployments.
Week 3: Preventing unauthorized access
Understanding the interplay between authentication, authorization and session management. Practical ways to secure the authentication process, prevent authorization bypasses and harden session management mechanisms.
Week 4: Securely Handling untrusted data
Investigation of injection attacks over time. Understanding the cause behind both server-side and client-side injection attacks. Execution of common injection attacks, and implementation of various defenses.
Week 5: Conclusion
Putting the contents of this course into perspective, and relating it back to the most relevant threats from the introduction. Overview of current best practices for building secure web applications.",Web Security Fundamentals
https://www.classcentral.com/course/ni-891,"What makes WiFi faster at home than at a coffee shop? How does Google order its search results from the trillions of webpages on the Internet? Why does Verizon charge $15 for every GB of data we use? Is it really true that we are connected in six social steps or less?

These are just a few of the many intriguing questions we can ask about the social and technical networks that form integral parts of our daily lives. This course is about exploring the answers, using a language that anyone can understand. We will focus on fundamental principles like “sharing is hard”, “crowds are wise”, and “network of networks” that have guided the design and sustainability of today’s networks, and summarize the theories behind everything from the social connections we make on platforms like Facebook to the technology upon which these websites run.

Unlike other networking courses, the mathematics included here are no more complicated than adding and multiplying numbers. While mathematical details are necessary to fully specify the algorithms and systems we investigate, they are not required to understand the main ideas. We use illustrations, analogies, and anecdotes about networks as pedagogical tools in lieu of detailed equations.

All the features of this course are available for free.  It does not offer a certificate upon completion.
      


          Introduction
    -An introduction to what this course is about: the fundamentals behind social and technical networks.

Power Control in Cellular Networks
    -How is it possible that we can all communicate effectively without disrupting each other's calls, messages, or Internet usage? In this lesson, we will take a look at some of the methods that have been developed for letting us ""share"" the air over which our phones communicate.

Random Access in Wifi Networks
    -In this lesson, we will investigate WiFi, another type of wireless network. Rather than having stringent power control algorithms as we saw for cellular, WiFi relies on ""random access"" methods to manage interference among users in the same location.

PageRank by Google
    -In this lesson, we will take a look at PageRank, Google's famous algorithm for ordering the results on its search page. PageRank is a prime example of how coming up with the right ""ranking"" of a set of items is a difficult yet important question in networking.

Product Rating on Amazon
    -The decision of whether or not to purchase something online is often driven by the ratings that previous customers have left for it. In this lesson, we will take a look at Amazon's review system, and the see how ""crowds are wise"" is another important networking principle.

Movie Recommendation on Netflix
    -One of the perks of having a Netflix subscription is getting recommendations of movies to watch. Behind the scenes, Netflix uses powerful algorithms to determine which will be suggested to each person specifically. In this lesson, we will take a look at the main ideas behind these algorithms.

Midterm

Viral Videos on YouTube
    -What does it take for a video to become ""viral"" on YouTube? In this lesson, we will take a look at some of the key factors and models that have been used to explain this phenomenon. At the core is the notion of information cascade in a network, which is the counterpart to the wisdom of crowds.

Influencing People in Social Networks
    -In this lesson, we will continue with our theme of influence, now paying more attention to people's social networks. We will discuss different ways of measuring importance and a popular model for influence spread in social networks like Facebook and Twitter.

   Pricing Data
    -Data makes up a significant part of our cell phone bills. How do cellular providers set these price points? In this lesson, we will see how so-called usage-based pricing schemes can send better signals than flat- rate, “buffet” schemes, leading to better sharing of the network.

 Routing Traffic through the Internet
    -It is hard to overstate the impact that the Internet has had on society. In this lesson, we will overview the  fundamental concepts behind the way the Internet is designed. We will also take a look at routing, which is the process of determining how packets of information are transported.

Controlling Congestion in the Internet
    -The Internet has many important tasks to manage, like routing packets (discussed in the last module) and controlling congestion. This workload is modularized into different functional layers, each responsible for performing a different set of functions, as we will see in this lesson. We will also look at the principles of congestion control, managed at the transport layer.

It's a Small World
    -Six degrees of separation is a widely told story in popular science. How can it still be a ""small world"" with the enormity of the Internet today? It depends on how the social networks are structured, and on how we search for short paths, as we will see in this lesson.

Final Exam
    -The final covers the last six lessons in the course (those after the midterm). Like the midterm, the questions are all multiple choice, and tend to be easier than the homework questions but harder than the in-video quizzes.",Networks Illustrated: Principles without Calculus
https://www.classcentral.com/course/teachingscience-7791,"This course will prepare you for teaching science in higher education. In this MOOC you will learn to make your knowledge as an excellent researcher accessible to your students. We will show you how to communicate science to novices as well as advanced students in science. You will experience the value of teaching with analogies and you will be guided to train your students' competences. Based on up-to-date findings from research into teaching and learning science you will be able to
- implement evidence-based strategies into your own teaching,
- use students everyday-conceptions for the development of courses,
- prepare analogies and models to teach in your field,
- implement problem-based teaching,
- set up for experiments and teach the nature of science.

This course enables you to teach abstract science topics to your students and make them become active and successful learners. The course is based on lectures (videos), handouts (knowledge-to practice briefs), which supplement the knowledge taught in the lectures and assignments to implement the teaching strategies into your own practice.
      


          Introduction: Teaching and Learning Science
    -Welcome to your first week of Teaching Science at University! In this first module we will give you an overview of what you will learn during our 5-week course and show you what you can achieve as an excellent lecturer or teaching assistant at your university! In the first lesson our focus is on evidence-based teaching. We will show you how you can base your lectures, lab classes, and courses on science education research. You will learn about main principles of visible learning and mind frames which will help you to embrace these principles. Then we will adapt learning theories to science teaching, starting with behaviorism up to cognitivism, constructivism, and neurodidactics. Interviews with a Professor in Animal Behaviour and a Professor in Neuroscience give further insight in the way we learn. At the end of the first week, you should be able to implement and reflect upon one evidence-based teaching strategy in your own teaching. Have fun!

Conceptual Change
    -Understanding scientific concepts is the core of learning science, but often our pre-instructional conceptions act as barriers to reach an appropriate understanding. In this module we will show how to guide students from their everyday conceptions to scientific ones. You will learn how to use your students’ pre-conceptions not as obstacles but as starting points for teaching science. We will show you some methods for a quick assessment of your students’ conceptions. We look at strategies how we can change our students’ conceptions and how we can help your students to change their ideas. Finally we consider how you as a teacher can foster student engagement in class. At the end of the second week you should be able to address the pre- instructional conceptions of your students in your teaching.

Teaching with analogies
    -This week we would like to show how invisible concepts become visible. In everyday life we learn so many things by comparing and contrasting. From research we know that the use of analogies and metaphors are important features in the scientific endeavor, and their use in teaching science seems a natural extension. We raise the question whether analogies are just excellent communication tools or if they can generate new knowledge. What do the majority of students really understand when analogies are used to explain abstract and difficult ideas such as molecular structures, diffusion, and plate tectonics? We show that It is important to consider students’ personal constructions since no student enters the lecture hall as “tabula rasa.” Science classrooms are common settings in which analogies are used to enhance concept learning; therefore, improving the way analogies are used in science education has important teaching and learning consequences. At the end of the third week you should be able to choose good analogies for teaching science and implement them fruitfully.

(Re-)Frame your science teaching
    -This week we want to show you how we can frame our science teaching to increase interest, motivation, and understanding of the students. In the first lesson we ask how the framing of science teaching can help students see the relevance of science for society. We look at problems from everyday life and their potential to foster students understanding of science. Activating our students is one key to reducing failure rates in our classrooms. We look how to design a new course by setting the goals our students have to achieve and how to foster learning when supervising a thesis. Finally we look how to communicate risk and uncertainty in an appropriate way to foster understanding. At the end of this week you should be able to frame your science teaching to make it relevant for your students.

Teaching science in a lab or field
    -This week we focus on improving students’ learning in a lab or in the field. In the first lesson we show you how to design a lab class, then we focus on delivering a lab class. We show you how you can use design principles (known as “gestalt principles”) to present experiments in a manner which is easy for your students to understand. Then we look at a model on students’ competences on experimentation that you can use to track the development of your students’ conceptual development. From research we know that students often hold inadequate conceptions about the nature of science and the scientific endeavor. We show you how you can address these conceptions to enable your students to understand the meaning of experiments, models, and theories in science. Finally we focus on the role of models in science education. We look at a model for model competence you can use to analyse where your students stand and to train different dimensions of dealing with models. At the end of this week you should be able to design a lab class that improves the inquiry skills of your students.",Teaching Science at University
https://www.classcentral.com/course/ibm-ai-workflow-ai-production-17099,"This is the sixth course in the IBM AI Enterprise Workflow Certification specialization.   You are STRONGLY encouraged to complete these courses in order as they are not individual independent courses, but part of a workflow where each course builds on the previous ones.    

This course focuses on models in production at a hypothetical streaming media company.  There is an introduction to IBM Watson Machine Learning.  You will build your own API in a Docker container and learn how to manage containers with Kubernetes.  The course also introduces  several other tools in the IBM ecosystem designed to help deploy or maintain models in production.  The AI workflow is not a linear process so there is some time dedicated to the most important feedback loops in order to promote efficient iteration on the overall workflow.
 
By the end of this course you will be able to:
1.  Use Docker to deploy a flask application
2.  Deploy a simple UI to integrate the ML model, Watson NLU, and Watson Visual Recognition
3.  Discuss basic Kubernetes terminology
4.  Deploy a scalable web application on Kubernetes 
5.  Discuss the different feedback loops in AI workflow
6.  Discuss the use of unit testing in the context of model production
7.  Use IBM Watson OpenScale to assess bias and performance of production machine learning models.

Who should take this course?
This course targets existing data science practitioners that have expertise building machine learning models, who want to deepen their skills on building and deploying AI in large enterprises. If you are an aspiring Data Scientist, this course is NOT for you as you need real world expertise to benefit from the content of these courses.
 
What skills should you have?
It is assumed that you have completed Courses 1 through 5 of the IBM AI Enterprise Workflow specialization and you have a solid understanding of the following topics prior to starting this course: Fundamental understanding of Linear Algebra; Understand sampling, probability theory, and probability distributions; Knowledge of descriptive and inferential statistical concepts; General understanding of machine learning techniques and best practices; Practiced understanding of Python and the packages commonly used in data science: NumPy, Pandas, matplotlib, scikit-learn; Familiarity with IBM Watson Studio; Familiarity with the design thinking process.
      


            Read more
          



          Feedback loops and Monitoring
    -This module focuses on feedback loops and monitoring.  Feedback loops represent all the possible ways you can return to an earlier stage in the AI enterprise workflow. We initially discussed feedback loops in the first course of this specialization; however, here our focus is on unit testing.  We are also looking at business value, a very important consideration that often gets overlooked; is the model having a significant effect on business metrics as intended?  It is important to be able to use log files that have been standardized across the team to answer questions about business value as well as performance monitoring.  You will have an opportunity of completing a case study on performance monitoring, where you will write unit tests for a logger and a logging API endpoint, test them, and write a suite of unit tests to validate if the logging is working correctly.

Hands on with Openscale and Kubernetes
    -This module will wrap up the formal learning in this course by completing hands on tutorials of Watson Openscale and Kubernetes.  IBM Watson OpensScale is a suite of services that allows you to track the performance of production AI and its impact on business goals, with actionable metrics, in a single console. Kubernetes is a container orchestration platform for managing, scheduling and automating the deployment of Docker containers. The containers we have developed as part of this course are essentially microservices meant to be deployed as cloud native applications.

Capstone: Pulling it all together (Part 1)
    -In this module you start part one (Data Investigation) of a three-part capstone project designed to pull everything you have learned together.  We have provided a brief review of what you should have learned thus far; however, you may want to review the first five courses prior to starting the project.  A major goal of this capstone is to emulate a real-world scenario, so we won’t be providing notebooks to guide you as we have done with the previous case studies.

Capstone: Pulling it all together (Part 2)
    -In this module you will complete your capstone project and submit it for peer review. Part 2 of the Capstone project involves building models and selecting the best model to deploy. You will use time-series algorithms to predict future values based on previously observed values over time. In part 3 of the Capstone project, your focus will be creating a post-production analysis script that investigates the relationship between model performance and the business metrics aligned with the deployed model. After completing and submitting your capstone project, you will have access to the solution files for further review.",AI Workflow: AI in Production
https://www.classcentral.com/course/edx-simulation-neuroscience-9539,"Simulation Neuroscience is an emerging approach to integrate the knowledge dispersed throughout the field of neuroscience. 
The aim is to build a unified empirical picture of the brain, to study the biological mechanisms of brain function, behaviour and disease. This is achieved by integrating diverse data sources across the various scales of experimental neuroscience, from molecular to clinical, into computer simulations. 
This is a unique, massive open online course taught by a multi-disciplinary team of world-renowned scientists.In this first course, you will gain the knowledge and skills needed to create simulations of biological neurons and synapses. 
This course is part of a series of three courses, where you will learn to use
state-of-the-art modeling tools of the HBP Brain Simulation Platform to simulate neurons, build neural networks, and perform your own simulation experiments. 
We invite you to join us and share in our passion to reconstruct, simulate and understand the brain!



Week 1: Simulation neuroscience: An introduction, 
Understanding the brain
Approaches and Rationale of Simulation Neuroscience 
The principles of simulation neuroscience 
Data strategies 
Neuroinformatics 
Reconstruction and simulation strategies 
Summary and Caveats 
Experimental data 
Single neuron data collection techniques
Morphological profiles 
Electrophysiological profiles 
Caveats and summary of experimental data techniques 
Single neuron data
Ion channels 
Combining profiles 
Cell densities 
Summary and Caveats 
Synapses
Synapses 
Synaptic dynamics 
Week 2: Neuroinformatics
Introduction to neuroinformatics
Text mining 
Data integration and knowledge graphs
Knowledge graphs
Ontologies
Neuroinformatics 
Brain atlases and knowledge space 
Motivation of data-integration 
Fixed data approach to data integration 
Blue Brain Nexus 
Architecture of Blue Brain Nexus 
Design a provenance entity
Ontologies 
Creating your own domain 
MINDS
Conclusion 
Acquisition of neuron electrophysiology and morphology data
Generating data 
Using data 
Design an entity
An entity design and the provenance model
Conclusion 
Morphological feature extraction
Morphological structures, 
Understanding neuronal morphologies using NeuroM
Statistics and visualisation of morphometric data 
Week 3: Modeling neurons
Introduction to the single neuron
Introduction
Motivation for studying the electrical brain 
The neuron
A structural introduction
An electrical device
Electrical neuron model
Modeling the electrical activity 
Hodgkin & Huxley 
Tutorial creating single cell electrical models
Single cell electrical model: passive 
Making it active 
Adding a dendrite 
Connecting cells 
Week 4: Modeling synapses
Modeling synaptic potential
Modeling the potential 
Rall's cable model 
Modeling synaptic transmission between neurons
Synaptic transmission 
Modeling synaptic transmission 
Modeling dynamic synapses tutorial
Defining your synaps 
Compiling your modifies 
Hosting & testing your synaps model 
Reconfigure your synaps to biological ranges 
Defining a modfile for a dynamic TM synapse 
Compiling and testing the modfile 
Week 5: Constraining neurons models with experimental data
Constraining neuron models with experimental data
Constraining neuron model with experimental data. 
Computational aspects of optimization 
Tools for constraining neuron models 
Tutorials for optimization
Setting up the components 
Week 6: Exam week
NMC portal
Accessing the NMC portal
Running models on your local computer
Downloading and interacting with the single cell models
Injecting a current",Simulation Neuroscience
https://www.classcentral.com/course/futurelearn-basic-science-understanding-experiments-2127,"Get to grips with science, by carrying out fun experiments at home
On this practical course you will start thinking like a scientist, by carrying out experiments at home.
You will extract the DNA from fruit, observe osmosis in action, see how different liquids behave when frozen, and bake a potato to destruction.
As you carry out these experiments, you will develop scientific skills including observation, record-keeping, data analysis and experiment control.
The course was produced with the kind support of Dangoor Education. You may also enjoy Basic Science: Understanding Numbers.
This course is intended for anyone with an interest in making scientific observations through experimentation, and does not require any previous experience of studying the subject.
The experiments do involve both hot and cold temperatures so younger learners may need supervision. As per FutureLearn’s terms and conditions - if you are under 13, you must ask an adult to create an account using their own name and communicate in discussions on your behalf.
All of the experiments can be carried out with items you would find in a typical kitchen, but before you start, you should probably make sure you have the following:
Shopping list

a cucumber
a kiwi
methylated spirits (or a bottle of vodka!)
olive oil
a potato
salt
sugar
washing-up liquid
yeast
distilled water

Equipment list

cling film
oven gloves
a freezer
an ice cube tray
kitchen scales
a marker pen
a microwave or oven
a paper clip
a printer
a ruler
a vegetable peeler
drinking glasses
knife




            Read more",Basic Science: Understanding Experiments
https://www.classcentral.com/course/edx-chinese-thought-ancient-wisdom-meets-modern-science-2471,"*Note - This is an Archived course*
This course is designed to give students a thorough introduction to Warring States (5th-3rd century BCE) Chinese thought, focusing on Confucianism, Daoism, Mohism and Legalism. Sometime known as the age of “the Hundred Schools of Thought,” this period of Chinese history witnessed the formation of all of the major indigenous schools of Chinese thought, which in turn had an impact on the development of East Asian cultural history that is still felt today. Important themes to be discussed include conceptions of the self, models of self-cultivation and rationality, and differences in spiritual and political ideals. Students will be exposed to both received texts and recently discovered archeological texts; this combination of sources will both enrich students’ understanding of the world of thought in early China and call into question the boundaries drawn between the traditionally-defined “schools” such as Daoism or Confucianism. Parallels with developments in Western philosophical and religious traditions will be highlighted. We will also explore the relevance of early Chinese thought for contemporary debates in ethics, moral education, and political philosophy, as well as the manner in which early Chinese models of the self anticipate recent developments in the evolutionary and cognitive sciences.

All required readings are available within the courseware, courtesy of Crown Publishers and Hackett Publishing Company. Print version of the books from which most of the readings are drawn, Trying Not to Try and Readings in Classical Chinese Philosophy, are also available for purchase through the publishers’ site or amazon.
If you are having trouble viewing the course about video, you may download it here.
See also: 
Chinese Thought: Ancient Wisdom Meets Modern Science - Part 2
This is a past/archived course. At this time, you can only explore this course in a self-paced fashion. Certain features of this course may not be active, but many people enjoy watching the videos and working with the materials. Make sure to check for reruns of this course.



            Read more",Chinese Thought: Ancient Wisdom Meets Modern Science
https://www.classcentral.com/course/developing-ai-applications-azure-17329,"This course introduces the concepts of Artificial Intelligence and Machine learning. We'll discuss machine learning types and tasks, and machine learning algorithms. You'll  explore Python as a popular programming language for machine learning solutions, including using some scientific ecosystem packages which will help you implement machine learning. 

Next, this course introduces the machine learning tools available in Microsoft Azure. We'll review standardized approaches to data analytics and you'll receive specific guidance on Microsoft's Team Data Science Approach. As you go through the course, we'll introduce you to Microsoft's pre-trained and managed machine learning offered as REST API's in their suite of cognitive services. We'll implement solutions using the computer vision API and the facial recognition API, and we'll do sentiment analysis by calling the natural language service.   

Using the Azure Machine Learning Service you'll create and use an Azure Machine Learning Worksace.Then you'll train your own model, and you'll deploy and test your model in the cloud. Throughout the course you will perform hands-on exercises to practice your new AI skills. By the end of this course, you will be able to create, implement and deploy machine learning models.
      


          Introduction to Artificial Intelligence
    -This module introduces Artificial Intelligence and Machine learning. Next, we talk about machine learning types and tasks.  This leads into a discussion of machine learning algorithms.  Finally we explore python as a popular language for machine learning solutions and share some scientific ecosystem packages which will help you implement machine learning.   By the end of this unit you will be able to implement machine learning models in at least one of the available python machine learning libraries.  

Standardized AI Processes and Azure Resources
    -This module introduces machine learning tools available in Microsoft Azure.  It then looks at standardized approaches developed to help data analytics projects to be successful.  Finally, it gives you specific guidance on Microsoft's Team Data Science Approach to include roles and tasks involved with the process.  The exercise at the end of this unit points you to Microsoft's documentation to implement this process in their DevOps solution if you don't have your own.  

Azure Cognitive APIs
    -This module introduces you to Microsoft's pretrained and managed machine learning offered as REST API's in their suite of cognitive services.  We specifically implement solutions using the computer vision api, the facial recognition api, and do sentiment analysis by calling the natural language service.   

Azure Machine Learning Service: Model Training
    -This module introduces you to the capabilities of the Azure Machine Learning Service. We explore how to create and then reference an ML workspace.  We then talk about how to train a machine learning model using the Azure ML service.  We talk about the purpose and role of experiments, runs, and models.  Finally, we talk about 
Azure resources available to train your machine learning models with.  Exercises in this unit include creating a workspace, building a compute target, and executing a training run using the Azure ML service.  

Azure Machine Learning Service:  Model Management and Deployment
    -This module covers how to connect to your workspace.  Next, we discuss how the model registry works and how to register a trained model locally and from a workspace training run.  In addition, we show you the steps to prepare a model for deployment including identifying dependencies, configuring a deployment target, building a container image.  Finally, we deploy a trained model as a webservice and test it by sending JSON objects to the API.",Developing AI Applications on Azure
https://www.classcentral.com/course/sql-data-science-capstone-17298,"Data science is a dynamic and growing career field that demands knowledge and skills-based in SQL to be successful. This course is designed to provide you with a solid foundation in applying SQL skills to analyze data and solve real business problems.

Whether you have successfully completed the other courses in the Learn SQL Basics for Data Science Specialization or are taking just this course, this project is your chance to apply the knowledge and skills you have acquired to practice important SQL  querying and solve problems with data. You will participate in your own personal or professional journey to create a portfolio-worthy piece from start to finish. You will choose a dataset and develop a project proposal. You will explore your data and perform some initial statistics you have learned through this specialization. You will uncover analytics for qualitative data and consider new metrics that make sense from the patterns that surface in your analysis. You will put all of your work together in the form of a presentation where you will tell the story of your findings. Along the way, you will receive feedback through the peer-review process. This community of fellow learners will provide additional input to help you refine your approach to data analysis with SQL and present your findings to clients and management.
      


          Getting Started and Milestone 1: Project Proposal and Data Selection/Preparation
    -In this first milestone, you will select your client and import your dataset. You will begin to explore your data to understand it and make assumptions about your data. You will draft a project proposal to act as a guide as you explore your data and prove or disprove your hypotheses.

Milestone 2: Descriptive Stats & Understanding Your Data
    -In this milestone, you will start to execute your project proposal. You will start looking at your data and perform initial statistic models to explore your data and determine what you have available to you. 

Milestone 3: Beyond Descriptive Stats (Dive Deeper/Go Broader)
    -In this milestone, you will go beyond the descriptive statistics you completed in the last milestone. This milestone is really about diving deeper to analyze your data, beyond descriptive stats. Maybe you need to analyze qualitative data or textual data to get a full picture.

Milestone 4: Presenting Your Findings (Storytelling)
    -In this milestone, you will present your findings. You will identify your audience and create a presentation tailored to them. You will be able to tell the story of analyses and make recommendations.",SQL for Data Science Capstone Project
https://www.classcentral.com/course/object-oriented-principles-8884,"A fun introduction to object-oriented programming in Python
Object-oriented programming is a programming paradigm based on objects and data rather than actions and logic.
This online course will introduce you to the principles of object-oriented programming in Python, showing you how to create objects, functions, methods, and classes.
You’ll use what you learn to create your own text-based adventure game. You will have the chance to share your code with other learners, and see theirs.
If you’re an educator, you’ll also be able to develop ideas for using object-oriented programming in your classroom.
This course is designed for people who are already familiar with Python programming and want to learn a different programming paradigm, understand and use existing libraries more effectively, or create code which is useful to other people.
It will be particularly useful for A level educators and students.
Python 3 or Trinket.",Object-oriented Programming in Python: Create Your Own Adventure Game
https://www.classcentral.com/course/edx-introduction-to-computing-using-python-7622,"In this computer science course, you will learn about foundational computing principles, such as how to write and read computer code and how to run and debug code.
You will learn about programming concepts in Python and how they demonstrate computing principles and domain applications that use programming concepts and computing principles in real applications.
The course will also cover:

procedural programming
control structures
data structures
advanced topics in algorithms and object-oriented programming

This course builds on a custom textbook written for the class and online course delivery and provides ample interaction and formative evaluation. The course teaches both the theory and implementation of core computing concepts in a highly interactive, multi-modal manner.



Unit 1: Computing
In this unit, we'll cover the basics of computing: what it means to write computer code, how to read computer code, and what it means to run and debug code.

Unit 2: Procedural Programming
In this unit, we'll cover the basic paradigm of programming, procedural programming. In procedural programming, series of commands are executed in order. Here, we'll discuss variables, logical operators, and mathematical operators.

Unit 3: Control Structures
In this unit, we'll cover control structures, which are lines of code that control when other lines of code run. We'll cover conditionals, loops, functions, and error handling.

Unit 4: Data Structures
In this unit, we'll cover how data is structure to be operated upon by a computer. Specifically, we'll focus on structures that bring together multiple different pieces of data, like strings, lists, dictionaries, and file input and output.

Unit 5: Advanced Topics
In this unit, we'll preview the next topics in computing: object-oriented programming and computer algorithms.",Introduction to Computing using Python
https://www.classcentral.com/course/edx-algorithm-design-and-analysis-8520,"How do you optimally encode a text file? How do you find shortest paths in a map? How do you design a communication network? How do you route data in a network? What are the limits of efficient computation?
This course, part of the Computer Science Essentials for Software Development Professional Certificate program, is an introduction to design and analysis of algorithms, and answers along the way these and many other interesting computational questions.
You will learn about algorithms that operate on common data structures, for instance sorting and searching; advanced design and analysis techniques such as dynamic programming and greedy algorithms; advanced graph algorithms such as minimum spanning trees and shortest paths; NP-completeness theory; and approximation algorithms.
After completing this course you will be able to design efficient and correct algorithms using sophisticated data structures for complex computational tasks.



          Week 1: Mathematical Preliminaries; Asymptotic analysis and recurrence relations; Sorting and Searching; Heaps and Binary Search Trees
Week 2: Algorithm Design Paradigms - Divide-and-Conquer algorithms, Dynamic Programming, Greedy Algorithms
Week 3: Graphs and graph traversals; minimum spanning trees; shortest paths
Week 4: Flows; NP-completeness; Approximation Algorithms",Algorithm Design and Analysis
https://www.classcentral.com/course/advanced-data-science-capstone-11715,"This project completer has proven a deep understanding on massive parallel data processing, data exploration and visualization, advanced machine learning and deep learning and how to apply his knowledge in a real-world practical use case where he justifies architectural decisions, proves understanding the characteristics of different algorithms, frameworks and technologies and how they impact model performance and scalability. 

Please note: You are requested to create a short video presentation at the end of the course. This is mandatory to pass. You don't need to share the video in public.
      


          Week 1 - Identify DataSet and UseCase
    -In this module, the basic process model used for this capstone project is introduced. Furthermore, the learner is required to identify a practical use case and data set

Week 2 - ETL and Feature Creation
    -This module emphasizes on the importance of ETL, data cleansing and feature creation as a preliminary step in ever data science project 

Week 3 - Model Definition and Training
    -This module emphasizes on model selection based on use case and data set. It is important to understand how those two factors impact choice of a useful model algorithm. 

Model Evaluation, Tuning, Deployment and Documentation
    -One a model is trained it is important to assess its performance using an appropriate metric. In addition, once the model is finished, it has to be made consumable by business stakeholders in an appropriate way",Advanced Data Science Capstone
https://www.classcentral.com/course/predictive-analytics-data-mining-13798,"This course introduces students to the science of business analytics while casting a keen eye toward the artful use of numbers found in the digital space. The goal is to provide businesses and managers with the foundation needed to apply data analytics to real-world challenges they confront daily in their professional lives. Students will learn to identify the ideal analytic tool for their specific needs; understand valid and reliable ways to collect, analyze, and visualize data; and utilize data in decision making for their agencies, organizations or clients.
      


          Module 0:  Get Ready & Module 1: Drowning in Data, Starving for Knowledge
    -This module will introduce you to the most common and important unsupervised learning technique – Clustering. You will have an understanding of different applications of clustering analysis after this module. You will also learn when we need clustering and why it is important. Then, you will be introduced to a variety of clustering methods.

Module 2: Decision Trees 
    -In this module, we will discuss how to use decision trees to represent knowledge. The module concludes with a presentation of the Random Forest method that overcomes some of the limitations (such as high variance or low precision) of a single decision tree constructed from data.


Module 3: Rules, Rules, and More Rules
    -This module will focus on three key topics, namely rules, nearest neighbor methods, and Bayesian methods. Over the course of this module, you will be exposed to how rules factor into the world of data and how they play a role in the analysis of data. The second and third topics focus on the classification of data.

Module 4: Model Performance and Recommendation Systems
    -In this module, you will study tools for recognizing what to recommend, and identify cross-sell or upsell opportunities. As the last module of the course, we will wrap up the content so far and you will get an opportunity to practice on your own and learn how to adapt these models to drive business impact in your own organizations.",Predictive Analytics and Data Mining
https://www.classcentral.com/course/advanced-manufacturing-process-analysis-8154,"Variability is a fact of life in manufacturing environments, impacting product quality and yield. Through this course, students will learn why performing advanced analysis of manufacturing processes is integral for diagnosing and correcting operational flaws in order to improve yields and reduce costs.   

Gain insights into the best ways to collect, prepare and analyze data, as well as computational platforms that can be leveraged to collect and process data over sustained periods of time. Become better prepared to participate as a member of an advanced analysis team and share valuable inputs on effective implementation.    

Main concepts of this course will be delivered through lectures, readings, discussions and various videos. 

This is the fourth course in the Digital Manufacturing & Design Technology specialization that explores the many facets of manufacturing’s “Fourth Revolution,”  aka Industry 4.0, and features a culminating project involving creation of a roadmap to achieve a self-established DMD-related professional goal.

To learn more about the Digital Manufacturing and Design Technology specialization, please watch the overview video by copying and pasting the following link into your web browser: https://youtu.be/wETK1O9c-CA
      


          Introduction to Advanced Manufacturing Process Analysis
    -The purpose of this module is to introduce the concept of advanced analysis in improvement of manufacturing processes. Also, this module will help you to understand the difference between discrete manufacturing and continuous manufacturing.

Data Collection
    -Storing big data is quite different from handling traditional data. This difference is explained in this module. The purpose of this module is to introduce various steps involved in data analysis. Data Collection, Data Storage, Data Organization and Data Pre-processing concepts are explained. 

Data Analysis: Computational Techniques and Platforms
    -The purpose of this module is to introduce various techniques used in advanced analysis, like Determination of Significant Variables/Factors, Data Visualization, and Anomaly Detection. Also, this module will introduce various computational platforms (HPC, Cloud computing techniques) that exist for carrying out advanced analysis.",Advanced Manufacturing Process Analysis
https://www.classcentral.com/course/mobile-health-monitoring-systems-12685,"This join course created by SPSU and ETU  includes 5 modules dedicated to different stages of the system development. Its modules represent several widely separated fields of biomedical engineering. We interconnect them by applying the knowledge from them all to a common task – the development of a prototype of an mHealth ECG system with built-in data-driven signal processing and analysis. Working on this task throughout the course, you will acquire a knowledge on how these branches of science, including electronics, mathematics, data science and programming are applied together in a real project. Pieces of hardware and software, as well as the data sets that we utilize in this course are the same components that we use in our work developing prototypes of devices and algorithms for our tasks in science and engineering.
The course is a joint work of Saint Petersburg State University and Saint Petersburg Electrotechnical University ETU (""LETI"").
Note that the goal of the course is not to provide you with fundamental knowledge on any of the topics highlighted in the modules, but to give you some useful skills on implementing them in practical tasks.
      


          Remote health monitoring system hardware
    -Welcome to Module 1! Medical systems for remote monitoring of patients have become extremely popular in recent years. Most of them have a similar structure, which will be discussed in detail in this module using the example of an electrocardiogram signal registration device. We will talk about hardware part of modern ECG recorders, and problems, connected with processing of biomedical signals.

Data Exchange Between Device And Personal Computer
    -Welcome to Module 2! The implementation of the protocol for transferring data from a patient’s wearable device to a computer is an extremely important step in the entire development of a telemedicine system. This module will consider the easiest and most affordable wired data transfer method using the RS-232 interface, virtual Com ports and the MatLab software environment.

Preprocessing of Biomedical Signals
    -Welcome to Module 3! Use you may know, biomedical signals are corrupted by a significant amount of noise. So, noise removal is used in order to increase signal quality. We will talk about basics method to prepare your signal for future analysis. In the Programming part of the Module we will learn how to evaluate and analyze ECG-signal spectrum and create a digital filter using MATLAB.

Event Detection in Biomedical Signals
    -Welcome to Module 4! In most cases, biomedical signal analysis assumes that we have some reference or basic events in the signal. It can be QRS-complexes (for ECG), breaths (for spirogram), eyes movements (for EEG) or steps (for accelerometric signal). We will look closely to this task in the context of ECG-analysis. You will learn different QRS-detection algorithms and create QRS-detector using MATLAB.

Developing Data-Driven Recommendation System
    -Welcome to Module 5! In this module you will further develop your mobile-based health monitoring system. How to deal with extracted features and how can they help you in creating recommendations – these are the primary questions for this module. This is a very broad topic, involving methods from statistical analysis, machine learning and medical practice. We will study a practical approach to use these methods in developing monitoring systems on the example, which is, in our case, a recognition of noisy ECG complexes and their removal.",The Development of Mobile Health Monitoring Systems
https://www.classcentral.com/course/edx-mycs-computer-science-for-beginners-2957,"How do computers work? What do computer scientists do?  What does it take to make a computer or a computer program work? We answer these questions and more with MyCS: Computer Science for Beginners.
 
We believe that anyone can succeed in and enjoy computer science. This course is an early introduction to CS, designed for anyone who's completely new to the field. It explores a combination of the basic principles of how computers work and how we can use them to solve interesting problems and create amazing things. Lessons alternate between general exercises and assignments in Scratch, which offer a chance to both practice some basic concepts of computer programming and explore the many cool, creative, and useful applications of CS.
 
You don't need any CS or programming background to do this course - just a bit of basic math and a lot of creative thinking. The course is intended especially for middle school students and their teachers, but is good for learners of all ages.
 
This material is based upon work supported by the National Science Foundation under Grant No. 1240939. Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation (NSF).",MyCS: Computer Science for Beginners
https://www.classcentral.com/course/edx-introduction-to-statistics-inference-932,"Statistics 2 at Berkeley is an introductory class taken by about 1,000 students each year. Stat2.3x is the last in a sequence of three courses that make up Stat2x, the online equivalent of Berkeley's Stat 2. The focus of Stat2.3x is on statistical inference: how to make valid conclusions based on data from random samples. At the heart of the main problem addressed by the course will be a population (which you can imagine for now as a set of people) connected with which there is a numerical quantity of interest (which you can imagine for now as the average number of MOOCs the people have taken). If you could talk to each member of the population, you could calculate that number exactly. But what if the population is so large that your resources will not stretch to interviewing every member? What if you can only reach a subset of the population?
Stat 2.3x will discuss good ways to select the subset (yes, at random); how to estimate the numerical quantity of interest, based on what you see in your sample; and ways to test hypotheses about numerical or probabilistic aspects of the problem.
The methods that will be covered are among the most commonly used of all statistical techniques. If you have ever read an article that claimed, ""The margin of error in such surveys is about three percentage points,"" or, ""Researchers at the University of California at Berkeley have discovered a highly significant link between ...,"" then you should expect that by the end of Stat 2.3x you will have a pretty good idea of what that means. Examples will range all the way from a little girl's school science project (seriously – she did a great job and her results were published in a major journal) to rulings by the U.S. Supreme Court.
The fundamental approach of the series was provided in the description of Stat2.1x and appears here again: There will be no mindless memorization of formulas and methods. Throughout the course, the emphasis will be on understanding the reasoning behind the calculations, the assumptions under which they are valid, and the correct interpretation of results.



            Read more",Introduction to Statistics: Inference
https://www.classcentral.com/course/cities-2993,"Urbanization is reaching a new peak in the contemporary world with the rise of mega cities. Researchers try to make sense of these large urban areas using a variety of concepts. The class will review debates and present social science models of cities to analyse and compare contemporary developments.

General Overview Help Center

Urbanization is reaching a new peak in the contemporary world with the rise of mega cities. Researchers try to make sense of these large urban areas using a variety of concepts. The class will review debates and present social science models of cities to analyse and compare contemporary developments.
Globalization, Europeanization processes support the rapid developments of cities in different part of the world. Urbanization is reaching a new high in the contemporary world with the rise of mega cities (beyond 15 million inhabitants) such as Calcutta, Los Angeles, Dhaka, Cairo, Tokyo, New York, Shanghai, Mexico or Seoul. Beyond the modern metropolis, researchers try to make sense of these large urban areas using a variety of concepts such as the ‘postmetropolis’, ‘global cities’, and ‘global city-regions’. The class will review debates and present social science models of cities and metropolis to analyse and compare contemporary developments. How can do we study those cities when they become mega urban regions, does size matter and for what? Do we see the making of a vast urban world or by contrast beyond the apparent convergence of complex globalisation processes understood in relation to globalised capitalism, is it possible to identify masked differentiations and the strengthening of different urban worlds? How do we make sense of this urban world when cities are not independent units but have to be understood both in terms of territories, rootedness, and at the same time in terms of relations to take into account flux, mobility, circulations ? What is the relevance of social science concepts developed in the Western world to analyse the transformation of Lagos? To what extent may the systematic development of new forms of comparison between northern cities and cities from the South change social sciences and contribute to overcome the bias towards national comparison? 
For the time being, given current conditions of capitalism, political, economic, cultural and social questions are increasingly becoming urban questions. In the modern conception of the world/globalcity, characterised by size, the aggregation of housing, differentiated divisions of labour, and the density of interaction, several conceptions of cities exist which have become entangled and sometimes opposed to each other. These different conceptions underline different processes of integration: the material city of walls, squares, houses, roads, light, utilities, buildings, waste, and physical infrastructure; the cultural city in terms of imaginations, differences, representations, ideas, symbols, arts, texts, senses, religion, and aesthetics; the politics and policies of the city in terms of domination, power, government, mobilisation, public policies, welfare, education; the social city of riots, ethnic, economic and gender inequalities, everyday life and social movements; and the economy of the city : the division of labour, scale, production, consumption, trade.....
Classic urban questions about inequalities, housing, government, integration, are combined with issues about the urban fabric, questions of mobility and rootedness, sustainable development and risks, the making of the cyborg cities, questions of social control and riots, urban culture, innovation and urban economic development.

All video produced by Sciences Po for this Mooc are under Creative Commons (BY / NC / SA)

Recommended Background
The course is designed for undergraduates but it also will interest graduates and professionals concerned in urban issues.

The course is organized in 8 sequences and displays multimedia contents (images, video, original documents). There will be also assignments that consist in participating to discussions related to theoretical models presented in the course based on case studies of your choice, and peer assessments on your contributions.

Syllabus :

Week #1 : Introduction, definition, urban questions and the use of models

Week #2 : European cities and the weberian model of integration

Week #3 : Colonial and post colonial cities

Week #4 : Industrial cities (and Socialist cities) and Marxist models

Week #5 : The American metropolis and the Chicago School, 

Week #6 : Post metropolis, fragments and differences

Week #7 : Global cities and mega cities

Week #8 : Smart cities and the sociology of science and technology
      


            Read more
          



          Week 1 – Introduction
    -Introduction to urban sociology

Week 2 – European City
    -European city model

Week 3 – Colonial City
    -Colonial city model

Week 4 – Industrial City
    -Industrial city model

Week 5 – Metropolis
    -Metropolis model

Week 6 – Global City
    -Global city model

Week 7 – Post Metropolis
    -Post metroplis model

Week 8 – Digital City
    -Digital city model",Cities are back in town : urban sociology for a globalizing urban world
https://www.classcentral.com/course/mining-medical-data-12055,"The goal of this course is to understand the foundations of Big Data and the data that is being generated in the health domain and how the use of technology would help to integrate and exploit all those data to extract meaningful information that can be later used in different sectors of the health domain from physicians to management, from patients to care givers, etc. The course will offer to the student a high-level perspective of the importance of the medical context within the European context, the types of data that are managed in the health (clinical) context, the challenges to be addressed in the mining of unstructured medical data (text and image) as well as the opportunities from the analytical point of view with an introduction to the basics of data analytics field.
      


          Introduction

Challenges in unstructured data in health domain

NLP in medical domain

Medical Image Analysis

Data Analysis of structured information",Foundations of mining non-structured medical data
https://www.classcentral.com/course/computerscience2-10671,"This course  introduces the broader discipline of computer science to people having basic familiarity with Java programming.  It covers the second half of our book Computer Science: An Interdisciplinary Approach (the first half is covered in our Coursera course Computer Science: Programming with a Purpose, to be released in the fall of 2018). Our intent is to demystify computation and to build awareness about the substantial intellectual underpinnings and rich history of the field of computer science.

First, we introduce classic algorithms along with scientific techniques for evaluating performance, in the context of modern applications. Next, we introduce classic theoretical models that allow us to address fundamental questions about computation, such as computability, universality, and intractability. We conclude with machine architecture (including machine-language programming and its relationship to coding in Java) and logic design (including a full CPU design built from the ground up).

The course emphasizes the relationships between applications programming, the theory of computation, real computers, and the field's history and evolution, including the nature of the contributions of Boole, Shannon, Turing, von Neumann, and others.

All the features of this course are available for free. No certificate will be offered upon completion.
      


          INFORMATION ABOUT LECTURES 1–10
    -This lesson provides information about the course Computer Science: Programming with a Purpose, which is the precursor to Computer Science: Algorithms, Theory, and Machines.

SORTING AND SEARCHING
    -We introduce and study classic algorithms for two fundamental problems, in the context of realistic applications. Our message is that efficient algorithms (binary search and mergesort, in this case) are a key ingredient in addressing computational problems with scalable solutions that can handle huge instances, and that the scientific method is essential in evaluating the effectiveness of such solutions.

STACKS AND QUEUES
    -Our introduction to data structures is a careful look at the fundamental stack and queue abstractions, including performance specifications. Then we introduce the concept of linked structures and focus on their utility in developing simple, safe, clear, and efficient implementations of stacks and queues.

SYMBOL TABLES
    -The symbol table abstraction is one of the most important and useful programmer's tools, s we illustrate with several examples in this lecture. Extending the scientific approach of the previous two lectures, we introduce and study binary search trees, a classic data structure that supports efficient implementations of this abstraction.

INTRODUCTION TO THE THEORY OF COMPUTING
    -The theory of computing helps us address fundamental questions about the nature of computation while at the same time helping us better understand the ways in which we interact with the computer. In this lecture, we introduce formal languages and abstract machines, focusing on simple models that are actually widely useful in practical applications.

TURING MACHINES
    -In 1936, Alan Turing published a paper that is widely hailed as one of the most important scientific papers of the 20th century. This lecture is devoted to the two far-reaching central ideas of the paper: All computational devices have equivalent computational power, and there are limitations to that power.

INTRACTABILITY
    -As computer applications expanded, computer scientists and mathematicians realized that a refinement of Turing's ideas is needed. Which computational problems can we solve with the resource limitations that are inescapable in the real world? As described in this lecture, this question, fundamentally, remains unanswered.

A COMPUTING MACHINE
    -Every programmer needs understand the basic characteristics of the underlying computer processor being used. Fortunately, the fundamental design of computer processors has changed little since the 1960s. In this lecture, we provide insights into how your Java code actually gets its job done by introducing an imaginary computer that is similar to both the minicomputers of the 1960s and the microprocessor chips found in today's laptops and mobile devices.

VON NEUMANN MACHINES
    -Continuing our description of processor design and low-level programming, we provide context stretching back to the 1950s and discuss future implications of the von Neumann machine, where programs and data are kept in the same memory. We examine in detail the idea that we design new computers by simulating them on old ones, something that Turing's theory guarantees will always be effective.

COMBINATIONAL CIRCUITS
    -Starting with a few simple abstractions (wires that can carry on/off values and switches that can control the values carried by wires), we address in this lecture the design of the circuits that implement computer processors. We consider gates that implement simple logical functions and components for higher-level functions, such as addition. The lecture culminates with a full circuit for an arithmetic/logic unit.

CENTRAL PROCESSING UNIT
    -In this lecture, we provide the last part of our answer to the question ""How does a computer work?"" by developing a complete circuit for a computer processor, where every switch and wire is visible. While vastly different in scale, this circuit, from a design point of view, has many of the same characteristics as the circuits found in your computer and your phone.","Computer Science:  Algorithms, Theory, and Machines"
https://www.classcentral.com/course/mongodb-aggregation-framework-10368,"This course will teach you how to perform data analysis using MongoDB's powerful Aggregation Framework.

You'll begin this course by building a foundation of essential aggregation knowledge. By understanding these features of the Aggregation Framework you will learn how to ask complex questions of your data. This will lay the groundwork for the remainder of the course where you'll dive deep and learn about schema design, relational data migrations, and machine learning with 
MongoDB.

By the end of this course you'll understand how to best use MongoDB and its Aggregation Framework in your own data science workflow.
      


          The Fundamentals of MongoDB Aggregation
    -In this module you'll learn the fundamentals of MongoDB's Aggregation Framework. This will cover basics like filtering and sorting, as well as how to transform array data, how to group documents together, how to join data, and how to traverse graph data.

Leveraging MongoDB's Flexible Schema
    -This module is going to be focused on the different ways you can leverage MongoDB's flexible schema. You'll learn how to migrate a relational schema, how to enhance existing schemas, and how to merge datasets via an entity resolution technique.

Machine Learning with MongoDB
    -This module is focused on demonstrating how MongoDB can be used in different machine learning workflows. You'll learn how to perform machine learning  directly in MongoDB, how to prepare data for machine learning with MongoDB, and how to analyze data with MongoDB in preparation of doing machine learning in Python.",MongoDB Aggregation Framework
https://www.classcentral.com/course/edx-introduction-to-probability-part-1-the-fundamentals-8968,"The world is full of uncertainty: accidents, storms, unruly financial markets, and noisy communications. The world is also full of data. Probabilistic modeling and the related field of statistical inference are the keys to analyzing data and making scientifically sound predictions.

This is Part 1 of a 2-part sequence on the basic tools of probabilistic modeling. Part 1 introduces the general framework of probability models, multiple discrete or continuous random variables, expectations, conditional distributions, and various powerful tools of general applicability. Part 2 will then continue into further topics that include laws of large numbers, the main tools of Bayesian inference methods, and an introduction to random processes (Poisson processes and Markov chains).

The contents of the two parts of the course are essentially the same as those of the corresponding MIT class, which has been offered and continuously refined over more than 50 years. It is a challenging class, but will enable you to apply the tools of probability theory to real-world applications or your research.

Probabilistic models use the language of mathematics. But instead of relying on the traditional ""theorem - proof"" format, we develop the material in an intuitive -- but still rigorous and mathematically precise -- manner. Furthermore, while the applications are multiple and evident, we emphasize the basic concepts and methodologies that are universally applicable.

Photo by User: Pablo Ruiz Múzquiz on Flickr. (CC BY-NC-SA 2.0)



            Read more
          




Probability models and axioms
Conditioning, Bayes’ rule, independence
Counting methods in discrete probability
Discrete random variables (distributions, mean, variance, conditioning, etc.)
Continuous random variables (including general forms of Bayes’ rule)
Further topics (derived distributions; covariance & correlation, etc.)",Introduction to Probability: Part 1 - The Fundamentals
https://www.classcentral.com/course/microbiome-2305,"Imagine if there were an organ in your body that weighed as much as your brain, that affected your health, your weight, and even your behavior. Wouldn’t you want to know more about it? There is such an organ — the collection of microbes in and on your body, your human microbiome.
      


          Introduction to Microbes and the Human Microbiome
    -Welcome Citizen Scientists! We're very pleased to have you join us on an exploration of the human microbiome. This is a fascinating area of study, and we hope you will find this six-module course worthwhile. Each module's content will be presented in similar fashion; our team will introduce topics by way of pre-recorded video lectures interspersed with guest interviews by subject matter experts. Module 1 will provide a broad overview about microbes and their diversity on earth and in the human body.

Studying the Microbiome
    -In this module, we will dive into the fundamentals of how we study the human microbiome. We highlight recent advances in microbiome research methods and take you on a tour of the Knight lab. Please keep in mind, that Modules 2 and 3 are meant to provide a glimpse into our world of data generation and analysis. Modules 4, 5, and 6 will be less technical and provide a broad overview of fascinating research on the human microbiome. Stick with us!   

Making Sense Out of Microbial Data
    -This module highlights the basics of generating and analyzing microbiome data. We will also discuss how computational scientists are revolutionizing the development of tools for analyzing large, complex biological data sets and show you some of the cool ways that we visualize data! This module will help you understand data plots in later modules, but do not get discouraged if the material here is too technical, a full understanding is not required to complete the course! 

The Human Gut Microbiome and Your Health
    -Now that we've given you some background about the methods we use to analyze microbial data, it's time for us to talk more about recent discoveries in microbiome research. This module will focus on the main factors impacting the gut microbiota as well as the influence of the gut microbiota on nutrition and gut health. This is the fun part, so get excited!

Gut Microbe-Host Interactions: Beyond Nutrition
    -You're more than halfway through the course! We hope you've been learning lots of new, exciting things about the human gut microbiota! In this module, we'll shift the focus from nutrition and gut health to the rest of your body. How do your gut microbes and your immune system interact? What about your nervous system? Does the gut microbiota play a role in allergies and stress? 

What's in the American Gut
    -We will wrap up the course in this module by discussing what's in the American Gut. Rob will walk us through results from the American Gut Project and compare results from Jeff Leach and Michael Pollan. We will also hear from Michael Pollan on the importance of microbiome research and how it has changed the way he thinks about his health and what he eats.",Gut Check: Exploring Your Microbiome
https://www.classcentral.com/course/swayam-python-for-data-science-14266,"The course aims at equipping participants to be able to use python programming for solving data science problems.
 
INTENDED AUDIENCE : Final Year Undergraduates
PRE-REQUISITES : Knowledge of basic data science algorithms
INDUSTRY SUPPORT : Honeywell, ABB, Ford, Gyan data pvt. Ltd.

      


COURSE LAYOUT
Week 1:•BASICS OF PYTHON SPYDER (TOOL)


• Introduction Spyder
• Setting working Directory
• Creating and saving a script file
• File execution, clearing console, removing variables from environment, clearing environment
• Commenting script files
• Variable creation
• Arithmetic and logical operators
• Data types and associated operations



Week 2:•Data Structures


Lists
Tuples
Dictionary
Sets


• Numpy


Array
Matrix and associated operations
Linear algebra and related operations

Week 3:•Pandas dataframe and dataframe related operations on Toyota Corolla dataset


Reading files
Exploratory data analysis
Data preparation and preprocessing


•Data visualization on Toyoto Corolla dataset using matplotlib and seaborn libraries


Scatter plot
Line plot
Bar plot
Histogram
Box plot
Pair plot


•Control structures using Toyota Corolla dataset


if-else family
for loop
for loop with if break
while loop


•FunctionsWeek 4:CASE STUDY
•Regression


Predicting price of pre-owned cars


•Classification


Classifying personal income",Python for Data Science
https://www.classcentral.com/course/edx-climate-change-the-science-4001,"Do you want to talk about climate change from an informed perspective? Are you interested in how global warming works? Climate change is the biggest challenge of our time, and climate science is critical to finding solutions. How can we make the best decisions about our present and future? By taking this course, you can be part of the global conversation. 
Climate Change: The Science is an introduction to climate science basics. We’ll discuss flows of energy and carbon in Earth’s climate system, how climate models work, climate history, and future forecasts.
This course will give you the knowledge you need, and practice communicating about climate change. You’ll meet people from around the world with a huge range of local and regional climate change issues. Join us, learn the science, and share your own stories.",Climate Change: The Science
https://www.classcentral.com/course/r-data-visualization-7176,"The data science revolution has produced reams of new data from a wide variety of new sources. These new datasets are being used to answer new questions in way never before conceived. Visualization remains one of the most powerful ways draw conclusions from data, but the influx of new data types requires the development of new visualization techniques and building blocks. This course provides you with the skills for creating those new visualization building blocks. We focus on the ggplot2 framework and describe how to use and extend the system to suit the specific needs of your organization or team. Upon completing this course, learners will be able to build the tools needed to visualize a wide variety of data types and will have the fundamentals needed to address new data types as they come about.
      


          Welcome to Building Data Visualization Tools
    -Before we get started, we'll take a quick overview of the course.

Plotting with ggplot2
    -Now, we'll dive into creating and customizing ggplot2 plots.

Mapping and interactive plots
    -Mapping is a critical part of many data visualizations. During this module, we'll teach you how to create simple and dynamic maps with ggplot2 and ggmap, how to overlay data, and how to create chloropleth maps of US counties.

The grid Package
    -The grid package in R implements the primitive graphical functions that underly the ggplot2 plotting system. In this module, you'll learn how to work with grid to build graphics.

Building New Graphical Elements
    -Building and modifying a theme in ggplot2 is a key feature of the ggplot2 package and system for building data graphics. In this final module, you'll learn to build a new theme and modifying existing themes with new features.",Building Data Visualization Tools
https://www.classcentral.com/course/nanosensors1-5200,"Nanotechnology and nanosensors are broad, interdisciplinary areas that encompass (bio)chemistry, physics, biology, materials science, electrical engineering and more. The present course will provide a survey on some of the fundamental principles behind nanotechnology and nanomaterials and their vital role in novel sensing properties and applications. The course will discuss interesting interdisciplinary scientific and engineering knowledge at the nanoscale to understand fundamental physical differences at the nanosensors. By the end of the course, students will understand the fabrication, characterization, and manipulation of nanomaterials, nanosensors, and how they can be exploited for new applications. Also, students will apply their knowledge of nanotechnology and nanosensors to a topic of personal interest in this course.

----------------
COURSE OBJECTIVES
The course main objective is to enhance critical, creative, and innovative thinking. The course encourages multicultural group work, constructing international 'thinking tanks' for the creation of new ideas. Throughout the course, you will be asked to reflect upon your learning, think ""out of the box"", and suggest creative ideas.   

The course is set to encourage the understanding of:
1. The importance of nanoscale materials for sensing applications.
2. Approaches used for characterizing sensors based nanomaterials.
3. Approaches used for tailoring nanomaterials for a specific sensing application.
4. Metallic and semiconductor nanoparticles.
5. Organic and inorganic nanotubes and nanowires.
6. Optical, mechanical and chemical sensors based on nanomaterials.
7. Hybrid nanomaterial-based sensors.

----------------
We recommend that you read the following supplementary reading materials:
-Jiří Janata, Principles of Chemical Sensors, Springer, 2d Edition (1989).
-Roger George Jackson, Novel Sensors and Sensing, CRC Press (2004).
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

Teaching Team

About Professor Haick Hossam

Professor Hossam Haick is an expert in the field of nanotechnology, nanosensors, and non-invasive disease diagnosis. Prof. Haick is the recipient of the prestigious Marie Curie Excellence Award, ERC Award, and the FP-7 Health Award. He is also the recipient of more than 42 international honors and prizes for his achievements, including a Knight of the Order of Academic Palms (conferred by the French Government) and the “List of the World’s Top 35 Young Scientists”, and the Discovery Award of the Bill & Melinda Gates. Prof. Haick is the founder and the leader of a European consortium of eight universities and companies for the development of advanced generation of nanosensors for disease diagnosis. He also serves as an associate editor of the two journals and serves as an advisory consultant to the Chemical Abstracts Service (CAS) – the world's authority for chemical information - a senior scientific advisory member of several national and international companies and institutes, and as a scientific evaluator in the European Commission.
Email: hhossam@technion.ac.il  
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

Course Staff

Meital Bar-Segev, Teaching Assistant: Received her B.A. (Cum Laude) in Chemistry and B.Sc (Cum Laude) in Materials Engineering from the Technion – Israel Institute of Technology (both in 2010). During her studies, she worked in a student position at Tower Semiconductors Ltd. After graduation she worked at Alfred Mann Institute in the Technion (AMIT) as a process development engineer. Currently, she performs her Ph.D. degree (direct track) in the Russell Berrie Nanotechnology Institute (RBNI) of the Technion under the supervision of Prof. Hossam Haick. The research of Meital focuses is the development of electronic skin based on nanoparticles.

Abeer Watted, Teaching Assistant: Received her B.Sc. and M.Sc. in Transportation and Highways Engineering from the Technion.  She is a Ph.D. student at the Faculty of Education in Science and Technology at the Technion, under the supervision of Asst. Prof. Miri Barak. She received a second master degree in Educatu in Science and Technology from the Technion in 2013. Her research focuses on science education and inquiry-based laboratories. Currently, Abeer works as a lecturer at Al-Qasemi Academic College of Education, where she serves also as the head of Civil Engineering Department.

Maya Usher, Teaching Assistant: Received her B.A. and M.A. (Cum Laude) in Communication Studies from Sapir Academic College and Ben Gurion University- Israel (2009; 2013 respectively). Currently, Maya is a PhD. candidate at the Faculty of Education in Science and Technology at the Technion, under the supervision of Asst. Prof. Miri Barak. Her research focuses on examining online collaborative learning in small multicultural groups. 

Muhammad Khatib, Teaching Assistant: Received his B.Sc in Biochemical Engineering from the Technion – Israel Institute of Technology (2015). His final research project, conducted with Prof. Avi Schroeder, dealt with harnessing liposome-based drug delivery systems to applications in precise agriculture. Currently, he performs his Ph.D. (special track) in the Department of Chemical Engineering of the Technion under the supervision of Prof. Hossam Haick, and his research focuses on self-healing devices for monitoring infectious diseases.

Miri Barak, Pedagogical Advisor: Assistant Professor at the Faculty of Education in Science and Technology, Technion- Israel Institute of Technology. She is the Head of the Science and Learning Technologies group and the advisor of graduate students. Her academic activities focus on developing, integrating, and evaluating science education curricula at school and higher education levels. Her studies involve the use of information and communication technologies (ICT), with emphasis on emerging web-2.0 and cloud applications, to foster meaningful learning and high-order thinking.
      


            Read more
          



          Introduction to Nanotechnology, Part 1
    -The description goes here

Introduction to Nanotechnology, Part 2
    -The description goes here

Introduction to Sensors’ Science and Technology
    -The description goes here

Metal Nanoparticles-based Sensors
    -The description goes here

Quantum Dots Sensor
    -The description goes here","Nanotechnology and Nanosensors, Part1"
https://www.classcentral.com/course/kadenze-gender-race-and-technology-5893,"What are the issues affecting women and minorities in the creative and technological fields?
What are some of the ways to solve them? Why is diversity important? These are some of the
questions we will address in this class. The format of our sessions will vary between
presentations by the instructor and interviews with guests. We will be looking at case studies,
examining our own attitudes and biases, and coming up with solutions. We will have nationally
and internationally renowned guests from various fields at the intersection of art and technology.
This is a great opportunity to find out more about fields within and beyond your interests and to
study the current practices employed by leaders from various creative and technological fields.



Session 1: Welcome Course Introduction
Session 2: Gender Studies/ Feminist Studies 101 Jump into readings and wiki editing workshop.
Session 3: The Histories Of Sexuality, Gender, And Identity Read ""A Cyborg Manifesto: Science, Technology, and Socialist- Feminism in the Late Twentieth Century,"" in Simians, Cyborgs and Women, ""Split Subjects, Not Atoms; or, How I Fell in Love with My Prosthesis."" The Cyborg Handbook, and ""Tinysex and Gender Trouble."" Sex/Machine: Readings in Culture, Gender and Technology.
Session 4: Technology And Vision Read ""Digitizing race: Visual cultures of the Internet"", and ""Entering the picture: Judy Chicago, the Fresno Feminist Art Program and the collective visions of women artists"".
Session 5: Technology, Gender, And Desire Read works from Judith Halberstam, Adranne Wadewitz, and Amy Adele Hasinoff. Introduction of WikiStorming Assignment.
Session 6: Technology, Whiteness And Racialization – Part I Read works from L. Nakamura, Vernadette V Gonzalez, and Robyn Magalit. We will also be looking at ""Black Girls Code"" and continuing work on the WikiStorming assignment.
Session 7: Technology & Privacy Look at readings; “Spectatorship, Power and Knowledge”, ""Facegen and the Technovisual Politics of Embodied Surfaces."",“Face to Anti-Face - Op-Art”, and ""Camouflage From Face Detection”. Start work on Feminist Mapping Project.
Session 8: The Body In The World Read works by Anne Fausto-Sterlng, Susan Best, Elizabeth Grosz, and Elizabeth Wilson. Continue work with collecting data for Feminist Mapping assignment.
Session 9: Technology, Representation And The Female Body Read ""The Myth of the Vaginal Orgasm"", ""Castration and Medusa: Orlan's Art on the Cutting Edge"", ""Serene and Happy and Distant: An Interview with Orlan"", and ""Anger, Art and Medicine: Working with Orlan"". Continue work on Feminist Mapping project with tools and best practices.
Session 10: Activism: Social Justice & Social Media Read ‘Our Demand Is Simple: Stop Killing Us’: How a group of black social media activists built the nation’s first 21st-century civil rights movement, and “Equal Rights Takes to the Barricades - NYTimes.com”. View “Egypt: The viral vlog of Asmaa Mahfouz that helped spark an uprising – Boing Megan Winget, PhD 5 Boing”. Continue Feminist Mapping project with spiffifying the data.
Session 11: Activism: Technology, Masculinity And Militarism Read ""Video Games and Machine Dreams of Domination"", ""Breakdown in the Gray Room: Recent Turns in the Image War"", and Columbia University Report on US Drone Strikes. Continue with Feminist Mapping assignment focusing on tools; Google Maps, HyperCities and StoryMaps.
Session 12: Gendering Climate Change, Engendering Responsibility Read selected works from Margaret Atwood and L. Weintraub. Watch ""Chasing Ice"". Continue with Feminist Mapping and mapping tools.","Gender, Race and Technology"
https://www.classcentral.com/course/hadoop-4269,"This course is for novice programmers or business people who would like to understand the core tools used to wrangle and analyze big data. With no prior experience, you will have the opportunity to walk through hands-on examples with Hadoop and Spark frameworks, two of the most common in the industry. You will be comfortable explaining the specific components and basic processes of the Hadoop architecture, software stack, and execution environment.   In the assignments you will be guided in how data scientists apply the important concepts and techniques such as Map-Reduce that are used to solve fundamental problems in big data.  You'll feel empowered to have conversations about big data and the data analysis process.
      


          Hadoop Basics
    -Welcome to the first module of the Big Data Platform course. This first module will provide insight into Big Data Hype, its technologies opportunities and challenges.  We will take a deeper look into the Hadoop stack and tool and technologies associated with Big Data solutions.  


Introduction to the Hadoop Stack
    -In this module we will take a detailed look at the Hadoop stack ranging from the basic HDFS components, to application execution frameworks, and languages, services.

Introduction to Hadoop Distributed File System (HDFS)
    -In this module we will take a detailed look at the Hadoop Distributed File System (HDFS). We will cover the main design goals of HDFS, understand the read/write process to HDFS, the main configuration parameters that can be tuned to control HDFS performance and robustness, and get an overview of the different ways you can access data on HDFS.

Introduction to Map/Reduce
    -This module will introduce Map/Reduce concepts and practice.  You will learn about the big idea of Map/Reduce and you will learn how to design, implement, and execute tasks in the map/reduce framework. You will also learn the trade-offs in map/reduce and how that motivates other tools.

Spark
    -Welcome to module 5, Introduction to Spark, this week we will focus on the Apache Spark cluster computing framework, an important contender of Hadoop MapReduce in the Big Data Arena.

Spark provides great performance advantages over Hadoop MapReduce,especially for iterative algorithms, thanks to in-memory caching. Also, gives Data Scientists an easier way to write their analysis pipeline in Python and Scala,even providing interactive shells to play live with data.",Hadoop Platform and Application Framework
https://www.classcentral.com/course/swift-5-programming-introduction-17282,"Welcome to Introduction to Programming in Swift 5.

In this course we will introduce you to the absolute basics of the Swift programming language.  Whether you are a brand new programmer or have experience with other programming languages this course is for you.

Some of the things you will learn in this course are:

•	An Introduction to Swift 5 programming concepts
•	Installing the necessary tools
•	Working with data such as Integers and Strings
•	Creating reusable code with functions
•	Working with data constructs such as arrays and dictionaries
•	Object-oriented programming
•	Model View Controller

By the end of this course you will know how to build simple programs with the Swift programming language and you will be ready to learn iOS mobile development.
      


          Installation, Setup & Your First Code

Variables, Strings and Numbers

Conditional Logic, Arrays and Loops

Dictionaries, Functions and Optionals

Architecture & Object-Oriented Programming in Swift",Introduction to Programming in Swift 5
https://www.classcentral.com/course/dataviz-6808,"In this first course of the specialization, you will discover just what data visualization is, and how we can use it to better see and understand data. Using Tableau, we’ll examine the fundamental concepts of data visualization and explore the Tableau interface, identifying and applying the various tools Tableau has to offer. By the end of the course you will be able to prepare and import data into Tableau and explain the relationship between data analytics and data visualization. This course is designed for the learner who has never used Tableau before, or who may need a refresher or want to explore Tableau in more depth.  No prior technical or analytical background is required.  The course will guide you through the steps necessary to create your first visualization story from the beginning based on data context,  setting the stage for you to advance to the next course in the Specialization.
      


          Getting Started & Introduction to Data Visualization
    -Welcome to this first module, where you will begin to discover the power of data visualization. You will define the meaning and purpose of data visualization and explore the various types of data visualization tools, beyond Tableau. You will install Tableau on your own device and create your first visualization.

Exploring and Navigating Tableau
    -With the last module, you were able to create your first visualization through guided practice. The secret to doing visualizations is really knowing the tool you will be using. For this module, you will explore and navigate the Tableau interface and be able to use specific tools as you begin your visualization journey.

Making Data Connections
    -Creating visualizations require data and in this module, you will discuss the various data sources for visualization and specifically what can be used in Tableau. You will prepare your data and identify the types of data connections possible with Tableau. You will be able to connect and merge to multiple data sources which can help make your visualizations more powerful.

Context of Data Visualization & Course Wrap-Up
    -Data visualization is about telling a story using data. However, before you can be successful at data visualization, you must understand the ""who"", ""what"", and ""how"" of data context. In this final module, you will be able to determine who your audience will be and what your relationship to them is. You will analyze a real world application of data context and be able to write out a visualization story based on data context.",Fundamentals of Visualization with Tableau
https://www.classcentral.com/course/independent-nonlinear-dynamics-1-geometry-of-chaos-2446,"The theory developed here (that you will not find in any other course :) has much in common with (and complements) statistical mechanics and field theory courses; partition functions and transfer operators are applied to computation of observables and spectra of chaotic systems. Nonlinear dynamics I: Geometry of chaos

Topology of flows - how to enumerate orbits, Smale horseshoes
Dynamics, quantitative - periodic orbits, local stability
Role of symmetries in dynamics

Nonlinear dynamics II: Chaos rules

Transfer operators - statistical distributions in dynamics
Spectroscopy of chaotic systems
dynamical zeta functions
Dynamical theory of turbulence

The course is in part an advanced seminar in nonlinear dynamics, aimed at PhD students, postdoctoral fellows and advanced undergraduates in physics, mathematics, chemistry and engineering.



Week 1: Flows and mapsTrajectoriesRead quickly all of Chapter 1 - do not worry if there are stretches that you do not understand yet. Study all of Chapter 2Flow visualized as an iterated mappingDiscrete time dynamical systems arise naturally by recording the coordinates of the flow when a special event happens: the Poincare section method, key insight for much that is to follow.
Week 2: Linear stabilityThere goes the neighborhoodSo far we have concentrated on description of the trajectory of a single initial point. Our next task is to define and determine the size of a neighborhood, and describe the local geometry of the neighborhood by studying the linearized flow. What matters are the expanding directions.Cycle stabilityIf a flow is smooth, in a sufficiently small neighborhood it is essentially linear. Hence in this lecture, which might seem an embarrassment (what is a lecture on linear flows doing in a book on nonlinear dynamics?), offers a firm stepping stone on the way to understanding nonlinear flows. Linear charts are the key tool of differential geometry, general relativity, etc, so we are in good company.
Week 3: Linear stabilityStability exponents are invariants of dynamicsWe prove that (1) Floquet multipliers are the same everywhere along a cycle, and (b) that they are invariant under any smooth coordinate transformation.Pinball wizardThe dynamics that we have the best intuitive grasp on is the dynamics of billiards. For billiards, discrete time is altogether natural; a particle moving through a billiard suffers a sequence of instantaneous kicks, and executes simple motion in between.
Week 4: World in a mirrorDiscrete symmetries of dynamicsWhat is a symmetry of laws of motion? The families of symmetry-related full state space cycles are replaced by fewer and often much shorter ""relative"" cycles, and the notion of a prime periodic orbit is replaced by the notion of a ""relative"" periodic orbit, the shortest segment that tiles the cycle under the action of the group. Discrete symmetries: a review of the theory of finite groupsDiscrete symmetry reduction of dynamics to a fundamental domainWhile everyone can visualize the fundamental domain for a 3-disk billiard, the simpler problem - symmetry reduction of 1d dynamics that is equivariant under a reflection, the most common symmetry in applications - seems to baffle everyone. So here is a step-by-step walk through to this simplest of all symmetry reductions.
Week 5: Relativity for cyclistsContinuous symmetries of dynamicsSymmetry reduction: If the symmetry is continuous, the interesting dynamics unfolds on a lower-dimensional ""quotiented"" system, with ""ignorable"" coordinates eliminated (but not forgotten). Hilbert's invariant polynomials. Cartan's moving frames.Got a continuous symmetry? Freedom and its challengesWhenever you have a continuous symmetry, you need to cut the orbit to pick out one representative for the whole family. For continuous spatial symmetries, this is achieved by slicing. And then there is dicing.
Week 6: Charting the state spaceSlice and diceSymmetry reduction is the identification of a unique point on a group orbit as the representative of this equivalence class. Thus, if the symmetry is continuous, the interesting dynamics unfolds on a lower-dimensional `quotiented', or `reduced' state space M/G. In the method of slices the symmetry reduction is achieved by cutting the group orbits with a set of hyperplanes, one for each continuous group parameter Moving frames give us a great deal of freedom - we discuss how to choose a frame The most natural of all moving frames: the comoving frame, the frame for space cowboys.Qualitative dynamics, for pedestriansQualitative properties of a flow partition the state space in a topologically invariant way.
Week 7: Stretch, fold, pruneThe spatial ordering of trajectories from the time ordered itinerariesQualitative dynamics: (1) temporal ordering, or itinerary with which a trajectory visits state space regions and (2) the spatial ordering between trajectory points, the key to determining the admissibility of an orbit with a prescribed itinerary. Kneading theory.Qualitative dynamics, for cyclistsDynamical partitioning of a plane. Stable/unstable invariant manifolds, and how they partition the state space in intrinsic, topologically invariant manner. Henon map is the simplest example.Week 8: Fixed points, and how to get themFinding cyclesWhy nobody understands anybody? The bane of night fishing - plus how to find all possible orbits by (gasp!) thinking.Finding cycles; long cycles, continuous time cyclesMulti-shooting; d-dimensional flows; continuous-time flows.
Week 9Chapter 17 - Walkabout: Transition graphsTopological dynamics encoded by means of transition matrices/Markov graphs. Read all of it.Chapter 18 - CountingYou learn here how to count distinct orbits, and in the process touch upon all the main themes of this book, going the whole distance from diagnosing chaotic dynamics to - while computing the topological entropy from transition matrices/Markov graphs - our first zeta function. The long time dynamics of a discrete-time system is described by (1) generating all orbits by action of the 1-time step transition matrix, and (2) expressing the result as a ""generating function"". Here we derive the trace formula, the determinant and the topological zeta function. If you do not understand how to derive these, you'll be lost for the rest of the semester, and what fun is that? Read sects. 18.1 - 18.4; 18.6 - 18.7, ChaosBook vers. approx 15.3.
Week 10Chapter 19 - Transporting densitiesA first attempt to move the whole phase space around - natural measure and fancy operators. Skip sects. 19.3 and 19.6.Chapter 20 - AveragingOn the necessity of studying the averages of observables in chaotic dynamics. Formulas for averages are cast in a multiplicative form that motivates the introduction of evolution operators. Discrete-time and generating functions continued and compared. Infinitesimal time evolution related to the infinite time dynamics via a Laplace transform. The stage is set for the classical trace formula. Read sects. 20.1 and 20.2. Skip sect. 20.1.3 ""Moments, cumulants""
Week 11Chapter 21 - Trace formulasIf there is one idea that one should learn about chaotic dynamics, it happens in this chapter: the (global) spectrum of the evolution is dual to the (local) spectrum of periodic orbits. The duality is made precise by means of trace formulas. The course is OVER. Trace formulae are beautiful, and there is nothing more to say. Just some mopping up to do.Chapter 22 - Spectral determinantsWe derive the spectral determinants, dynamical zeta functions. While traces and determinants are formally equivalent, determinants are the tool of choice when it comes to computing spectra. Skip sects. 20.5 and 20.6.
Week 12Chapter 23 - Cycle expansionsSpectral eigenvalues and dynamical averages are computed by expanding spectral determinants into cycle expansions, expansions ordered by the topological lengths of periodic orbits. Skip sects. 23.3.1 ""Newton algorithm for determining the evolution operator eigenvalues"", and 23.6 ""Stability ordering of cycle expansions"".Chapter 20 - AveragingRead sect. 20.1, including sect. 20.1.3 ""Moments, cumulants""Chapter 24 - Deterministic diffusionWe derive exact formulas for diffusion constants transport coefficients. All from first principles, without invoking any Boltzmann-Gibbs probabilistic notions. Read sect. 28.1: Foundations of statistical mechanics illuminated by 2-dimensional Lorentz gas.
Week 13Chapter 24 - Deterministic diffusionRead sect. 28.2: A class of simple 1-dimensional dynamical systems where all transport coefficients can be evaluated analytically, by hand. Diffusion is a non-monotonic function of the local expansion rate, and it is non-gaussian, with a non-vanishing kurtosis. Perhaps the most fundamental diagnostic of deterministic chaos is the non-differentiable dependence of its transport coefficients on smooth variations of system parameters.Chapter xx - Finite groupsSelf-study week part I: Finite groups. Cyclic groups of two and three elements. Symmetries of a triangle, six element group multiplication table. Matrix representations. Regular representations. This is standard material, not written up in ChaosBook, but necessary for the course. We liked Tinkham, chapter 2, or Dresselhaus chapters 1 and 2 (early version available as lecture notes).
Week 14Chapter xx- Irreducible representationsSelf-study week part II: Characters. Orthogornality relations. Character tables. If you have understood character projection operators, we are set. We liked Tinkham, chapter 3, or Dresselhaus chapters 3 and 4 (early version available as lecture notes).Chapter 25 - Discrete symmetry factorizationSymmetries simplify and improve the cycle expansions in a rather beautiful, not entirely obvious way, by factorizing cycle expansions. Read sects. 25.1 and 25.2. For a one-d map with reflection symmetry determinants factorize into symmetric and and antisymmetric ones, and each one receives contributions from all kinds of orbits. In a not entirely obvious way. A triple home run: simpler symbolic dynamics, fewer cycles needed, much better convergence of cycle expansions. Once you master this, going back is unthinkable.
Week 15Chapter 25 - Discrete symmetry factorization3 disk pinball symmetries suffice to illustrate all that is needed to factorized spectral determinants for any system with a discrete symmetry: character. Discrete symmetry tiles the state space, and dynamics can be reduced to dynamics on the fundamental domain, together with a finite matrix that keeps track of the tile the full state space trajectory lands on. We need some group theory (one needs to underatand the projection to irreducible representations) and illustrate how different classes of periodic orbits contribute to different invariant subspaces for the 3-disk pinball. Read sects. 25.2 - 25.6.Chapter 26 - Continuous symmetry factorizationTrace formulas relate short time dynamics (unstable period ic orbits) to long time invariant state space densities (natural measure). A trace formula for a partially hyperbolic (N+ 1)-dimensional compact manifold invariant under a global continuous symmetry is derived. In this extension of “periodic orbit” theory there are no or very few periodic orbits - the relative periodic orbits that the trace formula has support on are almost never eventually periodic
Week 16Chapter 30 - “Turbulence” - a one spatial dimension warmupFlows described by PDEs are said to be `infinite dimensional' because if one writes them down as a set of ODEs, one needs infinitely many of them to represent the dynamics of one PDE. The long-time dynamics of many such systems of physical interest is finite-dimensional. Here we cure you of the fear of infinite-dimensional flows.Tutorial - Turbulence? A stroll through 61,506 dimensionsIn the world of everyday, moderately turbulent fluids flowing across planes and down pipes, a velvet revolution is taking place. Experiments are as detailed as simulations, there is a zoo of exact numerical solutions that one dared not dream about a decade ago, and portraits of turbulent fluid's state space geometry are unexpectedly elegant. We take you on a tour of this newly breached, hitherto inaccessible territory. Mastery of fluid mechanics is no prerequisite, and perhaps a hindrance: the tutorial is aimed at anyone who had ever wondered how we know a cloud when we see one, if no cloud is ever seen twice? And how do we turn that into mathematics?",Nonlinear Dynamics 1: Geometry of Chaos
https://www.classcentral.com/course/bayesian-6097,"This course describes Bayesian statistics, in which one's inferences about parameters or hypotheses are updated as evidence accumulates. You will learn to use Bayes’ rule to transform prior probabilities into posterior probabilities, and be introduced to the underlying theory and perspective of the Bayesian paradigm. The course will apply Bayesian methods to several practical problems, to show end-to-end Bayesian analyses that move from framing the question to building models to eliciting prior probabilities to implementing in R (free statistical software) the final posterior distribution. Additionally, the course will introduce credible regions, Bayesian comparisons of means and proportions, Bayesian regression and inference using multiple models, and discussion of Bayesian prediction.

We assume learners in this course have background knowledge equivalent to what is covered in the earlier three courses in this specialization: ""Introduction to Probability and Data,"" ""Inferential Statistics,"" and ""Linear Regression and Modeling.""
      


          About the Specialization and the Course
    -This short module introduces basics about Coursera specializations and courses in general, this specialization: Statistics with R, and this course: Bayesian Statistics. Please take several minutes read this information. Thanks for joining us in this course!

The Basics of Bayesian Statistics
    -Welcome! Over the next several weeks, we will together explore Bayesian statistics. In this module, we will work with conditional probabilities, which is the probability of event B given event A. Conditional probabilities are very important in medical decisions. By the end of the week, you will be able to solve problems using Bayes' rule, and update prior probabilities.Please use the learning objectives and practice quiz to help you learn about Bayes' Rule, and apply what you have learned in the lab and on the quiz. 

Bayesian Inference
    -In this week, we will discuss the continuous version of Bayes' rule and show you how to use it in a conjugate family, and discuss credible intervals. By the end of this week, you will be able to understand and define the concepts of prior, likelihood, and posterior probability and identify how they relate to one another.

Decision Making
    -In this module, we will discuss Bayesian decision making, hypothesis testing, and Bayesian testing. By the end of this week, you will be able to make optimal decisions based on Bayesian statistics and compare multiple hypotheses using Bayes Factors. 

Bayesian Regression
    -This week, we will look at Bayesian linear regressions and model averaging, which allows you to make inferences and predictions using several models. By the end of this week, you will be able to implement Bayesian model averaging, interpret Bayesian multiple linear regression and understand its relationship to the frequentist linear regression approach. 

Perspectives on Bayesian Applications
    -This week consists of interviews with statisticians on how they use Bayesian statistics in their work, as well as the final project in the course.

Data Analysis Project
    -In this module you will use the data set provided to complete and report on a data analysis question. Please read the background information, review the report template (downloaded from the link in Lesson Project Information), and then complete the peer review assignment.",Bayesian Statistics
https://www.classcentral.com/course/datascimed-10645,"An increasing volume of data is becoming available in biomedicine and healthcare, from genomic data, to electronic patient records and data collected by wearable devices. Recent advances in data science are transforming the life sciences, leading to precision medicine and stratified healthcare. 

In this course, you will learn about some of the different types of data and computational methods involved in stratified healthcare and precision medicine.  You will have a hands-on experience of working with such data.  And you will learn from leaders in the field about successful case studies. 

Topics include: (i) Sequence Processing, (ii) Image Analysis, (iii) Network Modelling, (iv) Probabilistic Modelling, (v) Machine Learning, (vi) Natural Language Processing, (vii) Process Modelling and (viii) Graph Data.

Watch the course promo video here: http://edin.ac/2pn350P
      


          Welcome to the Course
    -Join us this week to find out how the course works and to try your hand at programming in Python!

WELCOME TO WEEK 2
    -This week you will be introduced to Sequence Processing and Medical Image Analysis. Explore the course materials to find out about recent advances in these areas and how they contribute to Precision Medicine!

WELCOME TO WEEK 3
    -This week you will learn about Probabilistic and Network Modelling, and how they are applied to biomedicine. You will also be introduced to Machine Learning and explore the opportunities it brings to the medical field.

WELCOME TO WEEK 4
    -This week you will discover how clinical notes and other free-form text can be analysed with the use of Natural Language Processing techniques. You will also find out how Process Modelling can help us understand, stratify and improve healthcare processes.

WELCOME TO WEEK 5
    -In this final week of the course you will learn how the Graph Data model allows for effective linkage of different data in the life sciences. You will also explore societal, legal and ethical implications of precision medicine and stratified healthcare.",Data Science in Stratified Healthcare and Precision Medicine
https://www.classcentral.com/course/social-media-data-analytics-7019,"Learner Outcomes: After taking this course, you will be able to:
- Utilize various Application Programming Interface (API) services to collect data from different social media sources such as YouTube, Twitter, and Flickr.
- Process the collected data - primarily structured - using methods involving correlation, regression, and classification to derive insights about the sources and people who generated that data.
- Analyze unstructured data - primarily textual comments - for sentiments expressed in them.
- Use different tools for collecting, analyzing, and exploring social media data for research and development purposes.

Sample Learner Story: Data analyst wanting to leverage social media data.
Isabella is a Data Analyst working as a consultant for a multinational corporation. She has experience working with Web analysis tools as well as marketing data. She wants to now expand into social media arena, trying to leverage the vast amounts of data available through various social media channels. Specifically, she wants to see how their clients, partners, and competitors view their products/services and talk about them. She hopes to build a new workflow of data analytics that incorporates traditional data processing using Web and marketing tools, as well as newer methods of using social media data.

Sample Job Roles requiring these skills: 
- Social Media Analyst
- Web Analyst
- Data Analyst
- Marketing and Public Relations 

Final Project Deliverable/ Artifact: The course will have a series of small assignments or mini-projects that involve data collection, analysis, and presentation involving various social media sources using the techniques learned in the class.
      


            Read more
          



          Introduction to Data Analytics
    -In this first unit of the course, several concepts related to social media data and data analytics are introduced. We start by first discussing two kinds of data - structured and unstructured. Then look at how structured data, the primary focus of this course, is analyzed and what one could gain by doing such analysis. Finally, we briefly cover some of the visualizations for exploring and presenting data.Make sure to go through the material for this unit in the sequence it's provided. First, watch the four short videos, then take the practice test, followed by the two quizzes. Finally, read the documents about installation and configuration of Python and R. This is very important - before proceeding to the next units, make sure you have installed necessary tools, and also learned how to install new packages/libraries for them. The course expects students to have programming experience in Python and R.

Collecting and Extracting Social Media Data
    -In this unit we will see how to collect data from Twitter and YouTube. The unit will start with an introduction to Python programming. Then we will use a Python script, with a little editing, to extract data from Twitter. A similar exercise will then be done with YouTube. In both the cases, we will also see how to create developer accounts and what information to obtain to use the data collection APIs.

Once again, make sure to go item-by-item in the order provided. Before beginning this unit, ensure that you have all the right tools (Python, R, Anaconda) ready and configured. The lessons depend on them and also your ability to install required packages.

Data Analysis, Visualization, and Exploration
    -In this unit, we will focus on analyzing and visualizing the data from various social media services. We will first use the data collected before from YouTube to do various statistics analyses such as correlation and regression. We will then introduce R - a platform for doing statistical analysis. Using R, then we will analyze a much larger dataset obtained from Yelp.

Make sure you have covered the material in the previous units before proceeding with this. That means, having all the tools (Anaconda, Python, and R) as well as various packages installed. We will also need new packages this time, so make sure you know how to install them to your Python or R. If needed, please review some basic concepts in statistics - specifically, correlation and regression - before or during working on this unit.

Case Studies
    -In the final unit of this course, we will work on two case studies - both using Twitter and focusing on unstructured data (in this case, text). The first case study will involve doing sentiment analysis with Python. The second case study will take us through basic text mining application using R. We wrap up the unit with a conclusion of what we did in this course and where to go next for further learning and exploration.",Social Media Data Analytics
https://www.classcentral.com/course/wharton-customer-analytics-4353,"Data about our browsing and buying patterns are everywhere.  From credit card transactions and online shopping carts, to customer loyalty programs and user-generated ratings/reviews, there is a staggering amount of data that can be used to describe our past buying behaviors, predict future ones, and prescribe new ways to influence future purchasing decisions. In this course, four of Wharton’s top marketing professors will provide an overview of key areas of customer analytics: descriptive analytics, predictive analytics, prescriptive analytics, and their application to real-world business practices including Amazon, Google, and Starbucks to name a few. This course provides an overview of the field of analytics so that you can make informed business decisions. It is an introduction to the theory of customer analytics, and is not intended to prepare learners to perform customer analytics. 

Course Learning Outcomes: 

After completing the course learners will be able to...

Describe the major methods of customer data collection used by companies and understand how this data can inform business decisions

Describe the main tools used to predict customer behavior and identify the appropriate uses for each tool 

Communicate key ideas about customer analytics and how the field informs business decisions

Communicate the history of customer analytics and latest best practices at top firms
      


          Introduction to Customer Analytics
    -What is Customer Analytics? How is this course structured? What will I learn in this course? What will I learn in the Business Analytics Specialization? These short videos will give you an overview of this course and the specialization; the substantive lectures begin in Week 2.

Descriptive Analytics
    -
In this module, you’ll learn what data can and can’t describe about customer behavior as well as the most effective methods for collecting data and deciding what it means.  You’ll understand the critical difference between data which describes a causal relationship and data which describes a correlative one as you explore the synergy between data and decisions, including the principles for systematically collecting and interpreting data to make better business decisions. You’ll also learn how data is used to explore a problem or question, and how to use that data to create products, marketing campaigns, and other strategies. By the end of this module, you’ll have a solid understanding of effective data collection and interpretation so that you can use the right data to make the right decision for your company or business.


Predictive Analytics
    -Once you’ve collected and interpreted data, what do you do with it? In this module, you’ll learn how to take the next step: how to use data about actions in the past to make to make predictions about actions in the future. You’ll examine the main tools used to predict behavior, and learn how to determine which tool is right for which decision purposes. Additionally, you’ll learn the language and the frameworks for making predictions of future behavior. At the end of this module, you’ll be able to determine what kinds of predictions you can make to create future strategies, understand the most powerful techniques for predictive models including regression analysis, and be prepared to take  full advantage of analytics to create effective data-driven business decisions.

Prescriptive Analytics
    -How do you turn data into action? In this module, you’ll learn how prescriptive analytics provide recommendations for actions you can take to achieve your business goals. First, you’ll explore how to ask the right questions, how to define your objectives, and how to optimize for success. You’ll also examine critical examples of prescriptive models, including how quantity is impacted by price, how to maximize revenue, how to maximize profits, and how to best use online advertising. By the end of this module, you’ll be able to define a problem, define a good objective, and explore models for optimization which take competition into account, so that you can write prescriptions for data-driven actions that create success for your company or business.

Application/Case Studies
    -How do top firms put data to work? In this module, you’ll learn how successful businesses use data to create cutting-edge, customer-focused marketing practices. You’ll explore real-world examples of the five-pronged attack to apply customer analytics to marketing, starting with data collection and data exploration, moving toward building predictive models and optimization, and continuing all the way to data-driven decisions. At the end of this module, you’ll know the best way to put data to work in your own company or business, based on the most innovative and effective data-driven practices of today’s top firms.",Customer Analytics
https://www.classcentral.com/course/edx-democracy-and-development-perspectives-from-africa-8810,"On a continent once dominated by closed political systems, democratic political institutions have taken root in more than a dozen African countries over the past 20 years. In this course, you’ll learn about this remarkable experiment, and try to better understand both the opportunities and the challenges of democratic governance.
We have interviewed more than 50 African academics, politicians, leaders, and students about how democracy works, and in this course, we provide opportunities to learn from these various African experts.
Each week, MIT Professor Evan Lieberman will introduce key topics in the study of democratic development in Africa, and highlight key ideas and insights from various African colleagues. Students will gain a solid introduction to African political development using analytical tools from the social sciences.
The course is for anyone interested in gaining a better understanding of African politics; learning about relationship between democratic politics and the attainment of improved human development; and/or obtaining an introduction to political science approaches to these topics.



Week 1: Introduction
Week 2: From Difficult Legacies to Democratization
Discussion of how historical legacies of slavery and colonial rule affected trajectories of African development, and the critical regime transitions to democracy in the late 20th century. We hear from leading scholars of African political development. 
Week 3: The African Citizenry: Diversity, Public Opinion and Civil Society
This module will focus on understanding the characteristics, wants, and needs of citizens living in contemporary African democracies. We learn about the role of different cleavages such as ethnicity and gender. Researchers from the Afrobarometer project discuss a key tool for measuring public opinion. 
Week 4: Understanding the Rules of the Game: Institutions in African Democracies
This module will discuss some of the key challenges of democratic rule and explores a range of institutional solutions. We look at the tradeoffs associated with these options and how they play themselves out in various African settings. Political insiders describe how these systems work. 
Week 5: Accountability and Service Delivery
In this module, we discuss the various channels through which citizens hold politicians accountable, and investigate the relationship between democratic politics and the actual attainment of government-provided goods and services. We highlight some frequent bottlenecks as well as examples in which democratic pressures have advanced key development policies. We speak with leading NGO representatives and leading scholars of African accountability. 
Week 6: The Expanding Role of Human Rights and the Judiciary
This module explores the expanding role of courts and the increasing use of human rights appeals in various African countries. We focus on reflections from a High Court Judge in Kenya, and attorneys from a leading human rights law firm in South Africa 
Week 7: Digital Democracy
This module explores the ways in which new technologies, especially new media, are transforming the ways in which citizens obtain access to information, mobilize, and apply pressure to governments. While new technologies offer exciting opportunities, we also highlight substantial challenges. We gain firsthand insights from leading scholars and actors in the African digital space.",Democracy and Development: Perspectives from Africa
https://www.classcentral.com/course/wharton-operations-analytics-4204,"This course is designed to impact the way you think about transforming data into better decisions. Recent extraordinary improvements in data-collecting technologies have changed the way firms make informed and effective business decisions. The course on operations analytics, taught by three of Wharton’s leading experts, focuses on how the data can be used to profitably match supply with demand in various business settings. In this course, you will learn how to model future demand uncertainties, how to predict the outcomes of competing policy choices and how to choose the best course of action in the face of risk. The course will introduce frameworks and ideas that provide insights into a spectrum of real-world business challenges, will teach you methods and software available for tackling these challenges quantitatively as well as the issues involved in gathering the relevant data.

This course is appropriate for beginners and business professionals with no prior analytics experience.
      


          Introduction, Descriptive and Predictive Analytics
    -In this module you’ll be introduced to the Newsvendor problem, a fundamental operations problem of matching supply with demand in uncertain settings. You'll also cover the foundations of descriptive analytics for operations, learning how to use historical demand data to build forecasts for future demand.  Over the week, you’ll be introduced to underlying analytic concepts, such as random variables, descriptive statistics, common forecasting tools, and measures for judging the quality of  your forecasts.

Prescriptive Analytics, Low Uncertainty
    -In this module, you'll learn how to identify the best decisions in settings with low uncertainty by building optimization models and applying them to specific business challenges. During the week, you’ll use algebraic formulations to concisely express optimization problems, look at how algebraic models should be converted into a spreadsheet format, and learn how to use spreadsheet Solvers as tools for identifying the best course of action. 

Predictive Analytics, Risk
    -How can you evaluate and compare decisions when their impact is uncertain? In this module you will learn how to build and interpret simulation models that can help you to evaluate complex business decisions in uncertain settings. During the week, you will be introduced to some common measures of risk and reward, you’ll use simulation to estimate these quantities, and you’ll learn how to interpret and visualize your simulation results.

Prescriptive Analytics, High Uncertainty 
    -This module introduces decision trees, a useful tool for evaluating decisions made under uncertainty. Using a concrete example, you'll learn how optimization, simulation, and decision trees can be used together to solve more complex business problems with high degrees of uncertainty. You'll also discover how the Newsvendor problem introduced in Week 1 can be solved with the simulation and optimization framework introduced in Weeks 2 and 3.",Operations Analytics
https://www.classcentral.com/course/data-results-5028,"Important note: The second assignment in this course covers the topic of Graph Analysis in the Cloud, in which you will use Elastic MapReduce and the Pig language to perform graph analysis over a moderately large dataset, about 600GB. In order to complete this assignment, you will need to make use of Amazon Web Services (AWS). Amazon has generously offered to provide up to $50 in free AWS credit to each learner in this course to allow you to complete the assignment. Further details regarding the process of receiving this credit are available in the welcome message for the course, as well as in the assignment itself. Please note that Amazon, University of Washington, and Coursera cannot reimburse you for any charges if you exhaust your credit.

While we believe that this assignment contributes an excellent learning experience in this course, we understand that some learners may be unable or unwilling to use AWS. We are unable to issue Course Certificates for learners who do not complete the assignment that requires use of AWS. As such, you should not pay for a Course Certificate in Communicating Data Results if you are unable or unwilling to use AWS, as you will not be able to successfully complete the course without doing so.

Making predictions is not enough!  Effective data scientists know how to explain and interpret their results, and communicate findings accurately to stakeholders to inform business decisions.  Visualization is the field of research in computer science that studies effective communication of quantitative results by linking perception, cognition, and algorithms to exploit the enormous bandwidth of the human visual cortex.  In this course you will learn to recognize, design, and use effective visualizations.

Just because you can make a prediction and convince others to act on it doesn’t mean you should.  In this course you will explore the ethical considerations around big data and how these considerations are beginning to influence policy and practice.   You will learn the foundational limitations of using technology to protect privacy and the codes of conduct emerging to guide the behavior of data scientists.  You will also learn the importance of reproducibility in data science and how the commercial cloud can help support reproducible research even for experiments involving massive datasets, complex computational infrastructures, or both.

Learning Goals: After completing this course, you will be able to:
1. Design and critique visualizations
2. Explain the state-of-the-art in privacy, ethics, governance around big data and data science
3. Use cloud computing to analyze large datasets in a reproducible way.
      


            Read more
          



          Visualization
    -Statistical inferences from large, heterogeneous, and noisy datasets are useless if you can't communicate them to your colleagues, your customers, your management and other stakeholders.  Learn the fundamental concepts behind information visualization, an increasingly critical field of research and increasingly important skillset for data scientists.  This module is taught by Cecilia Aragon, faculty in the Human Centered Design and Engineering Department.

Privacy and Ethics
    -Big Data has become closely linked to issues of privacy and ethics: As the limits on what we *can* do with data continue to evaporate, the question of what we *should* do with data becomes paramount.  Motivated in the context of case studies, you will learn the core principles of codes of conduct for data science and statistical analysis.  You will learn the limits of current theory on protecting privacy while still permitting useful statistical analysis. 

Reproducibility and Cloud Computing
    -Science is facing a credibility crisis due to unreliable reproducibility, and as research becomes increasingly computational, the problem seems to be paradoxically getting worse.  But reproducibility is not just for academics: Data scientists who cannot share, explain, and defend their methods for others to build on are dangerous.  In this module, you will explore the importance of reproducible research and how cloud computing is offering new mechanisms for sharing code, data, environments, and even costs that are critical for practical reproducibility.",Communicating Data Science Results
https://www.classcentral.com/course/introduction-to-calculus-12547,"The focus and themes of the Introduction to Calculus course address the most important foundations for applications of mathematics in science, engineering and commerce. The course emphasises the key ideas and historical motivation for calculus, while at the same time striking a balance between theory and application, leading to a mastery of key threshold concepts in foundational mathematics. 

Students taking Introduction to Calculus will: 
•	gain familiarity with key ideas of precalculus, including the manipulation of equations and elementary functions (first two weeks), 
•	develop fluency with the preliminary methodology of tangents and limits, and the definition of a derivative (third week),
•	develop and practice methods of differential calculus with applications (fourth week),
•	develop and practice methods of the integral calculus (fifth week).
      


          Precalculus (Setting the scene)
    -This module begins by looking at the different kinds of numbers that fall on the real number line, decimal expansions and approximations, then continues with an exploration of manipulation of equations and inequalities, of sign diagrams and the use of the Cartesian plane.

Functions (Useful and important repertoire)
    -This module introduces the notion of a function which captures precisely ways in which different quantities or measurements are linked together.  The module covers quadratic, cubic and general power and polynomial functions; exponential and logarithmic functions; and trigonometric functions related to the mathematics of periodic behaviour.  We create new functions using composition and inversion and look at how to move backwards and forwards between quantities algebraically, as well as visually, with transformations in the xy-plane.

Introducing the differential calculus
    -This module introduces techniques of differential calculus. We look at average rates of change which become instantaneous, as time intervals become vanishingly small, leading to the notion of a derivative. We then explore techniques involving differentials that exploit tangent lines. The module introduces Leibniz notation and shows how to use it to get information easily about the derivative of a function and how to apply it.

Properties and applications of the derivative
    -This module continues the development of differential calculus by introducing the first and second derivatives of a function.  We use sign diagrams of the first and second derivatives and from this, develop a systematic protocol for curve sketching. The module also introduces rules for finding derivatives of complicated functions built from simpler functions, using the Chain Rule, the Product Rule, and the Quotient Rule, and how to exploit information about the derivative to solve difficult optimisation problems.

Introducing the integral calculus
    -This fifth and final module introduces integral calculus, looking at the slopes of tangent lines and areas under curves.  This leads to the Fundamental Theorem of Calculus. We explore the use of areas under velocity curves to estimate displacement, using averages of lower and upper rectangular approximations. We then look at limits of approximations, to discover the formula for the area of a circle and the area under a parabola.  We then develop methods for capturing precisely areas under curves, using Riemann sums and the definite integral. The module then introduces indefinite integrals and the method of integration by substitution. Finally, we discuss properties of odd and even functions, related to rotational and reflectional symmetry, and the logistic function, which modifies exponential growth.",Introduction to Calculus
https://www.classcentral.com/course/aging-research-cannabis-cbd-thc-13818,"This Healthy Aging and Future of Cannabis Research course is designed to have you think critically about the health effects of cannabis (i.e., marijuana) in the context of inflammation, exercise, and aging. You'll learn how inflammation and the microbiome may be related to the disorders discussed in class, and how cannabis may influence these disorder through modulating inflammation. We'll describe the relationship between the endocannabinoid system and exercise, and how cannabinoids may affect exercise performance and recovery. You'll learn how to identify key features of aging and how cannabinoids may influence the aging process. Obtaining this knowledge will be helpful in terms of informing public policy, public health, and personal decisions regarding the use of cannabis products.
      


          Inflammation and the Microbiome
    -In this module, we will discuss how our gut microbiome and endocannabinoid system influences inflammatory disease states. We will also discuss how the gut and brain communicate and regulate inflammatory states through what is known as the ""gut-brain axis.""

Sports, Exercise, Recovery, and Cannabis
    -In this module, we will discuss the role of endocannabinoids in exercise, and how cannabis may impact exercise. We will also discuss the importance of exercise recovery, and how cannabis may impact recovery. 

Healthy Aging and Cannabis
    -In this module, we will discuss the common challenges older adults face while aging such as pain and depression, as well as common treatments used for these conditions tailored to this population. We will also discuss the research on cannabis for these conditions, and discuss the specific risks that this population faces with regards to cannabis use. 

The Future of Cannabis Research
    -In this module, we will do a quick overview of the main takeaways from this series of courses regarding the risks and benefits of cannabis use. We will discuss the controversies around using cannabis as a therapeutic and consider how cannabis could be used as an alternative medicine. We will discuss lingering questions and gaps in the literature and research that need to be filled. Lastly, we will discuss the Citizen's Science Initiative - a crowdsourcing data science project with the purpose of collecting much needed and relevant data on the health effects of cannabis for specific clinical populations.",Healthy Aging and the Future of Cannabis Research
https://www.classcentral.com/course/statistics-project-6100,"The capstone project will be an analysis using R that answers a specific scientific/business question provided by the course team. A large and complex dataset will be provided to learners and the analysis will require the application of a variety of methods and techniques introduced in the previous courses, including exploratory data analysis through data visualization and numerical summaries, statistical inference, and modeling as well as interpretations of these results in the context of the data and the research question. The analysis will implement both frequentist and Bayesian techniques and discuss in context of the data how these two approaches are similar and different, and what these differences mean for conclusions that can be drawn from the data.

A sampling of the final projects will be featured on the Duke Statistical Science department website.

Note: Only learners who have passed the four previous courses in the specialization are eligible to take the Capstone.
      


          About the Capstone Project
    -Welcome to the capstone project! This week's content is an introduction to the project assignment and goals. The readings in this week will introduce the data set that you will be analyzing for your project and the specific questions you will answer using data analysis techniques we learned in the previous courses. It is important to understand what we will be doing in the course before jumping into the detailed analysis. So we encourage you to start with the first lecture to get the big picture, and then delve into the specifics of the analysis. Enjoy, and good luck! Remember, if you have questions, you can post them on the discussion forums.

Exploratory Data Analysis (EDA)
    -This week you will work on conducting an exploratory analysis of the housing data. Exploratory analysis is an essential first step for familiarizing yourself with and understanding the data. 

In this week, you will complete a quiz which will guide you through certain important aspects of the data. The insights you gain through this assignment will help inform modeling in the future quizzes and peer assessments. 

Feel free to post questions about this assignment on the discussion forum. 

EDA and Basic Model Selection - Submission
    -This week we will dig deeper into our exploratory data analysis of the data. We now have all the information and data necessary to perform a deep dive into the EDA and it is time start your initial analysis report! We encourage you to start your analysis report (presented in peer-review format next week) early so you will have enough time to complete it. You will conduct exploratory data analysis, model selection, and model evaluation, and then complete a written report which answers several questions which will guide you through the process. This report will be your first peer-review assignment in this course. 

EDA and Basic Model Selection - Evaluation
    -Great work so far! We hope you will also learn as much from evaluating your peers' work as completing your own assignment. Happy learning!

Model Selection and Diagnostics
    -We are half way through the course! In this week, you will continue model selection and model diagnostics, which will serve a starting point for your final project. You will be assessed on your work through a quiz. If you have any questions so far, don't hesitate to post on the forum so that others can help and discuss the question together.

Out of Sample Prediction
    -In this week, you will gain experience using your model to perform out-of-sample prediction and validation.  The skills honed this week will guide you through your final analysis in the weeks to come.  Please feel free to go back to prior weeks and review the necessary background knowledge. 

Final Data Analysis - Submission
    -In the next two weeks, you will complete your final data analysis project. You will submit your answers using the Final Data Analysis peer review assignment link in Week 8.

Final Data Analysis - Evaluation
    -Congratulations on making through to the final week of the course! In this week, we will finish this data analysis project by completing the evaluation of three of your peers' assignments.",Statistics with R Capstone
https://www.classcentral.com/course/swayam-discrete-mathematics-12929,"The course will be an introduction to Discrete Mathematics which comprises of the essentials for a computer science student to go ahead and study any other topics in  the subject. The emphasis will be on problem solving as well as proofs. We will be providing motivational illustrations and applications through out the course. The course doesnt assume any pre-requisites except for high school level arithmetic and algebra.



Week 1  : CountingWeek 2  : Set TheoryWeek 3  : LogicWeek 4  : RelationsWeek 5  : FunctionsWeek 6  : Mathematical InductionWeek 7  : Pigeonhole PrincipleWeek 8  : Graph Theory - 01
Week 9  :  Graph Theory - 02Week 10  : Generating FunctionsWeek 11  : Principle of Inclusion-ExclusionWeek 12  :  Recurrence Relations",Discrete Mathematics
https://www.classcentral.com/course/food-fraud-4048,"##
The food industry is one of the most important commercial sectors in the world. Everyone uses it, but how many people abuse it? As we witness the increasing globalisation of the supply chain, a growing challenge is verifying the questionable identity of raw materials in the food we eat.
In this course we will look at topical issues concerning ‘food fraud’ and explore ways in which analytical chemistry can help in its identification and prevention. We’ll share fascinating examples, such as the history of white bread and a surprising ingredient once found in bitter beer.
The University of East Anglia has joined forces with the world-renowned Institute of Food Research (IFR) to bring you this unique course. You’ll be led by Kate Kemsley, a specialist in the use of advanced instrumentation for measuring the chemical composition of food materials. Course content is linked with UEA’s MChem postgraduate programme, which supports final-year students’ practical research projects in this area of science.
Where could this course take me?
If you are planning to study Chemistry at college or university - this course will give you an essential overview of some instrumental techniques that you are likely to encounter. This includes exploration of infrared technology, NMR and mass spectrometry; important areas of Chemistry for A-Level students to grasp.
This course is also designed to support the professional development of those currently working in the food industry, who want to delve deeper into the methods analytical chemists take in the measurements of food materials and ingredients. It will act as the perfect refresher for your current knowledge base, as you can interact online with thousands of individuals working in the food sector today.
What and how will I learn?
You’ll acquire knowledge and understanding of infrared technology, NMR and mass spectrometry with practical examples linked to current standards and issues in the food sector. You will gain a global perspective of the value of chemistry in this area and learn from analytical chemists in action.
By enjoying a balance of theory and practical applications, students learn directly from academics at the University of East Anglia and scientists from the Institute of Food Research, with a brilliant chance to network throughout the duration of the course.
No formal qualifications, just an interest in food fraud and a basic understanding of chemistry.



            Read more",Identifying Food Fraud
https://www.classcentral.com/course/edx-data-science-linear-regression-10352,"Linear regression is commonly used to quantify the relationship between two or more variables. It is also used to adjust for confounding. This course, part ofourProfessional Certificate Program in Data Science, covers how to implement linear regression and adjust for confounding in practice using R. 
In data science applications, it is very common to be interested in the relationship between two or more variables. The motivating case study we examine in this course relates to the data-driven approach used to construct baseball teams described in Moneyball. We will try to determine which measured outcomes best predict baseball runs by using linear regression. 
We will also examine confounding, where extraneous variables affect the relationship between two or more other variables, leading to spurious associations. Linear regression is a powerful technique for removing confounders, but it is not a magical process. It is essential to understand when it is appropriate to use, and this course will teach you when to apply this technique.",Data Science: Linear Regression
https://www.classcentral.com/course/meaningful-marketing-insights-6913,"With marketers are poised to be the largest users of data within the organization, there is a need to make sense of the variety of consumer data that the organization collects. Surveys, transaction histories and billing records can all provide insight into consumers’ future behavior, provided that they are interpreted correctly. In Introduction to Marketing Analytics, we introduce the tools that learners will need to convert raw data into marketing insights. The included exercises are conducted using Microsoft Excel, ensuring that learners will have the tools they need to extract information from the data available to them. The course provides learners with exposure to essential tools including exploratory data analysis, as well as regression methods that can be used to investigate the impact of marketing activity on aggregate data (e.g., sales) and on individual-level choice data (e.g., brand choices). 

To successfully complete the assignments in this course, you will require Microsoft Excel. If you do not have Excel, you can download a free 30-day trial here: https://products.office.com/en-us/try
      


          Meet Dr. Schweidel & Course Overview
    -In this module, students will be introduced to the instructor, Dr. David Schweidel and get and overview of the course. 

Exploring your Data with Visualization and Descriptive Statistics, Part 1
    -Modules 2 and 3 focus on identifying appropriate descriptive statistics (measures of central tendency and dispersion) for different types of data, as well as recoding data using reference commands to prepare it for analysis. Additionally, you will manipulate and summarize data using pivot tables in Excel, produce visualizations that are appropriate based on the type of data being analyzed, and interpret statistics and visualizations to draw conclusions to address relevant marketing questions.

Exploring your Data with Visualization and Descriptive Statistics, Part 2
    -Modules 2 and 3 focus on identifying appropriate descriptive statistics (measures of central tendency and dispersion) for different types of data, as well as recoding data using reference commands to prepare it for analysis. Additionally, you will manipulate and summarize data using pivot tables in Excel, produce visualizations that are appropriate based on the type of data being analyzed, and interpret statistics and visualizations to draw conclusions to address relevant marketing questions.

Regression Analysis for Marketing Data
    -In this module, you will be asked to determine the appropriate type of regression for different types of marketing data and will perform regression analysis to assess the impact of marketing actions on outcomes of interest, such as sales, traffic, and brand choices. You will also be asked to interpret regression output to understand overall model performance and importance of different predictors, as well as make predictions using the appropriate regression model.

From Analysis to Action
    -This final module will connect the results of regression analysis to marketing decisions. You will learn to build tools that allow users to evaluate outcomes based on different marketing decisions, as well as characterize the extent of uncertainty in outcomes based on the selected marketing decisions.",Meaningful Marketing Insights
https://www.classcentral.com/course/amnhearth-863,"The AMNH course The Dynamic Earth: A Course for Educators provides students with an overview of the origin and evolution of the Earth. Informed by the recently released Next Generation Science Standards, this course examines geological time scales, radiometric dating, and how scientists “read the rocks.” We will explore dramatic changes in the Earth over the last 4 billion years, including how the evolution of life on Earth has affected its atmosphere. In addition to looking at geology on a global scale, participants will take to their own backyards to explore and share their local geologic history. Course participants will bring their understanding of the dynamic Earth - along with content resources, discussion questions, and assignments - into their own teaching.
      


          Introduction & The Mystery of Geologic Time
    -You will explore the ways scientists study the rock record to determine the geologic history of the Earth. 

Evolution of the Atmosphere
    -You will learn how the evolution of photosynthetic life changed the concentration of oxygen in the oceans and atmosphere, and how this is reflected in the rock record. You will also become familiar with how the Next Generation Science Standards connect to this week’s content. Finally, you will complete a written assignment: an analysis of a local geologic feature.

Plate Tectonics: Mountain Building
    -You will learn how convection causes solid rock to flow in the Earth’s mantle and how the movement of the Earth’s tectonic plates forms mountains. You will also learn how to identify and address common student misconceptions about plate tectonics.


Plate Tectonics: Earthquakes
    -You will learn about earthquake risk. Using a multimedia teaching case about earthquake risk in Bangladesh, you will learn how scientists define and assess the risk from geologic events. You will also learn how to implement this or similar teaching cases with your students.",The Dynamic Earth: A Course for Educators
https://www.classcentral.com/course/python-analysis-9551,"This course will continue the introduction to Python programming that started with Python Programming Essentials and Python Data Representations.  We'll learn about reading, storing, and processing tabular data, which are common tasks.  We will also teach you about CSV files and Python's support for reading and writing them.  CSV files are a generic, plain text file format that allows you to exchange tabular data between different programs. These concepts and skills will help you to further extend your Python programming knowledge and allow you to process more complex data.

By the end of the course, you will be comfortable working with tabular data in Python. This will extend your Python programming expertise, enabling you to write a wider range of scripts using Python.

This course uses Python 3.  While most Python programs continue to use Python 2, Python 3 is the future of the Python programming language. This course uses basic desktop Python development environments, allowing you to run Python programs directly on your computer.
      


          Dictionaries
    -This module will teach you about Python's dictionary data type and its capabilities.  Dictionaries are used to map keys to values within programs.

Tabular Data and Nested Data Structures
    -This module will teach you about storing tabular data within Python programs using lists and dictionaries.

Tabular Data and CSV Files
    -This module will teach you the basics of CSV files and how to read them from Python programs. We will discuss the use of Python's csv module to help you access tabular data in CSV files.

Organizing Data
    -This module will teach you how to sort data in Python. You will organize and analyze tabular data.",Python Data Analysis
https://www.classcentral.com/course/web-science-1262,"##
You may already be an avid user of the Web, but this introduction to Web Science will help you better understand it as both a social and technical system - a global information infrastructure, built from the interactions of people and technologies.
This free online course is based on our experience of trying to understand how the Web has grown and changed through technical innovation, economics, politics and everyday use.
Explore the past and future of the Web
In Week 1, we’ll ask what would happen if the Web was switched off right now. We’ll use this question to explore the history of the Internet and find out why we’re so dependent on it today. You’ll have the opportunity to contribute to the course, by telling us how you use the Web in your part of the world.
In Week 2, we’ll look to the future, finding out how emerging trends – including big data, the semantic web and the Internet of Things – will change both the infrastructure of the Web and the ways in which we use it.
By following this course, you will have a greater understanding of the Web and begin to develop skills for the digital era – skills that are useful for everyday life and widely sought by the technology-driven employers of today.
Learn with well-known experts in Web Science
You’ll learn with well-known experts from the University of Southampton’s Web Science Institute, including lead educators, Professors Leslie Carr and Susan Halford, and contributors, Professors Dame Wendy Hall and Sir Nigel Shadbolt.
They will provide you with an understanding of the way that the technology of the Web interacts with our economy, society and culture. Other University of Southampton Web Science courses are an Introduction to Linked Data and the Semantic Web and The Power of Social Media.
Sarah - a previous learners on the course - enjoyed it so much, that she’s gone on to take a PhD in Web Science with the University of Southampton. “I was just absolutely fascinated by everything in the course,” she says. Read Sarah’s story.
This course is aimed at anyone who wishes to further their understanding of the way that the technology of the Web interacts with our economy, society and culture.



            Read more",Web Science: How the Web Is Changing the World
https://www.classcentral.com/course/edx-introduction-to-data-structures-7391,"Well organised data structures allow for quick and efficient retrieval of information and are essential for modern computing. Organised data can be easily sorted, ordered, and searched to retrieve information that meets certain requirements.
In Introduction to Data Structures, you’ll learn the fundamentals of creating data structures, and gain exposure to coding and visualising data structures. You’ll explore the importance and impact of well organised data.
You’ll learn how to build a program from small pieces and understand why organisational approaches make such a difference to some very common approaches to solutions.
The course identifies the most important and useful data structures in use in modern programming and each will be presented with exercises for building, visualising, and manipulating that structure. Each exercise embeds a simple and intuitive application for the particular organisation of data that we present. Through the course you will be given a concrete understanding of data structures by writing your own programs to interact with the data structures.
You’ll get the most from this course if you have some understanding of simple programming, and the Foundation week of the course will allow you to test the level of knowledge you require. Learners that have completed the Think. Create. Code. course will have sufficient coding skills to take this course.",Introduction to Data Structures
https://www.classcentral.com/course/studying-cities-social-science-methods-f-13837,"Welcome!

Are you looking to learn more about how to conduct scientific research, specifically in an urban or local context? Then you have found the right course: Studying Cities: Social Science Methods for Urban Research by the Institute for Housing and Urban Development Studies (IHS), Erasmus University Rotterdam. During the course you will gain more insight in the different steps of the research cycle, and build a firm foundation for your own future research endeavors.

Before any (urban) researcher may start conducting research, it is crucial to understand the different aspects and elements of doing research. The course will guide you through the various steps of the research cycle to provide you with the basic knowledge necessary for any Master-level program, but with a special focus on urban and local development. The course starts with introductory lectures on the problem statement, research objective, empirical cycle and the research question. Over the following weeks you will also learn the components and criteria of the theoretical framework and operationalization, research strategies, and the collection and analysis of quantitative and qualitative data. You will be provided with the necessary tools to understand and evaluate these key steps in scientific research by watching video lectures with in-video questions and by completing the final peer review, which will use all the elements you have learnt throughout the course.
      


          Research Topic
    -By studying this week’s materials and by answering the related questions and quiz, you will gain a deeper understanding of the need and the criteria for a problem statement, the main components of the research design and how to formulate a good research question. You will learn the different aspects in order to understand these primary steps in conducting research, and be given the tools to evaluate the quality of research questions according to the criteria. 

Theoretical Framework and Operationalization
    -By studying this week’s materials and by answering the related questions and quiz, you will gain more insight in how operationalization transitions theory to empirical research. You will learn how an empirical researcher creates the transformation from the research question to the conceptual framework, and from the complex concepts of this framework to measurable (unambiguous) indicators. You will also become aware of the most common mistakes inexperienced researchers make in the operationalization.

Research Strategies
    -By studying this week’s materials and by answering the related questions and quiz, you will gain more knowledge about the possible strategies or approaches in empirical research. The research strategy of any research should be a coherent body of decisions concerning the way in which the researcher is going to carry out the research in order to obtain valid answers to the research questions. The main strategies in social science research will be discussed during this week’s lectures, namely the survey, quasi-experiment, case study and desk research (working with existing large data sets). You will gain basic knowledge on these 4 strategies, and how they link to research questions. By the end of the week you will understand the importance of choosing appropriate methods and techniques in relation to a research question. 

Quantitative and Qualitative Data
    -By studying this week’s materials and by answering the related questions and quiz, you will gain knowledge on the basics of collecting data. The video lectures will teach you how to deal with primary quantitative data collection (survey) and secondary quantitative data collection (existing large data sets). We’ll continue the week with qualitative data collection, both primary (interviews) and secondary (from existing literature). Therefore you will gain a basic understanding of the data collection for each of the research strategies treated last week.

Quantitative and Qualitative Analysis
    -By studying this week’s materials and by answering the related questions and quiz, you will gain insight in the analysis of the different types of data. From the point of data collection last week, it is important to understand the various ways to analysis the data. During this week you collect the essential knowledge on data collection that any academic researcher needs. Links to other MOOCs will be shared that can be used to broader your knowledge on specific statistics. The week concludes with the final test, encompassing all you have learned during the course. By passing this final test, you will pass the course.",Studying Cities: Social Science Methods for Urban Research
https://www.classcentral.com/course/networksonline-744,"Learn how to model social and economic networks and their impact on human behavior.  How do networks form, why do they exhibit certain patterns, and how does their structure impact diffusion, learning, and other behaviors?   We will bring together models and techniques from economics, sociology, math, physics, statistics and computer science to answer these questions.

The course begins with some empirical background on social and economic networks, and an overview of concepts used to describe and measure networks. Next, we will cover a set of models of how networks form, including random network models as well as strategic formation models, and some hybrids. We will then discuss a series of models of how networks impact behavior, including contagion, diffusion, learning, and peer influences.

You can find a more detailed syllabus here:  http://web.stanford.edu/~jacksonm/Networks-Online-Syllabus.pdf 

You can find a short introductory videao here: http://web.stanford.edu/~jacksonm/Intro_Networks.mp4
      


          Introduction, Empirical Background and Definitions  
    -Examples of Social Networks and their Impact, Definitions, Measures and Properties: Degrees, Diameters, Small Worlds, Weak and Strong Ties, Degree Distributions

Background, Definitions, and Measures Continued
    -Homophily, Dynamics, Centrality Measures: Degree, Betweenness, Closeness, Eigenvector, and Katz-Bonacich. Erdos and Renyi Random Networks: Thresholds and Phase Transitions

Random Networks
    -Poisson Random Networks, Exponential Random Graph Models, Growing Random Networks, Preferential Attachment and Power Laws, Hybrid models of Network Formation.

Strategic Network Formation
    -Game Theoretic Modeling of Network Formation, The Connections Model, The Conflict between Incentives and Efficiency, Dynamics, Directed Networks, Hybrid Models of Choice and Chance.

Diffusion on Networks
    -Empirical Background, The Bass Model, Random Network Models of Contagion, The SIS model, Fitting a Simulated Model to Data.

Learning on Networks
    -Bayesian Learning on Networks, The DeGroot Model of Learning on a Network, Convergence of Beliefs, The Wisdom of Crowds, How Influence depends on Network Position..

Games on Networks
    -Network Games, Peer Influences: Strategic Complements and Substitutes, the Relation between Network Structure and Behavior, A Linear Quadratic Game, Repeated Interactions and Network Structures.

Final Exam
    -The description goes here",Social and Economic Networks:  Models and Analysis
https://www.classcentral.com/course/spark-sql-17045,"This course is for students with SQL experience and now want to take the next step in gaining familiarity with distributed computing using Spark. Students will gain an understanding of when to use Spark and how Spark as an engine uniquely combines Data and AI technologies at scale. The four modules build on one another and by the end of the course the student will understand: Spark architecture, Spark DataFrame, optimizing reading/writing data, and how to build a machine learning model. The first module will introduce Spark, including how Spark works with distributed computing and what are Spark Dataframes. Module 2 covers the core concepts of Spark such as storage vs. computing, caching, partitions and Spark UI. The third module looks at Engineering Data Pipelines covering connecting to databases, schemas and type, file formats and writing good data. The final module looks at the application of Spark with Machine Learning through the business use case, a short introduction to what machine learning is, building and applying models and a final course conclusion. By understanding when to use Spark, either scaling out when the model or data is too large to process on a single machine, or having a need to simply speed up to get faster results, students will hone their SQL skills and become a more adept Data Scientist.
      


          Introduction to Spark
    -In this module, you will be able to discuss the core concepts of distributed computing and be able to recognize when and where to apply them. You'll be able to identify the basic data structure of Apache Spark™, known as a DataFrame. You will be able to use the collaborative Databricks workspace and write SQL code that executes against a cluster of machines.

Spark Core Concepts
    -In this module, you will be able to explain the core concepts of Spark, and increase query performance by caching your data and modifying Spark configurations. You will also be able to use the Spark UI to analyze performance and identify bottlenecks.

Engineering Data Pipelines
    -In this module, you will be able to identify and discuss the general demands of data applications. You'll be able to access data in a variety of formats and compare and contrast the tradeoffs between these formats. You will explore and examine semi-structured JSON data, which is common in big data environments, schemas, and parallel data writes. You will be able to create an end-to-end pipeline that reads data, transforms it, and saves the result.

Machine Learning Applications of Spark
    -In this module, you will be able to define the basics of machine learning and identify the difference between regression and classification problems. You will build a linear regression model and use it to make predictions using Spark SQL. You will also be able to describe how machine learning fits in with concepts you learned in this course and from the other courses in this series. And lastly, you will be able to explain how a machine learning model is trained.",Distributed Computing with Spark SQL
https://www.classcentral.com/course/edx-statistics-unlocking-the-world-of-data-7508,"Data is everywhere, from the media to the health sciences, and from financial forecasting to engineering design. It drives our decisions, and shapes our views and beliefs. But how can we make sense of it?
This course introduces some of the key ideas and concepts of statistics, the discipline that allows us to analyse and interpret the data that underpins modern society.
In this course, you will explore the key principles of statistics for yourself, using interactive applets, and you will learn to interpret and evaluate the data you encounter in everyday life.
No previous knowledge of statistics is required, although familiarity with secondary school mathematics is advisable.
Logo image: (C) The University of Edinburgh 2016 CC BY, derived from Waverley Bridge, by Manuel Farnlack on Flickr, 2010 CC BY



Week 1: Introducing Data
What is statistics? We begin the course with this question, and see how data lies at the heart of statistics. We look at common techniques for presenting and summarising data. 
Week 2: Patterns in Data
We look further into the science of data analysis, focusing on finding and interpreting relationships between different data sets, and on using trends in data to make predictions. 
Week 3: Collecting Data
We look at key methods of data collection, seeing how we generally use samples of a population to make predictions about the whole population. We learn about how to choose a representative sample, and how to set up a statistical experiment. 
Week 4: Uncertainty in Data
Using samples to make predictions about a population brings uncertainty into our data. As the study of risk and uncertainty, probability is therefore key to understanding statistics. We introduce the ideas here for describing and quantifying uncertainty via probabilities. 
Week 5: Distribution
We look again at probability and describe a range of common situations that lead to standard forms for describing the associated probability of different possible outcomes. The ability to describe such probabilities provides the basis for building up the knowledge and understanding needed to study deeper statistical methods. 
Week 6: Estimation
We will build on the idea of estimating properties of a population using sample data. Further, as the answer that we provide is only an estimate of the (unknown) true value, we will also describe how we may construct an associated uncertainty interval for the parameter being estimated, using properties of the sampling distribution. 
We introduce the testing method that is fundamental to all of science: the hypothesis test. We learn how to set up and perform a hypothesis test, and look at how such tests are used in scientific research. 
Week 7: Statistical Testing
We introduce the concepts of the testing method that is fundamental to all of science: the hypothesis test. We learn how to set up and perform simple hypothesis tests. 
Week 8: Further Statistical Testing
We build on the ideas of the hypothesis test and look at further tests that are commonly used in scientific research.",Statistics: Unlocking the World of Data
https://www.classcentral.com/course/edx-the-science-of-parenting-8936,"Everyone has an opinion on parenting – where babies should sleep, what they should eat, and whether parents should spank, scold, or praise. What’s more, the media often offers support for whichever opinions appear most popular at any given time. This leaves those of us who like to base our decisions on firm, provable facts feeling dizzy.“The Science of Parenting” addresses this confusion by moving beyond the chatter and opinion surrounding parenting, and by looking directly at the science. Parenting itself is far from a science. Nevertheless, scientists have conducted thousands of studies that can help parents – or future parents – make sensible, informed decisions. One goal of this course will be to provide a survey of important scientific findings spanning a range of topics that are central to the lives of parents: 

diet
sleep
discipline
learning
screen time
impulse control
vaccination 

We’ll also explore ongoing mysteries, like what causes autism, and why so many children are allergic to peanuts.Perhaps more important, this course will not only dig into existing science, but will also explore the underlying nature of parenting science itself. Often, scientists measure correlations: They ask how different parenting practices are related to different behaviors in children. But the claims they make from ' correlational data are often much, much stronger. For example, from correlational data, scientists often claim that parents cause the behaviors of their kids. This course will show how this type of error – common in the scientific literature – can explain a significant amount of the confusion present in the media and general public. We will discuss how to avoid the same error when evaluating science, and how to use the sum of available evidence to inform decision making.The course’s instructor, David Barner, is a leading authority on cognitive development. He is joined by leading experts on behavior genetics, vaccination, autism, lying, and spanking, as well as by real live parents who try to use science to inform their decisions. This class is suitable not only for parents, future parents, and grandparents, but also for professionals interested in health care, social work, and early childhood education who want to increase their knowledge and analysis skills.
      


            Read more
          




Week 1: The Nature vs. Nurture Debate; Adoption and Behavior Genetics
Week 2: Learning Language; Screen time; Preschool; Music
Week 3: Morality; Self Control; Family Structure
Week 4: Autism and Vaccination; Sleep; Diet & Breastfeeding
Week 5: Learning and School: The Achievement Gap; Learning Styles; Acceleration; Homeschooling",The Science of Parenting
https://www.classcentral.com/course/web-applications-php-9566,"In this course, you'll explore the basic structure of a web application, and how a web browser interacts with a web server. You'll be introduced to the request/response cycle, including GET/POST/Redirect. You'll also gain an introductory understanding of Hypertext Markup Language (HTML), as well as the basic syntax and data structures of the PHP language, variables, logic, iteration, arrays, error handling, and superglobal variables, among other elements. An introduction to Cascading Style Sheets (CSS) will allow you to style markup for webpages. Lastly, you'll gain the skills and knowledge to install and use an integrated PHP/MySQL environment like XAMPP or MAMP.
      


          Introduction to Dynamic Web Content
    -We look at the basic structure of a web application and how a web browser interacts with a web server. We explore the Request-Response Cycle that is the basis of the Hypertext Transfer Protocol (HTTP).

HyperText Markup Language (HTML)
    -We briefly cover the basics of the HyperText Markup Language (HTML) that is the markup for web pages.  We hope that you already have some expertise in HTML and that this is mostly review.

Cascading Style Sheets (CSS)
    -We briefly cover the basics of cascading Style Sheets (CSS) that allow us to style the markup for web pages.

Installing PHP and SQL
    -Our first technical task is to work through the installation steps including installing a text editor, installing MAMP or XAMPP (or equivalent), creating a MySql Database, and writing a PHP program.



Introduction to PHP
    -We begin learning PHP.

PHP Arrays
    -We look at unique aspects of arrays in the PHP language.


PHP Functions
    -We look at unique aspects of functions in PHP.

PHP and HTML Forms
    -We look at how HTML forms are created and processed in the PHP language.",Building Web Applications in PHP
https://www.classcentral.com/course/edx-data-science-visualization-10347,"As part of our Professional Certificate Program in Data Science, this course covers the basics of data visualization and exploratory data analysis. We will use three motivating examples and ggplot2, a data visualization package for the statistical programming language R. We will start with simple datasets and then graduate to case studies about world health, economics, and infectious disease trends in the United States. 
We'll also be looking at how mistakes, biases, systematic errors, and other unexpected problems often lead to data that should be handled with care. The fact that it can be difficult or impossible to notice a mistake within a dataset makes data visualization particularly important. 
The growing availability of informative datasets and software tools has led to increased reliance on data visualizations across many areas. Data visualization provides a powerful way to communicate data-driven findings, motivate analyses, and detect flaws. This course will give you the skills you need to leverage data to reveal valuable insights and advance your career.",Data Science: Visualization
https://www.classcentral.com/course/gis-applications-5586,"Welcome to the last course of the specialization (unless your continuing on to the capstone project, of course!). 
Using the knowledge you’ve learned about ArcGIS, complete technical tasks such raster calculations and suitability analysis. In this class you will become comfortable with spatial analysis and applications within GIS during four week-long modules:

Week 1: You'll learn all about remotely sensed and satellite imagery, and be introduced to the electromagnetic spectrum. At the end of this week, you'll be able to find and download satellite imagery online and use it for two common types of analysis: NDVI and trained classification.

Week 2: You'll learn how to use ModelBuilder to create large processing workflows that use parameters, preconditions, variables, and a new set of tools. We'll also explore a few topics that we don't really have time to discuss in detail, but might whet your appetite for future learning in other avenues: geocoding, time-enabled data, spatial statistics, and ArcGIS Pro.

Week 3: In week three, we'll make and use digital elevation models using some new, specific tools such as the cut fill tool, hillshades, viewsheds and more. We'll also go through a few common algorithms including a very important one: the suitability analysis.

Week 4: We'll begin the final week by talking about a few spatial analyst tools we haven't yet touched on in the specialization: Region Group to make our own zones, Focal Statistics to smooth a hillshade, Reclassify to change values, and Point Density to create a density surface. Finally, we'll wrap up by talking about a few more things that you might want to explore more as you start working on learning about GIS topics on your own.

Take Geospatial and Environmental Analysis as a standalone course or as part of the Geographic Information Systems (GIS) Specialization. You should have equivalent experience to completing the first, second, and third courses in this specialization, ""Fundamentals of GIS,"" ""GIS Data Formats, Design, and Quality"", and ""Geospatial and Environmental Analysis,"" respectively, before taking this course. By completing the fourth class you will gain the skills needed to succeed in the Specialization capstone.
      


            Read more
          



          Course Overview, Imagery, and Raster Calculator
    -In this module, we'll learn all about remote sensing and satellite imagery, starting out with an introduction to remotely sensed data and the electromagnetic spectrum before learning about satellite and aerial imagery capture and data products. You'll learn how to find and download satellite imagery online and how to use it in two different common types of analysis: NDVI and a trained classification. In the second lesson, you'll learn how to use some basic tools to support image analysis using Raster Calculator and Spatial Analyst.

ModelBuilder and Other Topics
    -In this module, we will learn about ModelBuilder, a drag and drop tool for automating, and reusing workflows in ArcGIS. We'll explore how models are constructed, build our own models, and undertake building a large processing workflow together in ModelBuilder that uses parameters, preconditions, variables, and a set of tools we haven't used before to work. In the second half of the module, we'll take a brief look at a few topics you should know about, but that we won't have time to explore in depth. You'll be introduced to geocoding, time enabled data, spatial statistics, and ArcGIS Pro. These are little teasers of potential capabilities you might want to explore more in the future on your own.

Digital Elevation Models and Common Algorithms
    -In this module, we'll be looking at DEMs and workflows. In the first half, we'll make and use a handful of products derived from digital elevation models, including contour lines, hillshades, viewsheds, and the cut fill tool. In the second half of the module, we'll go through a few common algorithms, starting with one of the most important ones to know: the suitability analysis. Then, we'll learn about the hydrologic processing you did in the tutorial assignment for the previous module and go through it step by step together.

Spatial Analyst and Where to Go from Here
    -In this module, we'll start by learning how to use a few different tools and concepts in Spatial Analyst that we haven't touched on before. We'll use Region Group to make our own zones, Focal Statistics to smooth a hillshade, Reclassify to change values, and Point Density to create a density surface. In the second half of the module, we'll give you some suggestions of directions for future learning by showing you all the things we *didn't* cover in this specialization, including web and mobile GIS applications, field data collection workflows, industry specific tools and workflows, spatial statistics, in-depth design and cartography, programming and GIS servers, and other GIS systems like QGIS and companion applications like Geospatial Modelling Environment. These can serve as seeds for your future GIS learning and careers!","Imagery, Automation, and Applications"
https://www.classcentral.com/course/edx-biochemistry-biomolecules-methods-and-mechanisms-12585,"Do you want to prepare for medical school, study a STEM field, become a research scientist, or transition to a career in the booming biotechnology industry? Or maybe you just want to understand the chemical reactions that govern life itself. Join Professor Yaffe, an MIT professor and practicing surgeon, as he guides you through the science that inspires countless doctors, researchers, and students alike.
We developed 7.05x Biochemistry with an emphasis on:

Developing your scientific thinking skills including articulating hypotheses, performing thought experiments, interpreting data, and designing experiments.
Using data based on real scientific experiments and highlighting the scientific process.
Asserting that biology is an active field that changes daily through examples of MIT (and other current) research, not static information in a textbook.
Visualizing real molecular structures with PyMOL to better understand function and mechanism.
Appreciating the quantitative aspects of biochemistry and practicing this quantitation with MATLAB.
Translating topics in biochemistry to diseases and medicine.
Conveying the authentic MIT firehose experience.
Implementing the science of learning in the course design.

We offer a thorough and robust means of certifying edX learners in their mastery of the MITx biochemistry content, through the MITx 7.05x Biochemistry Competency Exam. This challenging option is available only to those who register for the verified-certificate track, and successful completion of this exam is the majority of the assessment grade that counts toward a certificate. The Competency Exam will be open from June 23, 2020 to June 30, 2020.



            Read more
          



The course includes the following learning sequences: 

Introduction to Biochemistry; pH and Buffers
Amino Acids and Proteins
Protein Purification
Protein Structure
Protein Folding
Hemoglobin and Allostery
Hemoglobin and the Bohr Effect
Enzyme Chemistry
Enzyme as Catalysts
Enzyme Kinetics
Membranes, Channels, Transporters, and Pumps
Blood Clotting
Signal Transduction","Biochemistry: Biomolecules, Methods, and Mechanisms"
https://www.classcentral.com/course/python-representation-9550,"This course will continue the introduction to Python programming that started with Python Programming Essentials.  We'll learn about different data representations, including strings, lists, and tuples, that form the core of all Python programs.  We will also teach you how to access files, which will allow you to store and retrieve data within your programs. These concepts and skills will help you to manipulate data and write more complex Python programs.

By the end of the course, you will be able to write Python programs that can manipulate data stored in files.  This will extend your Python programming expertise, enabling you to write a wide range of scripts using Python

This course uses Python 3.  While most Python programs continue to use Python 2, Python 3 is the future of the Python programming language. This course introduces basic desktop Python development environments, allowing you to run Python programs directly on your computer. This choice enables a smooth transition from online development environments.
      


          Strings
    -This module will teach you about Python's string data type and its capabilities. Strings are used to represent text within programs.

Basics of Lists
    -This module will teach you the basics of Python's list data type. Lists are used to hold a sequence of data within programs.

List Manipulation
    -This module will dive further into the use of lists. You will learn how about mutating the contents of a list and the implications of doing so.

File Access
    -This module will teach you how to access files in Python.",Python Data Representations
https://www.classcentral.com/course/computational-social-science-ucdavis-18710,"Digital technology has not only revolutionized society, but also the way we can study it. Currently, this is taken advantage of by the most valuable companies in Silicon Valley, the most powerful governmental agencies, and the most influential social movements. What they have in common is that they use computational tools to understand, and ultimately influence human behavior and social dynamics. An increasing part of human interaction leaves a massive digital footprint behind. Studying it allows us to gain unprecedented insights into what society is and how it works, including its intricate social networks that had long been obscure. Computational power allows us to detect hidden patterns through analytical tools like machine learning and to natural language processing. Finally, computer simulations enable us to explore hypothetical situations that may not even exist in reality, but that we would like to exist: a better world. This specialization serves as a multidisciplinary, multi-perspective, and multi-method guide on how to better understand society and human behavior with modern research tools. This specialization gives you easy access to some of the exciting new possibilities of how to study society and human behavior. It is the first online specialization collectively taught by Professors from all 10 University of California campuses.



          Course 1: Computational Social Science Methods- This course gives you an overview of the current opportunities and the omnipresent reach of computational social science. The results are all around us, every day, reaching from the services provided by the world’s most valuable companies, over the hidden influence of governmental agencies, to the power of social and political movements. All of them study human behavior in order to shape it. In short, all of them do social science by computational means. In this course we answer three questions: I. Why Computational Social Science (CSS) now? II. What does CSS cover? III. What are examples of CSS? In this last part, we take a bird’s-eye view on four main applications of CSS. First, Prof. Blumenstock from UC Berkeley discusses how we can gain insights by studying the massive digital footprint left behind today’s social interactions, especially to foster international development. Second, Prof. Shelton from UC Riverside introduces us to the world of machine learning, including the basic concepts behind this current driver of much of today's computational landscape. Prof. Fowler, from UC San Diego introduces us to the power of social networks, and finally, Prof. Smaldino, from UC Merced, explains how computer simulation help us to untangle some of the mysteries of social emergence.Course 2: Big Data, Artificial Intelligence, and Ethics- This course gives you context and first-hand experience with the two major catalyzers of the computational science revolution: big data and artificial intelligence. With more than 99% of all mediated information in digital format and with 98% of the world population using digital technology, humanity produces an impressive digital footprint. In theory, this provides unprecedented opportunities to understand and shape society. In practice, the only way this information deluge can be processed is through using the same digital technologies that produced it. Data is the fuel, but machine learning it the motor to extract remarkable new knowledge from vasts amounts of data. Since an important part of this data is about ourselves, using algorithms in order to learn more about ourselves naturally leads to ethical questions. Therefore, we cannot finish this course without also talking about research ethics and about some of the old and new lines computational social scientists have to keep in mind. As hands-on labs, you will use IBM Watson’s artificial intelligence to extract the personality of people from their digital text traces, and you will experience the power and limitations of machine learning by teaching two teachable machines from Google yourself.Course 3: Social Network Analysis- This course is designed to quite literally ‘make a science’ out of something at the heart of society: social networks. Humans are natural network scientists, as we compute new network configurations all the time, almost unaware, when thinking about friends and family (which are particular forms of social networks), about colleagues and organizational relations (other, overlapping network structures), and about how to navigate delicate or opportunistic network configurations to save guard or advance in our social standing (with society being one big social network itself). While such network structures always existed, computational social science has helped to reveal and to study them more systematically. In the first part of the course we focus on network structure. This looks as static snapshots of networks, which can be intricate and reveal important aspects of social systems. In our hands-on lab, you will also visualize and analyze a network with a software yourself, which will help to appreciate the complexity social networks can take on. During the second part of the course, we will look at how networks evolve in time. We ask how we can predict what kind of network will form and if and how we could influence network dynamics.Course 4: Computer Simulations- Big data and artificial intelligence get most of the press about computational social science, but maybe the most complex aspect of it refers to using computational tools to explore and develop social science theory. This course shows how computer simulations are being used to explore the realm of what is theoretically possible. Computer simulations allow us to study why societies are the way they are, and to dream about the world we would like to live in. This can be as intuitive as playing a video game. Much like the well-known video game SimCity is used to build and manage an artificial city, we use agent-based models to grow and study artificial societies. Without hurting anyone in the real world, computer simulations allow us explore how to make the world a better place. We play hands-on with several practical computer simulation models and explore how we can combine hypothetical models with real world data. Finally, you will program a simple artificial society yourself, bottom-up. This will allow you to feel the complexity that arises when designing social systems, while at the same time experiencing the ease with which our new computational tools allow us to pursue such daunting endeavors.Course 5: Computational Social Science Capstone Project- CONGRATULATIONS! Not only did you accomplish to finish our intellectual tour de force, but, by now, you also already have all required skills to execute a comprehensive multi-method workflow of computational social science. We will put these skills to work in this final integrative lab, where we are bringing it all together. We scrape data from a social media site (drawing on the skills obtained in the 1st course of this specialization). We then analyze the collected data by visualizing the resulting networks (building on the skills obtained in the 3rd course). We analyze some key aspects of it in depth, using machine learning powered natural language processing (putting to work the insights obtained during the 2nd course). Finally, we use a computer simulation model to explore possible generative mechanism and scrutinize aspects that we did not find in our empirical reality, but that help us to improve this aspect of society (drawing on the skills obtained during the 4th course of this specialization). The result is the first glimpse at a new way of doing social science in a digital age: computational social science. Congratulations! Having done all of this yourself, you can consider yourself a fledgling computational social scientist!",Computational Social Science
https://www.classcentral.com/course/mongodb-university-m101p-mongodb-for-developers-600,"Learn everything you need to know to get started building a MongoDB-based app.
This course will go over basic installation, JSON, schema design, querying, insertion of data, indexing and working with language drivers. We will also cover working in sharded and replicated environments. In the course, you will build a blogging platform, backed by MongoDB. Our code examples will be given in Python. A brief Python introduction is included in the course.
Prerequisites
To take this course, you should have a working knowledge of Python. Knowledge of relational databases is not required.",M101P: MongoDB for Developers
https://www.classcentral.com/course/edx-data-analytics-and-learning-2144,"Capturing and analyzing data has changed how decisions are made and resources are allocated in businesses, journalism, government, and military and intelligence fields. Through better use of data, leaders are able to plan and enact strategies with greater clarity and confidence. Data drives increased organizational efficiency and a competitive advantage. Simply, analytics provide new insight and actionable intelligence.
In education, the use of data and analytics to improve learning is referred to as learning analytics. Analytics have not yet made the impact on education that they have made in other fields. That’s starting to change. Software companies, researchers, educators, and university leaders recognize the value of data in improving not only teaching and learning, but the entire education sector. In particular, learning analytics enables universities, schools, and corporate training departments to improve the quality of learning and overall competitiveness. Research communities such as the International Educational Data Mining Society (IEDMS) and the Society for Learning Analytics Research (SoLAR) are developing promising models for improving learner success through predictive analytics, machine learning, recommender systems (content and social), network analysis, tracking the development of concepts through social systems, discourse analysis, and intervention and support strategies. The era of data and analytics in learning is just beginning.
Data, Analytics, and Learning provides an introduction to learning analytics and how it is being deployed in various contexts in education, including to support automated intervention, to inform instructors, and to promote scientific discovery. Additionally, we will discuss tools and methods, what skills data scientists need in education, and how to protect student privacy and other rights. The course will provide a broad overview of the field, suitable for a broad audience. Learners will explore the logic of analytics, the basics of finding, cleaning, and using educational data, predictive models, text analysis, and activity graphs and social networks. We will discuss use of analytics in data domains such as log files and text data.  Tableau Software is partnering with University of Texas Arlington to provide analytics software to course participants as well as technical support and guest lectures. Additional software will be introduced and discussed throughout the course.
How this course works:
This course will experiment with multiple learning pathways. It has been structured to allow learners to take various pathways through learning content - either in the existing edX format or in a social competency-based and self-directed format. Learners will have access to pathways that support both beginners, and more advanced students, with pointers to additional advanced resources. In addition to interactions within the edX platform, learners will be encouraged to engage in distributed conversations on social media such as blogs and Twitter.



            Read more","Data, Analytics, and Learning"
https://www.classcentral.com/course/musictech-605,"How can we use computers to create expressive, compelling music? And how can we write computer software to help us create and organize sounds in new ways? This course provides a hands-on introduction to the field of music technology as both a creative musical practice and an interdisciplinary technical research pursuit. Students will be able to compose music in digital audio workstation software using both audio and symbolic representations; to write code to algorithmically generate music, analyze sound, and design sound; and to describe the essential theory and history behind these activities as well as their connection to cutting-edge computer music research. Through the exploration of topics such as acoustics, psychoacoustics, digital sound, digital signal processing, audio synthesis, spectral analysis, algorithmic composition, and music information retrieval, we will explore the deep relationships between art and science, between theory and practice, and between experimental and popular electronic music.

We will learn about these topics in the context of digital audio workstation (DAW) software, the multi-track editing paradigm that has been dominant in music production since the 1980s. As we learn about the foundations behind such software, we will use this knowledge to more effectively create music with it, and we will also write a series of short software programs that extend the software’s ability to manipulate, transform, and analyze sound.

NOTE: The Survey of Music Technology course will close to new enrollments on September 24th, 2018.
      


            Read more
          



Module 1: Introduction and the Basics of SoundThe first module provides an introduction to the course and lessons in acoustics, psychoacoustics, timbre, digital representation of sound, and spectral representation of sound.Module 2: Digital Audio WorkstationsThis module will look at DAW history and key features, music representation, recording and editing audio in a DAW, effects and automations, and aesthetic context.Module 3: Working With MIDIIn this module we will take a look at MIDI specification (history, structure, limitations), real and virtual MIDI devices, and MIDI sequencing in the DAW. The module concludes with the first of two peer reviewed assignments, in which students create a multi-track DAW audio and MIDI composition.Module 4: Algorithmic Composition Basic TechniquesIn this module students will learn the basics of Python programming and the EarSketch API and the history and practice of algorithmic composition.Module 5: Algorithmic Composition AdvancedThis module looks at more advanced topics in algorithmic programming for music including stochastic composition, chance music, process music, and modeling.Module 6: Future DirectionsThis module will help students by describing the core research areas in computer music and their future directions. We will explore music information retrieval, live coding, machine musicianship, new musical interfaces, mobile music, and networked music.",Survey of Music Technology
https://www.classcentral.com/course/amnhgenetics-861,"How have advances in genetics affected society? What do we need to know to make ethical decisions about genetic technologies? This course includes the study of cloning, genetic enhancement, and ownership of genetic information. Course participants will acquire the tools to explore the ethics of modern genetics and learn how to integrate these issues into their classrooms.
      


          Introduction and From Mendel to 1000 Genomes
    -You will explore the history of genetics and genomics, and be introduced to ways of thinking ethically about issues involving genetic technology. You will learn how ethical issues can be used to spark your students’ interest, and how to uncover students’ misconceptions. 

DNA Fingerprinting, Cloning, and the Future
    -You will explore systems biology, stem cells, and cloning and the applications of these technologies. You will also learn about the ethics of cloning, which will be the basis for your written assignment, which opens this week. 

Genomics in Medicine
    -You will see how genetic information is being used to individualize medical treatments and take a video tour of the Sackler Institute for Comparative Genomics at the American Museum of Natural History. You will also apply the Science and Engineering practices from A Framework for K-12 Science Education and the Next Generation Science Education Standards in considering how to engage students in discussion about ethics.

Genomes, Agriculture, and Society
    -This week you will learn about the societal implications of genetically modified food, and discuss ways to incorporate this issue into your teaching.",Genetics and Society: A Course for Educators
https://www.classcentral.com/course/edx-a-resilient-future-science-and-technology-for-disaster-risk-reduction-7218,"This course aims to introduce participants to existing and emerging technologies suitable for disaster risk reduction while promoting the overall aim of sustainable development. The course focuses on three main natural hazards- floods, landslides and earthquakes. It also discusses the challenges and limits of adapting and adopting technologies depending on context (Global North and Global South) with examples from Switzerland, Nepal, Colombia, Philippines and other countries.
Image: “Earthquake in Nepal” by Asian Development Bank (www.adb.org) is licensed under BY-NC-ND 2.0 (permission granted 18 January 2016)



Chapter 1: Introduction to Disaster Risk Reduction and Science and Technology for DRR
Introduction to basic DRR concepts such as hazard, disaster, vulnerability, risk, capacity and resilience, and to define what is science and technology for DRR. 
Chapter2: Science and Technology for Risk Assessment
Presentation of tools and technologies that can help complete hazard, vulnerability, and risk assessments. 
Chapter3: Science and Technology for Prevention
Presentation of examples of technologies and structural measures that help to prevent and mitigate risks, the non-structural aspects of prevention, including actors and governance with a science and technology linkage, and case studies that show non-structural science, tools and technology application. 

Chapter 4: Science and Technology for Early-Warning and Preparedness
Introduction to early-warning systems and examples of preparedness actions, and discussions on appropriate technologies for preparedness. 
Chapter 5: Science and Technology for Disaster Response and Emergency Relief
Introduction to technologies that are used when a disaster strikes and in its immediate aftermath, and show how technologies such as robotics (e.g. UAVs) and ICT can help indisaster response. 
Chapter 6: Science and Technology for Post-Disaster Recovery and Reconstruction
Introduction to technologies that can allow the assessment of the damages and presentation oftechnologies that could help to “build-back better.” 
Chapter 7: Science and Technology for Resilience and Sustainable Development
Presentation on how science and technologycan help the international, national and local levels to become more resilient against disasters and examples of how science and technology for DRR help to increase resilience. Introduction of risk as an engine for development and general constraints and opportunities on the use of technology for DRR, resilience and sustainable development.",A Resilient Future: Science and Technology for Disaster Risk Reduction
https://www.classcentral.com/course/analytics-mysql-4181,"This course is an introduction to how to use relational databases in business analysis.  You will learn how relational databases work, and how to use entity-relationship diagrams to display the structure of the data held within them.  This knowledge will help you understand how data needs to be collected in business contexts, and help you identify features you want to consider if you are involved in implementing new data collection efforts.  You will also learn how to execute the most useful query and table aggregation statements for business analysts, and practice using them with real databases. No more waiting 48 hours for someone else in the company to provide data to you – you will be able to get the data by yourself!

By the end of this course, you will have a clear understanding of how relational databases work, and have a portfolio of queries you can show potential employers. Businesses are collecting increasing amounts of information with the hope that data will yield novel insights into how to improve businesses. Analysts that understand how to access this data – this means you! – will have a strong competitive advantage in this data-smitten business world.
      


          About this Specialization and Course 
    -The Coursera Specialization, ""Managing Big Data with MySQL"" is about how 'Big Data' interacts with business, and how to use data analytics to create value for businesses. This specialization consists of four courses and a final Capstone Project, where you will apply your skills to a real-world business process. You will learn to perform sophisticated data-analysis functions using powerful software tools such as Microsoft Excel, Tableau, and MySQL. To learn more about the specialization, please review the first lesson below, ""Specialization Introduction: Excel to MySQL: Analytic Techniques for Business.""  In this fourth course of this specialization, ""Managing Big Data with MySQL” you will learn how relational databases  work and how they are used in business analysis. Specifically, you will: (1) Describe the structure of relational databases; (2) Interpret and create entity-relationship diagrams and relational schemas that describe the contents of specific databases; (3) Write queries that retrieve and sort data that meet specific criteria, and retrieve such data from real MySQL and Teradata business databases that contain over 1 million rows of data; (4) Execute practices that limit the impact of your queries on other coworkers; (5) Summarize rows of data using aggregate functions, and segment aggregations according to specified variables; (6) Combine and manipulate data from multiple tables across a database; (7) Retrieve records and compute calculations that are dependent on dynamic data features; (8) Translate data analysis questions into SQL queries that accommodate the types of anomalies found in real data sets. By the end of this course, you will have a clear understanding of how relational databases work and have a portfolio of queries you can show potential employers. Businesses are collecting increasing amounts of information with the hope that data will yield novel insights into how to improve businesses.  Analysts that understand how to access this data – this means you! – will have a strong competitive advantage in this data-smitten business world.  To get started with this course, you can begin with, ""Introduction to Managing Big Data with MySQL.""  Please take some time to not only watch the videos, but also read through the course overview as there is extremely important course information in the overview.  

Understanding Relational Databases
    -Welcome to week 1! This week  you will learn how relational databases are organized, and practice making and interpreting Entity Relationship (ER) diagrams and relational schemas that describe the structure of data stored in a database. By the end of the week, you will be able to:Describe the fundamental principles of relational database design Interpret Entity Relationship (ER) diagrams and Entity Relationship (ER) schemas, andCreate your own ER diagrams and relational schemas using a software tool called ERDPlus that you will use to aid your query-writing later in the course.This week’s exercises are donated from a well-known Database Systems textbook, and will help you deepen and strengthen your understanding of how relational databases are organized.  This deeper understanding will help you navigate complicated business databases, and allow you to write more efficient queries.  At the conclusion of the week, you will test your understanding of database design principles by completing the Week 1 graded quiz. To get started, please begin with the video “Problems with Having a Lot of Data Used by a Lot of People.” As always, if you have any questions, post them to the Discussions. I hope you enjoy this week's materials!

 Queries to Extract Data from Single Tables 
    -Welcome to week 2! This week, you will start interacting with business databases. You will write SQL queries that query data from two real companies. One data set, donated from a local start-up in Durham, North Carolina called Dognition, is a MySQL database containing tables of over 1 million rows. The other data set, donated from a national US department store chain called Dillard’s, is a Teradata database containing tables with over a hundred million rows. By the end of the week, you will be able to:1.  Use two different database user interfaces2.  Write queries to verify and describe all the contents of the Dognition MySQL database and the Dillard’s Teradata database3.  Retrieve data that meet specific criteria in a socially-responsible using SELECT, FROM, WHERE, LIMIT, and TOP clauses, and4.  Format the data you retrieve using aliases, DISTINCT clauses, and ORDER BY clauses.Make sure to watch the instructional videos about how to use the database interfaces we have established for this course, and complete both the MySQL and the Teradata exercises. At the end of the week, you will test your understanding of the SQL syntax introduced this week by completing the Week 2 graded quiz.To get started, please begin with the video “Introduction to Week 2.”  As always, if you have any questions, post them to the Discussions. Enjoy this week's materials!


Queries to Summarize Groups of Data from Multiple Tables 
    -Welcome to week 3! This week, we are going to learn the SQL syntax that allows you to segment your data into separate categories and segment.  We are also going to learn how to combine data stored in separate tables.By the end of the week, you will be able to:Summarize values across entire columns, and break those summaries up according to specific variables or values in others columns using GROUP BY and HAVING clausesCombine information from multiple tables using inner and outer joinsUse strategies to manage joins between tables with duplicate rows, many-to-many relationships, and atypical configurationsPractice one of the slightly more challenging use cases of aggregation functions, andWork with the Dognition database to learn more about how MySQL handles mismatched aggregation levels.Make sure to watch the videos about joins, and complete both the MySQL and the Teradata exercises. At the end of the week, you will test your understanding of the SQL syntax introduced this week by completing the Week 3 graded quiz.We strongly encourage you to use the course Discussions to help each other with questions.  To get started, please begin with the video 'Welcome to Week 3.’I hope you enjoy this week’s materials!

 Queries to Address More Detailed Business Questions
    -Welcome to week 4, the final week of Managing Big Data with MySQL!  This week you will practice integrating the SQL syntax you’ve learn so far into queries that address analysis questions typical of those you will complete as a business data analyst. By the end of the week, you will be able to:Design and execute subqueriesIntroduce logical conditions into your queries using IF and CASE statementsImplement analyses that accommodate missing data or data mistakes, andWrite complex queries that incorporate many tables and clauses.By the end of this week you will feel confident claiming that you know how to write SQL queries to create business value. Due to the extensive nature of the queries we will practice this week, we have put the graded quiz that tests your understanding of the SQL strategies you will practice in its own week rather than including it in this week’s materials.  Make sure to complete both the MySQL exercises and the Teradata exercises, and we strongly encourage you to use the course Discussions to help each other with questions.  To get started, please begin with the video 'Welcome to Week 4.’I hope you enjoy this week’s materials!

Strengthen and Test Your Understanding 
    -This week contains the final ungraded Teradata exercises, and the final graded quiz for the course. The exercises are intended to hone and build your understanding of the last important concepts in the course, and lead directly to the quiz so be sure to do both!",Managing Big Data with MySQL
https://www.classcentral.com/course/edx-fundamentals-of-statistics-11482,"Statistics is the science of turning data into insights and ultimately decisions. Behind recent advances in machine learning, data science and artificial intelligence are fundamental statistical principles. The purpose of this class is to develop and understand these core ideas on firm mathematical grounds starting from the construction of estimators and tests, as well as an analysis of their asymptotic performance. 
After developing basic tools to handle parametric models, we will explore how to answer more advanced questions, such as the following: 

How suitable is a given model for a particular dataset?
How to select variables in linear regression?
How to model nonlinear phenomena?
How to visualize high-dimensional data?

Taking this class will allow you to expand your statistical knowledge to not only include a list of methods, but also the mathematical principles that link them together, equipping you with the tools you need to develop new ones. 
This course is part of theMITx MicroMasters Program in Statistics and Data Science. Master the skills needed to be an informed and effective practitioner of data science. You will complete this course and three others from MITx, at a similar pace and level of rigor as an on-campus course at MIT, and then take a virtually-proctored exam to earn your MicroMasters, an academic credential that will demonstrate your proficiency in data science or accelerate your path towards an MIT PhD or a Master's at other universities. To learn more about this program, please visit https://micromasters.mit.edu/ds/.



            Read more",Fundamentals of Statistics
https://www.classcentral.com/course/business-data-5757,"This course provides an analytical framework to help you evaluate key problems in a structured fashion and will equip you with tools to better manage the uncertainties that pervade and complicate business processes. Specifically, you will be introduced to statistics and how to summarize data and learn concepts of frequency, normal distribution, statistical studies, sampling, and confidence intervals.

While you will be introduced to some of the science of what is being taught, the focus will be on applying the methodologies. This will be accomplished through the use of Excel and data sets from many different disciplines, allowing you to see the use of statistics in very diverse settings. The course will focus not only on explaining these concepts, but also understanding the meaning of the results obtained.

Upon successful completion of this course, you will be able to:

•	Summarize large data sets in graphical, tabular, and numerical forms.
•	Understand the significance of proper sampling and why you can rely on sample information.
•	Understand why normal distribution can be used in so many settings.
•	Use sample information to infer about the population with a certain level of confidence about the accuracy of the estimations.
•	Use Excel for statistical analysis.

This course is part of the iMBA offered by the University of Illinois, a flexible, fully-accredited online MBA at an incredibly competitive price. For more information, please see the Resource page in this course and onlinemba.illinois.edu.
      


            Read more
          



          Course Orientation
    -You will become familiar with the course, your classmates, and our learning environment. The orientation will also help you obtain the technical skills required for the course.

Module 1: Introduction and Summarizing Data
    -Data is all around you, but what is the data telling you? The first step in making better decisions and taking action is to get a good understanding of information you have gathered. In this module we will learn about some of the tools in statistics that help us achieve this.

Module 2: Descriptive Statistics and Probability Distributions
    -We all have heard the phrase that a ""picture is worth a thousand words,"" but you certainly don’t want one of those to be ""what exactly am I looking at?"" So, now that you know to use ""pictures"" to summarize your data, let’s make those pictures easier to understand.

Module 3: Sampling and Central Limit Theorem
    -You are charged with analyzing a market segment for your company. You and your team have figured out what variables you need to understand; you also have an idea what factors might be influencing these variables of interest. Now you are ready to do your analysis. But, wait! Where is the data? How do you begin to get the data? In this module we will review the means by which you can begin to produce data – the concepts of sampling and Central Limit Theorem – and will help you understand how to produce ""good"" sample data and why sample data will work.

Module 4: Inference
    -You have sample data and have done the analysis – you think you can say something about the population based on your sample study.  But, do you have a sense of what are the chances of you being right or wrong?  How can you be surer? What else should you have considered? In this module, you will learn how to find the answers to these questions.",Exploring and Producing Data for Business Decision Making
https://www.classcentral.com/course/cs-programming-java-13151,"The basis for education in the last millennium was “reading, writing, and arithmetic;” now it is reading, writing, and computing. Learning to program is an essential part of the education of every student, not just in the sciences and engineering, but in the arts, social sciences, and humanities, as well. Beyond direct applications, it is the first step in understanding the nature of computer science’s undeniable impact on the modern world.  This course covers the first half of our book Computer Science: An Interdisciplinary Approach (the second half is covered in our Coursera course Computer Science: Algorithms, Theory, and Machines). Our intent is to teach programming to those who need or want to learn it, in a scientific context. 

We begin by introducing basic programming elements such as variables, conditionals, loops, arrays, and I/O. Next, we turn to functions, introducing key concepts such as recursion, modular programming, and code reuse. Then, we present a modern introduction to object-oriented programming.

We use the Java programming language and teach basic skills for computational problem solving that are applicable in many modern computing environments. Proficiency in Java is a goal, but we focus on fundamental concepts in programming, not Java per se.

All the features of this course are available for free. It does not offer a certificate upon completion.
      


          BASIC PROGRAMMING CONCEPTS
    -Why program? This lecture addresses that basic question. Then it describes the anatomy of your first program and the process of developing a program in Java using either virtual terminals or a program development environment, with some historical context. Most of the lecture is devoted to a thorough coverage of Java's built-in data types, with example programs for each.

CONDITIONALS AND LOOPS
    -The if, while, and for statements are Java's fundamental control structures. This lecture is built around short programs that use these constructs to address important computational tasks. Examples include sorting, computing the square root, factoring, and simulating a random process. The lecture concludes with a detailed example illustrating the process of debugging a program.

ARRAYS
    -Computing with a large sequence of values of the same type is extremely common. This lecture describes Java's built-in array data structure that supports such applications, with several examples, including shuffling a deck of cards, the coupon collector test for randomness, and random walks in a grid.

INPUT AND OUTPUT
    -To interact with our programs, we need mechanisms for taking information from the outside world and for presenting information to the outside world. This lecture describes several such mechanisms: for text, drawings, and animation. Detailed examples covered include fractal drawings that model natural phenomena and an animation of a ball bouncing around in the display window.

FUNCTIONS AND LIBRARIES
    -Modular programming is the art and science of breaking a program into pieces that can be individually developed. This lecture introduces functions (Java methods), a fundamental mechanism that enables modular programming. Motivating examples include functions for the classic Gaussian distribution and an application that creates digital music.

RECURSION
    -A recursive function is one that calls itself. This lecture introduces the concept by treating in detail the ruler function and (related) classic examples, including  the Towers of Hanoi puzzle, the H-tree, and simple models of the real world based on recursion. We show a common pitfall in the use of recursion, and a simple way to avoid it, which introduces a different (related) programming paradigm known as dynamic programming.

PERFORMANCE
    -When you develop a program, you need to be aware of its resource requirements. In this lecture, we describe a scientific approach to understanding performance, where we develop mathematical models describing the running time our programs and then run empirical tests to validate them. Eventually we come to a simple and effective approach that you can use to predict the running time of your own programs that involve significant amounts of computation.

ABSTRACT DATA TYPES
    -In Java, you can create your own data types and use them in your programs. In this and the next lecture, we show how this ability allows us to view our programs as abstract representations of real-world concepts. First we show the mechanics of writing client programs that use data types. Our examples involve abstractions such as color, images, and genes. This style of programming is known as object-oriented programming because our programs manipulate objects, which hold data type values.

CREATING DATA TYPES
    -Creating your own data types is the central activity in modern Java programming. This lecture covers the mechanics (instance variables, constructors, instance methods, and test clients) and then develops several examples, culminating in a program that uses a quintessential mathematical abstraction (complex numbers) to create visual representations of the famous Mandelbrot set.

PROGRAMMING LANGUAGES
    -We conclude the course with an overview of important issues surrounding programming languages. To convince you that your knowledge of Java will enable you to learn other programming languages, we show implementations of a typical program in C, C++, Python, and Matlab. We describe important differences among these languages and address fundamental issues, such as garbage collection, type checking, object oriented programming, and functional programming with some brief historical context.",Computer Science: Programming with a Purpose
https://www.classcentral.com/course/edx-foundations-of-data-structures-5755,"Data structures provide a means to manage large amounts of data for use in databases and internet indexing services. Efficient data structures are key for designing efficient algorithms and obtaining maintainable software design.
In this Computer Science course, you will start by learning basic data types, such as numbers, and gradually build a conceptual framework for organizing and managing efficient structures.
Topics covered:

Basic Data Types, Notion of an Abstract Data Type
Mathematical Properties of Sequences
Special Types of Sequences: Stacks, Queues, Strings
Implementation of Sequence Type: Arrays and Linked Lists
Trees
Sets and Maps
Graphs

Preliminary understanding of implementing sequence structures such as stacks, queues, and linked lists, will also be covered.
This course is part of the Fundamentals of Computer Science XSeries Program:

Programming Basics
Object-Oriented Programming
Implementation of Data Structures
Algorithms",Foundations of Data Structures
https://www.classcentral.com/course/statreasoning-1036,"A conceptual and interpretive public health approach to some of the most commonly used methods from basic statistics.
      


Introduction and Module 1This module, consisting of one lecture set, is intended to whet your appetite for the course, and examine the role of biostatistics in public health and medical research.  Topics covered include study design types, data types, and data summarization.Module 2A: Summarization and MeasurementModule 2A consists of two lecture sets that cover measurement and summarization of continuous data outcomes for both single samples, and the comparison of two or more samples.  Please see the posted learning objectives for these two lecture sets for more detail.Module 2B: Summarization and Measurement Module 2B includes a single lecture set on summarizing binary outcomes.  While at first, summarization of binary outcome may seem simpler than that of continuous outcomes, things get more complicated with group comparisons.  Included in the module are examples of and comparisons between risk differences, relative risk and odds ratios. Please see the posted learning objectives for these this module for more details.Module 2C: Summarization and Measurement This module consists of a single lecture set on time-to-event outcomes.   Time-to-event data comes primarily from prospective cohort studies with subjects who haven to had the outcome of interest at their time of enrollment.   These subjects are followed for a pre-established period of time until they either have there outcome, dropout during the active study period, or make it to the end of the study without having the outcome.  The challenge with these data is that the time to the outcome is fully observed on some subjects, but not on those who do not have the outcome during their tenure in the study. Please see the posted learning objectives for each lecture set in this module for more details.Module 3A: Sampling Variability and Confidence IntervalsUnderstanding sampling variability is the key to defining the uncertainty in any given sample/samples based estimate from a single study.  In this module, sampling variability is explicitly defined and explored through simulations.   The resulting patterns from these simulations will give rise to a mathematical results that is the underpinning of all statistical interval estimation and inference: the central limit theorem.  This result will used to create 95% confidence intervals for population means, proportions and rates from the results of a single random sample.Module 3B: Sampling Variability and Confidence IntervalsThe concepts from the previous module (3A) will be extended create 95% CIs for  group comparison measures (mean differences, risk differences, etc..) based on the results from a single study.Module 4A: Making Group Comparisons: The Hypothesis Testing ApproachModule 4A shows a complimentary approach to confidence intervals when comparing a summary measure between two populations via two samples; statistical hypothesis testing.  This module will cover some of the most used statistical tests including the t-test for means, chi-squared test for proportions and log-rank test for time-to-event outcomes.Module 4B: Making Group Comparisons: The Hypothesis Testing ApproachModule 4B extends the hypothesis tests for two populations comparisons to ""omnibus"" tests for comparing means, proportions or incidence rates between more than two populations with one test","Statistical Reasoning for Public Health 1: Estimation, Inference, & Interpretation"
https://www.classcentral.com/course/logic1-1454,"Information is everywhere: in our words and our world, our thoughts and our theories, our devices and our databases. Logic is the study of that information: the features it has, how it’s represented, and how we can manipulate it. Learning logic helps you formulate and answer many different questions about information:Does this hypothesis clash with the evidence we have or is it consistent with the evidence?Is this argument watertight, or do we need to add more to make the conclusion to really follow from the premises?Do these two sentences say the same things in different ways, or do they say something subtly different?Does this information follow from what’s in this database, and what procedure could we use to get the answer quickly?Is there a more cost-effective design for this digital circuit? And how can we specify what the circuit is meant to do so we could check that this design does what we want?These are questions about Logic. When you learn logic you'll learn to recognise patterns of information and the way it can be represented. These skills are used whether we're dealing with theories, databases, digital circuits, meaning in language, or mathematical reasoning, and they will be used in the future in ways we haven't yet imagined. Learning logic is a central part of learning to think well, and this course will help you learn logic and how you can apply it.If you take this subject, you will learn how to use the core tools in logic: the idea of a formal language, which gives us a way to talk about logical structure; and we'll introduce and explain the central logical concepts such as consistency and validity; models; and proofs. But you won’t only learn concepts and tools. We will also explore how these techniques connect with issues in linguistics, computer science, electronic engineering, and philosophy. 
      


            Read more
          



Week 1. The Syntax of Propositional Logic; Truth Tables; Classifying PropositionsWeek 2. Relationships between Propositions; Tree Proofs; Soundness and CompletenessWeeks 3–5. Applications to different reasoning domains (take at least two):Electronic Engineering — simplifying digital circuitsPhilosophy — vagueness and borderline casesComputer Science — databases, resolution and propositional PrologLinguistics — meaning: implication vs implicature",Logic: Language and Information 1
https://www.classcentral.com/course/gcp-big-data-ml-fundamentals-8234,"This 2-week accelerated on-demand course introduces participants to the Big Data and Machine Learning capabilities of Google Cloud Platform (GCP). It provides a quick overview of the Google Cloud Platform and a deeper dive of the data processing capabilities.

At the end of this course, participants will be able to:
• Identify the purpose and value of the key Big Data and Machine Learning products in the Google Cloud Platform
• Use CloudSQL and Cloud Dataproc to migrate existing MySQL and Hadoop/Pig/Spark/Hive workloads to Google Cloud Platform
• Employ BigQuery and Cloud Datalab to carry out interactive data analysis
• Choose between Cloud SQL, BigTable and Datastore
• Train and use a neural network using TensorFlow
• Choose between different data processing products on the Google Cloud Platform

Before enrolling in this course, participants should have roughly one (1) year of experience with one or more of the following:
• A common query language such as SQL
• Extract, transform, load activities
• Data modeling
• Machine learning and/or statistics
• Programming in Python

Google Account Notes:
• Google services are currently unavailable in China.
      


          Introduction to the Data and Machine Learning on Google Cloud Platform Specialization .
    -Welcome to the Big Data and Machine Learning fundamentals on GCP course. Here you will learn the basics of how the course is structured and the four main big data challenges you will solve for.

Recommending Products using Cloud SQL and Spark
    -In this module you will have an existing Apache SparkML recommendation model that is running on-premise. You will learn about recommendation models and how you can run them in the cloud with Cloud Dataproc and Cloud SQL.

Predict Visitor Purchases with BigQuery ML
    -In this module, you will learn the foundations of BigQuery and big data analysis at scale. You will then learn how to build your own custom machine learning model to predict visitor purchases using just SQL with BigQuery ML. 

Create Streaming Data Pipelines with Cloud Pub/sub and Cloud Dataflow
    -In this module you will engineer and build an auto-scaling streaming data pipeline to ingest, process, and visualize data on a dashboard. Before you build your pipeline you'll learn the foundations of message-oriented architecture and pitfalls to avoid when designing and implementing modern data pipelines.

Classify Images with Pre-Built Models using Vision API and Cloud AutoML
    -Don't want to create a custom ML model from scratch? Learn how to leverage and extend pre-built ML models like the Vision API and Cloud AutoML for image classification.

Summary
    -In this final module, we will review the key challenges, solutions, and topics covered as part of this fundamentals course. We will also review additional resources and the steps you can take to get certified as a Google Cloud Data Engineer.",Google Cloud Platform Big Data and Machine Learning Fundamentals
https://www.classcentral.com/course/pkubioinfo-1209,"A big welcome to “Bioinformatics: Introduction and Methods” from Peking University! In this MOOC you will become familiar with the concepts and computational methods in the exciting interdisciplinary field of bioinformatics and their applications in biology, the knowledge and skills in bioinformatics you acquired will help you in your future study and research.

Course materials are available under the CC BY-NC-SA License.
      


          Introduction and History of Bioinformatics
    -Welcome to “Bioinformatics: Introduction and Methods! Upon completion of this module you will be able to: become familiar with the essential concepts of bioinformatics; explore the history of this young area; experience how rapidly bioinformatics is growing. Our supplementary materials will give you a better understanding of the course lectures through they are not required in quizzes or exams

Sequence Alignment
    -Upon completion of this module, you will be able to: describe dynamic programming based sequence alignment algorithms; differentiate between the Needleman-Wunsch algorithm for global alignment and the Smith-Waterman algorithm for local alignment; examine the principles behind gap penalty and time complexity calculation which is crucial for you to apply current bioinformatic tools in your research; experience the discovery of Smith-Waterman algorithm with Dr. Michael Waterman himself.

Sequence Database Search
    -Upon completion of this module, you will be able to: become familiar with sequence databse search and most common databases; explore the algoritm behind BLAST and the evaluation of BLAST results; ajdust BLAST parameters base on your own research project.

Markov Model
    -Upon completion of this module, you will be able to: recognize state transitions, Markov chain and Markov models; create a hidden Markov model by yourself; make predictuions in a real biological problem with hidden Markov model.

Next Generation Sequencing (NGS): Mapping of Reads From Resequencing and Calling of Genetic Variants
    -Upon completion of this module, you will be able to: describe the features of NGS; associate NGS results you get with the methods for reads mapping and models for variant calling; examine pipelines in NGS data analysis; experience how real NGS data were analyzed using bioinformatic tools. This module is required before entering Module 8.

Functional Prediction of Genetic Variants
    -Upon completion of this module you will able to: describe what is variant prediction and how to carry out variant predictions; associate variant databases with your own research projects after you get a list of variants; recognize different principles behind prediction tools and know how to use tools such as SIFT, Polyphen and SAPRED according to your won scientific problem.

Mid-term Exam
    -The description goes here

Next Generation Sequencing: Transcriptome Analysis, and RNA-Seq
    -Upon completion of this module, you will be able to: describe how transcriptome data were generated; master the algorithm used in transcriptome analysis; explore how the RNA-seq data were analyzed. This module is required before entering Module 9.

Prediction and Analysis of Noncoding RNA
    -Upon completion of this module, you will be able to: Analyze non-coding RNAs from transcriptome data; identify long noncoding RNA (lncRNA) from NGS data and predict their functions.

Ontology and Identification of Molecular Pathways
    -Upon completion of this module, you will be able to: define ontology and gene ontology, explore KEGG pathway databses; examine annotations in Gene Ontology; identify pathways with KOBAS and apply the pipeline to drug addition study.

Bioinformatics Database and Software Resources
    -Upon completion of this module, you will be able to describe the most important bioinformatic resources including databases and software tools; explore both centralized resources such as NCBI, EBI, UCSC genome browser and lots of individual resources; associate all your bioinformatic problems with certain resources to refer to.

Origination of New Genes
    -Upon completion of this case study module, you will be able to: experience how to apply bioinformatic data, methods and analyses to study an important problem in evolutionary biology; examine how to detect and study the origination, evolution and function of species-specific new genes; create phylogenetic trees with your own data (not required) with Dr. Manyuan Long, a world-renowned pioneer and expert on new genes  from University of Chicago.

Evolution function analysis of DNA methyltransferase
    -Upon completion of this case study module, you will be able to: experience how to use bioinformatic methods to study the function and evolution of DNA methylases; share with Dr. Gang Pei, president of Tongji University and member of the Chinese Academy of Science, the experiences in scientific research and thought about MOOC.

Final Exam
    -The description goes here",Bioinformatics: Introduction and Methods 生物信息学: 导论与方法
https://www.classcentral.com/course/science-and-religion-101-9341,"This course examines the nature of both science and religion and attempts to explore the possible relationships between them. The primary purpose is to dispel the popular myth that science and religion are entrenched in a never-ending conflict. As a result, this course argues that if the limits of both science and religion are respected, then their relationship can be complementary.

Topics include: Science and Religion Categories and Foundational Principles, Definitions of Science and Religion, Science-Religion Models and Relationships, Intelligent Design and Natural Revelation, the Galileo Affair, Geology and Noah’s Flood, Evolution and Darwin’s Religious Beliefs, the Modern “Evolution” vs. “Creation” Debate, the Problem of Evil, and Interpretations of the Biblical Accounts of Origins in Genesis 1-11.

The course employs a Constructive Teaching Style in order that students can develop their personal views on the relationship between science and religion and on each of the topics listed above.

St. Joseph's College is a Catholic, undergraduate, liberal arts college on the University of Alberta campus. It is an independent institution that is affiliated with the University of Alberta.
      


          Introduction
    -During the first week of the course we will introduce the new and exciting Science-Religion Dialogue and point out that simple dichotomies and conflations lead to the commonly perceived warfare relationship between Science and Religion. As an initial move away from the conflict approach, this section examines the longstanding notion of a peaceful relationship known as the “Two Divine Books.” The Book of God’s Words is Scripture; the Book of God’s Works is nature. 
The definition of numerous categories (or terms) will begin the process for you to think critically about the issues and to defend your provisional position on the relationship between Science and Religion. We also introduce the first of the two foundational principles in this course. It is a philosophical principle termed “The Metaphysics-Physics Principle.”

Categories & Principles II & III
    -In this final section on Categories and Principles, we will consider foundational and religious epistemological (theory of knowledge) categories. In particular, does a belief in God, or a lack of belief in God, impact the step of faith or intellect jump in the Metaphysics-Physics Principle? This week also introduces the second foundational principle of this course termed “The Message-Incident Principle.” This is a hermeneutical principle for interpreting religious texts dealing with statements about the natural world. In order to develop a peaceful relationship between Science and Religion, it is critical to understand that religious texts like the Bible feature an ancient understanding of nature (i.e., an ancient science). During this week we also outline the basic positions on the origin of the universe and life—Young Earth Creation, Progressive Creation, Evolutionary Creation, Deistic Evolution, and Dysteleological Evolution.

What Is Religion?
    -This is a course on the relationship between Science and Religion, and in order to develop a relationship between them we first need to define them. Five different definitions of religion from various academic schools are presented, including those from religious studies, psychology, and philosophy. Notably, the academic definition of religion is wide and quite inclusive. In light of this information, we then outline the academic understanding of the Doctrine of Creation. During this week, we begin to examine specific Hermeneutical Principles. The Principle of Accommodation is the most important interpretive principle in Science and Religion allowing individuals to move away from scientific concordism and the notion that religious texts like the Bible offer scientific facts.

What Is Science?
    -In continuing with our exploration of the terms Science and Religion, this week we introduce five different definitions of science using historical examples—prehistoric science, Egyptian and Mesopotamian science, Greek science, modern science, and post-modern science. Notably, we will note that science has powerfully impacted religion throughout history. Like that of religion, the academic definition of science is wide. In particular, it has been intimately/inevitably connected to metaphysical beliefs. This section also outlines Critical Realism. This is philosophy of science embraced by a majority of Science and Religion scholars.

Models on the Relationships between Science & Religion
    -This is one of the most important weeks in the course. We outline the Science and Religion models of two of the founding members of this new academic discipline. Their models each include four different relationships between Science and Religion. John Haught’s model incorporates the relationships of Conflict, Contrast, Contact, and Confirmation. Ian Barbour has Conflict, Independence, Dialogue, and Integration relationships in his model. During this week, we will consider the hermeneutical principle of Historical Criticism. This is the notion that ancient Near Eastern motifs of origins—De Novo Creation, Lost Idyllic Age, Great Flood, and Tribal Formation—have been re-cycled and re-interpreted in the biblical accounts of origins (Genesis 1-11).

Intelligent Design & Natural Revelation
    -The topic of intelligent design continues to be intensely debated today. Building off the Metaphysics-Physics Principle, we will differentiate between the Argument from Design to Nature and the Argument from Nature to Design. The three classic biblical passages dealing with Intelligent Design are explored—Psalm 19, Romans 1, and Wisdom of Solomon 13. In order to offer balance in this section, we will also examine the views of the famed atheist Richard Dawkins. He believes that intelligent design is merely an illusion experienced by the vast majority of people that have ever lived.

Astronomy & the Galileo Affair
    -This is the first of three weeks examining historical events related to Science and Religion in order to draw lessons for today. Beginning with the famed astronomer Galileo, we will discover that he was a devout Christian and that he fully embraced the Two Divine Books (Book of God’s Word & Book of God’s Works) relationship of Science and Religion. His “Letter to the Grand Duchess Christina” (1615) is a rich source of insights on how to interpret Scripture and how to relate science and Christianity. We will then apply lessons from the Galileo Affair to the debate over biological evolution in ordered to assist people struggling with this science today. This week also begins an extensive series of Hermeneutical Principles demonstrating that the Bible has an ancient understanding of the structure of the world known as the “3-tier universe.”

Geology & the Biblical Flood
    -Over the 20 years that I have taught this course, I have found that religious students struggle the most with the topic of Noah’s flood in the Bible (Genesis 6-9). The first half of this section is a brief history of geology, beginning with the worldwide flood as the central paradigm and ending with its complete elimination from science. This is another example of science powerfully impacting religion. In the second half, the three basic views of the biblical flood are presented—Global Flood, Local Flood, and Re-Cycled & Re-Interpreted Flood Motif Theory. In particular, the challenging topic of whether or not Noah was a real person in history is explored. We also consider the notion that the biblical flood (Genesis 6-9) is composed of two original sources (Jahwist and Priestly sources).

Evolution & Darwin’s Religious Beliefs
    -This week we deal with the fascinating topic of the religious beliefs of Charles Darwin. To be sure, the theory of biological evolution has significant implications for religion. Evidence is drawn from Darwin’s notebooks, diaries, letters, and books, including his most famous book outlining the theory of evolution, On the Origin of Species (1859). To the surprise of most people, the belief in Intelligent Design was a concept that consumed Darwin throughout his life. In addition, we will also discover that only a few years before his death, he firmly stated, “It seems to me absurd to doubt that a man [or woman] may be an ardent theist & an evolutionist.” In other words, Charles Darwin thought it was perfectly logical to be both a religious person and also one who accepts biological evolution. Finally, this section considers the well-known proclamation of Richard Dawkins that “Darwin made it possible to be an intellectually fulfilled atheist.”

Genesis 1-11: Biblical Accounts of Origins
    -Building upon the hermeneutical principles presented throughout this course, this section examines the biblical accounts of origins in Genesis 1-11. In particular, it explores the notion that the opening chapters of the Bible are structured on four major origins motifs—De Novo Creation, Lost Idyllic Age, Great Flood, and Tribal Formation. More specifically, these ancient Near Eastern motifs were re-cycled and re-interpreted with the inspired spiritual truths of the ancient Hebrews. Numerous ancient features in Genesis 1-11 are identified—ancient cosmogony and historiography, ancient poetry and stylistic techniques, and ancient editing of two original sources (Jahwist and Priestly sources).

Modern Origins Debate
    -Every course on Science & Religion deals with the fascinating topic of the modern origins debate. The 5 most important views of the origin of the universe and life are presented in detail— Young Earth Creation, Progressive Creation, Evolutionary Creation, Deistic Evolution, and Dysteleological Evolution. The importance of scientific and historical concordism for each position is explained. We also explore the challenging topic of whether or not Adam was a real person in history by presenting the 4 best-known positions on human origins—De Novo Creation of Adam, Evolutionary Monogenism, Punctiliar Polygenism, and Gradual Polygenism. These different approaches to Adam are viewed in the light of the Apostle Paul’s letters in Romans 5 and 1 Corinthians 15 and St. Augustine’s Doctrine of Original Sin.

The Problem of Evil
    -The final section of the course deals with the problem of evil. If God is all-loving, all-knowing, and all-powerful, then why are there horrid natural realities like cancers and earthquakes, as well as moral evils like rape, murder, and genocides? Four basic approaches to theodicy (justifications for evil in the world) are presented—Augustinian, Irenaean, Hick’s Irenaean-Evolutionary, and Process Theology. In particular, we examine Greater Good and Pedagogical Arguments in theodicies. 

In light of the two foundation principles of this course, we conclude that it is possible for Science and Religion to be a peaceful and fruitful relationship. The Metaphysics-Physics Principle cautions us not to conflate our metaphysical beliefs with science. In particular, the belief that biological evolution is necessarily atheistic is a misguided conflation. It is perfectly logical, through a step of faith, to believe evolution has been ordained and sustained by a Creator. The Message-Incident Principle underlines that the Bible is not a book of science offering facts of nature ahead of their discovery by scientists. It is quite reasonable for religious people to embrace a non-concordist hermeneutic and to believe that God accommodated to the intellectual level of the ancient biblical writers by employing their ancient science to deliver inerrant spiritual truths.",Science & Religion 101
https://www.classcentral.com/course/edx-foundations-of-data-structures-5755,"Data structures provide a means to manage large amounts of data for use in databases and internet indexing services. Efficient data structures are key for designing efficient algorithms and obtaining maintainable software design.
In this Computer Science course, you will start by learning basic data types, such as numbers, and gradually build a conceptual framework for organizing and managing efficient structures.
Topics covered:

Basic Data Types, Notion of an Abstract Data Type
Mathematical Properties of Sequences
Special Types of Sequences: Stacks, Queues, Strings
Implementation of Sequence Type: Arrays and Linked Lists
Trees
Sets and Maps
Graphs

Preliminary understanding of implementing sequence structures such as stacks, queues, and linked lists, will also be covered.
This course is part of the Fundamentals of Computer Science XSeries Program:

Programming Basics
Object-Oriented Programming
Implementation of Data Structures
Algorithms",Foundations of Data Structures
https://www.classcentral.com/course/edx-nutrition-exercise-and-sports-14381,"Are you involved in sports and do you want to have a better understanding of the role of nutrition on performance and health? Do you want to learn whether certain nutritional strategies could be relevant for your own athletic performance and/or muscle growth? Are you a dietitian, physiotherapist or a health/sport coach and do you want to be able to provide proper nutritional advice for your clients? Or, are you none of the above but interested in nutrition and sports and want to make your own informed decisions about your daily food intake?
Then this online course is for you! 
Nutrition is crucial to live an active and healthy life, to support training, and to optimize performance. In this course, researchers and teachers from Wageningen University & Research will familiarize you with the nutritional aspects of exercise and sports. What are the basic concepts in exercise physiology and sport nutrition science? How is exercise being fueled for the different types of sports like; power sports, sprinting and endurance exercise? And how does protein support skeletal muscle mass and performance? In this course you will learn to estimate energy needs and understand thermoregulation and fluid balance. You will learn about the role of micronutrients and supplements in exercise performance. Moreover, you will be introduced to some health issues related to doing exercise.
This course also touches upon how the lessons learned from nutrition and sports research can be applied during ageing. For example, what are the benefits of extra protein in vulnerable age groups? 
Be aware that thiscourse will not tell you exactly what to eat. Instead, you will learn and understand the nutritional aspects of exercise and sport, so you can make your own informed decisions and critically evaluate nutritional advices and claims. 
For whom?
This course is especially useful for: 

Sport- and health coaches, Physiotherapists and Dietitians
People working in the (sport) food industry
Athletes and professional sporters
Everyone with a healthy appetite for knowledge about nutrition, exercise and sports

Ready to join the MOOC? This course contains several interesting and inspiring interviews with nutrition and sport professionals. It will provide basic understanding of Nutrition, Exercise and Sports, and contains challenging assignments that will give you insight in nutritional needs and performance benefits for (your) athletes, your clients or yourself.



            Read more
          



Week 1 | Introduction to Sport Nutrition (Science)
Key topics:
An introduction into Sports, Exercise and Nutrition, including types of Sports, Sport Nutrition Pyramid. An introduction into Sport Nutrition Science - including empirical cycle, study designs, critical issues and performance measurements. 
Week 2 | Skeletal Muscle, Exercise and Sports
Key topics: 
An introduction into Skeletal muscle anatomy & physiology, including contraction and energy transfer. Exercise capacity: Power & Endurance. Cardiopulmonal system during Exercise 
Week 3 | Energy and Fluid balance
Key topics: 
Energy requirement, energy availability. Thermoregulation, Fluid balance, (de)hydration & rehydration strategies 
Week 4 | Macronutrients
Key topics: 
Carbohydrates & fats as energy source, nutritional strategies. Skeletal muscle protein metabolism and dietary protein intake. 
Week 5 | Micronutrients and ergogenic supplements
Key topics: 
Function of micronutrients and recommendations: Iron, Magnesium, calcium and Vitamins D and B. Ergogenic supplements and sports performance 
Week 6 | Exercise and Nutrition during ageing
Key topics: 
Skeletal muscle and ageing, Protein & Exercise in older adults, Intervention strategies","Nutrition, Exercise and Sports"
https://www.classcentral.com/course/matrix-505,"When you take a digital photo with your phone or transform the image in Photoshop, when you play a video game or watch a movie with digital effects, when you do a web search or make a phone call, you are using technologies that build upon linear algebra.  Linear algebra provides concepts that are crucial to many areas of computer science, including graphics, image processing, cryptography, machine learning, computer vision, optimization, graph algorithms, quantum computation, computational biology, information retrieval and web search. Linear algebra in turn is built on two basic elements, the matrix and the vector.  In this class, you will learn the concepts and methods of  linear algebra, and how to use them to think about problems arising in computer science.  You will write small programs in the programming language Python to  implement basic matrix and vector functionality and algorithms, and use these to process real-world data to achieve such tasks as: two-dimensional graphics transformations, face morphing, face detection, image transformations such as blurring and edge detection, image perspective removal, classification of tumors as malignant or  benign, integer factorization, error-correcting codes, and secret-sharing.



The FunctionThe FieldThe VectorThe Vector SpaceThe MatrixThe BasisDimensionGaussian EliminationThe Inner ProductOrthogonalization",Coding the Matrix: Linear Algebra through Computer Science Applications
https://www.classcentral.com/course/global-water-security-12542,"How do we achieve water security for everyone?
Over the next 30 years it is estimated that 80% of the world’s population will live in areas with high levels of water scarcity.
How do we manage this so that we can ensure global water security for both people and ecosystems?
On this course, you’ll have an introduction to the challenges of water security and find out why human activity and environmental issues are putting increasing pressure on our water resources.
You’ll explore the physical, biological and social facets connecting to water security around the globe, where you live, and what can be done to achieve water security for all.
This course is aimed at anyone interested in global water security, but it may be of particular interest to water research professionals and students studying science.",The Challenge of Global Water Security
https://www.classcentral.com/course/big-data-project-5096,"Welcome to the Capstone Project for Big Data! In this culminating project, you will build a big data ecosystem using tools and methods form the earlier courses in this specialization. You will analyze a data set simulating big data generated from a large number of users who are playing our imaginary game ""Catch the Pink Flamingo"". During the five week Capstone Project, you will walk through the typical big data science steps for acquiring, exploring, preparing, analyzing, and reporting. In the first two weeks, we will introduce you to the data set and guide you through some exploratory analysis using tools such as Splunk and Open Office. Then we will move into more challenging big data problems requiring the more advanced tools you have learned including KNIME, Spark's MLLib and Gephi. Finally, during the fifth and final week, we will show you how to bring it all together to create engaging and compelling reports and slide presentations. As a result of our collaboration with Splunk, a software company focus on analyzing machine-generated big data, learners with the top projects will be eligible to present to Splunk and meet Splunk recruiters and engineering leadership.
      


          Simulating Big Data for an Online Game
    -This week we provide an overview of the Eglence, Inc. Pink Flamingo game, including various aspects of the data which the company has access to about the game and users and what we might be interested in finding out.

Acquiring, Exploring, and Preparing the Data
    -Next, we begin working with the simulated game data by exploring and preparing the data for ingestion into big data analytics applications.

Data Classification with KNIME
    -This week we do some data classification using KNIME. 

Clustering with Spark
    -This week we do some clustering with Spark. 

Graph Analytics of Simulated Chat Data With Neo4j
    -This week we apply what we learned from the 'Graph Analytics With Big Data' course to simulated chat data from Catch the Pink Flamingos using Neo4j. We analyze player chat behavior to find ways of improving the game. 

Reporting and Presenting Your Work

Final Submission",Big Data - Capstone Project
https://www.classcentral.com/course/ds-10631,"Apache Spark is the de-facto standard for large scale data processing. This is the first course of a series of courses towards the IBM Advanced Data Science Specialization. We strongly believe that is is crucial for success to start learning a scalable data science platform since memory and CPU constraints are to most limiting factors when it comes to building advanced machine learning models.

In this course we teach you the fundamentals of Apache Spark using python and pyspark. We'll introduce Apache Spark in the first two weeks and learn how to apply it to compute basic exploratory and data pre-processing tasks in the last two weeks. Through this exercise you'll also be introduced to the most fundamental statistical measures and data visualization technologies.

This gives you enough knowledge to take over the role of a data engineer in any modern environment. But it gives you also the basis for advancing your career towards data science. 

Please have a look at the full specialization curriculum:
https://www.coursera.org/specializations/advanced-data-science-ibm

If you choose to take this course and earn the Coursera course certificate, you will also earn an IBM digital badge.  To find out more about IBM digital badges follow the link ibm.biz/badging.


After completing this course, you will be able to:
•	Describe how basic statistical measures, are used to reveal  patterns within the data 
•	Recognize data characteristics, patterns, trends, deviations or inconsistencies, and potential outliers.
•	Identify useful techniques for working with big data such as dimension reduction and feature selection methods 
•	Use advanced tools and charting libraries to:
      o	improve efficiency of analysis of big-data with partitioning and parallel analysis 
      o	Visualize the data in an number of 2D and 3D formats (Box Plot, Run Chart, Scatter Plot, Pareto Chart, and Multidimensional Scaling)

For successful completion of the course, the following prerequisites are recommended: 
•	Basic programming skills in python
•	Basic math
•	Basic SQL (you can get it easily from https://www.coursera.org/learn/sql-data-science if needed)

In order to complete this course, the following technologies will be used:
(These technologies are introduced in the course as necessary so no previous knowledge is required.)
•	Jupyter notebooks (brought to you by IBM Watson Studio for free)
•	ApacheSpark (brought to you by IBM Watson Studio for free)
•	Python

We've been reported that some of the material in this course is too advanced. So in case you feel the same, please have a look at the following materials first before starting this course, we've been reported that this really helps.

Of course, you can give this course a try first and then in case you need, take the following courses / materials. It's free...

https://cognitiveclass.ai/learn/spark

https://dataplatform.cloud.ibm.com/analytics/notebooks/v2/f8982db1-5e55-46d6-a272-fd11b670be38/view?access_token=533a1925cd1c4c362aabe7b3336b3eae2a99e0dc923ec0775d891c31c5bbbc68

This course takes four weeks, 4-6h per week
      


            Read more
          



          Introduction the course and grading environment

Tools that support BigData solutions

Scaling Math for Statistics on Apache Spark

Data Visualization of Big Data",Fundamentals of Scalable Data Science
https://www.classcentral.com/course/canvas-network-caring-science-mindful-practice-3630,"This course provides tools to help caring professionals enhance professional caring practices in everyday work environments. Learners will be introduced to Watson’s Caring Science. Exploration and learning related to key concepts will be supported through the introduction of mindfulness practice, reflective narrative, and contemplative art. Asynchronous discussion, moderated by a team of educators knowledgeable in Caring Science, will provide a forum for ongoing interaction and discovery among participants during each eight-week class session. Participants who complete all of the course learning modules will earn certificates of completion.
Upon completion of this course, participants will be able to:

Explain Watson’s 10 Caritas Processes.
Describe how mindfulness practice might be useful in supporting deepened understanding and practice of Caring Science.
Provide professional examples that illustrate Watson’s 10 Caritas.
Provide professional examples that illustrate Transpersonal Caring Moments.
Discuss how Watson’s Caritas Consciousness Touchstones for Cultivating Love might be useful in everyday professional caring practice.

Teaching strategies include:

Course-specific reading materials in either print and/or online formats
Asynchronous online postings and discussion boards
Online reflective journaling
Multimedia presentations as appropriate in the online setting

Topical areas include:

Mindfulness and cultivating understanding of Watson’s Theory of Caring
Overview of Watson’s Theory
Thich Nhat Hanh’s 5 mindfulness trainings
Transpersonal Caring Moments
The 10 Caritas
Caritas Consciousness Touchstones for Cultivating Love

This class will be pass/fail. Students earning 80% of the total points available in the course will receive a passing grade and earn the corresponding certificate of completion.
Required textbook:
Sitzman, K., Watson, J. (2014). Caring Science, Mindful Practice. New York, New York: Springer Publishing.



            Read more","Caring Science, Mindful Practice"
https://www.classcentral.com/course/improving-statistical-questions-17049,"This course aims to help you to ask better statistical questions when performing empirical research. We will discuss how to design informative studies, both when your predictions are correct, as when your predictions are wrong. We will question norms, and reflect on how we can improve research practices to ask more interesting questions. In practical hands on assignments you will learn techniques and tools that can be immediately implemented in your own research, such as thinking about the smallest effect size you are interested in, justifying your sample size, evaluate findings in the literature while keeping publication bias into account, performing a meta-analysis, and making your analyses computationally reproducible.

If you have the time, it is recommended that you complete my course 'Improving Your Statistical Inferences' before enrolling in this course, although this course is completely self-contained.
      


          Module 1: Improving Your Statistical Questions
    -One of the biggest improvements most researchers can make is to more clearly specify their statistical questions. When you perform a study, what is it you really want to know?
What are different types of questions we can ask? Which question does a hypothesis test really answer, and is this answer actually what you are interested in, or is the question you are asking more about exploration, description, or prediction? How can we make riskier predictions than null-hypothesis tests, and why is this useful?

Module 2: Falsifying Predictions
    -There is little use in making predictions if you can never be wrong - so how do we make sure your predictions are falsifiable? We discuss why falsifiable predictions are important, and how to make your predictions falsifiable in practice. One important aspect of making predictions falsifiable is to specify a range of values that is not predicted, and we will examine different approaches to specifying a smallest effect size of interest.

Module 3: Designing Informative Studies
    -If studies are designed to answer a question, you should make sure the answer you will get after collecting data is informative. Instead of mindlessly setting Type 1 and Type 2 error rates, we will learn why it is important to be able to justify error rates, and some approaches how to do so. We discuss the benefits of using your smallest effect size of interest in power analyses, and why learning to simulate data is a useful tool. Simulations can help you to improve your understanding of statistics, enable you to design informative studies, and even ask novel questions.

Module 4: Meta-Analysis and Bias Detection
    -Regrettably we work in a scientific enterprise where the published literature does not reflect real research. Publication bias and selection biases lead to a scientific literature that can’t be interpreted without taking these biases into account. We will discuss what real research lines look like, and how to meta-analytically evaluate the literature while keeping bias in mind.

Module 5: Computational Reproducibility, Philosophy of Science, and Scientific Integrity
    -We discuss three last topics. First, we will make sure other people can use your data to ask new questions, by making sure your data analysis is computationally reproducible. Then, we will reflect on how your philosophy of science influences the types of questions you will ask, and what you value as you do research. Finally, we discuss scientific integrity, and reflect on why our research practice is not always aligned with the best possible ways to provide reliable answers to scientific questions.

Module 6: Final Exam
    -This module contains a graded exam. It covers content from the entire course. We recommend making this exam only after you went through all the other modules.",Improving Your Statistical Questions
https://www.classcentral.com/course/janux-physical-geology-for-science-and-engineering-majors-1590,"This course is an introduction to the basic principles of geology and is a general education course for science and engineering majors. It serves both as an introduction for those planning to continue in geology and as a comprehensive overview of geology for students in other fields. This course will also emphasize the social, economic, and political implications of geology processes.",Physical Geology for Science and Engineering majors
https://www.classcentral.com/course/udacity-introduction-to-machine-learning-course-2996,"Machine Learning is a first-class ticket to the most exciting careers in data analysis today. As data sources proliferate along with the computing power to process them, going straight to the data is one of the most straightforward ways to quickly gain insights and make predictions.  Machine learning brings together computer science and statistics to harness that predictive power. It’s a must-have skill for all aspiring data analysts and data scientists, or anyone else who wants to wrestle all that raw data into refined trends and predictions.This is a class that will teach you the end-to-end process of investigating data through a machine learning lens. It will teach you how to extract and identify useful features that best represent your data, a few of the most important machine learning algorithms, and how to evaluate the performance of your machine learning algorithms.This course is also a part of our Data Analyst Nanodegree.Why Take This Course?In this course, you’ll learn by doing! We’ll bring machine learning to life by showing you fascinating use cases and tackling interesting real-world problems like self-driving cars. For your final project you’ll mine the email inboxes and financial data of Enron to identify persons of interest in one of the greatest corporate fraud cases in American history.When you finish this introductory course, you’ll be able to analyze data using machine learning techniques, and you’ll also be prepared to take our Data Analyst Nanodegree. We’ll get you started on your machine learning journey by teaching you how to use helpful tools, such as pre-written algorithms and libraries, to answer interesting questions.



            Read more
          



You’ll learn how to start with a question and/or a dataset, and use machine learning to turn them into insights. Lessons 1-4: Supervised ClassificationNaive Bayes: We jump in headfirst, learning perhaps the world’s greatest algorithm for classifying text.Support Vector Machines (SVMs): One of the top 10 algorithms in machine learning, and a must-try for many classification tasks.  What makes it special?  The ability to generate new features independently and on the fly.Decision Trees: Extremely straightforward, often just as accurate as an SVM but (usually) way faster.  The launch point for more sophisticated methods, like random forests and boosting.Lesson 5: Datasets and QuestionsBehind any great machine learning project is a great dataset that the algorithm can learn from.  We were inspired by a treasure trove of email and financial data from the Enron corporation, which would normally be strictly confidential but became public when the company went bankrupt in a blizzard of fraud.  Follow our lead as we wrestle this dataset into a machine-learning-ready format, in anticipation of trying to predict cases of fraud.Lesson 6 and 7: Regressions and OutliersRegressions are some of the most widely used machine learning algorithms, and rightly share prominence with classification.  What’s a fast way to make mistakes in regression, though?  Have troublesome outliers in your data.  We’ll tackle how to identify and clean away those pesky data points.Lesson 8: Unsupervised LearningK-Means Clustering: The flagship algorithm when you don’t have labeled data to work with, and a quick method for pattern-searching when approaching a dataset for the first time.Lessons 9-12: Features, Features, FeaturesFeature Creation: Taking your human intuition about the world and turning it into data that a computer can use.Feature Selection: Einstein said it best: make everything as simple as possible, and no simpler.  In this case, that means identifying the most important features of your data.Principal Component Analysis: A more sophisticated take on feature selection, and one of the crown jewels of unsupervised learning.Feature Scaling: Simple tricks for making sure your data and your algorithm play nicely together.Learning from Text: More information is in text than any other format, and there are some effective but simple tools for extracting that information.Lessons 13-14: Validation and EvaluationTraining/testing data split: How do you know that what you’re doing is working?  You don’t, unless you validate.  The train-test split is simple to do, and the gold standard for understanding your results.Cross-validation: Take the training/testing split and put it on steroids.  Validate your machine learning results like a pro.Precision, recall, and F1 score:  After all this data-driven work, quantify your results with metrics tailored to what is most important to you.Lesson 15: Wrapping it all UpWe take a step back and review what we’ve learned, and how it all fits together.  ProjectsMini-project at the end of each lessonFinal project: searching for signs of corporate fraud in Enron data",Introduction to Machine Learning Course
https://www.classcentral.com/course/biostats2-1033,"Learn fundamental concepts in data analysis and statistical inference, focusing on one and two independent samples.
      


          Hypothesis Testing
    -In this module, you'll get an introduction to hypothesis testing, a core concept in statistics. We'll cover hypothesis testing for basic one and two group settings as well as power. After you've watched the videos and tried the homework, take a stab at the quiz.

Two Binomials
    -In this module we'll be covering some methods for looking at two binomials. This includes the odds ratio, relative risk and risk difference. We'll discussing mostly confidence intervals in this module and will develop the delta method, the tool used to create these confidence intervals. After you've watched the videos and tried the homework, take a crack at the quiz!

Discrete Data Settings
    -In this module, we'll discuss testing in discrete data settings. This includes the famous Fisher's exact test, as well as the many forms of tests for contingency table data. You'll learn the famous observed minus expected squared over the expected formula, that is broadly applicable. 

Techniques
    -This module is a bit of a hodge podge of important techniques. It includes methods for discrete matched pairs data as well as some classical non-parametric methods.",Mathematical Biostatistics Boot Camp 2
https://www.classcentral.com/course/edx-learning-from-data-introductory-machine-learning-course-1240,"This introductory computer science course in machine learning will cover basic theory, algorithms, and applications. Machine learning is a key technology in Big Data, and in many financial, medical, commercial, and scientific applications. It enables computational systems to automatically learn how to perform a desired task based on information extracted from the data. Machine learning has become one of the hottest fields of study today and the demand for jobs is only expected to increase. Gaining skills in this field will get you one step closer to becoming a data scientist or quantitative analyst.
This course balances theory and practice, and covers the mathematical as well as the heuristic aspects. The lectures follow each other in a story-like fashion:

What is learning?
Can a machine learn?
How to do it?
How to do it well?
Take-home lessons.




The topics in the story line are covered by 18 lectures of about 60 minutes each plus Q&A.

Lecture 1: The Learning Problem
Lecture 2: Is Learning Feasible?
Lecture 3: The Linear Model I
Lecture 4: Error and Noise
Lecture 5: Training versus Testing
Lecture 6: Theory of Generalization
Lecture 7: The VC Dimension
Lecture 8: Bias-Variance Tradeoff
Lecture 9: The Linear Model II
Lecture 10: Neural Networks
Lecture 11: Overfitting
Lecture 12: Regularization
Lecture 13: Validation
Lecture 14: Support Vector Machines
Lecture 15: Kernel Methods
Lecture 16: Radial Basis Functions
Lecture 17: Three Learning Principles
Lecture 18: Epilogue",Learning From Data (introductory Machine Learning course)
https://www.classcentral.com/course/edx-case-study-dna-methylation-data-analysis-2980,"In the PH525 case studies, we will explore the data analysis of an experimental protocol in depth, using various open source software, including R and Bioconductor. We will explain how to start with raw data, and perform the standard processing and normalization steps to get to the point where one can investigate relevant biological questions. Throughout the case studies, we will make use of exploratory plots to get a general overview of the shape of the data and the result of the experiment.
We will learn the basic steps in analyzing DNA methylation data, including reading the raw data, normalization, and finding regions of differential methylation across multiple samples.
This class was supported in part by NIH grant R25GM114818.
This course is part of a larger set of 8 total courses running Self-Paced through September 15th, 2015:

PH525.1x: Statistics and R for the Life Sciences
PH525.2x: Introduction to Linear Models and Matrix Algebra
PH525.3x: Advanced Statistics for the Life Sciences
PH525.4x: Introduction to Bioconductor
PH525.5x: Case study: RNA-seq data analysis
PH525.6x: Case study: Variant Discovery and Genotyping
PH525.7x: Case study: ChIP-seq data analysis
PH525.8x: Case study: DNA methylation data analysis
HarvardX requires individuals who enroll in its courses on edX to abide by the terms of the edX honor code. HarvardX will take appropriate corrective action in response to violations of the edX honor code, which may include dismissal from the HarvardX course; revocation of any certificates received for the HarvardX course; or other remedies as circumstances warrant. No refunds will be issued in the case of corrective action for such violations. Enrollees who are taking HarvardX courses as part of another program will also be governed by the academic policies of those programs.
HarvardX pursues the science of learning. By registering as an online learner in an HX course, you will also participate in research about learning. Read our research statement to learn more.
Harvard University and HarvardX are committed to maintaining a safe and healthy educational and work environment in which no member of the community is excluded from participation in, denied the benefits of, or subjected to discrimination or harassment in our program. All members of the HarvardX community are expected to abide by Harvard policies on nondiscrimination, including sexual harassment, and the edX Terms of Service. If you have any questions or concerns, please contact harvardx@harvard.edu and/or report your experience through the edX contact form.



            Read more",Case study: DNA methylation data analysis
https://www.classcentral.com/course/behavioralgenetics-1765,"Behavioral genetic methodologies from twin and adoption studies through DNA analysis will be described and applied to address longstanding questions about the origins of individual differences in behavioral traits.
      


          1
    -Unit # 1: Course Introduction and OverviewOverview:    Unit # 1 provides an overview to the field of human behavioral genetics and to this course. We will begin by discussing the early history of the field and how behavioral genetic research influenced and was influenced by the eugenics movement. Once this historical context has been established, we will define the field of behavioral genetics and use this definition to provide an overview of the course. This week’s lectures will end with two case studies that illustrate the importance of behavioral genetic approaches. The first is the famous John/Joan case, where one member of a monozygotic twin pair was raised as a boy and the other as a girl. The second is the human genetic disorder Phenylketonuria (PKU), which has been recognized as a paradigm of human genetic disease since its discovery in 1934.Unit Objectives:     At the end of this unit you should know•	The history of the founding of the field of behavioral genetics•	What the eugenics movement was and how it impacted psychology and behavioral genetics•	What the field of behavioral genetics covers•	How the John/Joan case represented the extreme of the “Blank Slate” mentality within psychology•	Why Phenylketonuria is considered a public health success and model of human genetic diseaseLecture Modules:A.	The Nature-Nurture Debate and Founding of Behavioral GeneticsB.                               The Eugenics MovementC.	What is Behavioral GeneticsD.	The John/Joan CaseE.	Phenylketonuria (PKU) F.     Huntington Disease (Supplemental)

2
    -In Unit #2 the twin study method will be introduced and general findings from twin studies in psychology and psychiatry will be reviewed. The two types of twins, monozygotic (MZ) and dizygotic (DZ), will be described and methods for assessing their similarity will be given. We will also look critically at the limitations of the twin study method and discuss alternative research designs, including adoption studies and the study of reared-apart twins. The importance of convergent evidence from multiple research designs will be emphasized.

3
    -Some of the most contentious issues in behavioral genetics surround the concept of heritability – Is it a meaningful statistic? Can it be accurately estimated in studies on humans? How should it be interpreted? In this unit we will discuss what is meant by heritability and describe some simple biometric (i.e., quantitative genetic) methods used for it estimation. The unit begins with a review of basic Mendelian inheritance and the introduction of some genetic terminology we will begin to use in the course. The ACE model of quantitative inheritance is described and we will discuss how this model is used to analyze twin data. Finally, the important concept of gene-environment interaction is formally introduced. Beginning this week with quantitative genetics and continuing next week with molecular genetics we will be jumping head first into the thicket of human genetic methodology. For some, this material may be more challenging than that which we covered in the first two weeks of this course. These weeks will, however, provide the foundation we will need to investigate in depth behavioral genetic research on schizophrenia and intelligence in weeks 5 and 6. Please make sure to post questions you have to the discussion forums and especially to the office hours forum.  

4
    -The Human Genome Project (HGP) was begun in 1990 and declared complete in 2003. It has revolutionized our understanding of genetics and will ultimately revolutionize medical practice. In my opinion, every educated citizen should know some basic findings from the HGP. This week’s lectures provide an introduction to molecular biology and the HGP. We will cover topics such as: What is DNA? What is a gene and how are genes structured? In what ways can human genomes differ? What is epigenetics and why do some researchers believe it is very important for understanding behavior? As in previous lectures, I will illustrate some of the basic human genetic phenomena through case studies, in this case ranging from calico cats to the human genetic disorders of Angelman and Prader-Willi syndromes.  
This week’s lectures continue what we began last week:  laying the foundation of genetic concepts and processes we will need to consider in some depth genetic research on schizophrenia and intelligence. Some participants in this course already have an extensive background in basic genetics and so will be very knowledgeable about material covered in the initial modules. But I think even these participants will have something to learn when we get to the later modules in the unit covering, e.g., Williams Syndrome, Prader-Willi Syndrome and Angelman Syndrome. For those with a more limited background in genetics, I recognize that the terminology introduced this week may at first seem a bit daunting. But if you stick with it, terms such as SNPs, methylation, exon, copy number variants, etc. which seem foreign now will become consolidated in your vocabulary through repeated use throughout the remaining lectures in this course.
There are several learning aids I would encourage you to use. First, we have created a Glossay, which you can link to off the navigation bar on the course website. Second, the Discussion Forums are a wonderful source of help. Other participants can be very helpful in answering your questions and a post in the Office Hours thread will be reviewed by us for response in the weekly office hour video. Finally, we give again online genetics education links in the Other Resources section below.  


5
    -Now that we have a foundation in basic biometric and molecular genetics we can begin to look in depth at genetic research for behavioral phenotypes. This week we will focus on schizophrenia. There are several reasons for this focus. First, genetics research has fundamentally changed the way researchers and mental health professionals think about this devastating illness; schizophrenia illustrates the successes as well as the limitations of the genetic approach to a psychiatric illness. Second, research on schizophrenia exemplifies what genetic researchers are finding with most common mental illnesses. Although, for example, the exact chromosomal locations of risk variants and the specific candidate genes implicated certainly vary from one psychiatric illness to the next, the basic features of the genetic architecture appears to be remarkably similar across multiple psychiatric illnesses, at least at this time. So an understanding of the genetics of schizophrenia will bring with it an understanding of much of psychiatric genetics.            
Before discussing the genetics research, however, I think it useful that we all know at least a little about what schizophrenia is. Thus the first two modules in this unit describe the clinical phenotype and some of its basic epidemiology, information that will no doubt be very familiar to those of you with a background in clinical psychology or psychiatry. Twin and adoption studies helped to establish the heritable nature of schizophrenia (Module C) and characterize the nature of environmental influence (Module D). The current frontier in genetics research on schizophrenia is to identify the specific genetic variants that underlie its heritability. Initial attempts at identifying risk alleles using the positional cloning strategy were generally unsuccessful yet provided key insights into the nature of the disorder (Module E). Very recently, important breakthroughs have been achieved through Genome Wide Association Studies (GWAS; Module F) and rare variant analysis (Module G).     
Although the basic foundation for this course was introduced in Units 1-4 and we strive to minimize our use of jargon, sometimes the technical term is exactly what is needed and we will continue to introduce new terms throughout the remainder of the course. So please make use of the Glossary (linked on the navigation bar). We created it in the hope it would help minimize the impact technical jargon might have on your mastering the lecture material. 

6
    -If there is an area of psychology that generates more heated debate than behavioral genetics it would be the field of intelligence research. While most of us acknowledge the differences among us in personality and even risk for mental illness, for some of us differences in intelligence seem more difficult to accept. I confess I am not completely sure why this is the case. Maybe it is because of the involvement of early intelligence researchers with the Eugenics Movement. Alternatively, maybe it is because the conclusions reached by some intelligence researchers seem to challenge our long-held beliefs about social equality, especially when those conclusions are biologically grounded. Regardless, intelligence, or as I prefer to call it general cognitive ability (GCA), has been a major focus of behavioral genetic research and we will use it as a prototype of behavioral genetic research on a quantitative psychological trait.As with the previous unit, we will begin with a brief discussion of what psychologists mean by intelligence or GCA. I will not try and review the vast empirical literature on the correlates of GCA; suffice to say that GCA is correlated, not always strongly, with many desirable outcomes including educational attainment, occupational achievement, health, mortality, criminal conviction, etc. Twin and adoption studies of GCA have implicated the importance of both genetic and nonshared as well as shared environmental influences. Behavioral genetic research has helped to identify features of the shared environment that appear to contribute to differences in intelligence, but, unlike with schizophrenia and other mental illnesses, it has been difficult to identify the specific genetic variants that contribute to the heritability of GCA.  This unit will end with a discussion of genetic research on intellectual disability, an important application of intelligence research.Just FYI, one thing we will NOT consider in this unit but some of you will wonder about is developmental behavioral genetic research on intelligence. I promise that it will be covered in Unit 7.

7
    -I am sure many of you wondered about the impact of age on biometric estimates when we discussed general cognitive ability last week. Indeed some of you asked about this issue on the Forums. You were right to raise the question because this is an important issue in the behavioral genetic literature. Given its importance, I thought it might work best to place the question of age moderation in a larger context, which we do this week. We will begin the week by returning to the distinction between shared and non-shared environmental influences, an important distinction in the behavioral genetic literature. You will see that while shared environmental influences are not important for most behavioral phenotypes, there are a few exceptions (including general cognitive ability). However, in all of these exceptional cases, the magnitude of shared environmental influences decreases with age as the heritability increases.
To understand this developmental pattern, at least from a behavioral genetic perspective, it is helpful to consider mechanisms of gene-environment correlation as well as behavioral genetic perspectives on family socialization. We end this unit with an overview of behavioral genetic research on aging.


8
    -It is hard to believe we are already to the 8th and final week of the course. This unit begins with an overall summary of human behavioral genetic research organized around four general findings, or ‘laws’ of behavioral genetic research. We will then consider, I suppose more accurate speculate about, the application of behavioral genetic research in the field of individualized or genomic medicine and the implications of behavioral genetic research for personal responsibility. This week’s lectures will also include an interview with Professor Irving Gottesman, a pioneer in the field who undertook pioneering behavioral genetic research on schizophrenia and personality.",Introduction to Human Behavioral Genetics
https://www.classcentral.com/course/python-data-visualization-8445,"In the capstone, students will build a series of applications to retrieve, process and visualize data using Python.   The projects will involve all the elements of the specialization.  In the first part of the capstone, students will do some visualizations to become familiar with the technologies in use and then will pursue their own project to visualize some other data that they have or can find.  Chapters 15 and 16 from the book “Python for Everybody” will serve as the backbone for the capstone. This course covers Python 3.
      


          Welcome to the Capstone
    -Congratulations to everyone for making it this far. Before you begin, please view the Introduction video and read the Capstone Overview. The Course Resources section contains additional course-wide material that you may want to refer to in future weeks.

Building a Search Engine
    -This week we will download and run a simple version of the Google PageRank Algorithm and practice spidering some content. The assignment is peer-graded, and the first of three optional Honors assignments in the course. This a continuation of the material covered in Course 4 of the specialization, and is based on Chapter 16 of the textbook. 

Exploring Data Sources (Project)
    -The optional Capstone project is your opportunity to select, process, and visualize the data of your choice, and receive feedback from your peers.  The project is not graded, and can be as simple or complex as you like. This week's assignment is to identify a data source and make a short discussion forum post describing the data source and outlining some possible analysis that could be done with it. You will not be required to use the data source presented here for your actual analysis.

Spidering and Modeling Email Data
    -In our second optional Honors assignment, we will retrieve and process email data from the Sakai open source project. Video lectures will walk you through the process of retrieving, cleaning up, and modeling the data.

Accessing New Data Sources (Project)
    -The task for this week is to make a discussion thread post that reflects the progress you have made to date in retrieving and cleaning up your data source so can perform your analysis.  Feedback from other students is encouraged to help you refine the process.

Visualizing Email Data
    -In the final optional Honors assignment, we will do two visualizations of the email data you have retrieved and processed: a word cloud to visualize the frequency distribution and a timeline to show how the data is changing over time.

Visualizing new Data Sources (Project)
    -This week you will discuss the analysis of your data to the class. While many of the projects will result in a visualization of the data, any other results of analyzing the data are equally valued, so use whatever form of analysis and display is most appropriate to the data set you have selected.","Capstone: Retrieving, Processing, and Visualizing Data with Python"
https://www.classcentral.com/course/dbessentials-4337,"Database Management Essentials provides the foundation you need for a career in database development, data warehousing, or business intelligence, as well as for the entire Data Warehousing for Business Intelligence specialization. In this course, you will create relational databases, write SQL statements to extract information to satisfy business reporting requests, create entity relationship diagrams (ERDs) to design databases, and analyze table designs for excessive redundancy. As you develop these skills, you will use either Oracle or MySQL to execute SQL statements and a database diagramming tool such as the ER Assistant or Visual Paradigm to create ERDs. We’ve designed this course to ensure a common foundation for specialization learners. Everyone taking the course can jump right in with writing SQL statements in Oracle or MySQL.
      


          Course Introduction
    -Module 1 provides the context for Database Management Essentials. When you’re done, you’ll understand the objectives for the course and know what topics and assignments to expect. Keeping these course objectives in mind will help you succeed throughout the course! You should read about the database software requirements in the last lesson of module 1. I recommend that you try to install the DBMS software this week before assignments begin in week 2.

Introduction to Databases and DBMSs
    -We’ll launch into an exploration of databases and database technology and their impact on organizations in Module 2. We’ll investigate database characteristics, database technology features, including non-procedural access, two key processing environments, and an evolution of the database software industry. This short informational module will ensure that we all have the same background and context, which is critical for success in the later modules that emphasize details and hands-on skills.


Relational Data Model and the CREATE TABLE Statement
    -Now that you have the informational context for database features and environments, you’ll start building! In this module, you’ll learn relational data model terminology, integrity rules, and the CREATE TABLE statement. You’ll apply what you’ve learned in practice and graded problems using a database management system (DBMS), either Oracle or MySQL, creating tables using the SQL CREATE TABLE statement and populating your tables using given SQL INSERT statements.


Basic Query Formulation with SQL
    -This module is all about acquiring query formulation skills. Now that you know the relational data model and have basic skills with the CREATE TABLE statement, we can cover basic syntax of the SQL SELECT statement and the join operator for combining tables. SELECT statement examples are presented for single table conditions, join operations, and grouping operations. You’ll practice writing simple SELECT statements using the tables that you created in the assignment for module 3.


Extended Query Formulation with SQL
    -Now that you can identify and use the SELECT statement and the join operator, you’ll extend your problem solving skills in this module so you can gain confidence on more complex queries. You will work on retrieval problems with multiple tables and grouping. In addition, you’ll learn to use the UNION operator in the SQL SELECT statement and write SQL modification statements.


Notation for Entity Relationship Diagrams
    -Module 6 represents another shift in your learning. In previous modules, you’ve created and populated tables and developed query formulation skills using the SQL SELECT statement. Now you’ll start to develop skills that allow you to create a database design to support business requirements. You’ll learn basic notation used in entity relationship diagrams (ERDs), a graphical notation for data modeling. You will create simple ERDs using basic diagram symbols and relationship variations to start developing your data modeling skills. 


ERD Rules and Problem Solving
    -Module 7 builds on your knowledge of database development using basic ERD symbols and relationship variations. We’ll be practicing precise usage of ERD notation and basic problem solving skills. You will learn about diagram rules and work problems to help you gain confidence using and creating ERDs.


Developing Business Data Models
    -In Module 8, you’ll use your ERD notation skills and your ability to avoid diagram errors to develop ERDs that satisfy specific business data requirements. You will learn and practice powerful problem-solving skills as you analyze narrative statements and transformations to generate alternative ERDs.


Data Modeling Problems and Completion of an ERD
    -Now that you have practiced data modeling techniques, you’ll get to wrestle with narrative problem analyses and transformations for generating alternative database designs in Module 9. At the end of this module, you’ll learn guidelines for documentation and detection of design errors that will serve you well as you design databases for business situations.


Schema Conversion
    -Modules 6 to 9 covered conceptual data modeling, emphasizing precise usage of ERD notation, analysis of narrative problems, and generation of alternative designs. Modules 10 and 11 cover logical database design, the next step in the database development process. In Module 10, we’ll cover schema conversion, the first step in the logical database design phase. You will learn to convert an ERD into a table design that can be implemented on a relational DBMS.


Normalization Concepts and Practice
    -Module 11 covers normalization, the second part of the logical database design process. Normalization provides tools to remove unwanted redundancy in a table design. You’ll discover the motivation for normalization, constraints to reason about unwanted redundancy, and rules that detect excessive redundancy in a table design. You’ll practice integrating and applying normalization techniques in the final lesson of this course.",Database Management Essentials
https://www.classcentral.com/course/material-science-engineering-6210,"Have you ever wondered why ceramics are hard and brittle while metals tend to be ductile?  Why some materials conduct heat or electricity while others are insulators?  Why adding just a small amount of carbon to iron results in an alloy that is so much stronger than the base metal?  In this course, you will learn how a material’s properties are determined by the microstructure of the material, which is in turn determined by composition and the processing that the material has undergone.

This is the second of three Coursera courses that mirror the Introduction to Materials Science class that is taken by most engineering undergrads at Georgia Tech.  The aim of the course is to help students better understand the engineering materials that are used in the world around them.  This first section covers the fundamentals of materials science including atomic structure and bonding, crystal structure, atomic and microscopic defects, and noncrystalline materials such as glasses, rubbers, and polymers.
      


          Phase Diagrams and Phase Equilibria
    -This course picks up with an overview of basic thermodynamics and kinetics as they pertain to the processing of crystalline materials.  The first module deals with phase diagrams - charts that tell us how a material will behave given a certain set of variables such as temperature, pressure, and composition.  You will learn how to interpret common and complex phase diagrams and how to extract useful information from them.

Kinetics of Structural Transformations
    -If thermodynamics, which we covered in the previous module, tells us how a material wants to change, then kinetics tells us how and how quickly that transformation occurs.  This module starts by explaining the driving force for phase transformations.  We will cover the nucleation and growth of precipitates, solidification, and sintering.  Finally, there are a number of lessons which apply all that has been covered in the course to understanding carbon steels.",Material Processing
https://www.classcentral.com/course/machine-learning-asset-management-alternative-dat-17098,"Over-utilization of market and accounting data over the last few decades has led to portfolio crowding, mediocre performance and systemic risks, incentivizing financial institutions which are looking for an edge to quickly adopt alternative data as a substitute to traditional data. This course introduces the core concepts around alternative data, the most recent research in this area, as well as practical portfolio examples and actual applications. The approach of this course is somewhat unique because while the theory covered is still a main component, practical lab sessions and examples of working with alternative datasets are also key. This course is fo you if you are aiming at carreers prospects as a data scientist in financial markets, are looking to enhance your analytics skillsets to the financial markets, or if you are interested in cutting-edge technology and research as  they apply to big data. The required background is: Python programming, Investment theory , and Statistics. This course will enable you to learn new data and research techniques applied to the financial markets while strengthening data science and python skills.
      


          Consumption
    -The consumption module introduces students to the basics of consumption-based alternative data. 
By aggregating online and offline consumer purchase activity and behavioral datasets including geolocation data (e.g., cell locations, satellite imagery etc.), transaction data (e.g.,  credit card transaction logs and point of sale data), as well as consumer interaction with brands and products on social media, researchers can learn about company performance ahead of official company earning announcements. 
Such information may be extremely useful and can provide investment and risk management advantages. This module reviews the theoretical aspects of various consumption datasets, and provides practical demonstrations of relevant data analytics.

Textual Analysis for Financial Applications
    -Module 2 is an introduction to text mining as well as a demonstration of how to get from data retrieval (web scraping) to financial market insights. Some of the classic text mining methodologies are covered such as vectorization of text (the bag of words approach), stop words for filtering, and term frequency-inverse document frequency (TF-IDF). Students will learn how text can be mathematically represented, and regularized/filtered to reduce noise. Measures of text-similarity will be covered in theoretical and practice sessions. Lab sessions go through examples of web scraping data, regularizing with the described techniques and finally, insights will be derived from the textual data.

Processing Corporate Filings
    -Module 3 is a practical extension of the text mining lessons to 10-K and 13-F, two of the most commonly researched corporate filings. This type of data can be extremely daunting when used by individual analysts due to the sheer size of the documents, but module 3 describes the methodologies for quantitatively analyzing these documents with Python code. Both the 10-K and 13-F documents are worked through, and within the lab sessions it is demonstrated how one can automatically pull this kind of data as well as define metrics around them. We investigate implementations of research in this field around similarity of given companies 10-K statements over time as well as similarity between fund holdings from the 13-F in the lab.

Using Media-Derived Data
    -The final module introduces both sentiment analysis in the context of textual data as well as network analysis in the context of connectivity of firms. Sentiment analysis is an avenue of potentially fruitful information that when done correctly can display what a general population might believe about a company (through for example social media) or even whether the company itself is positive or negative on future outlook (through analysis of tone in corporate filings). Network analysis, as shown in the research of course instructors and his colleagues, can be used to accurately capture how a financial network is oriented and what companies might perform well because of other firm’s mentioning them as a threat. The lab session of this module extends the corporate filings analysis to examine sentiment while also introducing a set of tweets which are then transformed into a network representation.",Python and Machine-Learning for Asset Management with Alternative Data Sets
https://www.classcentral.com/course/data-genes-medicine-7193,"This course distills for you expert knowledge and skills mastered by professionals in Health Big Data Science and Bioinformatics. You will learn exciting facts about the human body biology and chemistry, genetics, and medicine that will be intertwined with the science of Big Data and skills to harness the avalanche of data openly available at your fingertips and which we are just starting to make sense of. We’ll investigate the different steps required to master Big Data analytics on real datasets, including Next Generation Sequencing data, in a healthcare and biological context, from preparing data for analysis to completing the analysis, interpreting the results, visualizing them, and sharing the results.

Needless to say, when you master these high-demand skills, you will be well positioned to apply for or move to positions in biomedical data analytics and bioinformatics. No matter what your skill levels are in biomedical or technical areas, you will gain highly valuable new or sharpened skills that will make you stand-out as a professional and want to dive even deeper in biomedical Big Data. It is my hope that this course will spark your interest in the vast possibilities offered by publicly available Big Data to better understand, prevent, and treat diseases.
      


          Genes and Data
    -After this module, you will be able to
1. Locate and download files for data analysis involving genes and medicine.
2. Open files and preprocess data using R language.
3. Write R scripts to replace missing values, normalize data, discretize data, and sample data.


Preparing Datasets for Analysis
    -After this module, you will be able to: 
1. Locate and download files for data analysis involving genes and medicine.
2. Open files and preprocess data using R language.
3. Write R scripts to replace missing values, normalize data, discretize data, and sample data.


Finding Differentially Expressed Genes
    -After this module, you will be able to
1. Select features from highly dimensional datasets.
2. Evaluate the performance of feature selection methods.
3. Write R scripts to select features from datasets involving gene expressions.


Predicting Diseases from Genes
    -After this module, you will be able to
1. Build classification and prediction models.
2. Evaluate the performance of classification and prediction methods.
3. Write R scripts to classify and predict diseases from gene expressions.

Determining Gene Alterations
    -After this module, you will be able to
1. List different types of gene alterations.
2. Compare and contrast methods for detecting gene mutations.
3. Compare and contrast methods for detecting methylation.
4. Compare and contrast methods for detecting copy number variations.
5. Quantify genomic alterations.
6. Connect genomic alterations to differential expression of genes.
7. Write programs in R for determining gene alterations and their relationship with gene expression.


Clustering and Pathway Analysis
    -After this module, you will be able to 1. Find clusters in biomedical data involving genes.2. Analyze and visualize biological pathways. 3. Write R scripts for clustering and for pathway analysis.","Big Data, Genes, and Medicine"
https://www.classcentral.com/course/edx-sp20-computing-for-data-analysis-8223,"The modern data analysis pipeline involves collection, preprocessing, storage, analysis, and interactive visualization of data.
The goal of this course, part of the Analytics: Essential Tools and Methods MicroMasters program, is for you to learn how to build these components and connect them using modern tools and techniques.
In the course, you’ll see how computing and mathematics come together. For instance, “under the hood” of modern data analysis lies numerical linear algebra, numerical optimization, and elementary data processing algorithms and data structures. Together, they form the foundations of numerical and data-intensive computing.
The hands-on component of this course will develop your proficiency with modern analytical tools. You will learn how to mash up Python, R, and SQL through Jupyter notebooks, among other tools. Furthermore, you will apply these tools to a variety of real-world datasets, thereby strengthening your ability to translate principles into practice.",SP20: Computing for Data Analysis
https://www.classcentral.com/course/friendsmoneybytes-359,"You pick up your iPhone while waiting in line at a coffee shop. You google a not-so-famous actor, get linked to a Wikipedia entry listing his recent movies and popular YouTube clips of several of them. You check out user reviews on Amazon and pick one, download that movie on BitTorrent or stream that in Netflix. But suddenly the WiFi logo on your phone is gone and you're on 3G. Video quality starts to degrade, but you don't know if it's the server getting crowded or the Internet is congested somewhere. In any case, it costs you $10 per Gigabyte, and you decide to stop watching the movie, and instead multitask between sending tweets and calling your friend on Skype, while songs stream from iCloud to your phone. You're happy with the call quality, but get a little irritated when you see there're no new followers on Twitter. You may wonder how they all kind of work, and why sometimes they don't. Take a look at the list of 20 questions below. Each question is selected not just for its relevance to our daily lives, but also for the core concepts in the field of networking illustrated by its answers. This course is about formulating and answering these 20 questions.

All the features of this course are available for free.  It does not offer a certificate upon completion.
      


          Introduction
    -An introduction to what we will explore in this course: 20 practical questions and their answers, about your networked life.

What Makes CDMA Work for My Smartphone?
    -We study cellular network technology, the air interface between end-user devices and base stations, and an important algorithm which has been developed to manage interference between our devices as they share this medium: Distributed Power Control. 

How Does Google Sell Ad Spaces? 
    -How does Google sells the ads that appear on its search results page through auctions? We learn about different types of auction mechanisms, including those for single and multiple items. QUESTION 3: We explore PageRank, the famous algorithm that underlies how Google orders its list of search results whenever we type in a query.

How Does Google Rank Webpages? 
    -In this lecture, we will explore PageRank, the famous algorithm that underlies how Google orders its list of search results whenever we type in a query.

How Does Netflix Recommend Movies?
    -As a user of Netflix, you may have had movies recommended for you to watch. Behind the scenes, Netflix is leveraging powerful machine learning to determine which will be recommended to you specifically. In this lecture, we will study some of the fundamental algorithms that have been used for this purpose.

When Can I Trust an Average Rating on Amazon?
    -The decision of whether or not to make an online purchase is often driven by feedback that has been left by past customers, commonly in the form of star ratings. In this lecture, we will study Amazon's review system. In doing so, we will explore some of the methods for, and challenges behind, rating aggregation.

Why Does Wikipedia Even Work?
    -In this lecture, we focus on the concepts of crowdsourcing and consensus formation, which are two of the mechanisms allowing Wikipedia to be both a scalable and (reasonably) accurate encyclopedia. In particular, we will look at different voting systems, which are ways of determining consensus from a collection of individual preferences.

How Do I Viralize a Youtube Video?
    -In this lecture, we will study models that have been developed for the popularity of products over time, motivated by the phenomenon of videos going ""viral"" on YouTube. Overall, the theme will be the dependence of opinions, as opposed to the wisdom of crowds discussed in the previous two lectures.

How Do I Influence People on Facebook?
    -In this lecture, we continue with the theme of information spread in networks, turning to the effect of graph topology. In particular, we will discuss influence models for social networks like Facebook, and how to measure importance.

  Can I Really Reach Anyone in 6 Steps?
    -Six degrees of separation, or the small world phenomenon, has become one of the most widely told stories in popular science. In this lecture, we will study different models to explain both how short paths can exist in realistic networks, and how they can be discovered by people in the networks.

Does the Internet Have an Achilles' Heel?
    -At one time, there were rumors that the Internet has an Achilles' Heel, or a few center points which if attacked would completely disconnect the Internet. In this lecture, we debunk this myth, by showing that the fact the Internet is a ""scale-free"" network does imply it comes from a network model which would have such center points.

Why Do Mobile Carriers Charge Me $10/GB?
    -In recent years, mobile carriers have introduced a usage-based component to their data plans, where you are charged proportionally to the amount of data you consume. In this lecture, we will look at the reasons behind the switch to usage-based pricing, in terms of fundamental economic principles.

How Do I Save on Each GB?
    -In the last lecture, we studied flat-rate and usage-based pricing schemes for mobile carriers. What these both fail to model is the time varying aspect of demand: consumption varies throughout the day, leading to peaks and troughs in usage. In this lecture, we will look at methods of Smart Data Pricing for taking this into account.

How Does Traffic Go Through the Internet?
    -It is hard to overestimate the impact that the Internet has had on society. In this lecture, we will overview the layered architecture on which the Internet was designed, and will dive into the process of determining how packets of information are transported, known as routing.

Why Doesn't the Internet Collapse Under Congestion?
    -When the demand for capacity on the Internet exceeds the available supply on the network links, we have congestion. In this lecture, we will discuss the principles of distributed congestion control, and will detail protocols that have been designed to regulate demand for the Internet.

How can Skype and BitTorrent be free?
    -The amount of content on the Internet continues to grow at a rapid pace. One of the ways that content distribution at such massive scale is made possible is through peer to peer (P2P) protocols. In this lecture, we will study P2P applications like Skype and BitTorrent. In doing so, we will see how peers in a network can share the workload of distributing content throughout a network.

What's Inside the Cloud?
    -The Cloud is another rapidly growing Internet service, allowing users to rent storage and computation resources inside the network. In this lecture, we will see how the large data centers operated by Cloud providers can be constructed from a multitude of small switches.

Which Way to Watch Video on the Internet?
    -We have seen that the Internet provides a ""best effort"" service. In this lecture, we will look at how it supports video distribution, which often imposes stringent demands on throughput and delay.

Why is WiFi Faster at Home Than at Hotspot?
    -WiFi hotspots have become an essential feature of our wireless lifestyle. In this lecture, we will study WiFi, and focus specifically on common link layer protocols that are used to manage interference. In doing so, we will see why WiFi does not scale well beyond several devices sharing one access point.

Why Am I Only Getting 3% of the Cellular Speed?
    -Advertised network speeds are typically only those that can be obtained at the physical layer under ideal channel conditions. In this lecture, we will study various factors that impact the actual speeds we obtain at the application layer under realistic channel conditions.

Is It Fair that My Neighbor’s iPad Downloads Faster?
    -In this final lecture of the course, we will study a subject that we touched upon many times previously and forms an essential part of both social choice theory and technology network design: quantifying fairness of resource allocation.

Course Summary
    -Here, we will summarize the important points of what we have learned in this course.

Guest Lectures
    -This contains various guest lectures from renowned members of academia and industry who are experts across the topics covered in this course.","Networks: Friends, Money, and Bytes"
https://www.classcentral.com/course/magicmiddleages-3477,"Magical thought has always attracted human imagination. In this course we will introduce you to the Middle Ages through a wide conception of magic. Students will have an approach to medieval culture, beliefs and practices from the perspective of History and History of Science. Popular magic, as well as learned magic (alchemy, geomancy and necromancy) will be addressed. Moreover, we will also deal with how eastern practices and texts influenced western culture. In July 2016, the course will contain a brand-new module devoted to astrology. Magic in the Middle Ages offers a captivating overview of medieval society and promotes reflection about certain stereotypes associated with this period.

At the end of the course, the students:

a) will have overcome the usual prejudices about the Middle Ages, 
b) will be able to analyze historical documentation from the Middle Ages and recognize the most common patterns of juridical documents regarding witchcraft, and 
c) will be capable of distinguishing between popular magic and the magic of the learned people; will have a notion of which spiritual practices were allowed in medieval Europe and which ones were related to the devil, and will be aware of the link between a cultural product and the society that produced it.

This course is taught in English, although subtitles in English, Catalan and Spanish will also be provided.

COURSE SYLLABUS

Week 1. Introduction to medieval magic (Pau Castell).

Week 2. Magic & Heresy (Delfi I. Nieto-Isabel).

Week 3. From Magic to Witchcraft (Pau Castell).

Week 4. Magic in Islam (Godefroid de Callataÿ and Sébastien Moureau).

Week 5. Astrology & Geomancy (Theo Loinaz, Delfi I. Nieto-Isabel, Godefroid de Callataÿ and Blanca Villuendas).

© Gemma Pellissa Prades (coord.), Delfi I. Nieto-Isabel and Joana Palau Mumany
Magic in the Middle Ages by Gemma Pellissa Prades (coord.), Delfi I. Nieto-Isabel and Joana Palau Mumany is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License.
      


            Read more
          



          UNIT 1: INTRODUCTION TO MEDIEVAL MAGIC

UNIT 2: MAGIC & HERESY

UNIT 3: FROM MAGIC TO WITCHCRAFT

UNIT 4: MAGIC IN ISLAM

UNIT 5: ASTROLOGY & GEOMANCY",Magic in the Middle Ages
https://www.classcentral.com/course/edx-data-science-machine-learning-10353,"Perhaps the most popular data science methodologies come from machine learning. What distinguishes machine learning from other computer guided decision processes is that it builds prediction algorithms using data. Some of the most popular products that use machine learning include the handwriting readers implemented by the postal service, speech recognition, movie recommendation systems, and spam detectors. 
In this course,part ofourProfessional Certificate Program in Data Science, you will learn popular machine learning algorithms, principal component analysis, and regularization by building a movie recommendation system. 
You will learn about training data, and how to use a set of data to discover potentially predictive relationships. As you build the movie recommendation system, you will learn how to train algorithms using training data so you can predict the outcome for future datasets. You will also learn about overtraining and techniques to avoid it such as cross-validation. All of these skills are fundamental to machine learning.",Data Science: Machine Learning
https://www.classcentral.com/course/feature-engineering-11074,"Want to know how you can improve the accuracy of your machine learning models? What about how to find which data columns make the most useful features? Welcome to Feature Engineering on Google Cloud Platform where we will discuss the elements of good vs bad features and how you can preprocess and transform them for optimal use in your machine learning models.

In this course you will get hands-on practice choosing features and preprocessing them inside of Google Cloud Platform with interactive labs. Our instructors will walk you through the code solutions which will also be made public for your reference as you work on your own future data science projects.

>>> By enrolling in this course you agree to the Qwiklabs Terms of Service as set out in the FAQ and located at: https://qwiklabs.com/terms_of_service 
      


          Introduction
    -Want to know how you can improve the accuracy of your ML models? What about how to find which data columns make the most useful features? Welcome to Feature Engineering where we will discuss good vs bad features and how you can preprocess and transform them for optimal use in your models.

Raw Data to Features
    -Feature engineering is often the longest and most difficult phase of building your ML project. In the feature engineering process, you start with your raw data and use your own domain knowledge to create features that will make your machine learning algorithms work. In this module we explore what makes a good feature and how to represent them in your ML model.

Preprocessing and Feature Creation
    -This section of the module covers pre-processing and feature creation which are data processing techniques that can help you prepare a feature set for a machine learning system.


Feature Crosses
    -In traditional machine learning, feature crosses don’t play much of a role, but in modern day ML methods, feature crosses are an invaluable part of your toolkit.In this module, you will learn how to recognize the kinds of problems where feature crosses are a powerful way to help machines learn.

TF Transform
    -
TensorFlow Transform (tf.Transform) is a library for preprocessing data with TensorFlow. tf.Transform is useful for preprocessing that requires a full pass the data, such as:

- normalizing an input value by mean and stdev
- integerizing a vocabulary by looking at all input examples for values
- bucketizing inputs based on the observed data distribution

In this module we will explore use cases for tf.Transform.

Summary
    -Here we recap the major points you learned in each module on Feature Engineering: Selecting Good Features, Preprocessing at Scale, Using Feature Crosses, and Practicing with TensorFlow.",Feature Engineering
https://www.classcentral.com/course/edx-data-science-wrangling-10351,"In this course, part of our Professional Certificate Program in Data Science,we cover several standard steps of the data wrangling process like importing data into R, tidying data, string processing, HTML parsing, working with dates and times, and text mining. Rarely are all these wrangling steps necessary in a single analysis, but a data scientist will likely face them all at some point. 
Very rarely is data easily accessible in a data science project. It's more likely for the data to be in a file, a database, or extracted from documents such as web pages, tweets, or PDFs. In these cases, the first step is to import the data into R and tidy the data, using the tidyverse package. The steps that convert data from its raw form to the tidy form is called data wrangling. 
This process is a critical step for any data scientist. Knowing how to wrangle and clean data will enable you to make critical insights that would otherwise be hidden.",Data Science: Wrangling
https://www.classcentral.com/course/ruby-on-rails-web-services-mongodb-4321,"In this course, we will explore MongoDB, a very popular NoSQL database and Web Services concepts and integrate them both with Ruby on Rails. MongoDB is a used to handle documents with a pre-defined schema which will give the developers an ability to store, process and use data using it’s rich API. The modules will go in-depth from installation to CRUD operations, aggregation, indexing, GridFS and various other topics where we continuously integrate MongoDB with RailsRuby.  We will be covering the interface to MongoDB using the Mongo Ruby API and the Mongoid ORM framework (the MongoDB access counterpart to RDBMS/ActiveRecord within Rails).  The last portion of the course will focus on Web Services with emphasis on REST, its architectural style and integration of Web Services with Rails.  Core concepts of Web Services like request/response, filters, data representation (XML/JSON), web linking and best practices will covered in depth.

This course is ideal for students and professionals who have some programming experience and a working knowledge of databases.
      


          Introduction to MongoDB, MongoDB-Ruby API, and CRUD
    -In this module, we’re going to explore the history and the rationale behind NoSQL databases, their relationship to RDBMS, and dive into the basics of MongoDB. We will install MongoDB, create a database, collections and perform CRUD operations. We will end this module by integrating MongoDB with Ruby Shell and try out some simple examples.

Aggregation Framework, Performance, and Advanced MongoDB
    -In this module, we’re going to explore the fundamentals of the Aggregation framework in MongoDB.  We will work on examples where you will process data records and return computed results. You will learn about and get to work on hands-on examples where you will be grouping values from multiple documents and performing a variety of operations on the grouped data to get a single result. We will look at a number of aggregation commands and paging. We will explore some advanced concepts like full text search, GridFS, Geospatial API, and wrap up the module with detailed demonstrations of all the capabilities presented in this module.

Mongoid
    -In this module, we’re going to explore Mongoid, which is an Object-Document-Mapper (ODM) for MongoDB written in Ruby. We will learn to integrate Mongoid with Rails and work to understand document and relationship mapping, as well. We will work on a number of queries using the Mongoid API and wrap up the module by implementing Rails/Mongoid Model View Controller.

Web Services
    -In this module, we’re going to explore Web Services with a focus on caching and security. We will start off by looking at REST fundamentals, RMM (Richardson Maturity Model) and URI best practices. We will wrap up the topic by covering Client and Server Caching along with Web Service Security (OAuth 2).",Ruby on Rails Web Services and Integration with MongoDB
https://www.classcentral.com/course/python-machine-learning-for-investment-m-16888,"This course will enable you mastering machine-learning approaches in the area of investment management. It has been designed by two thought leaders in their field, Lionel Martellini from EDHEC-Risk Institute and John Mulvey from Princeton University. Starting from the basics, they will help you build practical skills to understand data science so you can make the best portfolio decisions.

The course will start with an introduction to the fundamentals of machine learning, followed by an in-depth discussion of the application of these techniques to portfolio management decisions, including the design of more robust factor models, the construction of portfolios with improved diversification benefits, and the implementation of more efficient risk management models. 

We have designed a 3-step learning process: first, we will introduce a meaningful investment problem and see how this problem can be addressed using statistical techniques. Then, we will see how this new insight from Machine learning can complete and improve the relevance of the analysis.

You will have the opportunity to capitalize on videos and recommended readings to level up your financial expertise, and to use the quizzes and Jupiter notebooks to ensure grasp of concept.

At the end of this course, you will master the various machine learning techniques in investment management.
      


          Introducing the fundamentals of machine learning

Machine learning techniques for robust estimation of factor models

Machine learning techniques for efficient portfolio diversification

Machine learning techniques for regime analysis 

Identifying recessions, crash regimes and feature selection",Python and Machine Learning for Asset Management
https://www.classcentral.com/course/python-data-processing-7751,"This course (The English copy of ""用Python玩转数据"" )  is mainly for non-computer majors. It starts with the basic syntax of Python, to how to acquire data in Python locally and from network, to how to present data, then to how to conduct basic and advanced statistic analysis and visualization of data, and finally to how to design a simple GUI to present and process data, advancing level by level. 

This course, as a whole, based on Finance data and through the establishment of popular cases one after another, enables learners to more vividly feel the simplicity, elegance, and robustness of Python. Also, it discusses the fast, convenient and efficient data processing capacity of Python in humanities and social sciences fields like literature, sociology and journalism and science and engineering fields like mathematics and biology, in addition to business fields. Similarly, it may also be flexibly applied into other fields.

The course has been updated. Updates in the new version are : 

1) the whole course has moved from Python 2.x to Python 3.x 
2) Added manual webpage fetching and parsing. Web API is also added. 
3) Improve the content order and enrich details of some content especially for some practice projects.

Note: videos are in Chinese (Simplified) with English subtitles. All other materials are in English.
      


          Welcome to learn Data Processing Using Python!
    -Hi, guys, welcome to learn “Data Processing Using Python”(The English version of ""用Python玩转数据"", url is https://www.coursera.org/learn/hipython/home/welcome)!In this course, I tell in a manner that enables non-computer majors to understand how to utilize this simple and easy programming language – Python to rapidly acquire, express, analyze and present data based on SciPy, Requests, Beautiful Soup libraries etc. Many cases are provided to enable you to easily and happily learn how to use Python to process data in many fields. 【Nov 18, 2019 @ @ @ @ @ @ @ Hi, all! The content is planned to be updated in the last two months. This update is relatively large, including practical operation and explanation of Python based cases, vector operation and broadcast ideas of numpy package and common applications, multiple links of data exploration and preprocessing (including in module 4), data analysis and data mining cases based on pandas, some of which are directly modified on the original video Some of them are presented in the form of expanded videos, especially the newly recorded videos, which have a lot of content to say, take a long time, and will be a little hard to learn. I have completed all the updates on Dec 16, 2019. Thank you for your patience. I hope you will enjoy the new version.】

Basics of Python
    -Hi, guys, welcome to learn Module 01 “Basics of Python”! I’ll first guide you to have a glimpse of its simplicity for learning as well as elegance and robustness. Less is more: the author of Python must know this idea well. After learning this module, you can master the basic language structures, data types, basic operations, conditions, loops, functions and modules in Python. With them, we can write some useful programs! 

Data Acquisition and Presentation
    -Welcome to learn Module 02 “Data Acquisition and Presentation”! After learning this module, you can master the modes of acquiring local data and network data in Python and use the basic and yet very powerful data structure sequence, string, list and tuple in Python to fast and effectively present data and simply process data. 

Powerful Data Structures and Python Extension Libraries
    -Welcome to learn Module 03 “Powerful Data Structures and Python Extension Libraries”! Have you felt you are closer to using Python to process data? After learning this module, you can master the intermediate-level and advanced uses of Python: data structure dictionaries and sets. In some applications, they can be very convenient. What’s special here is that, you can also feel the charm of such concise and efficient data structures: ndarray, Series and DataFrame in the most famous and widely applied scientific computing package SciPy in Python. 

Python Data Statistics and Mining
    -Welcome to learn Module 04 “Python data statistics and mining”! In this module, I will show you, over the entire process of data processing, the unique advantages of Python in data processing and analysis, and use many cases familiar to and loved by us to learn about and master methods and characteristics. After learning this module, you can preprocess the data and fast and effectively mine your desired or expected or unknown results from a large amount of data, and can also present those data in various images. In addition, the data statistics modes of all third party packages in Python are extraordinarily and surprisingly strong, but we, as average persons, can still understand and possess them. 

Object Orientation and Graphical User Interface
    -Welcome to Module 05 “Object Orientation and Graphical User Interface”! In this module, I will guide you to understand what object orientation is and the relationship between graphical user interface and object orientation. Learners are only required to understand the concepts so that you can more freely and easily pick up various new functions in future. No program writing is required here. Besides, you also need to master the basic framework of GUI, common components and layout management. After learning them, you will find development with GUI is actually not remote. It has an Easter egg, too ~~~",Data Processing Using Python
https://www.classcentral.com/course/intro-gis-5489,"Explore the world of spatial analysis and cartography with geographic information systems (GIS). In this class you will learn the basics of the industry’s leading software tool, ArcGIS, during four week-long modules: 

Week 1: Learn how GIS grew from paper maps to the globally integrated electronic software packages of today. You will install ArcGIS on your computer and learn how to use online help to answer technical questions.

Week 2: Open up ArcGIS and explore data using ArcMap. Learn the foundational concepts of GIS, how to analyze data, and make your first map.

Week 3: Make your own maps! Symbolize data and create an eye-catching final product. 

Week 4: Share your data and maps and learn to store and organize your data.

Take Fundamentals of GIS as a standalone course or as part of the Geographic Information Systems (GIS) Specialization. By completing the first class in the Specialization you will gain the skills needed to succeed in the full program.

Students who need an ArcGIS license will receive a non-commercial, 1 year student license for participation in this course and specialization.
      


          Course Introduction and Introduction to Geographic Information Systems (GIS)
    -In this module, we will cover course expectations, give you a quick overview of GIS and what's great about it, take a first look at ArcGIS and identify key elements in the interface, and define core geospatial concepts and terminology. In Section 2, we will discuss options for desktop GIS, the history of GIS and how it's used today, discuss resources and help that you can use, and lay out core skills that are relevant to you as a GIS analyst. We'll close out by showing you how to get a copy of ArcGIS for this course, and with a tutorial on getting started in ArcGIS.

ArcGIS Basics
    -In this module, we will explore GIS data using ArcMap and will explore and change properties of GIS layers to change map displays. We will subset data using selections, and explore feature attributes.  Finally, we will learn about projections and use that knowledge as we run geoprocessing tools.

Making Maps With Common Datasets
    -In this module we will identify common datasets in both the US and Internationally. We will use a new mode in ArcGIS to create complete maps that include proper symbology, legends, titles, north arrows, and data sources. We will further use more advanced mapping techniques to output map books and label items on the map.

Retrieving and Sharing Data
    -In this module, we will view and edit metadata in order to create higher quality data. We will retrieve data from the web and share data, discuss workspaces and file formats, and create layer and map packages. We will also use multiple file formats for GIS data and be able to appropriately choose between them based upon project requirements.",Fundamentals of GIS
https://www.classcentral.com/course/introduction-climate-change-health-16878,"Climate change is one of the greatest threats to human health in the 21st century. Yet these impacts to health are still not well recognized. Since you can’t change what you don’t understand, this course is designed to equip health and environmental professionals, as well as other changemakers and the public, with critical and usable knowledge to take positive action. The course begins with an introduction to the science of climate change and how climate change affects human health. It takes a deep dive into climate change’s adverse health effects, including those related to extreme heat, waterborne infections, insect-borne diseases, and exposure to storms and floods. Throughout, the theme of health equity is interwoven by pointing to what factors make some populations more vulnerable than others to climate change’s negative health impacts. Finally, the course explains how measures to reduce greenhouse gas emissions can not only limit future climate change but can also generate substantial immediate health “co-benefits” over and above the benefit of reducing climate change.

Following completion of the course, students will be able to: 
·       At an introductory level, describe how the climate has changed, explain the role of greenhouse gases in climate change, and describe how the climate is predicted to change in the future. 
·       Describe how climate change adversely impacts population health, with differing vulnerability across population sub-groups, through direct effects; through ecosystem transformation and degradation; and through the stress it places on political, economic, and social systems. 
·       Explain how adaptation and mitigation strategies can reduce adverse health impacts of climate change and can generate substantial non-climate health benefits in a just and equitable manner.
      


            Read more
          



          Welcome to Introduction to Climate Change and Health! 
    -This course begins with an introduction to the science of climate change and how climate change affects human health. It takes a deep dive into climate change’s adverse health effects, including those related to extreme heat, waterborne infections, insect-borne diseases, and exposure to storms and floods. Throughout, the theme of health equity is interwoven by pointing to factors that make some populations more vulnerable than others to climate change’s negative health impacts. Finally, the course explains how measures to reduce greenhouse gas emissions can not only limit future climate change but can also generate substantial immediate health “co-benefits” over and above the benefit of reducing climate change.

Fundamentals of Climate Change 
    -Why and how is the climate changing? What changes are predicted in the future under different climate change scenarios? 


Overview of Health Impacts of Climate Change, Adaptation, Mitigation, and Co-benefits
    -How does climate change impact health, and what populations are especially vulnerable to these impacts? How can mitigating climate change provide public health benefits in the short- and long-term? 


 Extreme Weather: Heat, Storms, & Floods
    -How does extreme weather, including heat, storms, and floods, negatively impact human health? What populations are most vulnerable to these health effects and why? How are these negative health effects projected to change in the future under climate change? 

Water-borne Infections and Vector-borne Diseases
    -What is the relationship between climate change and disease? In particular, how does climate change affect the spread, distribution, and incidence of certain water-borne diseases and vector-borne diseases? 

Course conclusion",Introduction to Climate Change and Health
https://www.classcentral.com/course/edx-agile-development-using-ruby-on-rails-advanced-558,"Part 2 of the UC Berkeley Agile Development Using Ruby on Rails XSeries Program will teach you to use JavaScript to enhance applications and create more sophisticated apps by adding relationships between models within the Ruby on Rails framework. You will also learn about what happens after the apps are deployed to real users, including how to monitor performance, identify and fix common performance problems, and avoid compromising customer data. Finally, learners will see how to apply Agile techniques to enhance and refactor legacy code and practice app deployment to real users to monitor performance, identify and fix common performance problems, and avoid compromising customer data.
Other topics covered in this software engineering course include:

How to form, organize and manage small programming teams
Introduction to design patterns: what they are and how to recognize opportunities to apply them
Using Rails for more advanced features like third-party authentication and elegantly expressing design patterns that arise frequently in SaaS

There will be four homework assignments: two programming assignments, an open source assignment and one assignment about operations/deployment. There will also be several short quizzes. The videos and homework assignments used in this offering of the course were revised in October 2016.",Agile Development Using Ruby on Rails - Advanced
https://www.classcentral.com/course/business-intelligence-data-analytics-15127,"‘Megatrends’ heavily influence today’s organisations, industries and societies, and your ability to generate insights in this area is crucial to your organisation’s success into the future. This course will introduce you to analytical tools and skills you can use to understand, analyse and evaluate the challenges and opportunities ‘megatrends’ will inevitably bring to your organisation. Via structured learning activities you will explore how these trends can be addressed through sustainability-oriented innovation. You will be introduced to key data analytics concepts such as systems thinking, multi-level perspectives and multidisciplinary methods for envisioning futures, and apply them to specific real-world challenges you and your organisation may face. And there’ll be a focus on future-proofing skills such as teamwork, collaboration with diverse stakeholders and accounting for judgements made within ethical decision-making frameworks.
      


          Basics of insight generation
    -Organisations and governments everywhere want to exploit data to predict behaviors and extract valuable real-world insights. Billions of devices and social media conversations are fueling the rate at which humanity is producing data. Therefore, we need more skills to understand data and make our systems, policies and governance models more efficient. In this week, we will highlight the potential of generating insights with the help of data in allowing individuals, businesses, and governments to make effective decisions.

Basic statistics: Foundations of quantitative insights
    -In week 2, we’ll focus on  basic statistics. It’s one of the most important components of Data Analytics and it’s crucial to have a clear understanding of all the related concepts to be successful in the data industry. Statistics provide us with a set of tools that offer ways to convert quantitative data and qualitative data into information that we can use to generate insights. 

The normal distribution and histograms
    - Businesses must constantly strive to offer “better” products and services than their competitors. One of the oldest and time-proven techniques by which we can visualise and think about quality in a methodological way is via normal distributions or bell curves. So in week 3,  we’ll start by learning about histograms and the normal curve  and then have a look at empirical rule which gives us a quick rough estimate about the spread of the given data. Finally, we’ll learn about the measures that quantify the interrelationships between two data variables. Correlation and covariance are two important measures that quantify the relationship between variables and we’ll study both.  

Data visualisation
    -Visualisation is a key technique which can provide answers hidden in data. In this week, you will explore various data visualisations available and how to use them for analysis. These techniques will empower you to create compelling stories and dashboards from your data that the non-analyst community can also understand easily. As a person working in the data industry, you don’t just need to deal with data and solve data-driven problems but the incumbent also needs to convince company executives and government officials of the right decisions to make. These executives/officials may not be well versed in data science, so the incumbent must but be able to present and visualise the data’s story in a way they will understand. And this module will help you achieve that.

Advanced charts and dashboards
    -This week we learn how to create bar and bullet charts, and dashboards. Data visualization helps to tell stories by curating data into a form easier to understand. A good visualisation tells a story, by removing the noise from data and highlighting the useful information. 

Demand forecasting
    -This week we’ll look at how, by using predictive modelling, we can generate actionable insights that when implemented will provide businesses with a predictable future outcome. Predictive modeling is a group of methods and algorithms that you can employ to forecast an outcome. Utilising basic predictive modelling techniques, we will also explore consumer demand forecasting.",Business intelligence and data analytics: Generate insights
https://www.classcentral.com/course/java-programming-4305,"Learn to code in Java and improve your programming and problem-solving skills. You will learn to design algorithms as well as develop and debug programs. Using custom open-source classes, you will write programs that access and transform images, websites, and other types of data. At the end of the course you will build a program that determines the popularity of different baby names in the US over time by analyzing comma separated value (CSV) files. 

After completing this course you will be able to:
1. Edit, compile, and run a Java program;
2. Use conditionals and loops in a Java program;
3. Use Java API documentation in writing programs. 
4. Debug a Java program using the scientific method;
5. Write a Java method to solve a specific problem;
6. Develop a set of test cases as part of developing a program;
7. Create a class with multiple methods that work together to solve a problem; and
8. Use divide-and-conquer design techniques for a program that uses multiple methods.
      


          Introduction to the Course
    -Welcome to “Java Programming: Solving Problems with Software”! We are excited that you are starting our course to learn how to write programs in Java, one of the most popular programming languages in the world. In this introductory module, you will get to meet the instructor team from Duke University and have an overview of the course. Have fun!

Fundamental Java Syntax and Semantics
    -In this module, you will learn to write and run your first Java programs, including one program that prints “Hello!” in various countries’ languages and another where you will analyze the perimeters and other information of shapes. To accomplish these tasks, you will learn the basics of Java syntax and how to design stepwise solutions with programs. By the end of this module, you will be able to: (1) Download and run BlueJ, the Java programming environment for this course; (2) Access the documentation for the Java libraries specially designed for this course; (3) Edit, compile, and run a Java program; (4) Construct methods, variables, if else statements, and for each loops in Java; and (5) Use Iterables (like DirectoryResource) to run a program that iterates over multiples lines in a document or webpage or multiple files in a directory.

Strings in Java
    -This module begins with a short presentation from Raluca Gordân, an assistant professor in Duke University’s Center for Genomic and Computational Biology, about an important problem genomics scientists encounter regularly: how to identify genes in a strand of DNA. To tackle this problem, you will need to understand strings: series of characters such as letters, digits, punctuation, etc. After learning about Java methods that work with strings, you will be able to find genes within a DNA string as well as tackle other string related problems, such as finding all of the links in a web page. By the end of this module, you will be able to: (1) Use important methods for the Java String class; (2) Use conditionals, for loops, and while loops appropriately in a Java program; (3) Find patterns in the data represented by strings to help develop the algorithm for your program; (4) Understand the importance of designing programs that keep different data processing steps separate; (5) Use the StorageResource iterable for this course to store some data for further processing; and (6) Rely on Java documentation to better understand how to use different Java packages and classes.

CSV Files and Basic Statistics in Java
    -A common format for storing tabular data (any data organized into columns and rows) is in comma separated values (CSV) files. In this module, you will learn how to analyze and manipulate data from multiple CSV data files using a powerful open-source software package: Apache Commons CSV. Using this library will empower you to solve problems that could prove too complex to solve with a spreadsheet. By the end of this module, you will be able to: (1) Use the open-source Apache Commons CSV package in your own Java programs; (2) Access data from one or many CSV files using Java; (3) Convert strings into numbers; (4) Understand how to use “null” in Java programs (when you want to represent “nothing”); (5) Devise an algorithm (and implement in Java) to answer questions about CSV data; and (6) Analyze CSV data across multiple CSV files (for example, find maximums, minimums, averages, and other simple statistical results).

MiniProject: Baby Names
    -This module wraps up the course with a mini project that ties together the different practices, skills, and libraries you have gained across the course! Using data on the popularity of different baby names in the United States from the past several decades, you will be able to compare different names’ popularity over time. While the data we have collected for this course is from the United States, we welcome you to share data from other countries in the course discussion forums. Good luck with the mini project!",Java Programming: Solving Problems with Software
https://www.classcentral.com/course/copyright-for-multimedia-5369,"Copyright questions about different formats (data, images, music and video) can be especially difficult.  Sometimes the law specifically distinguishes between these different formats, and in most cases there are media-specific considerations that impact a copyright analysis.  In this course we will look at four different media, paying special attention to the unique issues for each one and the kinds of information that is important when making copyright decisions for each type of material.  We will work through fair use issues for each multimedia format, look at format-specific exceptions in the law, and consider unique issues for seeking permission for film, music, images and data.

At the end of this course, participants will have a deeper understanding of how to apply our framework for making copyright decisions, and will be more comfortable with assessing multimedia issues.  They will have gained more and more diverse experience for considering fair use.
      


          Introduction and Getting Started
    -Copyright questions about different formats – data, images, music and video – can be especially difficult.  Sometimes the law specifically distinguishes between these different formats, and in most cases there are media-specific considerations that impact a copyright analysis.  In this course we will look at four different media types, paying special attention to the unique issues for each one and the kinds of information that are important when making copyright decisions.  We will work through fair use issues for each multimedia format, look at specific exceptions in the law, and consider unique issues for seeking permission for film, music, images and data. At the end of this course, participants will have a deeper understanding of how to apply our framework for making copyright decisions, and will be more comfortable with assessing multimedia issues. 

Data
    -Data can refer to many different types of materials, and the copyright situation is different depending on what particular type of data is meant.  In this module we will consider the different potential types of data, the rights associated with each one, and the copyright considerations involved when using data.  We will look carefully at how fair use applies in various data-use situations.


Images
    -Those who create or use works of visual arts benefit from an understanding copyright protections and exemptions.  Topics covered in this module include which works of visual arts get copyright protection, what special rights are afforded artists under the Visual Artists Rights Act (VARA), how to apply the TEACH Act and fair use to images, and what steps to take if you need to seek permission.  Finally, some attention will be given to social media, implied licenses that can arise when posting and using images, and privacy. 


Music and Audio
    -Copyright for music, and especially for recording music, is extremely complicated and difficult to untangle.  In this module we will explore the multiple rights that must be accounted for in almost every musical composition or recording.  We will pay special attention to the multitude of licenses that come in to play when creating or using music.  Exceptions for using music in teaching will be covered, and we will examine fair use considerations for different musical situations in detail.  This is a module that has important implications for musicians, music teachers, librarians, and all those who want to use or reuse music.


Film and Video
    -Copyright issues for film tend to be complicated because of the number of creators and creative works that come together to make them.  In this module, students will learn to apply  the fundamentals of copyright with regard to film.  Topics covered include identification of the various rights and rights holders involved in many films, the role of copyright exceptions when creating or using film in educational settings, and when and how to seek permission to make use of copyrighted material in films.",Copyright for Multimedia
https://www.classcentral.com/course/media-data-4925,"How can we know which numbers to trust?
Increasingly, we’re bombarded with all sorts of data about how society is changing. From opinion poll trends and migration data to economic results and government debt levels.
On this course from the Sheffield Methods Institute at University of Sheffield, we’ll look at ways of cutting through the confusion to decide what numbers reveal, when and why they (sometimes deliberately) mislead, and how to determine what is ‘fake news.’
This course is open to anyone who wants to know how to make sense of social statistics and economic data in the media.
It will be particularly useful to first-year undergraduate students studying social science, as well as school leavers who are thinking about taking a social science or quantitative social science degree.",Making Sense of Data in the Media
https://www.classcentral.com/course/fintech-11193,"Our primary goal is to help you to understand FinTech and to become more confident and persuasive in your ability to analyze and make recommendations to executives within the finance industry regarding how to react to these changes.

This FIRST MOOC ON FINTECH IN ASIA-PACIFIC offered by HKUST presents the insight of several professors from the top business school in Asia as well as perspectives from industry professionals.  HKUST has been ranked for many years as the No.1 EMBA program in the world, as the number one Finance program in Asia, and as the top MBA program in Asia by multiple independent rating and review journals and surveys.  

This course ""FinTech Foundations and Overview"" offers the combined strengths of HKUST in Business, Finance, and Technology as one the world's leading academic institutions on an important area of technology and business innovations.  For learners from outside Asia, this also gives an insight into changes happening in the most advanced FinTech markets of the world, since Asia leads worldwide in FinTech adoption and creative innovations.
      


          Introduction to FinTech
    -In this module (week one), students will gain a multi-dimensional perspective on what FinTech means from the perspective of large firms (and older participants in the industry - e.g. dinosaurs), entrepreneurs, investors, and consumers.  Examining what FinTech is, or is not, provides a foundations upon which students can build for better understanding of opportunities and changes. 

FinTech Business Applications
    -The Business Applications of FinTech are essentially the Fin part of the FinTech world, and in this module, we will examine applications across six categories of FinTech, including lending and personal finance, crowd-finding and business financing, payments and retail transactions, equity, trading and investment applications, various types of cryptocurrencies, and banking infrastructure and tools.

The Tech of FinTech
    -The Technology enabling and supporting FinTech is important to understand, and this module provides a brief introduction to each of the areas of technology that enable FinTech business changes, including identity and privacy technologies, blockchain and encryption, big data analytics, AI and automation, and consumer tech innovations.  This introduction is designed to be at a level appropriate for business managers or students of business, and is not intended to excite or engage tech geeks.

FinTech Implications for Established Business
    -Building on our understanding of FinTech market applications and FinTech technologies, we move in this module to examine the implications of FinTech changes and challenges for existing financial services companies, and we look at current and future trends in FinTech world-wide.  This module concludes, after the final quiz, with a final course project in which students will present their recommendations for senior managers of a large, established Asia-Pacific bank to take advantage of and respond to FinTech challenges and opportunities.",FinTech Foundations and Overview
https://www.classcentral.com/course/repdata-1716,"This course focuses on the concepts and tools behind reporting modern data analyses in a reproducible manner. Reproducible research is the idea that data analyses, and more generally, scientific claims, are published with their data and software code so that others may verify the findings and build upon them.  The need for reproducibility is increasing dramatically as data analyses become more complex, involving larger datasets and more sophisticated computations. Reproducibility allows for people to focus on the actual content of a data analysis, rather than on superficial details reported in a written summary. In addition, reproducibility makes an analysis more useful to others because the data and code that actually conducted the analysis are available. This course will focus on literate statistical analysis tools which allow one to publish data analyses in a single document that allows others to easily execute the same analysis to obtain the same results.
      


          Week 1: Concepts, Ideas, & Structure
    -This week will cover the basic ideas of reproducible research since they may be unfamiliar to some of you. We also cover structuring and organizing a data analysis to help make it more reproducible. I recommend that you watch the videos in the order that they are listed on the web page, but watching the videos out of order isn't going to ruin the story. 

Week 2: Markdown & knitr
    -This week we cover some of the core tools for developing reproducible documents. We cover the literate programming tool knitr and show how to integrate it with Markdown to publish reproducible web documents. We also introduce the first peer assessment which will require you to write up a reproducible data analysis using knitr. 

Week 3: Reproducible Research Checklist & Evidence-based Data Analysis
    -This week covers what one could call a basic check list for ensuring that a data analysis is reproducible. While it's not absolutely sufficient to follow the check list, it provides a necessary minimum standard that would be applicable to almost any area of analysis.

Week 4: Case Studies & Commentaries
    -This week there are two 
case studies involving the importance of reproducibility in science for you to watch.",Reproducible Research
https://www.classcentral.com/course/explorelight-3589,"This is an Exploratorium teacher professional development course taught by Teacher Institute staff, open to any science teacher (particularly middle or high school level) and science enthusiast. This is a hands-on workshop that explores topics and strategies teachers can use to help their students become active investigators of light.

Watch a preview video (copy and paste this link into your browser): https://youtu.be/fPvT_quBVIw

There are four weeks of course content, which require 2-4 hours per week. Each module builds upon the previous one, so we strongly suggest you follow the sequence we've outlined rather than skip ahead or do the course in less time. The course is designed to give you an opportunity to learn and share with others, not test what you know. There are weekly activity and reflection assignments, but these will not be graded. To receive credit for this course, you will need to complete the peer-reviewed final assignment.

As a participant, you will:
- Watch videos that demonstrate natural phenomena and the Exploratorium's approach to teaching and learning 
- Conduct personal investigations by engaging in hands-on activities based in those phenomena
- Reflect and share your experience doing activities
- Discuss and identify challenges and opportunities for teaching
- Devise a lesson of your own based on one or more of the activities

Each week, we'll look at a different light-related topic: We will start by examining human visual perception, then take a brief historical tour of our evolving scientific understanding. We’ll also look at optics and optical instruments and finish by looking at the wave nature of light. 

To get the most out of this experience, you'll have to try out some activities! In return, you'll get lots of valuable teaching resources, an in-depth understanding of the subject matter, and useful tips and techniques for the classroom.

NOTE: This is a hands-on workshop, so you will need to buy or find materials. All of the materials required are inexpensive and should be easy to obtain, and we welcome substitutions! A separate list of materials is available for each activity.
      


            Read more
          



          Introduction to Exploring Light 
    -Welcome to our course! This is a hands-on workshop designed for middle-school and high-school teachers and other people interested in teaching and learning about light. In this first week, we'll introduce you to our pedagogy at the Exploratorium Teacher Institute, which is about supporting educators to incorporate the hands-on, inquiry-based experiences of our museum into classrooms. We'll demonstrate exhibits and teach you how to do activities (which we call ""Science Snacks"") that explore and investigate natural phenomena, and you will need to gather your own materials to do experiments on your own. We hope you will share teaching tips and facilitation strategies with each other as well. We recommend you look through the materials below and follow the suggested course deadlines to get the most out of this experience. We also suggest you browse the discussion forums we've set up. To help you get started and find out who's in this course, please take a moment to introduce yourself in the forum. Please also fill out our pre-course survey, thanks!

Week One: Perception
    -We don't just see with our eyes; our brain plays a big role in determining what we see. A huge percentage of the human brain is devoted to processing visual information, but we still can't make sense of everything going on around us, so we rely on certain ""shortcuts"" or tricks. In other words, your brain makes things up!This week, we're going to explore a few interesting visual shortcuts and some of the technologies that have been invented to take advantage of them.Your assignment is to watch the videos below, try some activities at home, and share your experience in the discussion forums.Collect data about your peripheral vision and compare with your classmatesShow off your afterimage designs for Bird in a CageTake pictures of your experiments with Colored ShadowsWe can't wait to see what you come up with!

Week Two: History of Our Ideas About Light
    -A historical timeline approach to studying light illustrates the importance of models to the advancement of science. Scientific models of light have changed over the years as more and better experiments were done. At the same time, an important skill as a teacher is choosing the simplest model to help a student towards understanding.This week, we'll revisit some famous experiments and different models of light to advance our own understanding.We'd like you to start off by reading the introductory essay below. Then, watch the video demonstrations and try some activities on your own. This week, we'd also like you to pick an activity or two to share with someone else.Don't forget to post photos, videos and comments in the discussion forum to share with your fellow students.

Week Three: Optics and Image Making
    -This week, we're exploring optics and how to make images with light. In addition to our exhibit and activity demonstrations, you'll learn how to put activities together into a lesson that helps students develop and test a mental model of how the world works. We want you to do this lesson as a learner and then reflect and discuss with your peers in the forum. The lesson is designed as a series of experiments, each one giving you a piece of information that lets you make a mental model. You'll be presented with several scenarios, asked to make a prediction (it's VERY important that you stop and do this at each stage of the video), and then we'll reveal what happens. You'll have an opportunity to revise and adjust your model at each stage.   For those of you taking this course for credit, we recommend you begin working on your peer-reviewed assignment.  If you want some feedback before you submit your assignment, we suggest you post questions and drafts of your lesson plan in the forum. 

Week Four: The Wave Nature of Light
    -What is light? Sometimes we model it as a wave, sometimes as a particle. Light is light. Nevertheless, the wave properties of light lend themselves towards a rich array of experiments that help further our understanding.This is the final week of content for our course. Please continue to do activities this week, but also take a few moments to share what you learned, and any suggestions you have for us.If you are taking the course for a grade, please submit your final assignment and complete the required peer reviews before the deadline. We hope you have enjoyed this experience and that you'll come check out our museum in San Francisco!",Exploring Light: Hands-on Activities and Strategies for Teachers
https://www.classcentral.com/course/edx-programming-for-the-web-with-javascript-8518,"JavaScript is the programming language of the World Wide Web.
As a professional web software developer, you will not only need to know how to program in this simple yet powerful language, but you will need to understand the fundamentals of how data is exchanged on the World Wide Web (WWW) and what tools and frameworks are available to you for creating robust, interactive web applications.
This course, part of the CS Essentials for Software Development Professional Certificate program, provides an introduction to modern web development using JavaScript. In addition to exploring the basics of web page creation using HTML and CSS, you will learn advanced web page layout and responsive design tools such as Bootstrap. You will also learn how browsers represent a web page data using the Document Object Model (DOM) and how to develop dynamic, interactive web pages using JavaScript in the browser. Beyond fundamental JavaScript syntax and advanced language features such as callbacks, events, and asynchronous programming, you will work with jQuery, which provides functionality for simplified DOM manipulation and event handling.
This course will also introduce you to modern web frameworks and component-based libraries such as React.js for efficiently developing modular web page components, and D3.js for creating data-driven documents. We will also teach you how to represent and exchange data using JavaScript Object Notation (JSON), and how to access RESTful APIs on the web.
Server-side JavaScript is becoming more prevalent in the industry, with web frameworks such as Node.js and Express making it simple to create and deploy complex, data-driven web applications. This course will prepare you to use such frameworks and show you how to integrate them with NoSQL databases such as MongoDB.



            Read more
          



Week 1: Web Programming Basics
 
Week 2: Using JavaScript to Create Dynamic Web Pages
 
Week 3: Client-Side Frameworks for Developing Modular Web Page Components
 
Week 4: Building Scalable Web Apps with Server-Side JavaScript",Programming for the Web with JavaScript
https://www.classcentral.com/course/edx-stochastic-processes-data-analysis-and-computer-simulation-8246,"The motion of falling leaves or small particles diffusing in a fluid is highly stochastic in nature. Therefore, such motions must be modeled as stochastic processes, for which exact predictions are no longer possible. This is in stark contrast to the deterministic motion of planets and stars, which can be perfectly predicted using celestial mechanics.
This course is an introduction to stochastic processes through numerical simulations, with a focus on the proper data analysis needed to interpret the results. We will use the Jupyter (iPython) notebook as our programming environment. It is freely available for Windows, Mac, and Linux through the Anaconda Python Distribution.
The students will first learn the basic theories of stochastic processes. Then, they will use these theories to develop their own python codes to perform numerical simulations of small particles diffusing in a fluid. Finally, they will analyze the simulation data according to the theories presented at the beginning of course.
At the end of the course, we will analyze the dynamical data of more complicated systems, such as financial markets or meteorological data, using the basic theory of stochastic processes.



Week 1: Python programming for beginners  - Using Python, iPython, and Jupyter notebook - Making graphs with matplotlib - The Euler method for numerical integration - Simulating a damped harmonic oscillator Week 2: Distribution function and random number - Stochastic variable and distribution functions - Generating random numbers with Gaussian/binomial/Poisson distributions - The central limiting theorem - Random walkWeek 3: Brownian motion 1: basic theories - Basic knowledge of Stochastic process - Brownian motion and the Langevin equation - The linear response theory and the Green-Kubo formula Week 4: Brownian motion 2: computer simulation - Random force in the Langevin equation - Simple Python code to simulate Brownian motion - Simulations with on-the-fly animation Week 5: Brownian motion 3: data analyses - Distribution and time correlation - Mean square displacement and diffusion constant - Interacting Brownian particles Week 6: Stochastic processes in the real world - Time variations and distributions of real world processes - A Stochastic Dealer Model I - A Stochastic Dealer Model II - A Stochastic Dealer Model III",Stochastic Processes: Data Analysis and Computer Simulation
https://www.classcentral.com/course/basic-statistics-4312,"Understanding statistics is essential to understand research in the social and behavioral sciences. In this course you will learn the basics of statistics; not just how to calculate them, but also how to evaluate them. This course will also prepare you for the next course in the specialization - the course Inferential Statistics. 

In the first part of the course we will discuss methods of descriptive statistics. You will learn what cases and variables are and how you can compute measures of central tendency (mean, median and mode) and dispersion (standard deviation and variance). Next, we discuss how to assess relationships between variables, and we introduce the concepts correlation and regression. 

The second part of the course is concerned with the basics of probability: calculating probabilities, probability distributions and sampling distributions. You need to know about these things in order to understand how inferential statistics work. 

The third part of the course consists of an introduction to methods of inferential statistics - methods that help us decide whether the patterns we see in our data are strong enough to draw conclusions about the underlying population we are interested in. We will discuss confidence intervals and significance tests.

You will not only learn about all these statistical concepts, you will also be trained to calculate and generate these statistics yourself using freely available statistical software.
      


            Read more
          



          Before we get started...
    -In this module we'll consider the basics of statistics. But before we start, we'll give you a broad sense of what the course is about and how it's organized. Are you new to Coursera or still deciding whether this is the course for you? Then make sure to check out the 'Course introduction' and 'What to expect from this course' sections below, so you'll have the essential information you need to decide and to do well in this course! If you have any questions about the course format, deadlines or grading, you'll probably find the answers here. Are you a Coursera veteran and ready to get started? Then you might want to skip ahead to the first course topic: 'Exploring data'. You can always check the general information later. Veterans and newbies alike: Don't forget to introduce yourself in the 'meet and greet' forum!

Exploring Data
    -In this first module, we’ll introduce the basic concepts of descriptive statistics. We’ll talk about cases and variables, and we’ll explain how you can order them in a so-called data matrix. We’ll discuss various levels of measurement and we’ll show you how you can present your data by means of tables and graphs. We’ll also introduce measures of central tendency (like mode, median and mean) and dispersion (like range, interquartile range, variance and standard deviation). We’ll not only tell you how to interpret them; we’ll also explain how you can compute them. Finally, we’ll tell you more about z-scores. In this module we’ll only discuss situations in which we analyze one single variable. This is what we call univariate analysis. In the next module we will also introduce studies in which more variables are involved.

Correlation and Regression
    -In this second module we’ll look at bivariate analyses: studies with two variables. First we’ll introduce the concept of correlation. We’ll investigate contingency tables (when it comes to categorical variables) and scatterplots (regarding quantitative variables). We’ll also learn how to understand and compute one of the most frequently used measures of correlation: Pearson's r. In the next part of the module we’ll introduce the method of OLS regression analysis. We’ll explain how you (or the computer) can find the regression line and how you can describe this line by means of an equation. We’ll show you that you can assess how well the regression line fits your data by means of the so-called r-squared. We conclude the module with a discussion of why you should always be very careful when interpreting the results of a regression analysis.     

Probability
    -This module introduces concepts from probability theory and the rules for calculating with probabilities. This is not only useful for answering various kinds of applied statistical questions but also to understand the statistical analyses that will be introduced in subsequent modules. We start by describing randomness, and explain how random events surround us. Next, we provide an intuitive definition of probability through an example and relate this to the concepts of events, sample space and random trials. A graphical tool to understand these concepts is introduced here as well, the tree-diagram.Thereafter a number of concepts from set theory are explained and related to probability calculations. Here the relation is made to tree-diagrams again, as well as contingency tables. We end with a lesson where conditional probabilities, independence and Bayes rule are explained. All in all, this is quite a theoretical module on a topic that is not always easy to grasp. That's why we have included as many intuitive examples as possible.

Probability Distributions
    -Probability distributions form the core of many statistical calculations. They are used as mathematical models to represent some random phenomenon and subsequently answer statistical questions about that phenomenon. This module starts by explaining the basic properties of a probability distribution, highlighting how it quantifies a random variable and also pointing out how it differs between discrete and continuous random variables. Subsequently the cumulative probability distribution is introduced and its properties and usage are explained as well. In a next lecture it is shown how a random variable with its associated probability distribution can be characterized by statistics like a mean and variance, just like observational data. The effects of changing random variables by multiplication or addition on these statistics are explained as well.The lecture thereafter introduces the normal distribution, starting by explaining its functional form and some general properties. Next, the basic usage of the normal distribution to calculate probabilities is explained. And in a final lecture the binomial distribution, an important probability distribution for discrete data, is introduced and further explained. By the end of this module you have covered quite some ground and have a solid basis to answer the most frequently encountered statistical questions. Importantly, the fundamental knowledge about probability distributions that is presented here will also provide a solid basis to learn about inferential statistics in the next modules.

Sampling Distributions
    -Methods for summarizing sample data are called descriptive statistics. However, in most studies we’re not interested in samples, but in underlying populations. If we employ data obtained from a sample to draw conclusions about a wider population, we are using methods of inferential statistics. It is therefore of essential importance that you know how you should draw samples. In this module we’ll pay attention to good sampling methods as well as some poor practices. To draw conclusions about the population a sample is from, researchers make use of a probability distribution that is very important in the world of statistics: the sampling distribution. We’ll discuss sampling distributions in great detail and compare them to data distributions and population distributions. We’ll look at the sampling distribution of the sample mean and the sampling distribution of the sample proportion. 

Confidence Intervals
    -We can distinguish two types of statistical inference methods. We can: (1) estimate population parameters; and (2) test hypotheses about these parameters. In this module we’ll talk about the first type of inferential statistics: estimation by means of a confidence interval. A confidence interval is a range of numbers, which, most likely, contains the actual population value. The  probability that the interval actually contains the population value is what we call the confidence level. In this module we’ll show you how you can construct confidence intervals for means and proportions and how you should interpret them. We’ll also pay attention to how you can decide how large your sample size should be.

Significance Tests
    -In this module we’ll talk about statistical hypotheses. They form the main ingredients of the method of significance testing. An hypothesis is nothing more than an expectation about a population. When we conduct a significance test, we use (just like when we construct a confidence interval) sample data to draw inferences about population parameters. The significance test is, therefore, also a method of inferential statistics. We’ll show that each significance test is based on two hypotheses:  the null hypothesis and  the alternative hypothesis. When you do a significance test, you assume that the null hypothesis is true unless your data provide strong evidence against it. We’ll show you how you can conduct a significance test about a mean and how you can conduct a test about a proportion. We’ll also demonstrate that significance tests and confidence intervals are closely related. We conclude the module by arguing that you can make right and wrong decisions while doing a test. Wrong decisions are referred to as Type I and Type II errors.

Exam time!
    -This is the final module, where you can apply everything you've learned until now in the final exam. Please note that you can only take the final exam once a month, so make sure you are fully prepared to take the test. Please follow the honor code and do not communicate or confer with others while taking this exam. Good luck!",Basic Statistics
https://www.classcentral.com/course/algo2-426,"Algorithms are the heart of computer science, and the subject has countless practical applications as well as intellectual depth. This course is an introduction to algorithms for learners with at least a little programming experience. The course is rigorous but emphasizes the big picture and conceptual understanding over low-level implementation and mathematical details. After completing this course, you will have a greater mastery of algorithms than almost anyone without a graduate degree in the subject.  Specific topics in Part 2 include: greedy algorithms (scheduling, minimum spanning trees, clustering, Huffman codes), dynamic programming (knapsack, sequence alignment, optimal search trees, shortest paths), NP-completeness and what it means for the algorithm designer, analysis of heuristics, local search.  About the instructor: Tim Roughgarden has been a professor in the Computer Science Department at Stanford University since 2004. He has taught and published extensively on the subject of algorithms and their applications.  Note: this course is closing on October 10th, 2016, and relaunching as part of a specialization: https://www.coursera.org/specializations/algorithms



Week 1Two motivating applications; selected review; introduction to greedy algorithms; a scheduling application; Prim's MST algorithm.Week 2Kruskal's MST algorithm and applications to clustering; advanced union-find (optional); Huffman codes.Week 3Dynamic programming: introduction, the knapsack problem, sequence alignment, and optimal binary search trees.Week 4The Bellman-Ford algorithm; all-pairs shortest paths.Week 5NP-complete problems and exact algorithms for them.Week 6Approximation and local search algorithms for NP-complete problems; the wider world of algorithms.Final ExamFinal exam (1 attempt per 24 hours)","Algorithms: Design and Analysis, Part 2"
https://www.classcentral.com/course/edx-how-to-win-coding-competitions-secrets-of-champions-6300,"Want to be the programmer hot tech companies are looking for?
Take your programming skills to the next level and prove your excellence by learning how to succeed in programming competitions.
Besides improving your knowledge of algorithms and programming languages, you’ll gain unique experience in problem solving, thinking outside the box and meeting tough deadlines – all essential for boosting your value as a programmer and securing a coveted job in Silicon Valley (should you want one).
This computer science course is an introduction to competitive programming developed by ITMO University, the leading expert in IT and the only 7-time world champion of the Association for Computing Machinery - International Collegiate Programming Contest (ACM ICPC), the world's most prestigious programming contest.
You will learn all you need to know about the variety of programming competitions that exist, as well as basic algorithms and data structures necessary to succeed in the most popular of them.



Week 1: Welcome to competitive programming
Exploring different kinds of programming competitions and benefits of participating, as well as typical rules and challenges. An overview of algorithmic programming competitions. An introduction to community resources and online contests.
Week 2: Computational complexity and linear data structures
An overview of computational complexity (Big O notation). Exploring linear data structures (array, list, stack, queue): operations, complexity, implementation and examples.
Week 3: Sorting and search algorithms 1
An overview of sorting algorithms: insertion sort, quick sort, merge sort.
Week 4: Sorting and search algorithms 2
Theoretical limitations and practical guidelines for sorting. Binary search. Binary heaps and priority queues.
Week 5: Graph theory 1
Definition of graphs and examples of graph problems. Various ways of storing graphs in memory. Depth first search and its applications. Dynamic programming.
Week 6: Graph theory 2
Breadth first search. Eulerian and Hamiltonian paths and tours. Shortest paths.
Week 7: Final Exam
Solving a set of problems in limited time just like in a real programming competition.",How to Win Coding Competitions: Secrets of Champions
https://www.classcentral.com/course/edx-foundations-of-data-analysis-part-1-statistics-using-r-4805,"In this first part of a two part course, we’ll walk through the basics of statistical thinking – starting with an interesting question. Then, we’ll learn the correct statistical tool to help answer our question of interest – using R and hands-on Labs. Finally, we’ll learn how to interpret our findings and develop a meaningful conclusion.
This course will consist of:

Instructional videos for statistical concepts broken down into manageable topics
Guided questions to help your understanding of the topic
Weekly tutorial videos for using R Scaffolded learning with Pre-Labs (using R), followed by Labs where we will answer specific questions using real-world datasets
Weekly wrap-up questions challenging both topic and application knowledge

We will cover basic Descriptive Statistics – learning about visualizing and summarizing data, followed by a “Modeling” investigation where we’ll learn about linear, exponential, and logistic functions. We will learn how to interpret and use those functions with basic Pre-Calculus. These two “units” will set the learner up nicely for the second part of the course: Inferential Statistics with a multiple regression cap.
Both parts of the course are intended to cover the same material as a typical introductory undergraduate statistics course, with an added twist of modeling. This course is also intentionally devised to be sequential, with each new piece building on the previous topics. Once completed, students should feel comfortable using basic statistical techniques to answer their own questions about their own data, using a widely available statistical software package (R).
With these new skills, learners will leave the course with the ability to use basic statistical techniques to answer their own questions about their own data, using a widely available statistical software package (R). Learners from all walks of life can use this course to better understand their data, to make valuable informed decisions.
Join us in learning how to look at the world around us. What are the questions? How can we answer them? And what do those answers tell us about the world we live in?



            Read more
          



Week One: Introduction to Data

Why study statistics?
Variables and data
Getting to know R and RStudio

Week Two: Univariate Descriptive Statistics

Graphs and distribution shapes
Measures of center and spread
The Normal distribution
Z-scores 

Week Three: Bivariate Distributions

The scatterplot
Correlation

Week Four: Bivariate Distributions (Categorical Data)

Contingency tables
Conditional probability
Examining independence

Week Five: Linear Functions

What is a function?
Least squares
The Linear function – regression 

Week Six: Exponential and Logistic Function Models

Exponential data
Logs
The Logistic function model
Picking a good mode",Foundations of Data Analysis - Part 1: Statistics Using R
https://www.classcentral.com/course/linear-regression-r-public-health-13077,"Welcome to Linear Regression in R for Public Health!

Public Health has been defined as “the art and science of preventing disease, prolonging life and promoting health through the organized efforts of society”. Knowing what causes disease and what makes it worse are clearly vital parts of this. This requires the development of statistical models that describe how patient and environmental factors affect our chances of getting ill. This course will show you how to create such models from scratch, beginning with introducing you to the concept of correlation and  linear regression before walking you through importing and examining your data, and then showing you how to fit models. Using the example of respiratory disease, these models will describe how patient and other factors affect outcomes such as lung function. 

Linear regression is one of a family of regression models, and the other courses in this series will cover two further members. Regression models have many things in common with each other, though the mathematical details differ. 
This course will show you how to prepare the data, assess how well the model fits the data, and test its underlying assumptions – vital tasks with any type of regression. 
You will use the free and versatile software package R, used by statisticians and data scientists in academia, governments and industry worldwide.
      


          INTRODUCTION TO LINEAR REGRESSION
    -Before jumping ahead to run a regression model, you need to understand a related concept: correlation. This week you’ll learn what it means and how to generate Pearson’s and Spearman’s correlation coefficients in R to assess the strength of the association between a risk factor or predictor and the patient outcome. Then you’ll be introduced to linear regression and the concept of model assumptions, a key idea underpinning so much of statistical analysis.

Linear Regression in R
    -You’ll be introduced to the COPD data set that you’ll use throughout the course and will run basic descriptive analyses. You’ll also practise running correlations in R. Next, you’ll see how to run a linear regression model, firstly with one and then with several predictors, and examine whether model assumptions hold.

Multiple Regression and Interaction
    -Now you’ll see how to extend the linear regression model to include binary and categorical variables as predictors and learn how to check the correlation between predictors. Then you’ll see how predictors can interact with each other and how to incorporate the necessary interaction terms into the model and interpret them. Different kinds of interactions exist and can be challenging to interpret, so we will take it slowly with worked examples and opportunities to practise.

MODEL BUILDING
    -The last part of the course looks at how to build a regression model when you have a choice of what predictors to include in it. It describes commonly used automated procedures for model building and shows you why they are so problematic. Lastly, you’ll have the chance to fit some models using a more defensible and robust approach.",Linear Regression in R for Public Health
https://www.classcentral.com/course/systems-application-security-sscp-10338,"Welcome to Systems and Application Security Course!
In the Systems and Application Security Course, you will gain an understanding of computer code that can be described as harmful or malicious. Both technical and non-technical attacks will be discussed. You will learn how an organization can protect itself from these attacks. You will learn concepts in endpoint device security, cloud infrastructure security, securing big data systems, and securing virtual environments.
Objectives
1. Identify malicious code activity
2. Describe malicious code and the various countermeasures
3. Describe the processes for operating endpoint device security
4. Define mobile device management processes
5. Describe the process for configuring cloud security
6. Explain the process for securing big data systems
7. Summarize the process for securing virtual environments
      


          Identify and Analyze Malicious Code and Activity
    -Module Topics: Malicious Code, Malicious Code Countermeasures, Exploitation, Insider Threats, Spoofing, Phishing, Spam, and Botnet, Malicious Web Activity, Payloads, Malicious Activity Countermeasures, Malcode Mitigation, and Common Mistakes. Malicious Code includes topics like Key concepts, Example Worms, Polymorphic Viruses, Software Exploitation Methods, Scanners, Generations of Antivirus Scanning Software,  Generic Decryption (GD) Technology, Behavior-Blocking Software, Antivirus Software on the Firewall and IDS, Code signing, Code Signing Certificates, Sandboxing, Virtual Machine (VM), Social Engineering, Additional Examples of Social Engineering Attacks, and Security Awareness Training. Under the topic of Exploitation, you will learn about Long File Extensions, Fake Icon, Hostile Codecs, and E-mail. In Insider Threats, you will learn about Indicators of Malicious Threat Activity, Countermeasures, Direction, Prevention, and Deterrence Methods, Continual Training, and Insider Hardware Threats. In Spoofing, Phishing, Spam, and Botnets, you will learn about Spoofing, Examples of Spoofing, Phishing, Common Characteristics of Forged E-Mail Messages, Techniques, How Phishing Works, Impact of Phishing, How to Recognize a Phishing E-Mail, Spam, Spam Distribution Channels, How Does Spam Work?, Spam Techniques, Protecting users From Spam, Botnets, How Are Botnets Created?, Botnet-Led Exploits, Botnet Detection and Mitigation, Common Botnet Detection and Mitigation Techniques. In Malicious Web Activity, you will go through topics like Mobomarket Attack, Cross-site Scripting (XSS) Attacks, The Theory of XSS, XSS Attack Vectors, Is the Organization's Site Vulnerable to Cross-Site Scripting? Example of a Cross-Site Scripting Attack, How to check for Cross-Site Scripting Vulnerabilities, Zero-Day Exploits and Advanced Persistent Threats (APTS), Unknown Vulnerabilities management Process, Five Phases of APT, Brute-Force Attacks, Instant Messaging, Infected Factory Builds and Media, man-in-the-Middle Malcode, Malicious Activity Countermeasures, Network Layer, Application Layer, Modified Hosts File and DNS Changes, Inspection of Process, Rootkit, Rootkit Classifications, Behavioral Analysis of Malcode, and Static File Analysis.

Implement and Operate Endpoint Device Security
    -Module Topics: Host-Based Intrusion Detection Systems (HIDS), Host-Based Firewalls, Application Whitelisting, Endpoint Encryption, Trusted Platform Module (TPM), Mobile Device Management (MDM), Secure Browsing. In Host-Based Intrusion Detection Systems (HIDS), you will learn about Advantages and Disadvantages of HIDS. In Application Whitelisting, you will learn about software Restriction Policies (SRP), Trusted Platform Module (TPM). In Mobile Device Management (MDM), you will learn about Bring your Own Device (BYOD), Security, BYOD Policy Considerations, BYOD Policy Considerations, Corporate Owned, Personally Enabled (COPE), and Secure Browsing.

Operate and Configure Cloud Security
    -Module Topics: Introduction, Deployment Models, Service Models, Virtualization, Legal and Privacy Concerns, Classification of Discovered Sensitive Data, Mapping and Definition of Controls, Application of Defined Controls for Personally Identifiable Information (PII), Data Storage and Transmission, Encryption, Key Management, Masking/Obfuscation and Anonymization, Tokenization, Data Deletion Procedures and Mechanisms, Event Sources, Data Event Logging and Event Attributes, and Storage and Analysis of Data Events. Introduction covers the Five Essential Characteristics of Clouds. Deployment Models cover topics like Public, Private, Hybrid and Community Cloud, Service Models, SaaS, PaaS, and IaaS. Virtualization includes Hypervisor, and Types of Virtualization. In Legal and Privacy Concerns, you will learn about Key P&DP Questions, Country-Specific Legal Considerations, Jurisdiction and Applicable Law, Essential Requirements in P&DP Laws, Typical Meaning for Common Privacy Terms, Privacy Roles for Customer and Service Provider, Data Discovery, and Privacy Level Agreement (PLA). In Application of Defined Controls for Personally Identifiable Information (PII), you will learn about Cloud security Alliance Cloud Controls Matrix (CCM), CCM Security Domains, Data Dispersion in Cloud Storage, Threat to storage Types, Technologies Available to Address Threats, Data Loss Prevention (DLP), DLP Components, DLP Architecture, Cloud-Based DLP Considerations, and Best Practices. In Encryption, you will learn about Sample Use cases for Encryption, Cloud Encryption Challenges, Key Management, Key Storage in the Cloud, and Key Management in Software environments. In Masking/Obfuscation and Anonymization, you will learn about Data Masking/Obfuscation, Common Approaches for Data Masking, Primary Methods of Masking Data, and Data Anonymization. Tockenization covers topics like Tokenization and Cloud, Data Retention Policies, Data Deletion Procedures and Mechanisms, Disposal Options, Crypto-shredding, Data Archiving Policy, Security and Information Event Management (SIEM). Data Event Logging and Event Attributes covers topics like OWASP Recommendations, SIEM Capabilities, and SIEM Challenges.  

Secure Big Data Systems & Operate and Secure Virtual Environments
    -Module Topics for Secure Big Data Systems: Application Vulnerabilities and Architecture or Design Environments. Application Vulnerabilities include topics like Data Growth, Big Data, Interpreting Big, Data, Big Data Issues, and Challenges with 'Free' Analytic Tools. Architectural or Design Environments include topics like Distributed Computing Architectures, Key Challenges, Securing the Organization's Big Data, and Deploying Big Data for Security. Module Topics for Operate and Secure Virtual Environments: Software-Defined Network (SDN), Virtual Appliances, Continuity and Resilience, Attacks and Countermeasures, Common Virtualization Attacks, Recommendations and Best Practices for Secure Virtualization, and Shared Storage. In Software-Defined network (SDN), you will learn about How SDN Works. Virtual Appliances talks about Virtual Appliances Compared to Virtual Machines. In Continuity and Resilience you will learn about Host Clustering Concepts, VMware Distributed Resource Scheduling (DRS), Scalability and Reliability, windows Failover Clustering. In Common Virtualization Attacks, you will learn about Mitigation Strategies. In Recommendations and Best Practices for Secure Virtualization you will learn about Desktop Virtualization and Security, Network Security, Storage Networks, Auditing and Logging, Virtual Machine Security, Management Systems, Hypervisor Security, Time Synchronization, Remote Access, Backups, and Configuration and Change Management. 

Case Study

End-of-Course Assessment",Systems and Application Security
https://www.classcentral.com/course/humanevolution-681,"NOTE: This course is no longer available on Coursera. But the videos of the course have been uploaded by the instructor on Youtube here: https://www.youtube.com/watch?v=upRFk2b2vas&list=PL3aUlTZucB4GoRkOoVgVIbbN7JqrXioFQ
 
This course covers our evolutionary history across more than seven million years, from our origins among the apes up to the biological changes that are still unfolding today. If you enroll, you'll encounter the evidence for the earliest members of our lineage, as they begin the long pathway to humanity. You'll see how scientists are learning about the diets of ancient people, using microscopic evidence and chemical signatures in ancient teeth. We will explore together the exciting fossil discoveries of the last ten years, which have shaken up our notions of the origin of human culture and our own genus. Genomics has fundamentally transformed the way we understand our evolution, in many ways opening the direct evidence of our history to anyone. The course will teach you how to look inside the genomes of humans, Neandertals and other ancient people.  If you have used personal genomics to get your own genotypes, the course will guide you in connecting genetics to your ancestry among ancient humans.The course brings a special focus on the rapid evolutionary changes of the last 10,000 years. You'll learn about the consequences of our shift to agriculture, and the ways that people of industrialized nations are still changing today. At the end, we trek forward to anticipate what evolutionary changes may be in store for humanity in the future, using our knowledge of history and scientific understanding to inform our speculations.
      


            Read more",Human Evolution: Past and Future
https://www.classcentral.com/course/opensap-introduction-to-statistics-for-data-science-17229,"This course will provide you with the knowledge to understand some of the basic statistical concepts and practices that are the foundations of data science and the way we analyze data. We’ll also be highlighting how statistics can be misused and abused, leading to accidental misunderstandings or deliberate distortions to support a particular prejudiced view.
Throughout this course, you’ll be looking at how data can be summarized in a variety of ways to give you a descriptive overview of large data sets and their variations. We’ll explore how data distributions can be understood and compared. You’ll also learn how you can start finding patterns in the data, where changes in one variable may be (partly) explained by changes in another. In addition, you’ll learn a little about how to estimate the likelihood of certain outcomes based on certain prior information. Finally, we’ll link this up to some of the common tools available that make these kinds of analyses easier.
The course is spread over six weeks and consists of lectures and weekly assignments. Statistics can be a complex subject, but in this course, you’ll revisit the fundamental principles and start to appreciate how it can be used in your everyday life. We’ll focus primarily on the key principles.
 



Week 1: Introduction to Statistics
Week 2: Descriptive Statistics
Week 3: Correlation and Linear Regression
Week 4: Introduction to Probability
Week 5: Probability Distributions
Week 6: Connecting to Your SAP Solutions
Week 7: Final Exam",Introduction to Statistics for Data Science
https://www.classcentral.com/course/healthcare-data-13727,"Digital health is rapidly being realised as the future of healthcare. While this is placing emphasis on the input of quality health data in digital records and systems, the delivery of safe and quality healthcare relies not only on the input of data, but also the ability to access and derive meaning from data to generate evidence, inform decision making and drive better health outcomes.

This course provides insight into the use of healthcare data, including an overview of best practices and the practical realities of obtaining useful information from digital health systems via the understanding of the fundamental concepts of health data analytics.  

Learners will understand why data quality is essential in modern healthcare, as they are guided through various stages of the data life cycle, starting with the generation of quality health data, through to discovering patterns and extracting knowledge from health data using common methodologies and tools in the basic analysis, visualisation and communication of health data. In doing so, learners explore current healthcare delivery contexts, and future and emerging digital health data systems and applications that are rapidly becoming tomorrow’s reality.

On completion of this course, you will be able to:
1.	Identify digital health technologies, health data sources, and the evolving roles of health workforce in digital health environments
2.	Understand key health data concepts and terminology, including the significance of data integrity and stakeholder roles in the data life cycle
3.	Use health data and basic data analysis to inform and improve decision making and practice.
4.	Apply effective methods of communication of health data to facilitate safe and quality care.

During this course, you will interact with learning content contributed by:
•	Digital Health Cooperative Research Centre
•	Australian Digital Health Agency
•	eHealth NSW
•	Sydney Local Health District
•	The NSW Ministry of Health
•	Health Education and Training Institute
•	Clinical Excellence Commission 
•	Chris O’Brien Lifehouse
•	Monash Partners / Australian Health Research Alliance
•	Australian Research Data Commons
•	Justice Health & Forensic Mental Health Network
•	South Eastern Sydney Local Health District
•	Western Sydney Local Health District
•	Westmead Breast Cancer Institute
•	Agency for Clinical Innovation
•	Western NSW Local Health District
•	Sydney Children’s Hospital Network

This course is a collaborative venture between NSW Health, the University of Sydney and the Digital Health Cooperative Research Centre, including dedicated resources from eHealth NSW, Health Education and Training Institute, and the Research in Implementation Science & eHealth group. While many learning resources and case examples are drawn from the NSW Health service context, this course has relevance for all existing and future health workforce, regardless of role or work context.
Note: Materials used are for learning purposes and content may not reflect your organisation’s policies. When working with data, make sure you act within the guidelines and policies of your organisation.
      


            Read more
          



          An introduction to digital health
    -This module explores current digital health environments, identifying the many uses of digital health technologies and health data sources. We look at the evolving roles of the health workforce in digital health environments, considering roles and responsibilities. The importance of data analytics for decision making and healthcare outcomes is introduced.                                                                                                                                                           

Note: Materials used are for learning purposes and content may not reflect your organisation’s policies. When working with data, make sure you act within the guidelines and policies of your organisation.

Everyone plays a role in health data
    -In this module, we review key health data concepts and terminology. We emphasise the importance of data integrity and the benefits and consequences of high or low quality data. We look at the data life cycle and the roles and responsibilities of all stakeholders in the provision of quality healthcare. There are some case studies illustrating the consequences of poor quality data and we also look at the fundamentals of digital health legislation and policy.                                      Note: Materials used are for learning purposes and content may not reflect your organisation’s policies. When working with data, make sure you act within the guidelines and policies of your organisation.

Interpret health data - turn information into new insights 
    -In this module, we look at the use of health data and basic data analysis to inform and improve decision making and practice. We explore some common methods and tools used in the analysis of health data. There is an opportunity to develop a data query and to practice working with data.                                                                                                                         Note: Materials used are for learning purposes and content may not reflect your organisation’s policies. When working with data, make sure you act within the guidelines and policies of your organisation.

Share and integrate data into practice
    -In the final module, we look at the various modes of communication appropriate for sharing the results produced by data analysis.  We consider how effective communication of digital health data contributes to greater consumer engagement and well-being as well as more effective, evidence-based decision making within the healthcare system.                                                                                                                                                                                                   Note: Materials used are for learning purposes and content may not reflect your organisation’s policies. When working with data, make sure you act within the guidelines and policies of your organisation.",Using clinical health data for better healthcare
https://www.classcentral.com/course/introthermodynamics-815,"COURSE DESCRIPTION
This course provides an introduction to the most powerful engineering principles you will ever learn - Thermodynamics: the science of transferring energy from one place or form to another place or form. We will introduce the tools you need to analyze energy systems from solar panels, to engines, to insulated coffee mugs. More specifically, we will cover the topics of mass and energy conservation principles; first law analysis of control mass and control volume systems; properties and behavior of pure substances; and applications to thermodynamic systems operating at steady state conditions.

COURSE FORMAT
The class consists of lecture videos, which average 8 to 12 minutes in length. The videos include integrated In-Video Quiz questions. There are also quizzes at the end of each section, which include problems to practice your analytical skills that are not part of video lectures. There are no exams.

GRADING POLICY
Each question is worth 1 point. A correct answer is worth +1 point. An incorrect answer is worth 0 points. There is no partial credit. You can attempt each quiz up to three times every 8 hours, with an unlimited number of total attempts. The number of questions that need to be answered correctly to pass are displayed at the beginning of each quiz. Following the Mastery Learning model, students must pass all 8 practice quizzes with a score of 80% or higher in order to complete the course.

ESTIMATED WORKLOAD
If you follow the suggested deadlines, lectures and quizzes will each take approximately ~3 hours per week each, for a total of ~6 hours per week. 

TARGET AUDIENCE
Basic undergraduate engineering or science student.

FREQUENTLY ASKED QUESTIONS
- What are the prerequisites for taking this course? 
     An introductory background (high school or first year college level) in chemistry, physics, and calculus will help you be successful in this class.
-What will this class prepare me for in the academic world? 
     Thermodynamics is a prerequisite for many follow-on courses, like heat transfer, internal combustion engines, propulsion, and gas dynamics, to name a few.
-What will this class prepare me for in the real world? 
     Energy is one of the top challenges we face as a global society. Energy demands are deeply tied to the other major challenges of clean water, health, food resources, and poverty. Understanding how energy systems work is key to understanding how to meet all these needs around the world. Because energy demands are only increasing, this course also provides the foundation for many rewarding professional careers.
      


            Read more
          



          Week 1
    -In this module, we frame the context of energy and power supply and demand around the world. You will learn that understanding and correctly using units are critical skills for successfully analyzing energy systems. It is also important to be able to identify and categorize systems as “open” or “closed” and “steady state” or “transient”. Thermodynamics is a topic that is very notation intense, but the notation is very helpful as a check on our assumptions and our mathematics. Additionally, in this module we will refresh our understanding of some common thermodynamic properties.

Week 2
    -In this module, we will get started with the fundamental definitions for energy transfer, including the definitions of work transfer and heat transfer. We will also show (by example) how state diagrams are valuable for explaining energy transfer processes. Then, we have all the tools we need to define the 1st Law of Thermodynamics also called the Conservation of Energy. Your second assignment will emphasize these principles and skills.

Week 3
    -In this module, we introduce our first abstract concepts of thermodynamics properties – including the specific heats, internal energy, and enthalpy. It will take some time for you to become familiar with what these properties represent and how we use these properties. For example, internal energy and enthalpy are related to temperature and pressure, but they are two distinct thermodynamic properties. One of the hardest concepts of thermodynamics is relating the independent thermodynamic properties to each other. We have to become experts at these state relations in order to be successful in our analysis of energy systems. There are several common approximations, including the ideal gas model, which we will use in this class. The key to determining thermodynamic properties is practice, practice, practice! Do as many examples as you can.

Week 4
    -In this module we introduce the combined application of the Conservation of Mass and the Conservation of Energy for system analysis. We also review the common assumptions for typical energy transfer devices, like heat exchangers, pumps and turbines. Together these components will form the basis for all power plants used around the world.

Week 5
    -In this module, we tackle some of the most difficult systems to analyze – transient or time-varying systems. Any system where the energy transfer changes as a function of time requires transient analysis. Not only are these difficult problems to analyze, they are also difficult systems to design and interrogate. Some important transient problems include the start-up of a gas turbine or an internal combustion engine. Such transients are becoming more integral to the electrical power grid due to the introduction of more renewable power sources which are also more intermittent. These are very relevant and timely topics for the stationary power sector.

Week 6
    -In this module, we introduce some of the concepts of the Second Law of Thermodynamics. We will only discuss a small fraction of the vast material that falls under the topic of the Second Law. I encourage you to explore beyond our course material for very interesting discussions on the outcomes of the Second Law which include entropy, the absolute temperature scale and Carnot cycles. The most important aspect for our class, is that the Second Law provides a basis for defining the theoretical maximums and minimums for processes. Using these limits, we can define device and system efficiencies. We demonstrate these limits with examples of basic power plants. A good “take-home” exercise is to apply these limits to some of the devices and systems you see every day around you.

Week 7
    -In this module we focus on in-depth analysis of a Rankine power plant. The Rankine power plant is the fundamental design for stationary power generation when the working fluid is water (or steam) and the energy carrier is nuclear, coal, gas, or thermal solar power. We also learn that conventional power plants generate a lot of waste heat!  Co-generation is a great way to use that waste heat. Can you think of a few ways you might capture waste heat and use it productively? Then you might have your next environmentally sustainable business venture!

Week 8
    -In this module, we have a brief discussion of energy carriers – including fossil fuels and battery materials. These lectures highlight the thermodynamic properties of these energy carriers and storage materials that make these systems so attractive and at the same time, so difficult to replace. As this is our last module of the course, I hope you have enjoyed this Introduction to Thermodynamics and that you have learned some new skills. Good luck on all your adventures in energy systems!,",Introduction to Thermodynamics: Transferring Energy from Here to There
https://www.classcentral.com/course/m-scopy-1-4752,"Learn about the fundamentals of transmission electron microscopy in materials sciences: you will be able to understand papers where TEM has been used and have the necessary theoretical basis for taking a practical training on the TEM.

This course provides a comprehensive introduction to transmission electron microscopy (TEM) in the field of materials science. For an instrument operated by a single user, modern TEM provides an analytical platform with unsurpassed versatility, giving access to structural and chemical information from the micrometer to the sub-angstrom scale. In a thin, electron-transparent sample one can measure the crystallinity, grain structure, size, and defects, and the chemical composition. The crystal lattice can be imaged with atomic resolution, allowing observation of grain boundaries and interfaces. It is the only direct structural analysis method for studying nanoparticles.

With this course you will gain a deep understanding of modern TEM and the connection between: 
-	the optics and operation of the instrument; 
-	the physics of electron-matter interactions; 
-	insights into the materials properties of the sample. 

This gives the background to: 
-	identify TEM techniques suitable to solving specific scientific problems; 
-	interpret TEM data presented in articles; appreciate the impact of technological advances that have, for instance, led to sub-angstrom resolution by aberration correction. 
It can also be the basis for subsequent practical training on this remarkable instrument, and a stepping stone towards  learning very advanced techniques with magical names like “dark field holography” or  “angular resolved electron energy-loss spectroscopy”. 

Recommended background: 

Basics of crystallography and diffraction, college optics (construction of ray diagrams) are absolutely mandatory prerequisites; Fourier optics, more advanced crystallography and solid state physics are of great advantage.
      


            Read more
          



          Introduction
    -This week will be devoted to an introduction to the instrument, with some historical notes, as well as a review of the building blocks of a transmission electron microscope. In a second part, we will review the main lens aberrations relevant in transmission electron microscopy.

Introduction (II)
    -This week, we will see how to build the microscope from its individual components: lenses and aperture. Then we will have a review of the operating modes of the microscope.

Diffraction basics (I): Ewald sphere / Reciprocal lattice
    -In this week on the basics of electron diffraction we discuss the case of 2-beam diffraction at the Bragg angle in TEM and then show how it can be represented by the Ewald sphere/reciprocal lattice construction.

Diffraction basics (II): Multi-beam / Kinematical scattering
    -In this week we finish on the basics of electron diffraction, by first taking a look at zone axis or multi-beam diffraction where we have scattering from many different crystal planes at the same time. Next, we explain this by a relaxation of the Bragg condition in the Ewald sphere/reciprocal lattice construction resulting from the TEM sample size and shape. We then see how this affects diffraction spot intensity when slightly deviated from the perfect Bragg condition in the 2-beam case.

Diffraction and imaging: Dynamical effects (I)
    -In this week we will tackle the subject of dynamical scattering in TEM. Dynamical scattering is multiple elastic scattering; it effectively involves the diffraction and rediffraction of electrons as they transmit through a sample. In the first lecture, we look at the basic theory of dynamical scattering in the 2-beam case and use the theoretical expressions to calculate plots of beam intensity versus excitation error for different specimen conditions. In the next lecture, we use this theory to explain the dynamical scattering phenomenon of thickness fringes.

Diffraction and imaging: Dynamical effects (II)
    -This week we look at more effects of dynamical scattering, on both TEM images and diffraction pattern formation. First we look at how dynamical scattering produces bend contours in bright-field and dark-field images when the crystal lattice is bent across an imaged region of TEM sample. Secondly, a special case of dynamical scattering called double diffraction is introduced, in which multiple elastic scattering leads to the formation of diffraction spots for crystal planes which are systematic absences.

Phase contrast (I)
    -In this first week about phase contrast, we will define the contrast transfer function of the objective lens. In a second part we will consider an object that affects only weakly the phase of the electron wave and not its amplitude. This will lead us to the definition of the phase contrast transfer function. 

Phase contrast (II)
    -In this week we will analyse more in details the Phase Contrast Transfer Function, and see how it can be used to understand the contrast in the image of a thin amorphous film. In a second part, we will address the high resolution images of crystalline specimens.",Transmission electron microscopy for materials science
https://www.classcentral.com/course/edx-principles-of-machine-learning-python-edition-11609,"Machine learning uses computers to run predictive models that learn from existing data in order to forecast future behaviors, outcomes, and trends. 
In this data science course, you will be given clear explanations of machine learning theory combined with practical scenarios and hands-on experience building, validating, and deploying machine learning models. You will learn how to build and derive insights from these models using Python, and Azure Notebooks. 
edX offers financial assistance for learners who want to earn Verified Certificates but who may not be able to pay the fee. To apply for financial assistance, enroll in the course, then follow this link to complete an application for assistance.




Introduction to Machine Learning
Exploring Data
Data Preparation and Cleaning
Getting Started with Supervised Learning
Improving Model Performance
Machine Learning Algorithms
Unsupervised Learning

Note: This syllabus is preliminary and subject to change.",Principles of Machine Learning: Python Edition
https://www.classcentral.com/course/edx-discrete-time-signals-and-systems-part-1-time-domain-1236,"Technological innovations have revolutionized the way we view and interact with the world around us. Editing a photo, re-mixing a song, automatically measuring and adjusting chemical concentrations in a tank: each of these tasks requires real-world data to be captured by a computer and then manipulated digitally to extract the salient information. Ever wonder how signals from the physical world are sampled, stored, and processed without losing the information required to make predictions and extract meaning from the data?
Students will find out in this rigorous mathematical introduction to the engineering field of signal processing: the study of signals and systems that extract information from the world around us. This course will teach students to analyze discrete-time signals and systems in both the time and frequency domains. Students will learn convolution, discrete Fourier transforms, the z-transform, and digital filtering. Students will apply these concepts in interactive MATLAB programming exercises (all done in browser, no download required).
Part 1 of this course analyzes signals and systems in the time domain. Part 2 covers frequency domain analysis.
Prerequisites include strong problem solving skills, the ability to understand mathematical representations of physical systems, and advanced mathematical background (one-dimensional integration, matrices, vectors, basic linear algebra, imaginary numbers, and sum and series notation). Part 1 is a prerequisite for Part 2. This course is an excerpt from an advanced undergraduate class at Rice University taught to all electrical and computer engineering majors.



            Read more","Discrete Time Signals and Systems, Part 1: Time Domain"
https://www.classcentral.com/course/opensap-introduction-to-statistics-for-data-science-17229,"This course will provide you with the knowledge to understand some of the basic statistical concepts and practices that are the foundations of data science and the way we analyze data. We’ll also be highlighting how statistics can be misused and abused, leading to accidental misunderstandings or deliberate distortions to support a particular prejudiced view.
Throughout this course, you’ll be looking at how data can be summarized in a variety of ways to give you a descriptive overview of large data sets and their variations. We’ll explore how data distributions can be understood and compared. You’ll also learn how you can start finding patterns in the data, where changes in one variable may be (partly) explained by changes in another. In addition, you’ll learn a little about how to estimate the likelihood of certain outcomes based on certain prior information. Finally, we’ll link this up to some of the common tools available that make these kinds of analyses easier.
The course is spread over six weeks and consists of lectures and weekly assignments. Statistics can be a complex subject, but in this course, you’ll revisit the fundamental principles and start to appreciate how it can be used in your everyday life. We’ll focus primarily on the key principles.
 



Week 1: Introduction to Statistics
Week 2: Descriptive Statistics
Week 3: Correlation and Linear Regression
Week 4: Introduction to Probability
Week 5: Probability Distributions
Week 6: Connecting to Your SAP Solutions
Week 7: Final Exam",Introduction to Statistics for Data Science
https://www.classcentral.com/course/humanevolution-681,"NOTE: This course is no longer available on Coursera. But the videos of the course have been uploaded by the instructor on Youtube here: https://www.youtube.com/watch?v=upRFk2b2vas&list=PL3aUlTZucB4GoRkOoVgVIbbN7JqrXioFQ
 
This course covers our evolutionary history across more than seven million years, from our origins among the apes up to the biological changes that are still unfolding today. If you enroll, you'll encounter the evidence for the earliest members of our lineage, as they begin the long pathway to humanity. You'll see how scientists are learning about the diets of ancient people, using microscopic evidence and chemical signatures in ancient teeth. We will explore together the exciting fossil discoveries of the last ten years, which have shaken up our notions of the origin of human culture and our own genus. Genomics has fundamentally transformed the way we understand our evolution, in many ways opening the direct evidence of our history to anyone. The course will teach you how to look inside the genomes of humans, Neandertals and other ancient people.  If you have used personal genomics to get your own genotypes, the course will guide you in connecting genetics to your ancestry among ancient humans.The course brings a special focus on the rapid evolutionary changes of the last 10,000 years. You'll learn about the consequences of our shift to agriculture, and the ways that people of industrialized nations are still changing today. At the end, we trek forward to anticipate what evolutionary changes may be in store for humanity in the future, using our knowledge of history and scientific understanding to inform our speculations.
      


            Read more",Human Evolution: Past and Future
https://www.classcentral.com/course/analyze-709,"Using publicly available data from NASA of actual satellite observations of astronomical  x-ray sources, we explore some of the mysteries of the cosmos, including neutron stars, black holes, quasars and supernovae.  We will analyze energy spectra and time series data to understand how these incredible objects work.  We utilize an imaging tool called DS9 to explore the amazing diversity of astronomical observations that have made x-ray astronomy one of the most active and exciting fields of  scientific investigation in the past 50 years.

Each week we will explore a different facet of x-ray astronomy.  Beginning with an introduction to the nature of image formation, we then move on to examples of how our imaging program, DS9,  can aid our understanding of real satellite data.  You will using the actual data that scientists use when doing their work.  Nothing is ""canned"".  You will be able to appreciate the excitement that astronomers felt when they made their important discoveries concerning periodic binary x-ray sources, supernovae and their remnants, and extragalactic sources that have shaped our understanding of cosmology.
      


          Light and the Nature of Images....Plus, an Introduction to DS9
    -Welcome to Week 1 of ""Analyzing the Universe!"" This week we  explore the nature of light, and how we get astronomical information from the images we obtain. The lectures and ""wiki"" material address these themes: light, image formation, and DS9. Dive right in! 



 Basic Astronomical Data and a DS9 Smorgasbord
    -Welcome to week two of ""Analyzing the Universe"". This week we will be exploring some of the means we have at our disposal to find out many things about the stars. It is really quite incredible that these tiny pinpoints of light can yield so much information about their nature and about the structure of the Universe as a whole.   And if this is your first visit to the course, welcome and jump right in! 

Stellar Evolution and White Dwarfs
    -This week is our first in-depth look at an x-ray source, and it involves a white dwarf in a binary system. So sharpen up your detective skills, keep your copy of DS9 at the ready, and let's get down to business. It should be an exciting week.

Orbits, Gravity, and Clocks in the Sky
    -This week we turn our attention to another fascinating cosmic source, discovered in the infancy of x-ray astronomy: Cen X-3. In so doing, we will see how binary stars can determine and influence many of the interesting and surprising features of our observations.

Supernovae, Our Cosmic Recycling Centers
    -This week, we will be examining supernovae, and their remnants. These fascinating objects are the breeding grounds for future stars, and were the sources of virtually all the atoms that make up our solar neighborhood. Every atom of calcium in every bone in your body, for example, was once shot out of a supernova, billions of years ago. 

To the Ends of the Universe; Quasars, 3C273, and beyond
    - This week we wrap things up with trips to galaxies and exotic objects, seen long ago and far away. The mysterious quasars provide clues about the way our Universe is evolving in time. They are incredible objects (actually, come to think of it, what isn't incredible in the x-ray sky?) discovered almost exactly a half century ago, quite by accident. We will explore the astonishingly prodigious x-ray output of 3C 273, one of the nearest ones, at a mere 2.5 billion light years away.",Analyzing the Universe
https://www.classcentral.com/course/logic2-1455,"Information is everywhere: in our words and our world, our thoughts and our theories, our devices and our databases. Logic is the study of that information: the features it has, how it’s represented, and how we can manipulate it. Learning logic helps you formulate and answer many different questions about information:Does this hypothesis clash with the evidence we have or is it consistent with the evidence?Is this argument watertight, or do we need to add more to make the conclusion to really follow from the premises?Do these two sentences say the same things in different ways, or do they say something subtly different?Does this information follow from what’s in this database, and what procedure could we use to get the answer quickly?Is there a more cost-effective design for this digital circuit? And how can we specify what the circuit is meant to do so we could check that this design does what we want?These are questions about Logic. When you learn logic you'll learn to recognise patterns of information and the way it can be represented. These skills are used whether we're dealing with theories, databases, digital circuits, meaning in language, or mathematical reasoning, and they will be used in the future in ways we haven't yet imagined. Learning logic is a central part of learning to think well, and this course will help you learn logic and how you can apply it.This subject follows from Logic: Language and Information 1, to cover core techniques in first order predicate logic: the idea of formal languages with quantifiers, which gives us a way to talk about more logical structure than in propositional logic; and we will cover the central logical concepts such as consistency and validity; models; and proofs in predicate logic. But you won’t only learn these concepts and tools. We will also explore how these techniques connect with issues in linguistics, computer science, electronic engineering, mathematics, and philosophy.
      


            Read more
          



Week 1. The Syntax of Predicate Logic; Translations using quantifiersWeek 2. Models for Predicate Logic; Classifying propositions and arguments; Finite and Infinite DomainsWeek 3. Tree Proofs for Predicate Logic; Soundness and CompletenessWeek 4. Identity; Functions; Counting Weeks 5–8. Applications to different reasoning domains (take at least three):Electronic Engineering — simplifying digital circuits with timingPhilosophy — definite descriptions and existenceComputer Science — databases, resolution and PrologLinguistics — quantificational scopeMathematics — limits, continuity and quantifier alternation",Logic: Language and Information 2
https://www.classcentral.com/course/materials-science-5074,"We explore “10 things” that range from the menu of materials available to engineers in their profession to the many mechanical and electrical properties of materials important to their use in various engineering fields. We also discuss the principles behind the manufacturing of those materials.

By the end of the course, you will be able to:
* Recognize the important aspects of the materials used in modern engineering applications,
* Explain the underlying principle of materials science: “structure leads to properties,”
* Identify the role of thermally activated processes in many of these important “things” – as illustrated by the Arrhenius relationship.
* Relate each of these topics to issues that have arisen (or potentially could arise) in your life and work.

If you would like to explore the topic in more depth you may purchase Dr. Shackelford's Textbook:
J.F. Shackelford, Introduction to Materials Science for Engineers, Eighth Edition, Pearson Prentice-Hall, Upper
Saddle River, NJ, 2015
      


          Course Overview / The Menu of Materials / Point Defects Explain Solid State Diffusion
    -Welcome to week 1! In lesson one, you will learn to recognize the six categories of engineering materials through examples from everyday life, and we’ll discuss how the structure of those materials leads to their properties. Lesson two explores how point defects explain solid state diffusion. We will illustrate crystallography – the atomic-scale arrangement of atoms that we can see with the electron microscope. We will also describe the Arrhenius Relationship, and apply it to the number of vacancies in a crystal. We’ll finish by discussing how point defects facilitate solid state diffusion, and applying the Arrhenius Relationship to solid state diffusion.

Dislocations Explain Plastic Deformation / Stress vs. Strain -The “Big Four” Mechanical Properties
    -Welcome to week 2! In lesson three we will discover how dislocations at the atomic-level structure of materials explain plastic (permanent) deformation. You will learn to define a linear defect and see how materials deform through dislocation motion. Lesson four compares stress versus strain, and introduces the “Big Four” mechanical properties of elasticity, yield strength, tensile strength, and ductility. You’ll assess what happens beyond the tensile strength of an object. And you’ll learn about a fifth important property – toughness.

Creep Deformation / The Ductile-to-Brittle Transition
    -Welcome to week 3! In lesson five we’ll explore creep deformation and learn to analyze a creep curve.  We’ll apply the Arrhenius Relationship to creep deformation and identify the mechanisms of creep deformation. In lesson six we find that the phenomenon of ductile-to-brittle transition is related to a particular crystal structure (the body-centered cubic). We’ll also learn to plot the ductile-to-brittle transition for further analysis.

Fracture Toughness / Fatigue
    -Welcome to week 4! In lesson seven we will examine the concept of critical flaws. We’ll define fracture toughness and critical flaw size with the design plot. We’ll also distinguish how we break things in good and bad ways. Lesson eight explores the concept of fatigue in engineering materials. We’ll define fatigue and examine the fatigue curve and fatigue strength. We’ll also identify mechanisms of fatigue.

Making Things Fast and Slow / A Brief History of Semiconductors
    -Welcome to week 5! In lesson nine we’ll deal with how to make things fast and slow. We’ll examine the lead-tin phase diagram and look at its practical applications as an example of making something slowly. Then we’ll evaluate the TTT diagram for eutectoid steel, and compare diffusional to diffusionless transformations with the TTT diagram, monitoring how we make things rapidly. Lesson ten is a brief history of semiconductors. Here, we discuss the role of semiconductor materials in the modern electronics industry. Our friend Arrhenius is back again, and this time we’re applying the Arrhenius Relationship to both intrinsic and extrinsic semiconductors. We’ll also look at combined intrinsic and extrinsic behavior.",Materials Science: 10 Things Every Engineer Should Know
https://www.classcentral.com/course/independent-planning-for-monitoring-and-evaluation-11965,"How will you measure your project’s success? This course will help you answer this question by introducing the basics of monitoring and evaluation (M&E). In this course, you will learn how successful projects plan for data collection, management, analysis, and use. As you complete the course assignments, you will create an M&E plan for your own project.
 



Module 1: Introduction to Monitoring and Evaluation 
Link M&E to your project’s design
Module 2: Linking M&E to Project Design 
Define the indicators that you will measure
Module 3: Identifying Indicators & Targets
 Choose appropriate data collection methods
Module 4: Data Collection 
Create clear, useful data collection tools
Module 5: Roles & Responsibilities 
Assign M&E roles and responsibilities",Planning for Monitoring and Evaluation
https://www.classcentral.com/course/edx-bitcoin-and-cryptocurrencies-11417,"Developed by Blockchain at Berkeley and faculty from UC Berkeley's premier Computer Science department, this course presents Bitcoin and cryptocurrencies as the motivation for blockchain technologies, and provides a comprehensive and in-depth overview of the fundamental concepts of the crypto space with a particular emphasis on Bitcoin. The course covers basic properties of bitcoin, the mechanics behind it (e.g. including cryptographic hash functions, Bitcoin Script, privacy, and hash commitment schemes) and its roots in the Cypherpunk movement and Libertarian ideals. You'll learn about practical applications of Bitcoin such as wallets and mining, as well as how to destroy bitcoins, including network attacks and malicious mining strategies. We will also take a brief look at Ethereum and how blockchain can be used outside of cryptocurrencies. This course is open to anyone with any background. Whether you are planning your next career move as a blockchain developer, crypto trader, data analyst, researcher, or consultant, or are just looking for an introduction to the Bitcoin technology. This course will help you to begin developing the critical skills needed to future-proof your career. This course is part of the Blockchain Fundamentals Professional Certificate program.  If you are planning to enroll in the entire series, we suggest starting with this course and then progressing on to CS198.2x Blockchain Technology.
      


Bitcoin Protocol & Consensus: A High Level OverviewWe begin with some fundamental concepts such as the basic properties and intent of centralized/decentralized currency. We then build an in-depth understanding of Bitcoin from the ground up, divided into four stages: Identity, Transactions, Record Keeping, and Consensus. Blockchain History: From the Cypherpunk Movement to JP Morgan ChaseThis module delves into the origins and historical significance of Bitcoin. We look into the roots of Bitcoin in the Cypherpunk movement and Libertarian ideals, and examine the revolutionary significance of Bitcoin as opposed to some of its early predecessors. We then move onto exploring the history of the crypto space as a whole.Bitcoin Mechanics & Optimizations: A Technical OverviewWe examine the in-depth mechanics behind Bitcoin, such as the Bitcoin network, cryptography and cryptographic hash functions, Bitcoin Script, privacy, and hash commitment schemes.Bitcoin In Real Life: Wallets, Mining, and MoreWe examine the most frequently used real world aspects of Bitcoin, such as wallets, wallet mechanics, mining, transactions, and Bitcoin governance. We explain the various ways one can interface with the Bitcoin network, depending on the specific software they run. Game Theory & Network Attacks: How to Destroy BitcoinWe look into how to destroy Bitcoin, including various network attacks. Specifically, we look into vulnerabilities such as pool cannibalization, double spending and forking attacks, network attacks, the Goldfinger attack, malicious mining profit strategies, and 51% attacks.Ethereum & Smart Contracts: Enabling a Decentralized FutureThis module focuses on the properties behind the second largest blockchain platform, Ethereum. We introduce the Ethereum Virtual Machine and the idea of Turing completeness, and examine some of the key protocol differences between Bitcoin and Ethereum, such as the UTXO vs. accounts model and functionality. We then look into some of the use cases of Ethereum, and conclude with an overview of smart contracts and building decentralized applications. Having spent the last modules primarily on cryptocurrencies, this module encourages students to think about blockchain use cases outside of cryptocurrency.",Bitcoin and Cryptocurrencies
https://www.classcentral.com/course/clinical-natural-language-processing-12840,"This course teaches you the fundamentals of clinical natural language processing (NLP). In this course you will learn the basic linguistic principals underlying NLP, as well as how to write regular expressions and handle text data in R. You will also learn practical techniques for text processing to be able to extract information from clinical notes.  Finally, you will have a chance to put your skills to the test with a real-world practical application where you develop text processing algorithms to identify diabetic complications from clinical notes. You will complete this work using a free, online computational environment for data science hosted by our Industry Partner Google Cloud.
      


          Introduction: Clinical Natural Language Processing
    -This module covers the basics of text mining, text processing, and natural language processing. It also provides a information on the linguistic foundations that underly NLP tools.

Tools: Regular Expressions
    -This module introduces regular expressions, the method of text processing, and how to work with text data in R. Mastery is demonstrated through a programming assignment with applied questions.

Techniques: Note Sections
    -This module discusses how the section of a clinical note can affect the meaning of text in the section. A programming assignment provides hands on practice with how to apply this knowledge to process clinical text. 

Techniques: Keyword Windows
    -This module discusses how you can build windows of text around keywords of interest to understand the context and meaning of how the keyword is being used. A programming assignment provides hands on practice with how to apply this technique to process clinical text. 

Practical Application:  Identifying Patients with Diabetic Complications
    -Apply the tools and techniques that you have learned in the course to a real-world example!",Clinical Natural Language Processing
https://www.classcentral.com/course/edx-data-science-productivity-tools-10350,"A typical data analysis project may involve several parts, each including several data files and different scripts with code. Keeping all this organized can be challenging. 
Part of our Professional Certificate Program in Data Science, this course explains how to use Unix/Linux as a tool for managing files and directories on your computer and how to keep the file system organized. You will be introduced to the version control systems git, a powerful tool for keeping track of changes in your scripts and reports. We also introduce you to GitHub and demonstrate how you can use this service to keep your work in a repository that facilitates collaborations. 
Finally, you will learn to write reports in R markdown which permits you to incorporate text and code into a document. We'll put it all together using the powerful integrated desktop environment RStudio.",Data Science: Productivity Tools
https://www.classcentral.com/course/edx-introduction-to-quantum-transport-11881,"This course introduces the Schrödinger equation, using the tight-binding method to discuss the concept of bandstructure and E(k) relations, followed by an introduction to the NEGF method with simple illustrative examples. Concept of spinors is introduced along with the application of the NEGF method to spintronic devices.
No prior background in quantum mechanics or statistical mechanics is assumed.
This course is a part of a Purdue initiative that aims to complement the expertise that students develop with the breadth at the edges needed to work effectively in today's multidisciplinary environment. These serious short courses require few prerequisites and provide a general framework that can be filled in with self-study when needed.
Students taking this course will be required to complete three (3) proctored exams using the edX online Proctortrack software.
Introduction to Quantum Transport is one course in a growing suite of unique, 1-credit-hour short courses being developed in an edX/Purdue University collaboration. Students may elect to pursue a verified certificate for this specific course alone or as one of the six courses needed for the edX/Purdue MicroMasters program in Nano-Science and Technology. For further information and other courses offered and planned, please see the Nano-Science and Technology page. Courses like this can also apply toward a Purdue University MSECE degree for students accepted into the full master’s program.



            Read more
          



Week 1: Schrödinger Equation

1.1 Introduction
1.2 Wave Equation
1.3 Differential to Matrix Equation
1.4 Dispersion Relation
1.5 Counting States
Week 2: Schrödinger Equation (continued)

1.6 Beyond 1D
1.7 Lattice with a Basis
1.8 Graphene
1.9 Reciprocal Lattice/Valleys
1.10 Summing Up
Week 3: Contact-ing Schrödinger & Examples
2.1 Introduction
2.2 Semiclassical Model
2.3 Quantum Model
2.4 NEGF Equations
*2.5 Bonus Lecture, NOT covered on exams
2.6 Scattering Theory
Week 4: Contact-ing Schrödinger & Examples (continued)
 2.7 Transmission
2.8 Resonant Tunneling
2.9 Dephasing
2.10 Summing Up
3.1 Bonus Lecture, NOT covered on exams
3.2 Quantum Point Contact
__ 3.3 - 3.10 Bonus Lectures, NOT covered on exams 

Week 5: Spin Transport
4.1 Introduction
4.2 Magnetic Contacts
4.3 Rotating Contacts
4.4 Vectors and Spinors
4.5 - 4.6 Bonus Lectures NOT covered on exams
4.7 Spin Density/Current 
__ 4.8-4.10 Bonus Lectures NOT covered on exams
Text: S. Datta, “Lessons from Nanoelectronics”, Part B: Quantum Transport, World Scientific, Second Edition 2017
The manuscript will be available for download at the course's website.",Introduction to Quantum Transport
https://www.classcentral.com/course/java4android-5446,"This MOOC teaches you how to program core features and classes from the Java programming language that are used in Android, which is the dominant platform for developing and deploying mobile device apps. 

In particular, this MOOC covers key Java programming language features that control the flow of execution through an app (such as Java’s various looping constructs and conditional statements), enable access to structured data (such as Java's built-in arrays and common classes in the Java Collections Framework, such as ArrayList and HashMap), group related operations and data into classes and interfaces (such as Java's primitive and user-defined types, fields, methods, generic parameters, and exceptions), customize the behavior of existing classes via inheritance and polymorphism (such as subclassing and overriding virtual methods). Learners will apply these Java features in the context of core Android components (such as Activities and basic UI elements) by applying common tools (such as Android Studio) needed to develop Java programs and useful Android apps.  

Learners will work on several hands-on projects throughout the MOOC, i.e., each week will require learners to write solutions to programming assignments that reinforce the material covered in the lecture videos. There will be roughly 4-6 hours of student engagement time per week, including video lectures, quizzes, and programming assignments.
      


          Module 1: MOOC Overview
    -Module 1 summarizes the organization of the MOOC and the topics it covers.  It also discusses the MOOC prerequisites, workload, and learning strategies needed to complete the MOOC successfully.  It then presents an overview of key features in the Java language, outlining its support for object-oriented programming concepts that guide the development of Android apps.

Module 2: Introduction to Android Studio
    -Module 2 provides an overview of Android Studio, explaining how to install it and apply it to develop a simple app using basic Java and Android features presented in this MOOC.

Module 3: Writing a Simple Android App Using Basic Java Features
    -Module 3 shows how to write a simple Android app that defines variables using primitive Java data types, shows how to assign values to those variables, and output them to the Android display using Java classes and methods.

Module 4: Control Flow
    -Module 4 covers Java’s looping constructs (e.g., for loops, while loops, and do/while loops), as well as its conditional statements (e.g., if/else statements).

Module 5: Structured Data
    -Module 5 provides more detail on common data structures supported by Java, including built-in arrays, as well as core classes in the Java Collections Framework, such as ArrayList and HashMap.

Module 6: Classes and Interfaces
    -Module 6 covers Java classes and interfaces, focusing on data types, fields, methods, generic parameters, and exceptions.

ModuIe 7: Inheritance and Polymorphism
    -Module 7 examines Java's inheritance and polymorphism features (e.g., extending classes and virtual methods).

Module 8: Android Calculator App Mini-Project Assignment
    -Module 8 guides learners through the creation of an Android app that implements a simple calculator, which provides features for adding, subtracting, multiplying, and dividing numbers input by various means (e.g., via numbers and buttons on the Android user interface).",Java for Android
https://www.classcentral.com/course/amnhclimate-4193,"Our Earth’s Future is about the science of climate change and how to talk about it. You will learn from scientists in the fields of climatology, oceanography, Earth science, and anthropology who study how climate change is affecting people, populations, and ways of life. Explore the multiple lines of evidence for the human-induced climate change that is happening today, and consider what that means for the future of our planet. At the end of this course you will be able to understand key scientific principles, identify and address misconceptions, and contribute confidently to conversations about climate change.
      


          Climate Change Is Happening: See It
    -Human-induced climate change is happening. But in order to explore the evidence for this claim, we must first ask two questions: “What is science?” and “What is climate?” Once we understand how science is done and the basic dynamics of the climate system, we’ll focus on how scientists study ice cores, and see how evidence of climate change in the past is fundamental to understanding what lies ahead. 

It All Comes Down to the Ocean
    -Both the ocean’s sheer size – it covers seventy percent of our planet’s surface – and the properties of water make the ocean a major player in Earth’s climate system. An enormous reservoir of heat, the ocean is an important mechanism of heat storage and exchange with the atmosphere, which has important implications for climate change. We’ll focus on one of the consequences of warming:  melting of the Greenland and Antarctic ice sheets. How might this melting lead to future sea level rise? Scientists are studying geological records of past warming, and associated sea level rise, to see what the future may bring.

Climate Change is Happening: Model It
    -An important counterpart to observational evidence is computer modeling, an essential tool for investigating how the climate system works and how it will respond to continued greenhouse gas buildup in the atmosphere. How do we know that a model is accurate? One way is to consider a past event, enter the historic climate data, and see if the model successfully “hindcasts” the event in reasonable detail. Ever more detailed, today’s supercomputer models can even help identify the potential causes of climate events on a regional scale, as climatologist Dr. Michela Biasutti explains using her research on droughts in sub-Saharan Africa. 

Living with Climate Change
    -Climate change is often framed as a future phenomenon, but it’s clear that people are already experiencing the consequences. What are the effects?  It depends to some extent on where, and how, you live.  For example, in the Pacific Islands, where sea level rise is threatening entire ways of life, communities have come together to prepare. What happens when there’s no place to go? Coastal communities aren’t the only ones at risk; food insecurity may one day threaten us all. And of course, humans are not the only species affected, and some will be at even greater risk in the future.  

Mitigate, Adapt, or Suffer?
    -What happens next? We don’t know, but the answer depends far less on scientific data than on human action—or inaction. The major uncertainty is the future rate of greenhouse gas emissions, which is impossible to predict because it depends on socioeconomic, technological, and political developments. Furthermore, the risks posed by different kinds of natural phenomena vary widely, and similar events can have very different consequences depending on where and even when they occur. How will the effects be distributed, and how resilient are we? Hurricane Sandy provided lessons about our willingness to accept and plan for a future where severe climate events happen more frequently.",Our Earth's Future
https://www.classcentral.com/course/androidapps101-429,"This course is a novice-friendly and delightful introduction to computer science and to programming Android apps for smartphones and tablets. No prior programming knowledge is necessary. In this course you will have fun learning to create an app for modern Android devices, such as the Nexus tablet.
You will use the programming tools that Android software developers use to build your own useful app during this course. Along the way, we will introduce fundamental computer science principles and programming ideas that power today’s smartphone and tablet apps.
We will also peek beyond the borders of Android programming to the world of computer science. Meet computer science undergraduates, see one of the first vacuum tube computers, the first transistor, and now-modern scientific research on the Blue Waters supercomputer—all at Illinois.
Android Developer Track: Weeks 1–5 (required for passing the course):
This portion of the course is intended to give you a slow and gentle introduction to the basics of Android application development such as downloading, installing, and setting up the tools you will use in this course. You will also create your first Android app and share the results of your experience with your classmates—all while writing hardly any code at all! 
Computer Science and Programming Track: Weeks 6–8 (optional):
During this latter portion of the course, you can delve deeper into computer science fundamentals and beginner programming techniques. Together we will explore this content while developing another really cool project to share.



            Read more
          



This course is composed of 2 tracks organized into 8 distinct weekly topics:

Android Developer Track
Week 1: An App for Hello World
Week 2: A Simple App for ILLIAC
Week 3: A Working App for ILLIAC
Week 4: An App for Emily
Week 5: A Simple Web App and Debugging Code in 0g
Computer Science and Programming Track
Week 6: An App to Share My Views
Week 7: An App for Bitmaps and Images
Week 8: An App for Moving Pixels","Creative, Serious and Playful Science of Android Apps"
https://www.classcentral.com/course/edx-securing-data-in-azure-and-sql-server-8846,"Given the ever-expanding role of a SQL Server database administrator in today's security landscape, it's critical to know how to keep data secure.
In this course, join the experts for a look at user authentication--who the users are--and authorization--what they are allowed to do. Plus, find out about auditing system access and data encryption, to make sure your data is properly secured.
You'll examine these topics through the lenses of various platforms, comparing what they look like in SQL Server 2016, SQL Server v.Next on Linux, and Azure SQL Databases.
This computer science course introduces features and technologies for securing databases. Topics include: Authenticating Users and Connections, Authorizing Users to Access Resources, Auditing Access to Data, and Encrypting Data. You will learn how to secure data in SQL Server 2016, SQL Server v.Next on Linux, and Azure SQL Databases.



Module 1: Authenticating Users and Connections
This module introduces the planning process to prepare for deployments of SQL Server and Azure SQL Database. It covers considerations for hardware, software, security, and availability. 
Module 2: Authorizing Users to Access Resources
This module covers tasks and steps necessary to deploy SQL Server on Windows, on Linux, and in Azure SQL Database. 
Module 3: Auditing Access to Data
This module covers auditing access to data with DML (data manipulation language) triggers, server audits and database audits. 
Module 4: Encrypting Data
This module covers encrypting data with Transparent Data Encryption, Always Encrypted, and Dynamic Data Masking. 
Final Exam
After the last module you will take the final exam, which accounts for 70% of your grade and will be combined with the homework assignments in each module to determine your overall score. You must achieve an overall score of 70% or higher to pass this course and earn a certificate.",Securing Data in Azure and SQL Server
https://www.classcentral.com/course/advanced-data-structures-4346,"How does Google Maps plan the best route for getting around town given current traffic conditions?  How does an internet router forward packets of network traffic to minimize delay?  How does an aid group allocate resources to its affiliated local partners?

To solve such problems, we first represent the key pieces of data in a complex data structure. In this course, you’ll learn about data structures, like graphs, that are fundamental for working with structured real world data.  You will develop, implement, and analyze algorithms for working with this data to solve real world problems.   In addition, as the programs you develop in this course become more complex, we’ll examine what makes for good code and class hierarchy design so that you can not only write correct code, but also share it with other people and maintain it in the future.

The backbone project in this course will be a route planning application.  You will apply the concepts from each Module directly to building an application that allows an autonomous agent (or a human driver!) to navigate its environment.  And as usual we have our different video series to help tie the content back to its importance in the real world and to provide tiered levels of support to meet your personal needs.
      


          Introduction to the Course
    -Welcome to the first week in the third course of our Intermediate Java Programming Specialization.  Once again start with introductions, and in particular introduce the unique structure of this course.  Also, if you're not sure if this course is right for you, we've got an optional pre-course quiz coming right up that can help you figure out if you're in the right place.  If you decide to stay with us (and we really hope you will!) we've got a great backbone project for you: your very own mapping application, inspired by Google Maps!  The core data structure throughout this course is graphs, which may very well be the most fundamental data structure in all of computer science.  Ready to begin?  So are we!

Introduction to Graphs
    -This week we'll start getting technical, introducing you to the central data structure in the course: Graphs.  You'll learn the basics and then have a chance to dive in a little deeper into the code, getting ready to start building that Google Maps-like application.

Class design and simple graph search
    -This week you'll get the backbone of your map search engine up and running.  In previous courses, including the previous courses in this specialization, you've probably been given most of the classes you needed to complete the assignments.  But learning how to design classes from scratch is a key skill that you will need as you become a more sophisticated Java programmer.  This week we'll give you the tools you need to create a robust and elegant class design for your map search engine.  We'll introduce a similar problem and show you how it can be represented as a graph.  Then we'll introduce two core search algorithms: depth-first search and breadth-first search.  Finally, we'll turn our graph problem into a set of Java classes.   Your task on the programming assignment this week will be to do the same thing, but in the context on the map search engine!

Finding shortest paths in weighted graphs
    -In the past two weeks, you've developed a strong understanding of how to design classes to represent a graph and how to use a graph to represent a map.  In this week, you'll add a key feature of map data to our graph representation -- distances -- by adding weights to your edges to produce a ""weighted graph"".  Although this might seem like a small change, the algorithms that work for unweighted graphs may prove ineffective for weighted graphs.  To address this problem, you'll explore more advanced shortest path algorithms.  First, you'll see how to find the shortest path on a weighted graph, then you'll see how to find it more quickly.  In the project, you'll apply these ideas to create the core of any good mapping application: finding the shortest route from one location to another.

Route planning and NP-hard graph problems
    -In this week, we'll go beyond the problem of finding a path between two points, and focus on problems requiring overall path planning.  For example, if you wanted to go on errands and visit 6 different locations before returning home, what is the optimal route? This problem is actually a really well known problem in computer science known as the Travelling Salesperson Problem (TSP).  Attempting to solve the problem will lead us to explore complexity theory, what it means to be NP-Hard, and how to solve ""hard"" problems using heuristics and approximation algorithms.  We'll end the week by showing how reformulating a problem can have a huge impact: making something which was effectively unsolvable before, now solvable!  

End of Course Project Extension
    -You made it to the last week of our course!  We're glad you're still with us.  As a reward, there's no new content to learn this week.  Instead you'll get the opportunity to extend your project in a direction of your own choosing.  We hope you've got some neat ideas for personalizing your map application, and we look forward to seeing them in the peer review gallery.  Submitting to the peer review gallery is optional (though the extension is required), but we hope you'll choose to participate.",Advanced Data Structures in Java
https://www.classcentral.com/course/edx-sp18-time-series-analysis-10171,"Time Series Analysis has wide applicability in economic and financial fields but also to geophysics, oceanography, atmospheric science, astronomy, engineering, among many other fields of practice. This course will illustrate time series analysis using many applications from these fields.In this course, students will learn standard time series analysis topics such as modeling time series using regression analysis, univariate ARMA/ARIMA modelling, (G)ARCH modeling, Vector Autoregressive (VAR) model along with forecasting, model identification and diagnostics. Students will be given fundamental grounding in the use of such widely used tools in modeling time series.Throughout this course, students will be exposed to not only fundamental concepts of time series analysis but also many data examples using the R statistical software. Thus by the end of this course, students will also be familiar with the implementation of time series models using the R statistical software along with interpretation for the results derived from such implementations.This class is more about the opportunity for individual discovery than it is about mastering a fixed set of techniques.
      


Weeks 1-3: Introduction to basic concepts of time series analysisWeeks 4-6: Introduction to the ARMA Modeling and its extension, including illustration with data examplesWeek 7: Midterm 1 Examination Weeks 8-10: Introduction to most popular multivariate time series model, the VAR model, with data examplesWeeks 11-13: Introduction to GARCH modeling for heteroskedasticity, with data examplesWeek 14: Midterm 2 Examination Weeks 15: Overview of the time series models introduced in this course along with brief description of other time series methodsWeek 16: Final Examination",SP18:  Time Series Analysis
https://www.classcentral.com/course/sas-programming-basics-12319,"This course is for users who want to learn how to write SAS programs to access, explore, prepare, and analyze data. It is the entry point to learning SAS programming for data science, machine learning, and artificial intelligence. It is a prerequisite to many other SAS courses.

By the end of this course, you will know how to use SAS Studio to write and submit SAS programs that access SAS, Microsoft Excel, and text data. You will know how to explore and validate data, prepare data by subsetting rows and computing new columns, analyze and report on data, export data and results to other formats, use SQL in SAS to query and join tables.

Prerequisites:
Learners should have experience using computer software. Specifically, you should be able to understand file structures and system commands on your operating systems and access data files on your operating systems. No prior SAS experience is needed.
      


          Course Overview and Data Setup
    -In this module you learn about the course and you set up the data you need to do the practices in the course. 

Essentials
    -In this module you learn how to use SAS programming tools and the fundamentals of SAS program structure and syntax. 

Accessing Data
    -In this module, you learn to identify the features of a SAS table, access data through SAS libraries, and import data into SAS.

Exploring and Validating Data
    -In this module, you learn to use SAS procedures that provide insights about your data. You also learn to subset data so you can focus on particular segments, format data so you can easily understand it, and sort data to identify and resolve duplicate values.

Preparing Data
    -In this module, you learn how to do some common data manipulations, such as filtering rows and columns, computing new columns, and performing conditional processing.

Analyzing and Reporting on Data
    -In this module, we concentrate on summarizing data by using the SAS procedures that we touched on for data exploration. You also learn how to use titles, column labels, footnotes, and macro variables to enhance your reports and make them more meaningful.

Exporting Results
    -In this module, you learn to export SAS tables and results to Excel, Microsoft Word, and PDF files. 

Using SQL in SAS
    -In this module, you learn to use the SQL procedure to read and filter data. You also learn to create and join tables by using SQL.",Getting Started with SAS Programming
https://www.classcentral.com/course/crash-course-in-causality-8425,"We have all heard the phrase “correlation does not equal causation.”  What, then, does equal causation?  This course aims to answer that question and more!  

Over a period of 5 weeks, you will learn how causal effects are defined, what assumptions about your data and models are necessary, and how to implement and interpret some popular statistical methods.  Learners will have the opportunity to apply these methods to example data in R (free statistical software environment).

At the end of the course, learners should be able to:
1.  Define causal effects using potential outcomes
2.  Describe the difference between association and causation
3.  Express assumptions with causal graphs
4.  Implement several types of causal inference methods (e.g. matching, instrumental variables, inverse probability of treatment weighting)
5.  Identify which causal assumptions are necessary for each type of statistical method

So join us.... and discover for yourself why modern statistical methods for estimating causal effects are indispensable in so many fields of study!
      


          Welcome and Introduction to Causal Effects
    -This module focuses on defining causal effects using potential outcomes. A key distinction is made between setting/manipulating values and conditioning on variables. Key causal identifying assumptions are also introduced.

Confounding and Directed Acyclic Graphs (DAGs)
    -This module introduces directed acyclic graphs. By understanding various rules about these graphs, learners can identify whether a set of variables is sufficient to control for confounding.

Matching and Propensity Scores
    -An overview of matching methods for estimating causal effects is presented, including matching directly on confounders and matching on the propensity score. The ideas are illustrated with data analysis examples in R.

Inverse Probability of Treatment Weighting (IPTW)
    -Inverse probability of treatment weighting, as a method to estimate causal effects, is introduced. The ideas are illustrated with an IPTW data analysis in R.

Instrumental Variables Methods
    -This module focuses on causal effect estimation using instrumental variables in both randomized trials with non-compliance and in observational studies. The ideas are illustrated with an instrumental variables analysis in R.",A Crash Course in Causality:  Inferring Causal Effects from Observational Data
https://www.classcentral.com/course/dentmedpenn-2902,"The mouth is the window into human health.  This course provides an overview of dental medicine to engage, educate, excite and assist you in improving the oral health of your patients and members of your community. We will review topics in dental medicine including scope of the field, what to expect in function, and some of the many ways that dysfunction may present for different patients. This will include discussions of mouth, jaw, and tooth anatomy, pathology, and treatment. We will talk about differences between patients and the unique roles that different members of the dental field may play in treatment depending on the patient and condition. This course starts from basic concepts and proceeds to review trends in current research and technology. We offer scientific background, some skills for patient evaluation and interview, and some suggestions for further learning for those interested in or involved in dental education.
      


          Week 1 - Introduction to Dental Medicine and Its Relations to Public Health
    -In this course, you will learn about basic dental anatomy, how to evaluate a patient, and the causes and impact of oral diseases. We will use case examples and live demonstrations with patients to illustrate these points. Please note that some lectures in this course contain graphic medical images, including illustrations of the human body, oral cavity, early development, and photographs of medical conditions and deformities. Discretion is advised. The materials in this course are intended for education purposes only and are not intended to serve as professional medical advice, diagnosis, or treatment. Please seek the advice of your dentist, physician, or other qualified health professional if you have any questions related to this material and its relevance to your health or that of someone else. Week 1 is your introduction to dental medicine! This includes oral health's relation to general health, sources of infection, modern technology in dentistry, and the public health impact of dental medicine. Let's get started!

Week 2 - Form and Function of the Oral Cavity
    -The modules in week 2 describe basic dental anatomy including embryology of the oral cavity, oral functions, basic tooth structure, and clinical implications of disease. Emphasis is placed on the clinical implications of these concepts and structures.

Week 3 - Comprehensive Evaluation of Dental Patient Needs
    -These modules will demonstrate the evaluation of extra- and intraoral structures. They also review the taking of a thorough medical history, with live patient demonstrations. This unit emphasizes the complex relationship between the systemic and oral health.

Week 4 - Most Common Dental Diseases Affecting Teeth and Periodontium
    -Diseases affecting the dentition and its surrounding structures have a profound influence on the patient and his/her health. Untreated conditions can result in severe pain, localized, and systemic infections and result in partial or complete loss of teeth.The etiology and the contributing factors to these diseases are discussed in detail.

Week 5 - Oral Mucosal Conditions: Diagnosis and Management
    -Possible oral and mucosal conditions include anomalies, ulcers, cancer and associated diseases. Some of these conditions have localized or idiopathic etiology; others are manifestations of systemic diseases of the body. Many times these oral conditions appear as the initial symptom of a systemic disease. The management of such conditions often involves an interdisciplinary approach to management involving the patient's dentist, physician, and medical specialists.

Week 6 - The Science of Pain Affecting the Intraoral and Extraoral Structures
    -These modules address oral and facial pain from common conditions to rare ones, including an exploration of the psychological aspects of oral and facial pain. Dental pain can originate not only from diseased dentition, but also from various disorders affecting the TMJ, nerves, soft and hard tissue infections and other sources. Dental pain can have underlying psychosocial etiology as well, and the diagnosis in such cases can be challenging.

Week 7 - Overview of Dental Specialties: Scope and Modalities of Treatment
    -Selected cases in dental medicine ranging from oral surgery to prosthetic reconstruction are discussed in the context of the important role of dental specialists. Each presenter discusses the challenges of focused dental treatment and presents cases with ""before"" and ""after"" documentation.",Introduction to Dental Medicine
https://www.classcentral.com/course/kadenze-introduction-to-sound-and-acoustic-sketching-3776,"Introduction to Sound and Acoustic Sketching will offer tools and practices  to inspire students to approach sound and acoustics as elements in the sketching stage of a design project.
The course provides students with foundational knowledge and practical tools to analyze and use soundscapes and acoustic impulse responses in projects. In addition, a basic taxonomy of sound terms will be introduced, allowing students to develop a language for communicating and establishing dialogues about sound with all stakeholders in an audiovisual project. The practical component of the course is anchored in exercises that allow students to experiment and assimilate the different aspects of sound and acoustic sketching, namely:
• Sound Walks – Students practice “deep listening”, “sound scripting” and sound recording;
• Sound Browsing and Retrieving – Students learn how to obtain free sounds (using the Free Online Sound Repository Freesound.com) and build up a scripted inventory in the process of sound design;
• Sound Editing – Students learn how to produce a creative sound montage based on their acoustic memory and a sound design script, using the free multi-platform sound editing software Audacity;
• Critical Sound Review – By comparing the sound sketch produced in this exercise with the actual recording of the sound walk, students can develop critical insights about the their conceptual perception and representation of an acoustic phenomena, in comparison with the factual recording of the same event;
• Acoustic Mapping by Impulse Response – Students learn how to record an acoustic impulse response from a physical space;
• Acoustic Imprinting by Convolution – Students learn how to imprint a pre-recorded acoustic response in an original audio content, producing an acoustic simulation for an architectural space, using free multi-platform sound programing environment Pure Data/Chuck.
Upon the completion of these exercises, students will produce two sound sketches: designing a soundscape based on their recollection of sound events, and simulating an acoustic space, based on analogous impulse responses from similar spaces.
Furthermore, students will gain introductory experience using the using the free online sound repository Freesound.com, the free multi-platform sound editing software Audacity and the free multi-platform sound programing environment Pure Data (or Chuck).
 



            Read more
          



Session 1: Sound And Acoustics In this session, students will learn to distinguish between different elements in sound taxonomy, and sound facets and characteristics. We will also get familiar with the human hearing system. By the end of this session students will be able to comprehend basic acoustics and sound propagation in space.
Session 2: Soundscapes And Sound Walk In this session, students will understand the Concept and origin of soundscapes and recognize Soundscapes according to Schafer’s Categories (sound signals, keynote sounds, soundmarks, geophony, biophony and anthrophony).
Session 3: Sound Browsing And Retrieving In this session, students will learn how to browse and download sounds from freesound.org and understand how to create a repository of sounds according to a sound script.
Session 4: Sound Editing And Soundscape Sketching This session will cover the basics of editing with Audacity. At the end of this session, students will understand the concept of soundscape sketch.
Session 5: Critical Sound Review In this session, students will develop a critical sense of analysis for different moments of a soundscape and understand the difference between factual recording of soundscapes and a designed soundscape.
Session 6: Acoustic Mapping By Impulse Response In this session we will cover the concept of impulse response of architectural space.
Session 7: Acoustic Imprinting By Convolution In this session, students will learn the concept of convolution and how to implement it with Pure-Data or Chuck.",Introduction to Sound and Acoustic Sketching
https://www.classcentral.com/course/independent-information-visualization-627,"This course provides an overview about the state of the art in information visualization. It teaches the process of producing effective visualizations that take the needs of users into account. This year, the course can be taken for three Indiana University credits as part of the Online Data Science Program just announced by the School of Informatics and Computing. Students interested in applying to the program can find more information here.Among other topics, the course covers:

Data analysis algorithms that enable extraction of patterns and trends in data
Major temporal, geospatial, topical, and network visualization techniques
Discussions of systems that drive research and development.

Just like last year, students will have the opportunity to collaborate on real-world projects for a variety of clients. Click here to see the 2014 list of clients and projects. You can also see the detailed results of the 2013 client projects from the Visual Insights book here.Everyone who registers gains free access to the Scholarly Database(26 million paper, patent, and grant records) and the Sci2 Tool (100+ algorithms and tools).",Information Visualization
https://www.classcentral.com/course/edx-essential-statistics-for-data-analysis-using-excel-8248,"If you’re considering a career as a data analyst, you need to know about histograms, Pareto charts, Boxplots, Bayes’ theorem, and much more. In this applied statistics course, the second in our Microsoft Excel Data Analyst XSeries, use the powerful tools built into Excel, and explore the core principles of statistics and basic probability—from both the conceptual and applied perspectives. Learn about descriptive statistics, basic probability, random variables, sampling and confidence intervals, and hypothesis testing. And see how to apply these concepts and principles using the environment, functions, and visualizations of Excel.
As a data science pro, the ability to analyze data helps you to make better decisions, and a solid foundation in statistics and basic probability helps you to better understand your data. Using real-world concepts applicable to many industries, including medical, business, sports, insurance, and much more, learn from leading experts why Excel is one of the top tools for data analysis and how its built-in features make Excel a great way to learn essential skills.
Before taking this course, you should be familiar with organizing and summarizing data using Excel analytic tools, such as tables, pivot tables, and pivot charts. You should also be comfortable (or willing to try) creating complex formulas and visualizations. Want to start with the basics? Check out DAT205x: Introduction to Data Analysis using Excel. As you learn these concepts and get more experience with this powerful tool that can be extremely helpful in your journey as a data analyst or data scientist, you may want to also take the third course in our series, DAT206x Analyzing and Visualizing Data with Excel. This course includes excerpts from Microsoft Excel 2016: Data Analysis and Business Modeling from Microsoft Press and authored by course instructor Wayne Winston.edX offers financial assistance for learners who want to earn Verified Certificates but who may not be able to pay the fee. To apply for financial assistance, enroll in the course, then follow this link to complete an application for assistance.



            Read more
          



Module 1: Descriptive Statistics You will learn how to describe data using charts and basic statistical measures. Full use will be made of the new histograms, Pareto charts, Boxplots, and Treemap and Sunburst charts in Excel 2016. Module 2: Basic Probability You will learn basic probability including the law of complements, independent events, conditional probability and Bayes Theorem. Module 3: Random Variables You will learn how to find the mean and variance of random variables and then learn about the binomial, Poisson, and Normal random variables. We close with a discussion of the beautiful and important Central Limit Theorem. Module 4: Sampling and Confidence IntervalsYou will learn the mechanics of sampling, point estimation, and interval estimation of population parameters. Module 5: Hypothesis Testing You will learn null and alternative hypotheses, Type I and Type II error, One sample tests for means and proportions, Tests for difference between means of two populations, and the Chi Square Test for Independence.",Essential Statistics for Data Analysis using Excel
https://www.classcentral.com/course/kadenze-the-practical-history-of-typography-7599,"The Practical History of Typography serves as an introduction to The Complete Typographer, and provides a historical appreciation of the art and science of typography: display lettering (both hand drawn and mechanically generated), and text typefaces—a “historical bucket” approach. The course examines typefaces associated with key design and technological developments of the 20th century—the Bauhaus, the New Typography, etc.—with an eye towards critical analysis of form, moving right up to 2017, including advances in generative type and variable fonts for web.What Students Are Saying:""This is an fantastic course because you get to know a great deal about typography. As a graphic designer I would recommend it.""",The Practical History of Typography
https://www.classcentral.com/course/assembly-3290,"You may have heard a lot about genome sequencing and its potential to usher in an era of personalized medicine, but what does it mean to sequence a genome?

Biologists still cannot read the nucleotides of an entire genome as you would read a book from beginning to end. However, they can read short pieces of DNA. In this course, we will see how graph theory can be used to assemble genomes from these short pieces. We will further learn about brute force algorithms and apply them to sequencing mini-proteins called antibiotics. 

In the first half of the course, we will see that biologists cannot read the 3 billion nucleotides of a human genome as you would read a book from beginning to end.  However, they can read shorter fragments of DNA. In this course, we will see how graph theory can be used to assemble genomes from these short pieces in what amounts to the largest jigsaw puzzle ever put together.

In the second half of the course, we will discuss antibiotics, a topic of great relevance as antimicrobial-resistant bacteria like MRSA are on the rise.  You know antibiotics as drugs, but on the molecular level they are short mini-proteins that have been engineered by bacteria to kill their enemies.  Determining the sequence of amino acids making up one of these antibiotics is an important research problem, and one that is similar to that of sequencing a genome by assembling tiny fragments of DNA.  We will see how brute force algorithms that try every possible solution are able to identify naturally occurring antibiotics so that they can be synthesized in a lab.

Finally, you will learn how to apply popular bioinformatics software tools to sequence the genome of a deadly Staphylococcus bacterium that has acquired antibiotics resistance.
      


            Read more
          



          Week 1: Introduction to Genome Sequencing
    -Welcome to class!This course will focus on two questions at the forefront of modern computational biology, along with the algorithmic approaches we will use to solve them in parentheses:Weeks 1-2: How Do We Assemble Genomes? (Graph Algorithms)How Do We Sequence Antibiotics? (Brute Force Algorithms)Each of the two chapters of content in the class is accompanied by a Bioinformatics Cartoon created by talented San Diego artist Randall Christopher and serving as a chapter header in the Specialization's bestselling print companion. You can find the first chapter's cartoon at the bottom of this message. What does a time machine trip to 1735, a stack of newspapers, a jigsaw puzzle, and a giant ant invading a riverside city have to do with putting together a genome? Start learning today to find out!

Week 2: Applying Euler's Theorem to Assemble Genomes
    -Welcome to Week 2 of class!

This week in class, we will see how a 300 year-old mathematical theorem will help us assemble a genome from millions of tiny pieces of DNA.

Week 3: Sequencing Antibiotics
    -Welcome to Week 3 of class!

This week, we begin a new chapter, titled ""How Do We Sequence Antibiotics?""  In this chapter, we will learn how to determine the amino acid sequences making up antibiotics using brute force algorithms.

Below is this week's Bioinformatics Cartoon.



Week 4: From Ideal to Real Spectra for Antibiotics Sequencing
    -Welcome to Week 4 of class!

Last week, we discussed how to sequence an antibiotic peptide from an ideal spectrum. This week, we will see how to develop more sophisticated algorithms for antibiotic peptide sequencing that are able to handle spectra with many false and missing masses.

Week 5: Bioinformatics Application Challenge!
    -Welcome to Week 5 of class!

This week, we will see how to apply genome assembly tools to sequencing data from a dangerous pathogenic bacterium.",Genome Sequencing (Bioinformatics II)
https://www.classcentral.com/course/udacity-intro-to-descriptive-statistics-2309,"Statistics is an important field of math that is used to analyze, interpret, and predict outcomes from data. Descriptive statistics will teach you the basic concepts used to describe data. This is a great beginner course for those interested in Data Science, Economics, Psychology, Machine Learning, Sports analytics and just about any other field.Why Take This Course?This course will teach you the basic terms and concepts in statistics as well as guide you through introductory probability. You will learn how to....Use statistical research methods.Compute and interpret values like: Mean, Median, Mode, Sample, Population, and Standard Deviation.Compute simple probabilities. Explore data through the use of bar graphs, histograms, box plots, and other common visualizations.Investigate distributions and understand a distributions properties.Manipulate distributions to make probabilistic predictions on data.



Lesson 1 : Intro to Research MethodsYou will be introduced to several statistical study methods and learn the positives and negatives of each. Lesson 2 : Visualizing DataYou will learn how to take your data and display it to the world. You will learn to create and interpret histograms, bar charts, and frequency plots.Lesson 3 : Central TendencyIn this lesson you will learn to compute and interpret the 3 measures of center for distributions: the mean, median, and mode.Lesson 4 : VariabilityYou will learn how to quantify the spread of data using the range and standard deviation. You will also learn how to identify outliers in data sets using the concept of the interquartile range. Lesson 5 : StandardizingYou will learn how to convert distributions into the standard normal distribution using the Z-score. You will also learn how to compute proportions using standardized distributions. Lesson 6 : Normal DistributionYou will learn how to use normalized distributions to compute probabilities. You will also learn how to use the Z-table to look up the proportions of observations above, below, or in between values.  Lesson 7 : Sampling DistributionsYou will learn how to apply the concepts of probability and normalization to sample data sets.",Intro to Descriptive Statistics
https://www.classcentral.com/course/c-for-everyone-16909,"This course is for everyone. In the new world we live in, coding is a universally valuable skill, whether you're a scientist, artist, or a humanist. Algorithms are everywhere, and we all have to understand how they work. The C language is particularly well suited as an introduction to coding: It's a tried-and-true language, and it allows you to understand computing processes at a deep level. 
No prior knowledge of coding is needed for this course. We'll start at the beginning.
The time estimated time commitment for this course is five hours a week for five weeks.
      


          Introduction
    -An overview of the course, a history of the C language, and a first set of programming activities. 

Lexical Elements and Data Types
    -Lexical elements and data types, programming activities of increasing sophistication, and an optional discussion of more advanced issues. 

Flow of Control and Simple Functions
    -Flow of control and simple functions, even more sophisticated programming activities, and an optional discussion of more advanced issues. 

Advanced Functions, Recursion, Arrays, and Pointers
    -A continuation of functions, recursion, arrays, and pointers. 

Arrays and pointers
    -Further treatment of arrays and pointers and an interesting programming activity. 

Final Exam
    -The end of the first part of C for Everyone and an opportunity to assess your learning.",C for Everyone: Programming Fundamentals
https://www.classcentral.com/course/newwayhealthcare-657,"Interprofessional Healthcare Informatics is a graduate-level, hands-on interactive exploration of real informatics tools and techniques offered by the University of Minnesota and the University of Minnesota's National Center for Interprofessional Practice and Education. We will be incorporating technology-enabled educational innovations to bring the subject matter to life. Over the 10 modules, we will create a vital online learning community and a working healthcare informatics network. 

We will explore perspectives of clinicians like dentists, physical therapists, nurses, and physicians in all sorts of practice settings worldwide. Emerging technologies, telehealth, gaming, simulations, and eScience are just some of the topics that we will consider. 

Throughout the course, we’ll focus on creativity, controversy, and collaboration - as we collectively imagine and create the future within the rapidly evolving healthcare informatics milieu. All healthcare professionals and IT geeks are welcome!
      


          Introduction

Informatics Theory
    -Week 1 begins! This week, we explore and apply theories of healthcare informatics to professional practice. By the end of this week, you will be able to: describe informatics theory, analyze informatics theory related to practice and analyze health topics of interest to healthcare.

Data, Information, and Knowledge
    -This module explores and applies standardized terminologies to professional practice. By the end of this module, learners will be able to: analyze the transformation of data to information to knowledge and explore and apply standardized terminologies to professional practice.

Electronic Health Record (EHR) Components, Evidence-Based Practice
    -This module links EHR use to evidence-based practice. By the end of this module, learners will be able to: identify the benefits and goals of an electronic health record and analyze evidence-based practice within the context of the electronic health record.

Quality Improvement/ Workflow Analysis/ Redesign
    -Week 5 begins! This week we examine informatics in relationship to new technologies in healthcare. Telehealth and technology are creating new ways to link people, and care, and health information. By the end of this week, you will be able to: examine applications of telehealth technologies and describe methods of engaging consumers in using health information technologies.

Telehealth/ Consumer Health/ Mobile Technology
    -This module examines informatics in relationship to new technologies in healthcare. By the end of this module, learners will be able to: examine applications of telehealth technologies and describe methods of engaging consumers in using health information technologies.

Community/ Population Health
    -This module relates informatics to community and population health. By the end of this module, learners will be able to: relate informatics to community and population health and analyze applications of geospatial information systems and health.


Informatics, Gaming, and Simulation
    -This module describes applications of gaming, simulation, and virtual reality tools in healthcare. By the end of this module, learners will be able to: analyze informatics and gaming in relationship to health and healthcare and describe use of simulations and informatics to improve healthcare quality.


Informatics and Ethics
    -This module explores ethical issues related to healthcare informatics in the interprofessional context. By the end of this module, learners will be able to: explore ethical issues related to healthcare informatics in the interprofessional context and analyze security and privacy challenges related to healthcare informatics.

Data Exchange and Interoperability
    -This module explores interprofessional aspects of healthcare data exchange and interoperability. By the end of this module, learners will be able to: describe information exchange and interoperability and analyze interprofessional aspects of information exchange and interoperability in healthcare.

Informatics and the Foundation of Knowledge
    -This module explores the contribution of healthcare informatics to the foundation of knowledge in healthcare. By the end of this module, learners will be able to: analyze implications of Big Data for healthcare research and synthesize insights related to interprofessional healthcare informatics.",Interprofessional Healthcare Informatics
https://www.classcentral.com/course/udacity-cs-8802-artificial-intelligence-for-robotics-programming-a-robotic-car-1021,"Learn how to program all the major systems of a robotic car from the leader of Google and Stanford's autonomous driving teams. This class will teach you basic methods in Artificial Intelligence, including: probabilistic inference, planning and search, localization, tracking and control, all with a focus on robotics. Extensive programming examples and assignments will apply these methods in the context of building self-driving cars.
This course is offered as part of the Georgia Tech Masters in Computer Science. The updated course includes a final project, where you must chase a runaway robot that is trying to escape!
Why Take This Course?
This course will teach you probabilistic inference, planning and search, localization, tracking and control, all with a focus on robotics.
At the end of the course, you will leverage what you learned by solving the problem of a runaway robot that you must chase and hunt down!
Prerequisites and Requirements
Success in this course requires some programming experience and some mathematical fluency.
Programming in this course is done in Python. We will use some basic object-oriented concepts to model robot motion and perception. If you don’t know Python but have experience with another language, you should be able to pick up the syntax fairly quickly. If you have no programming experience, you should consider taking Udacity’s Introduction to Computer Science course before attempting this one.
The math used will be centered on probability and linear algebra. You don’t need to be an expert in either, but some familiarity with concepts in probability (e.g. probabilities must add to one, conditional probability, and Bayes’ rule) will be extremely helpful. It is possible to learn these concepts during the course, but it will take more work. Knowledge of linear algebra, while helpful, is not required.
See the Technology Requirements for using Udacity.



            Read more
          



Lesson 1: Localization

Localization
Total Probability
Uniform Distribution
Probability After Sense
Normalize Distribution
Phit and Pmiss
Sum of Probabilities
Sense Function
Exact Motion
Move Function
Bayes Rule
Theorem of Total Probability

Lesson 2: Kalman Filters

Gaussian Intro
Variance Comparison
Maximize Gaussian
Measurement and Motion
Parameter Update
New Mean Variance
Gaussian Motion
Kalman Filter Code
Kalman Prediction
Kalman Filter Design
Kalman Matrices

Lesson 3: Particle Filters

Slate Space
Belief Modality
Particle Filters
Using Robot Class
Robot World
Robot Particles

Lesson 4: Search

Motion Planning
Compute Cost
Optimal Path
First Search Program
Expansion Grid
Dynamic Programming
Computing Value
Optimal Policy

Lesson 5: PID Control

Robot Motion
Smoothing Algorithm
Path Smoothing
Zero Data Weight
Pid Control
Proportional Control
Implement P Controller
Oscillations
Pd Controller
Systematic Bias
Pid Implementation
Parameter Optimization

Lesson 6: SLAM (Simultaneous Localization and Mapping)

Localization
Planning
Segmented Ste
Fun with Parameters
SLAM
Graph SLAM
Implementing Constraints
Adding Landmarks
Matrix Modification
Untouched Fields
Landmark Position
Confident Measurements
Implementing SLAM

Runaway Robot Final Project","CS 8802, Artificial Intelligence for Robotics: Programming a Robotic Car"
https://www.classcentral.com/course/edx-mechanical-behavior-of-materials-part-3-time-dependent-behavior-and-failure-4010,"All around us, engineers are creating materials whose properties are exactly tailored to their purpose. This course is the third of three in a series of mechanics courses from the Department of Materials Science and Engineering at MIT. Taken together, these courses provide similar content to the MIT subject 3.032: Mechanical Behavior of Materials.
The 3.032x series provides an introduction to the mechanical behavior of materials, from both the continuum and atomistic points of view. At the continuum level, we learn how forces and displacements translate into stress and strain distributions within the material. At the atomistic level, we learn the mechanisms that control the mechanical properties of materials. Examples are drawn from metals, ceramics, glasses, polymers, biomaterials, composites and cellular materials.
Part 3 covers viscoelasticity (behavior intermediate to that of an elastic solid and that of a viscous fluid), plasticity (permanent deformation), creep in crystalline materials (time dependent behavior), brittle fracture (rapid crack propagation) and fatigue (failure due to repeated loading of a material).



Week 1: Linear viscoelasticity Spring-dashpot models Dynamic mechanical measurements Molecular basis for linear viscoelasticity Viscoelasticity in biomaterials  Week 2:   Plasticity Yield criteria Dislocations Week 3: Dislocation mechanics Hardening mechanisms Week 4:   Creep in crystalline materials Mechanisms of creep Deformation mechanism maps Creep fracture Week 5: Fracture mechanics Mechanisms of fast fracture Fatigue  Week 6: Final Quiz","Mechanical Behavior of Materials, Part 3:  Time Dependent Behavior and Failure"
https://www.classcentral.com/course/edx-introduction-to-bioconductor-annotation-and-analysis-of-genomes-and-genomic-assays-2970,"We begin with an introduction to the biology, explaining what we measure and why. Then we focus on the two main measurement technologies: next generation sequencing and microarrays. We then move on to describing how raw data and experimental information are imported into R and how we use Bioconductor classes to organize these data, whether generated locally, or harvested from public repositories or institutional archives. Genomic features are generally identified using intervals in genomic coordinates, and highly efficient algorithms for computing with genomic intervals will be examined in detail. Statistical methods for testing gene-centric or pathway-centric hypotheses with genome-scale data are found in packages such as limma, some of these techniques will be illustrated in lectures and labs.
Given the diversity in educational background of our students we have divided the series into seven parts. You can take the entire series or individual courses that interest you. If you are a statistician you should consider skipping the first two or three courses, similarly, if you are biologists you should consider skipping some of the introductory biology lectures. Note that the statistics and programming aspects of the class ramp up in difficulty relatively quickly across the first three courses. By the third course will be teaching advanced statistical concepts such as hierarchical models and by the fourth advanced software engineering skills, such as parallel computing and reproducible research concepts.
These courses make up 2 XSeries and are self-paced:
PH525.1x: Statistics and R for the Life Sciences
PH525.2x: Introduction to Linear Models and Matrix Algebra
PH525.3x: Statistical Inference and Modeling for High-throughput Experiments
PH525.4x: High-Dimensional Data Analysis
PH525.5x: Introduction to Bioconductor: annotation and analysis of genomes and genomic assays 
PH525.6x: High-performance computing for reproducible genomics
PH525.7x: Case studies in functional genomics
This class was supported in part by NIH grant R25GM114818.
HarvardX requires individuals who enroll in its courses on edX to abide by the terms of the edX honor code. HarvardX will take appropriate corrective action in response to violations of the edX honor code, which may include dismissal from the HarvardX course; revocation of any certificates received for the HarvardX course; or other remedies as circumstances warrant. No refunds will be issued in the case of corrective action for such violations. Enrollees who are taking HarvardX courses as part of another program will also be governed by the academic policies of those programs.
HarvardX pursues the science of learning. By registering as an online learner in an HX course, you will also participate in research about learning. Read our research statement to learn more.
Harvard University and HarvardX are committed to maintaining a safe and healthy educational and work environment in which no member of the community is excluded from participation in, denied the benefits of, or subjected to discrimination or harassment in our program. All members of the HarvardX community are expected to abide by Harvard policies on nondiscrimination, including sexual harassment, and the edX Terms of Service. If you have any questions or concerns, please contact harvardx@harvard.edu and/or report your experience through the edX contact form.



            Read more",Introduction to Bioconductor: Annotation and Analysis of Genomes and Genomic Assays
https://www.classcentral.com/course/regression-modeling-practice-4351,"This course focuses on one of the most important tools in your data analysis arsenal: regression analysis. Using either SAS or Python, you will begin with linear regression and then learn how to adapt when two variables do not present a clear linear relationship. You will examine multiple predictors of your outcome and be able to identify confounding variables, which can tell a more compelling story about your results. You will learn the assumptions underlying regression analysis, how to interpret regression coefficients, and how to use regression diagnostic plots and other tools to evaluate the quality of your regression model. Throughout the course, you will share with others the regression models you have developed and the stories they tell you.
      


          Introduction to Regression
    -This session starts where the Data Analysis Tools course left off. This first set of videos provides you with some conceptual background about the major types of data you may work with, which will increase your competence in choosing the statistical analysis that’s most appropriate given the structure of your data, and in understanding the limitations of your data set. We also introduce you to the concept of confounding variables, which are variables that may be the reason for the association between your explanatory and response variable. Finally, you will gain experience in describing your data by writing about your sample, the study data collection procedures, and your measures and data management steps. 

Basics of Linear Regression
    -In this session, we discuss more about the importance of testing for confounding, and provide examples of situations in which a confounding variable can explain the association between an explanatory and response variable. In addition, now that you have statistically tested the association between an explanatory variable and your response variable, you will test and interpret this association using basic linear regression analysis for a quantitative response variable. You will also learn about how the linear regression model can be used to predict your observed response variable. Finally, we will also discuss the statistical assumptions underlying the linear regression model, and show you some best practices for coding your explanatory variables
Note that if your research question does not include one quantitative response variable, you can use one from your data set just to get some practice with the tool. 


Multiple Regression
    -Multiple regression analysis is tool that allows you to expand on your research question, and conduct a more rigorous test of the association between your explanatory and response variable by adding additional quantitative and/or categorical explanatory variables to your linear regression model. In this session, you will apply and interpret a multiple regression analysis for a quantitative response variable, and will learn how to use confidence intervals to take into account error in estimating a population parameter. You will also learn how to account for nonlinear associations in a linear regression model. Finally, you will develop experience using regression diagnostic techniques to evaluate how well your multiple regression model predicts your observed response variable. 
Note that if you have not yet identified additional explanatory variables, you should choose at least one additional explanatory variable from your data set. When you go back to your codebooks, ask yourself a few questions like “What other variables might explain the association between my explanatory and response variable?”; “What other variables might explain more of the variability in my response variable?”, or even “What other explanatory variables might be interesting to explore?” Additional explanatory variables can be either quantitative, categorical, or both. Although you need only two explanatory variables to test a multiple regression model, we encourage you to identify more than one additional explanatory variable. Doing so will really allow you to experience the power of multiple regression analysis, and will increase your confidence in your ability to test and interpret more complex regression models. If your research question does not include one quantitative response variable, you can use the same quantitative response variable that you used in Module 2, or you may choose another one from your data set. 

Logistic Regression
    -In this session, we will discuss some things that you should keep in mind as you continue to use data analysis in the future. We will also teach also you how to test a categorical explanatory variable with more than two categories in a multiple regression analysis. Finally, we introduce you to logistic regression analysis for a binary response variable with multiple explanatory variables. Logistic regression is simply another form of the linear regression model, so the basic idea is the same as a multiple regression analysis. But, unlike the multiple regression model, the logistic regression model is designed to test binary response variables. You will gain experience testing and interpreting a logistic regression model, including using odds ratios and confidence intervals to determine the magnitude of the association between your explanatory variables and response variable.   
You can use the same explanatory variables that you used to test your multiple regression model with a quantitative outcome, but your response variable needs to be binary (categorical with 2 categories). If you have a quantitative response variable, you will have to bin it into 2 categories. Alternatively, you can choose a different binary response variable from your data set that you can use to test a logistic regression model. If you have a categorical response variable with more than two categories, you will need to collapse it into two categories.",Regression Modeling in Practice
https://www.classcentral.com/course/angular-8681,"This course concentrates mainly on Javascript based front-end frameworks, and in particular the Angular framework (Currently Ver. 6.x). This course will use Typescript for developing Angular application. Typescript features will be introduced in the context of Angular as part of the exercises. You will also get an introduction to the use of Angular Material and Angular Flex-Layout for responsive UI design. You will be introduced to various aspects of Angular including components, directives and services. You will learn about data binding, Angular router and its use for developing single-page applications. You will also learn about designing both template-driven forms and reactive forms. A quick introduction to Observables, reactive programming and RxJS in the context of Angular is included. You will then learn about Angular support for client-server communication through the HTTP client and the use of REST API on the server side. A quick tour through Angular animation support and Angular testing rounds off the course. You must have either completed the previous course in the specialization on Bootstrap 4, or have a working knowledge of front end web-UI frameworks to be able to navigate this course. Also a good working knowledge of JavaScript, especially ES 5 is strongly recommended.

At the end of this course you will:

- Be familiar with client-side Javascript frameworks and the Angular framework
- Be able to implement single page applications in Angular
- Be able to use various Angular features including directives, components and services
- Be able to implement a functional front-end web application using Angular
- Be able to use Angular Material and Angular Flex-Layout for designing responsive Angular applications
- Be able to use Observables and RxJS in the context of Angular applications
      


            Read more
          



          Front-End JavaScript Frameworks Overview: Angular
    -In this module we get a quick introduction to front-end JavaScript frameworks, followed by an introduction to Angular. We will also learn about Angular components and their templates.

Angular Services, Routing and Single Page Applications
    -In this week, you learn about data binding in Angular. You will learn how to design basic services. You will learn about Angular router and its use in designing single page applications. You will also learn about single page applications and use Angular Router to design single page applications.

Angular Forms, Angular and Reactive JavaScript
    -In this module we study Angular support for forms and form validation. Both template-driven forms and reactive forms will be introduced. You will also learn about Promises. Then you will learn briefly about reactive programming, RxJs and its use in Angular.

Client-Server Communication
    -In this module you will explore client-server communication using both Angular HTTP module and the REST API. You will get a brief introduction to animation support in Angular and create a custom attribute directive. You will also learn about testing, building and deploying Angular applications.",Front-End JavaScript Frameworks: Angular
https://www.classcentral.com/course/analyticalchem-838,"This course covers about a half a semester of instrumental analysis which is a standard part of the undergraduate chemistry curriculum. Any chemist has to understand how to analyze samples - whether they are water samples, blood samples or bits of a painting. Most often chemists do this using instruments of some sort. Machines like mass spectrometers or gas chromatographs can indicate both what's in a sample (qualitative) as well as how much of something there is(quantitative). If you are fascinated by shows like CSI, and have enough basic chemistry, this course would be great for you. However, the course is first and foremost designed for chemistry students working towards their degree.Students who complete this class will understand that analytical instruments are not black boxes, but rather complex tools whose utility depends in detail on how analysts both configure and apply them. Towards that end there are three pimary objectives. First, students will learn facts about major classes of instruments commonly used in chemical analysis. Their knowledge will be captured by the ability to block diagram these complex pieces of equipment, and tailor the specifications to the measurement needs. Second, the course will cover the basics of instrumental calibration and quality control. Analysts will develop the ability to apply calibration curves, internal standards and the method of standard addition as needed for various measurement problems. Finally, students must learn how to select and tailor the best instrumental method given a particular measurement need. This higher level skill involves critical evaluation of the strengths and limitations of the various method, and the ability to understand the context behind a measurement need.
      


            Read more
          



          Description: This course will provide students with a background in modern analytical chemistry with an emphasis on instrumentation. Applications of instrumental analytical chemistry in medicine, forensics and materials science will be presented. Course objectives:To reinforce chemical principles central to analytical chemistry.To introduce instrumental techniques for chemical measurement.To develop critical thinking for interpreting analytical data.To select instrumentation appropriate to the measurement need.Week 1: Overview of instrumental analysis and basic chemistry review Week 2: Atomic spectroscopies and the analysis of metals Week 3: Calibration, QA/QC, and improving instrumental analysis Week 4: The basic principles of chromatography Week 5: Gas chromatography Week 6: Liquid chromatography Week 7: Vibrational spectroscopies Week 8: Electronic and optical sensors",Analytical Chemistry / Instrumental Analysis
https://www.classcentral.com/course/edx-case-studies-in-functional-genomics-2976,"We will explain how to start with raw data, and perform the standard processing and normalization steps to get to the point where one can investigate relevant biological questions. Throughout the case studies, we will make use of exploratory plots to get a general overview of the shape of the data and the result of the experiment. We start with RNA-seq data analysis covering basic concepts of RNA-seq and a first look at FASTQ files. We will also go over quality control of FASTQ files; aligning RNA-seq reads; visualizing alignments and move on to analyzing RNA-seq at the gene-level: counting reads in genes; Exploratory Data Analysis and variance stabilization for counts; count-based differential expression; normalization and batch effects. Finally, we cover RNA-seq at the transcript-level: inferring expression of transcripts (i.e. alternative isoforms); differential exon usage. We will learn the basic steps in analyzing DNA methylation data, including reading the raw data, normalization, and finding regions of differential methylation across multiple samples. The course will end with a brief description of the basic steps for analyzing ChIP-seq datasets, from read alignment, to peak calling, and assessing differential binding patterns across multiple samples.
Given the diversity in educational background of our students we have divided the series into seven parts. You can take the entire series or individual courses that interest you. If you are a statistician you should consider skipping the first two or three courses, similarly, if you are biologists you should consider skipping some of the introductory biology lectures. Note that the statistics and programming aspects of the class ramp up in difficulty relatively quickly across the first three courses. By the third course will be teaching advanced statistical concepts such as hierarchical models and by the fourth advanced software engineering skills, such as parallel computing and reproducible research concepts.
These courses make up 2 XSeries and are self-paced:
PH525.1x: Statistics and R for the Life Sciences
PH525.2x: Introduction to Linear Models and Matrix Algebra
PH525.3x: Statistical Inference and Modeling for High-throughput Experiments
PH525.4x: High-Dimensional Data Analysis
PH525.5x: Introduction to Bioconductor: annotation and analysis of genomes and genomic assays 
PH525.6x: High-performance computing for reproducible genomics
PH525.7x: Case studies in functional genomics
This class was supported in part by NIH grant R25GM114818.
HarvardX requires individuals who enroll in its courses on edX to abide by the terms of the edX honor code. HarvardX will take appropriate corrective action in response to violations of the edX honor code, which may include dismissal from the HarvardX course; revocation of any certificates received for the HarvardX course; or other remedies as circumstances warrant. No refunds will be issued in the case of corrective action for such violations. Enrollees who are taking HarvardX courses as part of another program will also be governed by the academic policies of those programs.
HarvardX pursues the science of learning. By registering as an online learner in an HX course, you will also participate in research about learning. Read our research statement to learn more.
Harvard University and HarvardX are committed to maintaining a safe and healthy educational and work environment in which no member of the community is excluded from participation in, denied the benefits of, or subjected to discrimination or harassment in our program. All members of the HarvardX community are expected to abide by Harvard policies on nondiscrimination, including sexual harassment, and the edX Terms of Service. If you have any questions or concerns, please contact harvardx@harvard.edu and/or report your experience through the edX contact form.



            Read more",Case Studies in Functional Genomics
https://www.classcentral.com/course/grow-earth-sensor-10569,"Discover the world through citizen science, earth observation and open soil data
Did you know satellites are constantly monitoring soil moisture, even in your garden? Monitoring the moisture in soil can help predict floods, fires and droughts.
On this course, you will learn about the ESA’s Sentinel-1 Missions, and how citizen scientists collaborating with GROW are helping validate satellite data locally with sensors.
You’ll discover sensing, and become part of the GROW Citizen Observatory. You will collaborate with other growers and scientists to learn about soil sensors and make sense of soil data to improve your growing practice.
This course has been created for anyone interested in any of the following subjects: soil, climate, technology, satellites, food growing and the environment. You don’t need any special experience, however, it might be of particular interest to: small farmers, community and urban growers, gardeners, land managers and allotment growers as people interested in climate monitoring, sensing, social innovation and space science, technology enthusiasts and teachers in science and environment-related subjects. This course brings together people who love soil with people who love data.
You won’t need any specific equipment to participate in this course. This course will help you to learn more about soil sensors, so you may wish to try one out if you have one, but this is not required.



            Read more",Citizen Science: Sensing the World
https://www.classcentral.com/course/edx-data-science-probability-10348,"In this course, part of our Professional Certificate Program in Data Science,you will learn valuable concepts in probability theory. The motivation for this course is the circumstances surrounding the financial crisis of 2007-2008. Part of what caused this financial crisis was that the risk of some securities sold by financial institutions was underestimated. To begin to understand this very complicated event, we need to understand the basics of probability. 
We will introduce important concepts such as random variables, independence, Monte Carlo simulations, expected values, standard errors, and the Central Limit Theorem. These statistical concepts are fundamental to conducting statistical tests on data and understanding whether the data you are analyzing is likely occurring due to an experimental method or to chance. 
Probability theory is the mathematical foundation of statistical inference which is indispensable for analyzing data affected by chance, and thus essential for data scientists.",Data Science: Probability
https://www.classcentral.com/course/climate-change-12527,"This course is an introduction to the multiple ways our changing climate affects global population health, and to promising policy and practice responses.  More intense storms, heatwaves, and rising seas mean many, particularly the most vulnerable, now face growing risks of weather-related injury, illness, mental stress and even death. Because people care deeply about health outcomes, public health has great potential to convey the urgency of reducing greenhouse gas emissions and adapting to a warmer, more unpredictable climate.  The main message of the course is that public health must therefore “lean in” and become a more central player in climate change mitigation and adaptation.  Because climate-related health risks happen mainly at the local level, the course focuses on cities – increasingly key players in climate change policy.  Starting with an overview of the science consensus suggesting we have 10-20 years to prevent risks associated with exceeding 1.5°C of global warming and put in place adaptive policies, the course provides interactive lectures, expert interviews and case studies that build practical knowledge.  In the final assignment, participants apply course tools and strategies to a city of their choice, preparing them to contribute to climate mitigation and building health resiliency in their own local context.
      


          Introduction and Climate Science
    -Module I introduces learners to the basic definitions, principles and findings of climate change science, relying on reports of the UN-affiliated Intergovernmental Panel on Climate Change (IPCC), as well as the US National Climate Assessment, NASA, NOAA, and other science agencies.  Following a brief course overview, sessions cover how the climate has changed and may change in the future, including the recent IPCC report on global warming of 1.5 degrees C.  An interview with former EPA Administrator Gina McCarthy addresses why public health departments globally need to prepare for a changing climate, and an interview with Dr. Rufus Ewing, former Premier of Turks and Caicos, provides a perspective on the impacts of extreme storms and sea-level rise on vulnerable small island states.  A ten-question multiple-choice quiz provides an opportunity to take stock of module learning. 

Public Health Perspective
    -Module II details the health impacts of climate change on human populations, and why a changing climate provides both a challenge but also an opportunity for public health.  Direct impacts of climate change on human well-being are covered (including illness, injuries and death from extreme heat, precipitation, and worsening air quality) and indirect impacts (such as increased risk of vector-borne disease, risks to water quality and quantity, food security and safety, mental health, and climate-related relocation).  Emphasized points include the vulnerability of specific populations; the complex, interlinked and multi-scale nature of climate health challenges; and the particular hazards faced by cities – on the climate frontline due to their concentrated populations, the urban heat island effect and other factors.  An interview with Dr. Thomas Matte, former Assistant Health Commissioner for New York City, provides perspectives on Hurricane Sandy and its impacts; while an interview with former World Bank Institute Urban Director Dr. Mila Freire provides insights into how urban planning and public health can collaborate to enhance climate health outcomes in cities.  A ten-question quiz provides an opportunity to review and consolidate learning.



Assessment Frameworks and Case Study
    -Module III introduces learners to climate and health analytical tools and assessment methods they can use in their own local contexts, illustrating application of these tools through examples including a case study for the city of Barcelona presented by Dr. Joan Ramon Villalbi of the Barcelona Public Health Agency.  Among the assessment methods highlighted are the EU Climate Adapt framework, Health Impact Assessment (HIA), and innovative approaches such as “multisolving.”  Special focus is placed on the US Centers for Disease Control and Prevention (CDC) five-step adaptive-learning framework called “Building Resilience Against Climate Effects” (BRACE), with the US state of Maryland’s application of BRACE provided as an example illustrated through an interview with Dr. Clifford Mitchell, Director in the State Public Health Department's Environment Bureau.  A ten-question multiple-choice quiz provides an opportunity to verify learning, and the analytical tools discussed in this module provide guidance for completion of the final course assignment.

Policies and Practices
    -Module IV provides concrete examples of promising climate health adaptive policies and practices, covering information-driven practices such as surveillance as well as early warning systems (including an assignment to identify/evaluate a real-life early warning system).  Collaboration across non-health sectors -- particularly the physical infrastructure sectors including water, transport and electricity essential to city functioning -- is also covered, including an interview on financing of adaptive urban infrastructure with Bernard Sheahan, former Director of Infrastructure for the International Finance Corporation.  Sessions on communicating on climate change and health (including a “how-to” tutorial) help build concrete skills.  The course concludes with an interview with Dean Emeritus of JHSPH, Dr. Al Sommer, providing a forward-looking perspective on how public health can ""speak up"" on the challenges of climate change.  

Final Assignment
    -The final assignment is structured around application of concepts learned in the course to evaluation of the climate adaptation/action plan of a city or locality of the learner’s choice, which will be peer-graded based on a defined rubric.","Protecting Public Health in a Changing Climate:  A Primer for City, Local, and Regional Action"
https://www.classcentral.com/course/innovation-through-design-11588,"The evolution of design has seen it become a discipline no longer limited to the concerns of a singular, specific domain and develop to become a pathway for solving complex, nonlinear problems. Design is becoming a capability-enhancing skill, equipping people with the ability to deal with uncertainty, complexity and failure. 

In this course, we demonstrate how you can use design as a way of thinking to provide strategic and innovative advantage within your profession. Suitable for anyone who is curious about design and translating the processes and tools of design thinking into innovative opportunities, over 5 weeks we explore, apply and practice the design process: think, make, break and repeat.

Through introducing theoretical concepts and examining industry case studies with leading Australian design firms, we investigate design as learning about the context (the thinking part), building prototypes as tangible representations (the making part) and testing potential solutions (the breaking part). We build on this by showing the productive value of moving through the process quickly and often (the repeating part), to improve ideas and develop new insights. 

Throughout the course, you will follow us through three of Australia’s most exciting design offices and learn from practicing designers and leaders in design. This insight into industry will enable you to develop a comprehensive understanding of design and the role it can and does play within the innovation landscape. You will leave this course with a set of practical tools and techniques to apply to situations within your own professional context, to translate problems into opportunities and solutions, and ultimately to innovate through design.
      


            Read more
          



          Introducing design
    -This module introduces the concept of human-centred design and explores its role for innovation. We give a short introduction to design innovation and review the process that design innovation projects typically follow. The module also features interviews with industry experts about their views on what design innovation is and how it is applied in industry.

Design thinking
    -This module provides you with an understanding of the first step in any design innovation project, which we refer to as design thinking. We discuss its role in the human-centred design process and how it relates to innovation. The module will also examine some of the tools used to collect data about users and customers. Industry experts explain the role of this step and the methods they use through concrete case studies.

Design making
    -In this module, we look at the design making part of the process. In design making, user or customer data is turned into concepts, prototypes and minimum viable products, which can be used to gain initial feedback about ideas. Industry experts discuss the importance of ideation and prototyping in the design industry.

Design breaking
    -This module looks at the value of evaluating designs, referred to as the design breaking part of a design innovation process. We explain some methods for evaluating design solutions, introduce fundamental design principles and see how designers are applying these methods in industry design innovation projects.

Repeating design
    -This module focuses on the very important step in the design process of repeating, or iteration, and its role in design innovation. We also provide a summary of all the topics covered in the course and take you through the design process with a design research project. Industry experts share their insights and tips about working in the design industry.","Innovation Through Design: Think, Make, Break, Repeat"
https://www.classcentral.com/course/edx-introduction-to-data-science-17901,"The art of uncovering the insights and trends in data has been around for centuries. The ancient Egyptians applied census data to increase efficiency in tax collection and they accurately predicted the flooding of the Nile river every year. Since then, people working in data science have carved out a unique and distinct field for the work they do. This field is data science and in this course, you will meet some big data science practitioners and we will get an overview of what data science is today.",Introduction to Data Science
https://www.classcentral.com/course/edx-programming-with-python-for-data-science-6471,"This course is part of the Microsoft Professional Program Certificate in Data Science.
This practical course, developed in partnership with Coding Dojo, targets individuals who have introductory level Python programming experience. The course teaches students how to start looking at data with the lens of a data scientist by applying efficient, well-known mining models in order to unearth useful intelligence, using Python, one of the popular languages for Data Scientists. Topics include data visualization, feature importance and selection, dimensionality reduction, clustering, classification and more! All of the data sets used in this course are gathered live-data or inspired by real-world domains that can benefit from machine learning.",Programming with Python for Data Science
https://www.classcentral.com/course/edx-introduction-to-solar-systems-astronomy-3503,"This course is part of Global Freshman Academy (GFA), which means you can earn transferable ASU credit toward your college degree.
In this introductory 4-credit hour lecture and laboratory course, we will explore the origins, structure, contents, and evolution of our solar system and exosolar planetary systems. We will cover the history of astronomy, properties of light, instruments, the study of the solar system and nearby stars.
Throughout the course, we will learn about the Discovery Channel Telescope, the Lowell Observatory, the Challenger Space Center, and Meteor Crater, the world’s best-preserved meteorite impact site on Earth. We will also get a chance to virtually walk through the Lunar Exploration Museum and Arizona State University’s Moeur Building, home of the Mars Space Flight Facility where ASU scientists and researchers are using spacecraft instruments on Mars to explore the geology and mineralogy of the red planet.
This course satisfies the Natural Science — Quantitative (SQ) general studies requirement at Arizona State University. Introduction to Astronomy may satisfy a general education requirement at other institutions; however, it is strongly encouraged that you consult with your institution of choice to determine how these credits will be applied to their degree requirements prior to transferring the credit.



          Click to view the complete course syllabus here.",Introduction to Solar Systems Astronomy
https://www.classcentral.com/course/edx-cs50-s-understanding-technology-10142,"This is CS50's introduction to technology for students who don’t (yet) consider themselves computer persons. Designed for those who work with technology every day but don’t necessarily understand how it all works underneath the hood or how to solve problems when something goes wrong, this course fills in the gaps, empowering you to use and troubleshoot technology more effectively. Through lectures on hardware, the Internet, multimedia, security, programming, and web development, this course equips you for today’s technology and prepares you for tomorrow’s as well.",CS50's Understanding Technology
https://www.classcentral.com/course/mindware-8128,"Most professions these days require more than general intelligence. They require in addition the ability to collect, analyze and think about data. Personal life is enriched when these same skills are applied to problems in everyday life involving judgment and choice. This course presents basic concepts from statistics, probability, scientific methodology, cognitive psychology and cost-benefit theory and shows how they can be applied to everything from picking one product over another to critiquing media accounts of scientific research. Concepts are defined briefly and breezily and then applied to many examples drawn from business, the media and everyday life.

What kinds of things will you learn? Why it’s usually a mistake to interview people for a job. Why it’s highly unlikely that, if your first meal in a new restaurant is excellent, you will find the next meal to be as good. Why economists regularly walk out of movies and leave restaurant food uneaten. Why getting your picture on the cover of Sports Illustrated usually means your next season is going to be a disappointment. Why you might not have a disease even though you’ve tested positive for it. Why you’re never going to know how coffee affects you unless you conduct an experiment in which you flip a coin to determine whether you will have coffee on a given day. Why it might be a mistake to use an office in a building you own as opposed to having your office in someone else’s building. Why you should never keep a stock that’s going down in hopes that it will go back up and prevent you from losing any of your initial investment. Why it is that a great deal of health information presented in the media is misinformation.
      


            Read more
          



          Introduction
    -Individuals and cultures can make themselves smarter. Since the beginning of the Industrial Revolution, people have become enormously smarter. The Information Age requires a brand-new set of skills involving statistics, probability, cost-benefit analysis, principles of cognitive psychology, logic and dialectical reasoning.

Lesson 1: Statistics
    -Basic concepts of statistics and probability including the concepts of variable, normal distribution, standard deviation, correlation, reliability, validity, and effect size. Concrete examples are drawn from everyday life and show how the concepts can be used to solve ordinary problems.

Lesson 2: The Law of Large Numbers
    -How to think about events in such a way that they can be counted and a decision can be made about how much data is enough. You will learn about the concept of error variance and how it can be combatted by obtaining multiple observations. Your will learn that your judgments about people’s personalities are prone to serious errors that are largely avoided for judgments about abilities. And you will discover why it’s usually a mistake to interview job applicants. 

Lesson 3: Correlation
    -It can be extremely difficult to make an accurate assessment of how two variables are related to one another; prior beliefs can be more important than data in estimating the strength of a given relationship. You will learn simple tools to estimate degree of association. You will learn about the nature of illusory correlations and how to avoid them. You will learn about the concepts of confounded variable and self-selection error.

Lesson 4: Experiments
    -You will learn that correlations can only rarely provide conclusive evidence about whether one variable exerts a causal influence on another and why experiments provide far better evidence about causality than correlations. You will be shown how to conduct experiments in business settings and experiments on yourself. You will learn the distinction between within subject designs and between subject designs. You will learn about the concept of artifacts and some tricks for avoiding them. You will learn how to discover natural experiments.

Lesson 5: Prediction
    -You will learn about the kinds of systematic errors we make when trying to predict the future. You will learn about regression to the mean and why you should assume that extreme values on a variable will be less extreme when next observed. You will learn how to think about observations in terms of true score plus error. You will learn about the concept of base rate and why it must be taken into account when estimating probabilities of specific events.

Lesson 6: Cognitive Biases
    -We understand the world not through direct perception but through inferential procedures that we are unaware of. Our understanding of the world is heavily influenced by schemas or abstract representations of events. We are prone to serious judgment errors that can be avoided to a degree when we understand their basis. We make guesses about probability and causality by applying the representativeness heuristic based on similarity assessments which can be very misleading. We make judgments about frequency and probability by relying in part on the availability heuristic, judging things as frequent or probable to the degree that instances come readily to mind.

Lesson 7: Choosing and Deciding
    -How to conduct a cost-benefit analysis. Why you should throw the analysis away after doing it if the decision is personal and very important. How to avoid throwing good money after bad. How to avoid doing something that will prevent you from doing something more valuable. Why it can be expensive to try to avoid the possibility of loss. Why incentives can backfire.

Lesson 8: Logic and Dialectical Reasoning
    -The distinction between inductive logic and deductive logic. Syllogisms. Conditional reasoning. The distinction between truth of an argument and validity of an argument. The concepts of necessity and sufficiency. Venn diagrams. Common logical errors. When to avoid contradiction and when to embrace it, how to avoid undue certainty about judgments and decisions, and why attention to context rather than form is crucial for analysis of most real-world problems.

Conclusion",Mindware: Critical Thinking for the Information Age
https://www.classcentral.com/course/edx-explore-statistics-with-r-1836,"Do you want to learn how to harvest health science data from the Internet? Or learn to understand the world through data analysis? Start by learning R Statistics!
Skilled professionals who can process and analyze data are in great demand today. In this course you will explore concepts in statistics to make sense out of data. You will learn the practical skills necessary to find, import, analyze and visualize data. We will take a look under the hood of statistics and equip you with broad tools for understanding statistical inference and statistical methods. You will also perform some really complicated calculations and visualizations, following in the footsteps of Karolinska Institute’s researchers.
Statistical programming is an essential skill in our golden age of data abundance. Health science has become a field of big data, just like so many other fields of study. New techniques make it possible and affordable to generate massive data sets in biology. Researchers and clinicians can measure the activity for each of 30000 genes of a patient. They can read the complete genome sequence of a patient. Thanks to another trend of the decade, open access publishing, the results of such large scale health science are very often published for you to read free of charge. You can even access the raw data from open databases such as the gene expression database of the NCBI, National Center for Biotechnology Information.
We will dive into this data together. Learn how to use R, a powerful open source statistical programming language, and see why it has become the tool of choice in many industries in this introductory R statistics course. 



            Read more",Explore Statistics with R
https://www.classcentral.com/course/business-intelligence-data-warehousing-12421,"Welcome to the specialization course Business Intelligence and Data Warehousing. This course will be completed on six weeks, it will be supported with videos and various documents that will allow you to learn in a very simple way how to identify, design and develop analytical information systems, such as Business Intelligence with a descriptive analysis on data warehouses. You will be able to understand the problem of integration and predictive analysis of high volume of unstructured data (big data) with data mining and the Hadoop framework.

After completing this course, a learner will be able to
●	Create a Star o Snowflake data model Diagram through the Multidimensional Design from analytical business requirements and OLTP system
●	Create a physical database system 
●	Extract, Transform and load data to a data-warehouse.
●	Program analytical queries with SQL using MySQL
●	Predictive analysis with RapidMiner
●	Load relational or unstructured data to Hortonworks HDFS
●	Execute Map-Reduce jobs to query data on HDFS for analytical purposes


Programming languages:
For course 2 you will use the MYSQL language.

Software to download:
Rapidminer
MYSQL
Excel
Hortonworks Hadoop framework

In case you have a Mac / IOS operating system you will need to use a virtual Machine (VirtualBox, Vmware).
      


          Introduction to Business Intelligence as Analytical System
    -In the first module named Introduction to Business Intelligence as Analytical System, we will learn how the steps of the process of datawarehousing to automate analytical processes that companies need for their business strategies. Let's start!

Designing a Data Warehouse
    -After completing this module, a learner will be able to identify the entire process of datawarehousing, which consist on OLAP design concepts and multidimensional modelling. The learner will be able to design and create a data warehouse from OLAP requirements.

The ETL process and Analytical queries with SQL
    -After completing this module, a learner will differentiate from structured and unstructured data and will be able to extract, transform and load data into a datawarehouse. The student will also be able to program and execute OLAP queries with SQL.

 Predictive Analytics with Data mining
    -After completing this module, a learner will identify the main data mining tasks and some algorithms for classification, regression and clustering  for predictive and descriptive analysis on business intelligence. 

The problem of integration and analysis of unstructured data 
    -After completing this module, a learner will learn the types of data according to structure and how to integrate, store and analyze unstructured data.

Big Data and Hadoop Framework
    -After completing this module, a learner will understand the problem of big data, a possible solution to the analysis of big data with the Hadoop ecosystem and under which conditions should be apply each element of this ecosystem.",Business intelligence and data warehousing
https://www.classcentral.com/course/complexity-explorer-algorithmic-information-dynamics-from-networks-to-cells-3611,"This course provides a conceptual introduction to the new and exciting field of Algorithmic Information Dynamics focusing on mathematical and computational aspects in the study of causality. To this end, the course first covers key aspects from graph theory and network science, information theory, dynamical systems and algorithmic complexity in a tour the force to finally tackle causation from a model-driven approach removed from traditional statistics and classical probability theory. The course will venture into ongoing research to show exciting new avenues to uncharted territory.
It is desirable that students have some idea of basic mathematics but optional modules will be provided in a parallel track. Also desirable is some computer programming skills, but also some basics of the Wolfram Language and a 6-month access to Wolfram|One (Mathematica) will be granted (extendable by other 6 months). However, the course does not require you to adopt any particular programming language nor it requires one.
Because of its nature, the course is aimed to a wide range of possible students who have had some basic knowledge of college-level math or physics to active researchers seeking to take advantage of new tools for algorithmic data science beyond traditional machine learning.
After a conceptual overview of the main motivation and some historical developments, we review some preliminary aspects needed to understand the most advanced topics. These include basic concepts of statistics and probability, notions of computability and algorithmic complexity and brief introductions to graph theory and dynamical systems. We then dig deeper into the core of the course, that of Algorithmic Information Dynamics which brings all these areas together in harmony to serve in the challenge of causality discovery, the most important topic in science. Central to the course and the field is the theory of algorithmic probability that establishes a formal bridge between computation, complexity and probability.
Finally, we move towards new measures and tools related to reprogramming artificial and biological systems, applications to biological evolution, evolutionary programming, phase space and space-time reconstruction, epigenetic landscapes and aspects relevant to data analytics and machine learning such as model generation, feature selection, dimensionality reduction and causal deconvolution. We will showcase the tools and framework in applications to systems biology, genetic networks and cognition by way of behavioural sequences. Because of the wide scope of application students will be able apply the tools to their own data and own problems as we will be explaining how to do it in detail, and we will be providing all the tools and code for it.
Throughout the course, students will be given assignments that will go from the conceptual to the mathematical and computational intended to keep everybody engaged.
About the Instructor(s):Hector Zenil has a PhD in Computer Science from the University of Lille 1 and a PhD in Philosophy and Epistemology from the Pantheon-Sorbonne, University of Paris. He co-leads the Algorithmic Dynamics Lab at the Science for Life Laboratory (SciLifeLab), Unit of Computational Medicine, Center for Molecular Medicine at the Karolinska Institute in Stockholm, Sweden. He is also the head of the Algorithmic Nature Group, the Paris-based lab that started the Online Algorithmic Complexity Calculator and the Human Randomness Perception and Generation Project. Previously, he was a Research Associate at the Behavioural and Evolutionary Theory Lab at the Department of Computer Science at the University of Sheffield in the UK before joining the Department of Computer Science, University of Oxford as a faculty member and senior researcher.
Narsis Kiani has a PhD in Mathematics and has been a postdoctoral researcher at Dresden University of Technology and at the University of Heidelberg in Germany. She has been a VINNOVA Marie Curie Fellow in Sweden and co-leads the Algorithmic Dynamics Lab at the Science for Life Laboratory (SciLifeLab), Unit of Computational Medicine, Center for Molecular Medicine at the Karolinska Institute in Stockholm, Sweden.
Hector and Narsis are co-leaders of the Algorithmic Dynamics Lab at the Unit of Computational Medicine at Karolinska Institute.
Course Team:Antonio Rueda-Toicen has an MSc degree in Bioengineering and a Licentiate degree in Computer Science. He is an instructor and researcher at Instituto Nacional de Bioingeniería (INABIO) at Universidad Central de Venezuela and is a Research Programmer at the Algorithmic Dynamics Lab.



            Read more
          




A Computational Approach to Causality
Technical Skills and Selected Topics
A Brief Introduction to Graph Theory and Biological Networks
Basics of Computability, Information Theory and Algorithmic Complexity
Dynamical Systems as Models of the World
Algorithmic Information Dynamics
Applications to Behavioural, Evolutionary and Molecular Biology",Algorithmic Information Dynamics: From Networks to Cells
https://www.classcentral.com/course/edx-introduction-to-statistics-descriptive-statistics-614,"We are surrounded by information, much of it numerical, and it is important to know how to make sense of it. Stat2x is an introduction to the fundamental concepts and methods of statistics, the science of drawing conclusions from data.
The course is the online equivalent of Statistics 2, a 15-week introductory course taken in Berkeley by about 1,000 students each year. Stat2x is divided into three 5-week components. Stat2.1x is the first of the three.
The focus of Stat2.1x is on descriptive statistics. The goal of descriptive statistics is to summarize and present numerical information in a manner that is illuminating and useful. The course will cover graphical as well as numerical summaries of data, starting with a single variable and progressing to the relation between two variables. Methods will be illustrated with data from a variety of areas in the sciences and humanities.
There will be no mindless memorization of formulas and methods. Throughout Stat2.1x, the emphasis will be on understanding the reasoning behind the calculations, the assumptions under which they are valid, and the correct interpretation of results.
FAQ

What is the format of the class? 
Instruction will be consist of brief lectures and exercises to check comprehension. Grades (Pass or Not Pass) will be decided based on a combination of scores on short assignments, quizzes, and a final exam.


How much does it cost to take the course? 
Nothing! The course is free.


Will the text of the lectures be available? 
Yes. All of our lectures will have transcripts synced to the videos.


Do I need to watch the lectures live? 
No. You can watch the lectures at your leisure.


Can I contact the Instructor or Teaching Assistants? 
Yes, but not directly. The discussion forums are the appropriate venue for questions about the course. The instructors will monitor the discussion forums and try to respond to the most important questions; in many cases response from other students and peers will be adequate and faster.


Do I need any other materials to take the course? 
If you have any questions about edX generally, please see the edX FAQ.






            Read more",Introduction to Statistics: Descriptive Statistics
https://www.classcentral.com/course/complexity-explorer-algorithmic-information-dynamics-from-networks-to-cells-3611,"This course provides a conceptual introduction to the new and exciting field of Algorithmic Information Dynamics focusing on mathematical and computational aspects in the study of causality. To this end, the course first covers key aspects from graph theory and network science, information theory, dynamical systems and algorithmic complexity in a tour the force to finally tackle causation from a model-driven approach removed from traditional statistics and classical probability theory. The course will venture into ongoing research to show exciting new avenues to uncharted territory.
It is desirable that students have some idea of basic mathematics but optional modules will be provided in a parallel track. Also desirable is some computer programming skills, but also some basics of the Wolfram Language and a 6-month access to Wolfram|One (Mathematica) will be granted (extendable by other 6 months). However, the course does not require you to adopt any particular programming language nor it requires one.
Because of its nature, the course is aimed to a wide range of possible students who have had some basic knowledge of college-level math or physics to active researchers seeking to take advantage of new tools for algorithmic data science beyond traditional machine learning.
After a conceptual overview of the main motivation and some historical developments, we review some preliminary aspects needed to understand the most advanced topics. These include basic concepts of statistics and probability, notions of computability and algorithmic complexity and brief introductions to graph theory and dynamical systems. We then dig deeper into the core of the course, that of Algorithmic Information Dynamics which brings all these areas together in harmony to serve in the challenge of causality discovery, the most important topic in science. Central to the course and the field is the theory of algorithmic probability that establishes a formal bridge between computation, complexity and probability.
Finally, we move towards new measures and tools related to reprogramming artificial and biological systems, applications to biological evolution, evolutionary programming, phase space and space-time reconstruction, epigenetic landscapes and aspects relevant to data analytics and machine learning such as model generation, feature selection, dimensionality reduction and causal deconvolution. We will showcase the tools and framework in applications to systems biology, genetic networks and cognition by way of behavioural sequences. Because of the wide scope of application students will be able apply the tools to their own data and own problems as we will be explaining how to do it in detail, and we will be providing all the tools and code for it.
Throughout the course, students will be given assignments that will go from the conceptual to the mathematical and computational intended to keep everybody engaged.
About the Instructor(s):Hector Zenil has a PhD in Computer Science from the University of Lille 1 and a PhD in Philosophy and Epistemology from the Pantheon-Sorbonne, University of Paris. He co-leads the Algorithmic Dynamics Lab at the Science for Life Laboratory (SciLifeLab), Unit of Computational Medicine, Center for Molecular Medicine at the Karolinska Institute in Stockholm, Sweden. He is also the head of the Algorithmic Nature Group, the Paris-based lab that started the Online Algorithmic Complexity Calculator and the Human Randomness Perception and Generation Project. Previously, he was a Research Associate at the Behavioural and Evolutionary Theory Lab at the Department of Computer Science at the University of Sheffield in the UK before joining the Department of Computer Science, University of Oxford as a faculty member and senior researcher.
Narsis Kiani has a PhD in Mathematics and has been a postdoctoral researcher at Dresden University of Technology and at the University of Heidelberg in Germany. She has been a VINNOVA Marie Curie Fellow in Sweden and co-leads the Algorithmic Dynamics Lab at the Science for Life Laboratory (SciLifeLab), Unit of Computational Medicine, Center for Molecular Medicine at the Karolinska Institute in Stockholm, Sweden.
Hector and Narsis are co-leaders of the Algorithmic Dynamics Lab at the Unit of Computational Medicine at Karolinska Institute.
Course Team:Antonio Rueda-Toicen has an MSc degree in Bioengineering and a Licentiate degree in Computer Science. He is an instructor and researcher at Instituto Nacional de Bioingeniería (INABIO) at Universidad Central de Venezuela and is a Research Programmer at the Algorithmic Dynamics Lab.



            Read more
          




A Computational Approach to Causality
Technical Skills and Selected Topics
A Brief Introduction to Graph Theory and Biological Networks
Basics of Computability, Information Theory and Algorithmic Complexity
Dynamical Systems as Models of the World
Algorithmic Information Dynamics
Applications to Behavioural, Evolutionary and Molecular Biology",Algorithmic Information Dynamics: From Networks to Cells
https://www.classcentral.com/course/quality-of-healthcare-12800,"In this course, you will have the opportunity to learn about the great progress that has been made in measuring and evaluating quality of care.  We will discuss key concepts and methods.  You will also learn about how to use websites for comparing the quality of healthcare providers.  The course content is intended for a wide range of participants – for example, people who have a general interest in quality of care, consumers seeking information about how to choose a provider for themselves or family members, or leaders of business organizations who are responsible for employee health insurance benefits and network of providers.

By the end of this course, the learner should be able to: 

1. Explain key developments regarding how quality of care is measured and evaluated in the US.
2. Articulate basic framework for evaluating quality of outcomes of care including types of and criteria for selecting quality measures for evaluating and comparing providers. 
3. Discuss scientific issues and challenges for evaluating quality of care and methods for addressing these challenges.   
4. Identify and apply resources and tools for comparing the quality of care of providers.
      


          Foundational Concepts for Evaluating Quality
    -We will begin by briefly discussing key developments in the U.S. and elsewhere underlying changing 
perspectives toward the way quality of care is defined and evaluated.  We will then outline and discuss a basic conceptual framework for selecting measures for evaluating the quality of care by hospitals and physicians.  This discussion will draw attention to key distinctions between process and outcome measures and their relative advantages and disadvantages for evaluating quality of care.   This module will also include examples of quality measures that are currently in use.    

Scientific Issues and Challenges for Comparing Quality of Care Among Providers
    -We will discuss key challenges in making valid comparisons among healthcare providers in terms of their quality of care including case mix differences, small sample sizes and data integrity issues.  We will discuss methods and techniques for addressing such challenges.   We will show how these methods and techniques can be applied in practice to produce more useful quality of care evaluations.   

Resources and Tools for Evaluating Quality
    -We will cover consumer report cards and value-based purchasing programs, both of which constitute 
important applications of the science of measuring and evaluating quality of care.  Consumer report 
cards on quality of care frequently exist within publicly available websites. These websites provide 
consumers and other interested parties with quality-related information for comparing the performance of hospitals and physicians. Such resources and tools have been produced by government agencies, private health plans, and business organizations.  We will look at several examples of these resources and tools and consider their value as well as their limitations.     

Future Directions in Evaluating Quality of Care
    -We will discuss emerging developments pertaining to the science and practice of evaluating quality of 
care.  This discussion will include the increased interest in value-oriented measures of provider performance (i.e., efficiency as well as quality) and in composite measures.  Also, we will consider the debate over whether quality measures should be adjusted to account for differences among providers 
regarding the socio-economic characteristics of their patients and how such adjustments could be 
conducted.",Evaluating the Quality of Healthcare Delivery
https://www.classcentral.com/course/understanding-visualization-data-12647,"In this course, learners will be introduced to the field of statistics, including where data come from, study design, data management, and exploring and visualizing data. Learners will identify different types of data, and learn how to visualize, analyze, and interpret summaries for both univariate and multivariate data. Learners will also be introduced to the differences between probability and non-probability sampling from larger populations, the idea of how sample estimates vary, and how inferences can be made about larger populations based on probability sampling.

At the end of each week, learners will apply the statistical concepts they’ve learned using Python within the course environment. During these lab-based sessions, learners will discover the different uses of Python as a tool, including the Numpy, Pandas, Statsmodels, Matplotlib, and Seaborn libraries. Tutorial videos are provided to walk learners through the creation of visualizations and data management, all within Python. This course utilizes the Jupyter Notebook environment within Coursera.
      


          WEEK 1 - INTRODUCTION TO DATA
    -In the first week of the course, we will review a course outline and discover the various concepts and objectives to be mastered in the weeks to come. You will get an introduction to the field of statistics and explore a variety of perspectives the field has to offer. We will identify numerous types of data that exist and observe where they can be found in everyday life. You will delve into basic Python functionality, along with an introduction to Jupyter Notebook. All of the course information on grading, prerequisites, and expectations are on the course syllabus and you can find more information on our Course Resources page.

WEEK 2 - UNIVARIATE DATA
    -In the second week of this course, we will be looking at graphical and numerical interpretations for one variable (univariate data). In particular, we will be creating and analyzing histograms, box plots, and numerical summaries of our data in order to give a basis of analysis for quantitative data and bar charts and pie charts for categorical data. A few key interpretations will be made about our numerical summaries such as mean, IQR, and standard deviation. An assessment is included at the end of the week concerning numerical summaries and interpretations of these summaries.

WEEK 3 - MULTIVARIATE DATA
    -In the third week of this course on looking at data, we’ll introduce key ideas for examining research questions that require looking at more than one variable.  In particular, we will consider both numerically and visually how different variables interact, how summaries can appear deceiving if you don’t properly account for interactions, and differences between quantitative and categorical variables.  This week’s assignment will consist of a writing assignment along with reviewing those of your peers.

WEEK 4 - POPULATIONS AND SAMPLES
    -In this week, you’ll spend more time thinking about where data come from. The highest-quality statistical analyses of data will always incorporate information about the process used to generate the data, or features of the data collection design. You’ll be exposed to important concepts related to sampling from larger populations, including probability and non-probability sampling, and how we can make inferences about larger populations based on well-designed samples. You’ll also learn about the concept of a sampling distribution, and how estimation of the variance of that distribution plays a critical role in making statements about populations. Finally, you’ll learn about the importance of reading the documentation for a given data set; a key step in looking at data is also looking at the available documentation for that data set, which describes how the data were generated.",Understanding and Visualizing Data with Python
https://www.classcentral.com/course/edx-introduction-to-statistics-descriptive-statistics-614,"We are surrounded by information, much of it numerical, and it is important to know how to make sense of it. Stat2x is an introduction to the fundamental concepts and methods of statistics, the science of drawing conclusions from data.
The course is the online equivalent of Statistics 2, a 15-week introductory course taken in Berkeley by about 1,000 students each year. Stat2x is divided into three 5-week components. Stat2.1x is the first of the three.
The focus of Stat2.1x is on descriptive statistics. The goal of descriptive statistics is to summarize and present numerical information in a manner that is illuminating and useful. The course will cover graphical as well as numerical summaries of data, starting with a single variable and progressing to the relation between two variables. Methods will be illustrated with data from a variety of areas in the sciences and humanities.
There will be no mindless memorization of formulas and methods. Throughout Stat2.1x, the emphasis will be on understanding the reasoning behind the calculations, the assumptions under which they are valid, and the correct interpretation of results.
FAQ

What is the format of the class? 
Instruction will be consist of brief lectures and exercises to check comprehension. Grades (Pass or Not Pass) will be decided based on a combination of scores on short assignments, quizzes, and a final exam.


How much does it cost to take the course? 
Nothing! The course is free.


Will the text of the lectures be available? 
Yes. All of our lectures will have transcripts synced to the videos.


Do I need to watch the lectures live? 
No. You can watch the lectures at your leisure.


Can I contact the Instructor or Teaching Assistants? 
Yes, but not directly. The discussion forums are the appropriate venue for questions about the course. The instructors will monitor the discussion forums and try to respond to the most important questions; in many cases response from other students and peers will be adequate and faster.


Do I need any other materials to take the course? 
If you have any questions about edX generally, please see the edX FAQ.






            Read more",Introduction to Statistics: Descriptive Statistics
https://www.classcentral.com/course/healthcare-and-society-11947,"In contemporary societies healthcare is a key social institute that addresses the issues of maintenance and improvement of citizens’ health. While population health is largely produced outside of healthcare settings themselves, the functioning of healthcare, including diagnosis, treatment, and prevention of illness, injury, and other impairments, is essential for people’s wellbeing. Yet, healthcare can be and often is insufficiently accessible, responsive, and efficient for different members of society. How can healthcare provision and society be bridged?
Through the exploration of a combination of theoretical and practical perspectives, this online course highlights the necessity of a dialogue and collaboration between healthcare professionals, patients, and the public at large. Course participants will critically explore challenges posed by disjunctures between healthcare and society, analyze both benefits and unintended consequences of bridging the two, and propose ways to accomplish the bridging in practice of healthcare provision.

After completion of this course you will be able to:

1.	Recognize disjunctures between healthcare provision and society
2.	Be aware of consequences of disjunctures between healthcare provision and society
3.	Identify opportunities for bridging healthcare provision and society, using a biosocial approach to health
4.	Analyze cases of disjunctures between healthcare provision and society, and propose opportunities for bridging
5.	Recognize the historical trends of scientification, professionalization, and medicalization, in the relations between medicine, health care, and society.

This course was developed by a consortium of five universities: Maastricht University, National Research Tomsk State University, National University of ""Kyiv-Mohyla Academy"",  National Pirogov Memorial Medical University, Vinnytsya, and Siberian State Medical University within the framework of BIHSENA project. BIHSENA stands for “Bridging Innovations, Health and Societies: Educational capacity building in the Eastern European Neighbouring Areas”. BIHSENA project has been funded with support from the European Commission. This course reflects the views only of the authors, and the Commission cannot be held responsible for any use which may be made of the information contained therein.
      


            Read more
          



          Introduction to the course “Bridging health care and society”

Module 1. Why bridging?
    -During the last two centuries modern medicine has gained the role of being a key social institution. Advances in science have enriched medical practice with evidence of the causes and consequences of different diseases and have provided algorithms for effective forms of treatment. Health care has evolved and made impressive gains in protecting the wellbeing of individuals and society.
However, there is a number of problems that contemporary healthcare faces. Divergent priorities, understandings, and preferences between patients and healthcare practitioners can result in ineffective treatment, or worse, in health impairments. Lack of responsiveness by healthcare systems to everyday life and the needs of individuals they serve can result in an unequal access to health services by some population groups. These problems are the results of disjunctions between healthcare and patients, and in a broader scope, between medicine and society. This module highlights the importance of understanding such disjunctions and analyzing their roots and consequences. Learners will take a journey through the history of modern medicine and healthcare to explore how they have acquired their prominent characteristics of scientification and professionalization, expressed in a tendency of reducing a disease to a biological phenomenon while often not recognizing the personalities of patients and their cultures, beliefs and environments. During this module, we will focus on the reasons why these characteristics of patients and population groups are important for health provision and public health practices. 


Module 2. Bridging healthcare professionals and patients
    -Social roles of doctor and patient, as well as relations between them, are dramatically changing in contemporary societies in the context of rapid technological shifts and scientific advancements, the commercialization of medicine, and the introduction of the idea of wider public engagement in healthcare provision. During the second module of the course we will delve into these complexities in order to understand the perspectives of medical professionals and their patients, discrepancies between their mutual expectations, and ways through which trustful cooperation can be built. We will consider the key social science approaches to understanding doctors’ professional role and construction of authority. We will also investigate challenges to this authority that emerge in the context of contemporary transformations of medical institution. Particular attention will be paid to issues of patient choice and control in healthcare, and strategies through which patients approach medical services and establish trust in relations with healthcare professionals. Module 2 aims to delineate disjunctures between healthcare professionals and patients, and to offer possible ways to bridge perspectives of these two groups.

Module 3. Bridging healthcare services and population groups
    -Healthcare systems are established in many countries to ensure that individuals are able to obtain health services when illness strikes and that they have access to effective interventions to prevent or reduce risk of disease and disability. Yet, often we observe a disjuncture between healthcare and the population groups it is meant to serve, which results in problems with access to health care even where the necessary services are seemingly in place. 
Module 3 examines various kinds of barriers between population groups, their health, and healthcare and suggests ways to bridge the divide through linking social analysis with healthcare services provision for development of services adapted to the people’s needs, lifestyles, and circumstances.



Module 4. Bridging public health and public
    -The notion of public health appears to be intrinsically connected to the public domain. Yet, it appears that with increasing scientification and professionalization of public health over the course of past decades a gap between public health and public has been widening, rather than the other way around. During the last module of this course we will explore the reasons for these developments. Over the course of these last decades, public health has, firstly, expanded considerably, now covering ‘everything from eating, drinking and exercise to sleep, sex and work and addressing lifestyle from before conception right into extreme old age’, in the words of Klasien Horstman. Secondly, public health is increasingly invested in scientifically-based prevention, assuming that evidence-based interventions will turn risk behavior into healthy behavior and framing public health problems, largely, as technical problems which have to be solved through scientific expertise. This module traces the evolution of public health approaches and the rise of contemporary disjunctures between these approaches and the public they target. We see that in daily life people have their own ideas of risk and safety, have to deal with multiple other issues (such as supporting their families and adhering to their notions of the leading a good life), and operate within their unique contexts at specific rhythms. Consequently, the public often does not respond to public health interventions as expected. This module explores ways to bring the public back into public health and bridge the disjunctures demonstrated.",Bridging healthcare and society
https://www.classcentral.com/course/edx-data-analysis-for-social-scientists-6842,"This course is now part of two independent MITx MicroMasters programs. For both MicroMasters programs, learners will need to first enroll in and pass this course. However, each program will then require different final assessments for a course certificate toward the full MicroMasters credential:

1.MicroMasters in Data, Economics, and Development Policy (DEDP).
To pursue the DEDP MicroMasters credential, pass this course, create aMicroMasters in DEDP profile, and pass an additional in-person proctored exam.
To learn more about the DEDP program and how it integrates with MIT’s new blended Master’s degree, please visithttps://micromasters.mit.edu/dedp/.
2.MicroMasters in Statistics and Data Science (SDS).
To pursue the SDS MicoMasters credential, pass this course, and enroll in and pass the final assessment at14.310Fx Data Analysis in Social Sciences-Assessment on EdX.
Complete all 4 courses and the capstone exam in the SDS program to accelerate your path towards graduate studies at MIT or other universities. To learn more, please visithttps://micromasters.mit.edu/ds.
This statistics and data analysis course will introduce you to the essential notions of probability and statistics. We will cover techniques in modern data analysis: estimation, regression and econometrics, prediction, experimental design, randomized control trials (and A/B testing), machine learning, and data visualization. We will illustrate these concepts with applications drawn from real world examples and frontier research. Finally, we will provide instruction for how to use the statistical package R and opportunities for students to perform self-directed empirical analyses.
This course is designed for anyone who wants to learn how to work with data and communicate data-driven findings effectively.
Course Previews:
Our course previews are meant to give prospective learners the opportunity to get a taste of the content and exercises that will be covered in each course. If you are new to these subjects, or eager to refresh your memory, each course preview also includes some available resources. These resources may also be useful to refer to over the course of the semester.
A score of 60% or above in the course previews indicates that you are ready to take the course, while a score below 60% indicates that you should further review the concepts covered before beginning the course.
Please use the this link to access the course preview.



            Read more
          



14.310x – Data Analysis for Social Scientists
Week One: Introduction
Week Two: Fundamentals of Probability, Random Variables, Joint Distributions and Collecting Data
Week Three: Describing Data, Joint and Conditional Distributions of Random Variables
Week Four: Functions and Moments of a Random Variables & Intro to Regressions
Week Five: Special Distributions, the Sample Mean, the Central Limit Theorem
Week Six: Assessing and Deriving Estimators - Confidence Intervals, and Hypothesis Testing
Week Seven: Causality, Analyzing Randomized Experiments, & Nonparametric Regression
Week Eight: Single and Multivariate Linear Models
Week Nine: Practical Issues in Running Regressions, and Omitted Variable Bias
Week Ten: Endogeneity, Instrumental Variables, and Experimental Design 
Week Eleven: Intro to Machine Learning and Data Visualization
Optional: Writing an Empirical Paper",Data Analysis for Social Scientists
https://www.classcentral.com/course/edx-cs190-1x-scalable-machine-learning-2965,"Machine learning aims to extract knowledge from data, relying on fundamental concepts in computer science, statistics, probability and optimization. Learning algorithms enable a wide range of applications, from everyday tasks such as product recommendations and spam filtering to bleeding edge applications like self-driving cars and personalized medicine. In the age of ‘Big Data,’ with datasets rapidly growing in size and complexity and cloud computing becoming more pervasive, machine learning techniques are fast becoming a core component of large-scale data processing pipelines.
 
This course introduces the underlying statistical and algorithmic principles required to develop scalable real-world machine learning pipelines. We present an integrated view of data processing by highlighting the various components of these pipelines, including exploratory data analysis, feature extraction, supervised learning, and model evaluation. You will gain hands-on experience applying these principles using Apache Spark, a cluster computing system well-suited for large-scale machine learning tasks. You will implement scalable algorithms for fundamental statistical models (linear regression, logistic regression, matrix factorization, principal component analysis) while tackling key problems from domains such as online advertising and cognitive neuroscience.
 
This self-assessment document provides a short quiz, as well as online resources that review the relevant background material. 
      


            Read more",CS190.1x: Scalable Machine Learning
https://www.classcentral.com/course/edx-cs50-s-mobile-app-development-with-react-native-11505,"Please note that registration closes on 30 November 2019 and all assignments must be completed by 30 June 2020.
This course picks up where CS50 leaves off, transitioning from web development to mobile app development with React Native. 
The course introduces you to modern JavaScript (including ES6 and ES7) as well as to JSX, a JavaScript extension. Through hands-on projects, you'll gain experience with React and its paradigms, app architecture, and user interfaces. The course culminates in a final project for which you'll implement an app entirely of your own design.",CS50's Mobile App Development with React Native
https://www.classcentral.com/course/block-programming-k12-educators-conditio-12349,"Want to make a game that ends when you ""catch"" an object by clicking on it?  Or maybe you get points based on how close you came?  You'll do that in this class!

This class teaches the concepts of conditional loops and if/else statements.  For each concept, we'll start by helping you connect real-world experiences you are already familiar with to the programming concept you are about to learn.  Next, through a cognitively scaffolded process we'll engage you in developing your fluency with problem solving with repeat until loops, while loops, and if/else statements in a way that keeps frustration at a minimum.  

Along the way you will learn about the common challenges or ""bugs"" students have with these concepts as well as ways to help them find and fix those concepts.  You'll also be guided in running classroom discussions to help students develop deeper understanding of these concepts.

Finally, you'll learn how to support interactive learning experiences among your students with Peer Instruction. 
 Additionally, you will create a resource for your classroom to support an equitable classroom.
      


          Course Orientation
    -Meet Dr. Simon and fellow learners in this class!  Find out what you’ll be doing and learning. 

Conditional Loops
    -In this module we will learn about conditional loops and how they vary from fixed loops. We'll examine different examples of both loop types and look at some common challenges that you may come across. Finally you'll create your own conditional loop program and have the opportunity to create an assignment and conduct peer reviews.

More Conditional Loops
    -Now that you've gotten an introduction to conditional loops, we will further explore them and their variations. We will look at why some programs require conditional loops and discuss suggestions that will help students trace each program. Finally we'll learn about a variation on the repeat until loop, called the do-while loop.

If statements
    -In this module we'll get an introduction to conditionals, which are also known as if-else statements. First we'll examine some examples of if-else conditionals that exist in our everyday life. Next you will take a look at videos of completed programs and recreate the code. We'll end with some debugging tips and have you create your own if-else program assignment.

More If statements
    -Now that you have a basic understanding of conditionals, we look at some more complicated cases. You'll watch a video of how a teacher introduces the topic to her class and learn about conditionals with more than 2 scenarios. You'll also look at programs with two independent conditionals and learn how this varies from else-if statements. Finally, you'll analyze some misconceptions and challenges you initially had when learning about conditionals and create resources to help others learn about conditionals.

Equity & Pedagogy
    -In this module we take a look at peer instruction, an interactive teaching method that promotes learning. You will learn how peer instruction works and its benefits through various evidence-based studies. Then you'll determine how it can be applied to a computer science course and examine additional reasons peer instruction is beneficial in teaching computer science in class. You will have the opportunity to apply what you learn when creating a resource and peer reviewing others' work.",Computational Thinking for K-12 Educators: Conditional Loops and If Statements
https://www.classcentral.com/course/wrongfulconviction-2010,"According to
the National Registry of Exonerations, a joint project of Michigan Law and
Northwestern Law, over 1,600 individuals in the United States have been
exonerated after being convicted for crimes they did not commit. These are the
known cases of wrongful conviction—the actual number is much higher. Some of
these individuals have served years, even decades, in prison for these
crimes. Often, real offenders
have escaped justice as a result of the wrong person being accused and convicted. 
As noted, we
will approach this topic from a social scientific perspective. Social science
is a broad field that seeks to understand social interactions between
individuals, groups, and institutions. The field includes academic disciplines
such as sociology, criminology, psychology, economics, anthropology, political
science, and other related disciplines. 
In this
course we will explore wrongful convictions answering several key questions:

What do we mean by
     “wrongfully convicted,” and how common are wrongful convictions?
Who are wrongfully
     convicted?
Where in the
     criminal justice system do things go wrong to lead to wrongful
     convictions?
Why do wrongful
     convictions occur? 
How can social
     science contribute to understanding, and preventing wrongful convictions?

 For-credit option:This course will also be offered for Penn State credit.  This course option will require a heavier workload and offer instructor feedback and assessment on completed work.   More info here
      


            Read more
          



Each week we
will cover two lessons in the course. Each lesson, while related, will be considered independently.
Week One:
Introduction to the Criminal Justice System
Social Science and Public Policy: Due Process and Crime Control
Week Two: 
Wrongful Conviction Defined
Wrongful Conviction Demographics and Statistics
Week Three: 
Wrongful Conviction and the Criminal Justice Process—Where do things go wrong?
Causes of Wrongful Conviction: Eyewitness Misidentification—An Introduction
Week Four: 
Causes of Wrongful Conviction: Eyewitness Misidentification—System Variables
Causes of Wrongful Conviction: Eyewitness Misidentification—Estimator Variables
Week Five: 
Causes of Wrongful Conviction: False Confessions
Causes of Wrongful Conviction: Jailhouse Snitches and Informants
Week Six: 
Causes of Wrongful Conviction: Government Misconduct and Poor Defense
Myths and Misconceptions of Decision-Makers: Judges, Juries, and the Public
Week Seven: 
Using Social Science to Prevent Wrongful Convictions
What can you do?",Presumed Innocent? The Social Science of Wrongful Conviction
https://www.classcentral.com/course/edx-embedded-systems-shape-the-world-microcontroller-input-output-1484,"Learn how electronic gadgets are designed, developed, and built as embedded systems that shape the world.
This is part one of a two part sequence. Together these are hands-on, learn-by-doing courses that show you how to build solutions to real-world problems using embedded systems. In this course, we take a bottom-up approach to problem solving, building gradually from simple interfacing of switches and LEDs to complex concepts like a microcontroller-based pacemaker, digital lock, and a traffic light controller. We will present both general principles and practical tips for building circuits and programming the microcontroller in the C programming language. You will develop debugging skills using oscilloscopes, logic analyzers, and software instrumentation. Laboratory assignments are first performed in simulation, and then you will build and debug your system on the real microcontroller. At the conclusion of this part 1 you will possess the knowledge to build your own traffic light controller from the ground up.
This is the fourth time we have offered this course. Since the reviews have been overwhelmingly positive we do not plan major changes over the previous offerings of the course. We did however break the large class into two smaller classes. There are eight labs in part 1 and six labs in part 2. Students can pick and choose a subset of labs to achieve certification. The three labs that students found most rewarding in this part were designing the software algorithm for a demand pacemaker, interfacing switches and LEDS, and the finite state machine traffic light controller.
To complete this course, you will be required to purchase a Texas Instruments TM4C123 microcontroller kit and a few electronic components.
This microcontroller has a state-of-the-art ARM Cortex-M4 processor.
We will provide instructions about purchasing the kit and installing required software at: http://edx-org-utaustinx.s3.amazonaws.com/UT601x/index.html.



            Read more
          



The best way to understand what you will learn in this class is to list the labs you will complete and the example projects we will build. You will complete each lab first in simulation and then on the real board. For each module we will design a system and you will build and test a similar system.
Module 1: Welcome and introduction to course and staff 
Module 2: Fundamental concepts: numbers, computers, and the ARM Cortex M processor 
Lab 2. Run existing project on LaunchPad with switch input and LED output
Module 3: Electronics: resistors, voltage, current and Ohm’s Law 
Module 4: Digital Logic: transistors, flip flops and logic functions 
Lab 4. Debug a system with two inputs and two outputs
Module 5: Introduction to C programming 
Lab 5. Write a C function and perform input/output
Module 6: Microcontroller Input/Output 
Lab 6. Write C software that inputs from a switch and toggles an LED output
Module 7: Design and Development Process 
Lab 7. Write C functions that inputs from a switch and outputs to two LEDs, which is a virtual pacemaker
Module 8: Interfacing Switches and LEDs 
Lab 8. Interface an external switch and LED and write input/output software
Module 9: Arrays and Functional Debugging 
Lab 9. Write C functions using array data structures that collect/debug your system
Module 10: Finite State Machines 
Lab 10. Interface 3 switches and 6 LEDs and create a traffic light finite state machine",Embedded Systems - Shape The World: Microcontroller Input/Output
https://www.classcentral.com/course/supply-chain-analytics-16713,"Welcome to Supply Chain Analytics - the art and science of applying data analytics to assess and improve supply chain performance!

A supply chain is a complex system with conflicting objectives of cost efficiency and customer satisfaction. Supply chain management is becoming increasingly data driven. Through the real-life story and data of a major US telecommunication company, you will learn the analytics tools / skills to diagnose and optimize a supply chain. Upon completion of this course, you will be able to

1. Use data analytics to assess the impact of various strategies on all aspects of a supply chain, from inventory, shipping, to warehouse order fulfillment, store operations and customer satisfaction. 
2. Customize the supply chain strategy by product to improve the overall cost efficiency without sacrificing customer service. 
3. Obtain hands-on experience on the application and financial impact of analytics in integrated supply chain and logistics planning.

VASTA (name disguised) is a major wireless carrier in the US selling cell phones through a national network of retail stores. Recently, it wrote off a huge amount of obsolete inventory each year and was suffering a significant cost inefficiency in an increasingly stagnant market. VASTA must assess the competitive environment, and renovate its supply chain to stay competitive. At the end of this course, you will help VASTA save $billions on supply chain cost and retain its leadership in a stagnant and saturated market.

I hope you enjoy the course!
      


            Read more
          



          Welcome!
    -Welcome to Supply Chain Analytics! In this week, I shall first tell you the story of VASTA and the challenge it faces, then provide an overview of the course, learning outcomes and weekly topics. You will then learn competitive analysis and benchmarking to assess a firm’s competitive environment and identify the business opportunity.

General Principles and Intuition
    -In Week 2, you will understand the general principles of supply chain planning, and develop intuitions on the benefits and concerns of the push / pull strategies. The intuitions and insights will guide you in the quantitative supply chain analysis in Week 3.

Data Collection, Cost Estimation and Supply Chain Analytics
    -In Week 3, you will learn what data to collect, how to estimate various types of costs, and how to use data analysis to assess the impact of various strategies on different aspects of a supply chain. 

Customer Experience, Implementation and Project
    -In Week 4, you will learn how to assess the impact of the strategies on customer experience. You will get hands-on experience on the implementation and financial impact of supply chain analytics in a real-life example. You will complete this course by conducting a project to analyze the geographic difference for the strategies.",Supply Chain Analytics
https://www.classcentral.com/course/advanced-manufacturing-enterprise-8310,"Enterprises that seek to become proficient in advanced manufacturing must incorporate manufacturing management tools and integrate data throughout the supply chain to be successful. This course will make students aware of what a digitally connected enterprise is, as they learn about the operational complexity of enterprises, business process optimization and the concept of an integrated product-process-value chain. 

Students will become acquainted with the available tools, technologies and techniques for aggregation and integration of data throughout the manufacturing supply chain and entire product life-cycle. They will receive foundational knowledge to assist in efforts to facilitate design, planning, and production scheduling of goods and services by applying product life cycle data.  

Main concepts of this course will be delivered through lectures, readings, discussions and various videos. 

This is the sixth course in the Digital Manufacturing & Design Technology specialization that explores the many facets of manufacturing’s “Fourth Revolution,”  aka Industry 4.0, and features a culminating project involving creation of a roadmap to achieve a self-established DMD-related professional goal.

To learn more about the Digital Manufacturing and Design Technology specialization, please watch the overview video by copying and pasting the following link into your web browser: https://youtu.be/wETK1O9c-CA
      


          The Concept of a Connected and Collaborative Enterprise 
    -The purpose of this module is to educate students on why a holistic approach is necessary for analyzing the impact of advanced manufacturing on the success of an enterprise. 

How to Build a Digitally Connected Enterprise
    -The purpose of this module is to provide an overview of product lifecycle and describe the challenges and opportunities that organizations face in adoption of advanced manufacturing technologies. We will discuss the desire for collection of product lifecycle data as well as outline the required features for a highly connected enterprise. In addition, we will provide several examples of information-sharing infrastructures and will elaborate the concept of Product Lifecycle Management (PLM) system. Finally, we will discuss several examples of effective data collection technologies.

Introduction to a Set of Supply Chain Management Tools & Integrated Capabilities
    -In this module, we will introduce the current enterprise management tools (such as ERP, MRP, and MES) that are often employed to integrate capabilities of various entities through the supply chain. We will provide a broad overview of these tools, and will review the capabilities of each of them.

Ensure a Robust Infrastructure 
    -In this module, we discuss the importance of measuring the performance of supply chains. We will also discuss decision analysis methods and techniques that facilitate decision making through the entire product lifecycle.",Advanced Manufacturing Enterprise
https://www.classcentral.com/course/complexity-explorer-nonlinear-dynamics-mathematical-and-computational-approaches-1195,"This course provides a broad introduction to the field of nonlinear dynamics, focusing both on the mathematics and the computational tools that are so important in the study of chaotic systems.  The course is aimed at students who have had at least one semester of college-level calculus and physics, and who can program in at least one high-level language.    

After a quick overview of the field and its history, we review the basic background that students need in order to succeed in this course.  We then dig deeper into the dynamics of maps—discrete-time dynamical systems—encountering and unpacking the notions of state space, trajectories, attractors and basins of attraction, stability and instability, bifurcations, and the Feigenbaum number.  We then move to the study of flows, where we revisit many of the same notions in the context of continuous-time dynamical systems.  Since chaotic systems cannot, by definition, be solved in closed form, we spend several weeks thinking about how to solve them numerically and what challenges arise in that process.  We finish by learning about techniques and tools for applying all of this theory to real-world data.",Nonlinear Dynamics: Mathematical and Computational Approaches
https://www.classcentral.com/course/polimi-open-knowledge-archaeoastronomy-6172,"Archaeoastronomy is the “science of stars and stones”: it studies the relationships between the ancient monuments and the sky, in order to gain a better understanding of the ideas of the architects of the past and of their religious and symbolic world. The course provides the first complete, easy introduction to this fascinating discipline.
During the course, many spectacular ancient sites – such as Stonehenge in England, Giza and Karnak in Egypt, Chichen Itzá in the Yucatan, Macchu Picchu in Peru and the Pantheon in Rome – will be visited and the fascinating events occurring there in special days of the year (such as solstices, equinoxes, or the day of the foundation of Rome) will be shown and explained. The course also provides the necessary background on Astronomy with the naked eye and a general introduction to the role of Astronomy in religion and in the management of power among ancient cultures.",Archaeoastronomy
https://www.classcentral.com/course/ios-app-development-swift-5-17285,"Welcome to Introduction to iOS Application Development with Swift 5.

In this course you'll use your Swift skills to create iOS applications.

Some of the things you will learn in this course are:

•	Write the code to build your very first iOS application
•	Manage screen display with multiple views
•	Use auto layout and the interface builder
•	Create applications with user interaction
•	Design a user interface allowing for multiple screen size and direction
•	Write and execute unit tests to keep your code error-free
•	Perform various calculations using Swift

By the end of this course you will know how to build simple iOS applications and you'll be ready to move on and learn about using tables and data in iOS.
      


          Building Your First App

Swoosh App: Intro to Interface Builder

Supporting iPhones & iPads

Window Shopper App: Your First Fully Functional App

Window Shopper App: Continued",Introduction to iOS App Development with Swift 5
https://www.classcentral.com/course/descriptive-statistics-statistical-distr-7025,"The ability to understand and apply Business Statistics is becoming increasingly important in the industry. A good understanding of Business Statistics is a requirement to make correct and relevant interpretations of data. Lack of knowledge could lead to erroneous decisions which could potentially have negative consequences for a firm. This course is designed to introduce you to Business Statistics. We begin with the notion of descriptive statistics, which is summarizing data using a few numbers. Different categories of descriptive measures are introduced and discussed along with the Excel functions to calculate them. The notion of probability or uncertainty is introduced along with the concept of a sample and population data using relevant business examples. This leads us to various statistical distributions along with their Excel functions which are then used to model or approximate business processes. You get to apply these descriptive measures of data and various statistical distributions using easy-to-follow Excel based examples which are demonstrated throughout the course.

To successfully complete course assignments, students must have access to Microsoft Excel. 
________________________________________
WEEK 1
Module 1: Basic Data Descriptors
In this module you will get to understand, calculate and interpret various descriptive or summary measures of data. These descriptive measures summarize and present data using a few numbers. Appropriate Excel functions to do these calculations are introduced and demonstrated.

Topics covered include:
•	Categories of descriptive data
•	Measures of central tendency, the mean, median, mode, and their interpretations and calculations
•	Measures of spread-in-data, the range, interquartile-range, standard deviation and variance
•	Box plots
•	Interpreting the standard deviation measure using the rule-of-thumb and Chebyshev’s theorem
________________________________________
WEEK 2
Module 2: Descriptive Measures of Association, Probability, and Statistical Distributions
This module presents the covariance and correlation measures and their respective Excel functions. You get to understand the notion of causation versus correlation. The module then introduces the notion of probability and random variables and starts introducing statistical distributions.

Topics covered include:
•	Measures of association, the covariance and correlation measures; causation versus correlation
•	Probability and random variables; discrete versus continuous data
•	Introduction to statistical distributions
________________________________________
WEEK 3
Module 3: The Normal Distribution
This module introduces the Normal distribution and the Excel function to calculate probabilities and various outcomes from the distribution. 

Topics covered include:
•	Probability density function and area under the curve as a measure of probability
•	The Normal distribution (bell curve), NORM.DIST, NORM.INV functions in Excel
________________________________________
WEEK 4
Module 4: Working with Distributions, Normal, Binomial, Poisson
In this module, you'll see various applications of the Normal distribution. You will also get introduced to the Binomial and Poisson distributions. The Central Limit Theorem is introduced and explained in the context of understanding sample data versus population data and the link between the two.

Topics covered include:
•	Various applications of the Normal distribution
•	The Binomial and Poisson distributions
•	Sample versus population data; the Central Limit Theorem
      


            Read more
          



          Basic Data Descriptors

Descriptive Measures of Association, Probability, and Statistical Distributions

The Normal Distribution

Working with Distributions (Normal, Binomial, Poisson), Population and Sample Data","Basic Data Descriptors, Statistical Distributions, and Application to Business Decisions"
https://www.classcentral.com/course/reproducible-templates-analysis-10207,"This course will assist you with recreating work that a previous coworker completed, revisiting a project you abandoned some time ago, or simply reproducing a document with a consistent format and workflow. Incomplete information about how the work was done, where the files are, and which is the most recent version can give rise to many complications. This course  focuses on the proper documentation creation process, allowing you and your colleagues to easily reproduce the components of your workflow. Throughout this course, you'll receive helpful demonstrations of RStudio and the R Markdown language and engage in active learning opportunities to help you build a professional online portfolio.
      


          Introduction to Reproducible Research and Dynamic Documentation
    -This module provides an introduction to the concepts surrounding reproducibility and the Open Science movement, RStudio and GitHub, and foundational cases and authors in the field. 

R Markdown: Syntax, Document, and Presentation Formats
    -This module explores the R Markdown syntax to format and customize the layout of presentations or reports and will also look at inserting and creating objects such as tables, images, or video within documents.

R Markdown Templates: Processing and Customizing
    -This module goes further with R Markdown to help turn documents, reports, and presentations into templates for easier automation, reproducibility, and customization.

Leveraging Custom Templates from Leading Scientific Journals
    -This module delves into custom templates available for websites, books, and scientific publishers, such as Elsevier and the IEEE, with the chance to create your first R Package.

Working in Teams and Disseminating Templates and Reports
    -This module focuses on helpful tips for sharing and using the templates you create, as well as methods for organizing content. We'll also look at a few web-publishing services.",Reproducible Templates for Analysis and Dissemination
https://www.classcentral.com/course/udacity-intro-to-algorithms-364,"Ever played the Kevin Bacon game? This class will show you how it works by giving you an introduction to the design and analysis of algorithms, enabling you to discover how individuals are connected. Why Take This Course?By the end of this class you will understand key concepts needed to devise new algorithms for graphs and other important data structures and to evaluate the efficiency of these algorithms.



Lesson 1: A Social Network Magic TrickObjective: Become familiar with Algorithm Analysis. Eulerian PathCorrectness of NaïveRussian Peasants AlgorithmMeasuring TimeSteps for Naive, Steps for RussianDivide and ConquerLesson 2: Growth Rates in Social NetworksObjective: Use mathematical tools to analyze how things are connected.Chain, Ring and Grid NetworksBig Theta Planar GraphsNodes, Edges, RegionsGrowth Rate of Edges in Planar GraphHypercubeRandomly Generated GraphsN SquaredTangled HypercubeLesson 3: Basic Graph AlgorithmsObjective: Find the quickest route to Kevin Bacon. Properties of Social NetworksClustering CoefficientConnected ComponentsRunning Time of Connected ComponentsChecking Pairwise ConnectivityPairwise Shortest PathDepth vs. Breadth First SearchRecursion ReplacementMarvel ""Social"" NetworkFinding Bridge EdgesLesson 4: It’s Who You KnowObjective: Learn to keep track of your Best Friends using heaps.Degree CentralityTop K Via PartitioningThree Partitioning CasesProperties of a Heap Patch Up a HeapDown HeapifyHeap SortLesson 5: Strong and Weak BondsObjective: Work with Social Networks that have edge weights.Make a TreeStrength of ConnectionsWeighted Social NetworksHow to Find the Shortest PathDijkstra’s Shortest Path AlgorithmFloyd-Warshall IntroRandomizing Clustering Coefficient Bounds on the EstimateLesson 6: Hardness of Network ProblemsObjective: Explore what it means for a Social Network problem to be ""harder"" than other.TetristanExponential Running Time Degrees of HardnessReduction: Long and Simple PathPolynomial Time Decidable ProblemsNon-deterministic Polynomial Time Decidable ProblemClique Problem in NPFind the StrangersGraph Coloring is NP-CompleteLesson 7: Review and ApplicationInterview with Peter Winker (Professor, Dartmouth College) on Names and Boxes Problem && Puzzles and AlgorithmsInterview with Tina Eliassi-Rad (Professor, Rutgers University) on Statistical Measures in Network && Social Networks in Security and ProtestsInterview with Andrew Goldberg (Principal Researcher, Microsoft Research) on Practical AlgorithmsInterview with Vukosi Marivate (Graduate Student, Rutgers University) on Social AlgorithmsInterview with Duncan Watts (Principal Researcher, Microsoft) on Pathway That Can Use Two Nodes   Intro to Graph Search Animation",Intro to Algorithms
https://www.classcentral.com/course/machine-learning-accounting-python-18078,"This course, Machine Learning for Accounting with Python, introduces machine learning algorithms (models) and their applications in accounting problems. It covers classification, regression, clustering, text analysis, time series analysis. It also discusses model evaluation and model optimization. This course provides an entry point for students to be able to apply proper machine learning models on business related datasets with Python to solve various problems.

Accounting Data Analytics with Python is a prerequisite for this course. This course is running on the same platform (Jupyter Notebook) as that of the prerequisite course. While Accounting Data Analytics with Python covers data understanding and data preparation in the data analytics process, this course covers the next two steps in the process, modeling and model evaluation. Upon completion of the two courses, students should be able to complete an entire data analytics process with Python.
      


          INTRODUCTION TO THE COURSE
    -This module introduces time and date data, which provide unique learning opportunities and challenges. First, we will discuss how to properly handle time and date features within a Python program. Next, we will extend this discussion to handle data indexed by time and date information, which is known as time series data.

MODULE 1: INTRODUCTION TO MACHINE LEARNING
    -This module provides the basis for the rest of the course by introducing the basic concepts behind machine learning, and, specifically, how to perform machine learning by using Python and the scikit-learn machine learning module. First, you will learn about the basic types of machine learning. Next, you will learn an important step before applying machine learning algorithms, data pre-processing. Finally, you will learn how to leverage different types of machine learning algorithms in a Python script.

MODULE 2: FUNDAMENTAL ALGORITHMS I
    -This module introduces three machine learning algorithms. First, you will learn how linear regression can be considered a machine learning problem with parameters that must be determined computationally by minimizing a cost function. Next, you will learn Logistic Regression. Despite its name, Logistic Regression is a classification algorithm. Lastly, you will learn Decision Tree, which is a popular machine learning algorithm that can be used for both classification and regression. This module will dive deeper into the concept of machine classification, where algorithms learn from existing, labeled data to classify new, unseen data into specific categories; and, the concept of machine regression, where algorithms learn a model from data to make predictions for new, unseen continuous data. While these algorithms all differ in their mathematical underpinnings, they are often used for classifying numerical, text, and image data or performing regression in a variety of domains.

MODULE 3: Fundamental Algorithms II
    -This module introduces three more machine learning algorithms, k-nearest neighbors, support vector machine and random forest. All of them can be used for either classification or regression tasks.

MODULE 4: MODEL EVALUATION
    -Model Evaluation is an integral component of any data analytics project. It helps to find out how well the model will work on predicting future (out-of-sample) data. This module introduces basic model evaluation metrics for machine learning algorithms. First, the evaluation metrics for regression is presented. Next the metrics and technics to evaluate classification are introduced.

MODULE 5: MODEL OPTIMIZATION
    -This module introduces the techniques of model optimization. First, the basic techniques of feature selection is presented. Next, the technique of cross-validation is introduced, which can provide a more accurate evaluation on models. Finally, model selection, or hyperparameter tunning, which uses cross-validation, is introduced.

MODULE 6: INTRODUCTION TO TEXT ANALYSIS
    -In this module, you will start applying your new machine learning skills to an exciting data analytic topic: Text Analysis. First, we will review the process by which textual data is converted into numerical data that can be processed by a computer. Along with this are a number of new concepts that focus on manipulating these data to generate improved machine learning predictions. Second, we will apply machine learning algorithms, specifically classification, to text data. Finally, we will explore the more advanced concepts in text analysis and introduce a special kind of text classification: sentiment analysis.

MODULE 7: INTRODUCTOIN TO CLUSTERING
    -This module introduces clustering, where data points are assigned to sub groups of points based on some specific properties, such as spatial distance or the local density of points. While humans often find clusters visually with ease in a given data sets, computationally the problem is more challenging. This module starts by exploring the basic ideas behind this unsupervised learning technique. One of the most popular clustering techniques, K-means, is introduced. Next, a K-means case study is provided. Finally the density-based DB-SCAN technique is introduced.

MODULE 8: INTRODUCTION TO TIME SERIES DATA
    -This module introduces time and date data, which provide unique learning opportunities and challenges. First, we will discuss how to properly handle time and date features within a Python program. Next, we will extend this discussion to handle data indexed by time and date information, which is known as time series data.",Machine Learning for Accounting with Python
https://www.classcentral.com/course/health-protection-17355,"The Health Protection course is the fourth instalment of the wider Foundations of Public Health Practice specialisation from Imperial College London's Global Master of Public Health (MPH). The scope and content of this course has been developed from the ground up by a combined team of academics and practitioners drawing on decades of real-world public health experience as well as deep academic knowledge. Through short video lectures, practitioner interviews and a wide range of interactive activities, learners will be immersed in the world of public health practice.

Designed for those new to the discipline, over three modules (intended for three weeks of learning), learners will become familiar with the scope, principles and nuances of health protection in the context of public health practice. Beginning with the basics of Water, Sanitation and Health (WASH) based interventions, the course will introduce learners to the science and principles of practical microbiology, before examining vaccines, incident management and the threat posed by a wide range of manmade and natural environmental threats. By the end of this course, learners will be familiar and conversant with core health protection principles and approaches, and confident in discussing health protection issues when they move into practice.
      


          Module One: Water, sanitation and infectious diseases
    -This fourth course, ""Health Protection"", part of the wider Foundations of Public Health Practice specialisation, is designed to introduce learners to the area of operational and strategic health protection. This first module, entitled ""Water, sanitation and infectious diseases"" introduces learners to WASH-based initiatives before, in the second lesson, bringing learners up to speed on basic microbiology and the science that underpins communicable disease control. 

Module Two: Vaccines and management of communicable disease
    -This fourth course, ""Health Protection"", part of the wider Foundations of Public Health Practice specialisation, is designed to introduce learners to the area of operational and strategic health protection. This second module, entitled ""Vaccines and communicable disease control"" will cover the science and practice of vaccines. In the first lesson learners are introduced to the evidence-base and impact that vaccines have had on morbidity globally. Some of the main global players are also introduced before discussion of the ethical implications of mandatory vaccination (building on learning from the first course of this specialisation ""The Public Health Approach""). Bringing all of the learning on this course together, the second lesson introduces communicable disease control and the management of health protection incidents. 

Module Three: Environmental hazards and strategic health protection threats
    -This fourth course, ""Health Protection"", part of the wider Foundations of Public Health Practice specialisation, is designed to introduce learners to the area of operational and strategic health protection. This third module, entitled ""Environmental hazards and strategic health protection threats"" examines the non-communicable disease elements of health protection - with an introduction to CBRN and exploration of the public health approach in the context of major incidents and health emergencies. In the first lesson learners are introduced to the emerging public health topic of air quality: with specific exploration of the collision of circumstances leading to London's Ultra Low Emission Zone. The second lesson moves into CBRN with a case study of the Fukushima Daiichi radiological incident of 2011.",Foundations of Public Health Practice: Health Protection
https://www.classcentral.com/course/startup-626,"Spiritual sequel to Peter Thiel's CS183 course
    on startups. Bridges the gap between academic computer science and production
    software engineering. Fast-paced introduction to key tools and techniques
    (command line, dotfiles, text editor, distributed version control, debugging,
    testing, documentation, reading code, deployments), featuring guest appearances
    by senior engineers from successful startups and large-scale academic projects.
    Over the course of the class, students will build a command line application,
    expose it as a web service, and then link other students' applications
    and services together to build an HTML5 mobile app. General principles
    are illustrated through modern Javascript and the latest web technologies,
    including Node, Backbone, Coffeescript, Bootstrap, Git, and Github. 



          The syllabus is optimized to enable students to iterate on their final projects as soon as possible, with technical material in the first half of the class and entrepreneurial considerations in the second half.

Introduction and Quickstart
Tools: VMs, IAAS/PAAS, Unix Command Line, Text Editors, DCVS

Frontend: HTML/CSS/JS, Wireframing, Market Research

Backend: SSJS, Databases, Frameworks, Data Pipelines

APIs: Client-side templating, HTTP, SOA/REST/JSON, API as BizDev

Devops: Testing, Deployment, CI, Monitoring, Performance

Dev Scaling: DRY, Reading/Reviewing/Documenting Code, Parallelizing

Founding: Conception, Composition, Capitalization

Business Scaling: Promotion, CAC/LTV/Funnel, Regulation, Accounting

Summary and Demo Week",Startup Engineering
https://www.classcentral.com/course/gcp-exploring-preparing-data-bigquery-9674,"Welcome to the Coursera specialization, From Data to Insights with Google Cloud Platform brought to you by the Google Cloud team. I’m Evan Jones (a data enthusiast) and I’m going to be your guide.

This first course in this specialization is Exploring and Preparing your Data with BigQuery. Here we will see what the common challenges faced by data analysts are and how to solve them with the big data tools on Google Cloud Platform. You’ll pick up some SQL along the way and become very familiar with using BigQuery and Cloud Dataprep to analyze and transform your datasets.

This course should take about one week to complete, 5-7 total hours of work.  By the end of this course, you’ll be able to query and draw insight from millions of records in our BigQuery public datasets. You’ll learn how to assess the quality of your datasets and develop an automated data cleansing pipeline that will output to BigQuery. Lastly, you’ll get to practice writing and troubleshooting SQL on a real Google Analytics e-commerce dataset to drive marketing insights.

>>> By enrolling in this specialization you agree to the Qwiklabs Terms of Service as set out in the FAQ and located at: https://qwiklabs.com/terms_of_service 
      


          Welcome to From ​Data ​to ​Insights ​with ​Google ​Cloud Platform: ​Exploring ​and ​Preparing ​your ​Data
    -Learn the courses, content, and technologies that are part of this data analyst specialization

Module 1: Introduction ​to ​Data ​on Google ​Cloud ​Platform
    -Understand the core principles behind Google Cloud Platform and how to leverage them for big data analysis

Module 2: ​Big ​Data ​Tools ​Overview
    -Learn what are the key big data tools on Google Cloud Platform that you will be using to analyze, prepare, and visualize data

Module 3: ​Exploring ​your ​Data ​with SQL
    -Learn how to query your data with the basics of SQL (Structured Query Language) and practice writing queries in BigQuery

Module 4: ​Google ​BigQuery ​Pricing
    -Understand how pricing works in BigQuery and how you can best optimize your queries

Module 5: ​Cleaning ​and ​Transforming your ​Data
    -Understand the importance of creating high quality datasets and learn the tools that will help you transform your data",Exploring ​and ​Preparing ​your ​Data with BigQuery
https://www.classcentral.com/course/edx-paradigms-of-computer-programming-abstraction-and-concurrency-2630,"Louv1.2x and its predecessor Louv1.1x together give an introduction to all major programming concepts, techniques, and paradigms in a unified framework. We cover the three main programming paradigms: functional, object-oriented, and declarative dataflow.
The two courses are targeted toward people with a basic knowledge of programming. It will be most useful to beginning programming students, but the unconventional approach should be insightful even to seasoned professionals.
Louv1.1x (Fundamentals) covers functional programming, its techniques and its data structures. You’ll use simple formal semantics for all concepts, and see those concepts illustrated with practical code that runs on the accompanying open-source platform, the Mozart Programming System.
Louv1.2x (Abstraction and Concurrency) covers data abstraction, state, and concurrency. You’ll learn the four ways to do data abstraction and discuss the trade-offs between objects and abstract data types. You’ll be exposed to deterministic dataflow, the most useful paradigm for concurrent programming, and learn how it avoids race conditions.
To learn more about the practical organization of the two courses, watch the introductory video.",Paradigms of Computer Programming – Abstraction and Concurrency
https://www.classcentral.com/course/stanford-openedx-introduction-to-logic-7078,"This course is an introduction to Logic from a computational perspective. It shows how to encode information in the form of logical sentences; it shows how to reason with information in this form; and it provides an overview of logic technology and its applications - in mathematics, science, engineering, business, law, and so forth.
The course was originally designed for use at the college level. However, experience has shown that it works for secondary school students as well, and it can be used at the start of graduate school for those who have not yet seen the material.",Introduction to Logic
https://www.classcentral.com/course/opensap-in-memory-data-management-in-a-nutshell-2458,"While the first openSAP course, Introduction to Software Development on SAP HANA, is intended as an introductory class for software developers who are new to SAP HANA, it makes sense for course participants to obtain an understanding of the fundamental concepts of in-memory data management before the course starts.",In-Memory Data Management In a Nutshell
https://www.classcentral.com/course/cloud-iot-platform-12536,"Internet of Things (IoT) is an emerging area of information and communications technology (ICT) involving many disciplines of computer science and engineering including sensors/actuators, communications networking, server platforms, data analytics and smart applications. IoT is considered to be an essential part of the 4th Industrial Revolution along with AI and Big Data. This course aims at introducing IoT Cloud platforms from Samsung, Microsoft, Amazon, IBM and Google and how they can be used in developing IoT applications. This course will be offered in English. Subtitles/captions in English and will be also provided. 

IoT (Internet of Things, 사물인터넷)는 최근 중요한 정보통신기술로 주목 받고 있으며 센서/ 제어기, 통신 네트워크, 서버 플랫폼, 데이터 분석, 스마트 앱 등의 컴퓨터공학 기술들이 융합된 기술입니다. IoT는 인공지능, 빅데이터와 함께, 4차산업혁명의 3대 핵심 기술 중 하나로 손꼽히고 있습니다. 글로벌 Cloud 서비스 제공자들이 IoT를 특별히 지원하기 위하여 개발한 IoT Cloud 플랫폼들을 소개합니다. 이것들을 활용하여 다양한 IoT 어플리케이션을 개발할 수 있습니다. 본 과목은 영어로 진행되며, 영문자막(일부 한글과 영문 모두)을 제공합니다.
      


          Samsung ARTIK Cloud Platform

Microsoft Azure IoT Suite

Amazon Web Services IoT

IBM Watson IoT

Google Cloud IoT",Programming with Cloud IoT Platforms
https://www.classcentral.com/course/textretrieval-2734,"Recent years have seen a dramatic growth of natural language text data, including web pages, news articles, scientific literature, emails, enterprise documents, and social media such as blog articles, forum posts, product reviews, and tweets. Text data are unique in that they are usually generated directly by humans rather than a computer system or sensors, and are thus especially valuable for discovering knowledge about people’s opinions and preferences, in addition to many other kinds of knowledge that we encode in text. 

This course will cover search engine technologies, which play an important role in any data mining applications involving text data for two reasons. First, while the raw data may be large for any particular problem, it is often a relatively small subset of the data that are relevant, and a search engine is an essential tool for quickly discovering a small subset of relevant text data in a large text collection. Second, search engines are needed to help analysts interpret any patterns discovered in the data by allowing them to examine the relevant original text data to make sense of any discovered pattern. You will learn the basic concepts, principles, and the major techniques in text retrieval, which is the underlying science of search engines.
      


          Orientation
    -You will become familiar with the course, your classmates, and our learning environment. The orientation will also help you obtain the technical skills required for the course.

Week 1
    -During this week's lessons, you will learn of natural language processing techniques, which are the foundation for all kinds of text-processing applications, the concept of a retrieval model, and the basic idea of the vector space model. 

Week 2
    -In this week's lessons, you will learn how the vector space model works in detail, the major heuristics used in designing a retrieval function for ranking documents with respect to a query, and how to implement an information retrieval system (i.e., a search engine), including how to build an inverted index and how to score documents quickly for a query. 

Week 3
    -In this week's lessons, you will learn how to evaluate an information retrieval system (a search engine), including the basic measures for evaluating a set of retrieved results and the major measures for evaluating a ranked list, including the average precision (AP) and the normalized discounted cumulative gain (nDCG), and practical issues in evaluation, including statistical significance testing and pooling.

Week 4
    -In this week's lessons, you will learn probabilistic retrieval models and statistical language models, particularly the detail of the query likelihood retrieval function with two specific smoothing methods, and how the query likelihood retrieval function is connected with the retrieval heuristics used in the vector space model. 

Week 5
    -In this week's lessons, you will learn feedback techniques in information retrieval, including the Rocchio feedback method for the vector space model, and a mixture model for feedback with language models. You will also learn how web search engines work, including web crawling, web indexing, and how links between web pages can be leveraged to score web pages. 

Week 6
    -In this week's lessons, you will learn how machine learning can be used to combine multiple scoring factors to optimize ranking of documents in web search (i.e., learning to rank), and learn techniques used in recommender systems (also called filtering systems), including content-based recommendation/filtering and collaborative filtering. You will also have a chance to review the entire course.",Text Retrieval and Search Engines
https://www.classcentral.com/course/udacity-data-visualization-and-d3-js-2898,"Learn the fundamentals of data visualization and practice communicating with data. This course covers how to apply design principles, human perception, color theory, and effective storytelling to data visualization. If you present data to others, aspire to be an analyst or data scientist, or if you’d like to become more technical with visualization tools, then you can grow your skills with this course.The course does not cover exploratory approaches to discover insights about data. Instead, the course focuses on how to visually encode and present data to an audience once an insight has been found.This course is part of the Data Analyst Nanodegree.Why Take This Course?Learn by doing! You will analyze existing data visualization and create new ones to learn about the field. At it’s core, data visualization is a form of communication. Learn how to be a great communicator and how to enable readers to walk away from your graphics with insight and understanding. This course also makes use of open web standards (HTML, CSS, and SVG) to create data visualizations.You can also learn how to...communicate clearly with the best visual representation of your datatell stories, spark discussion, and create calls to actions for readersdesign graphics like ones from the NYTimes and other media companieshow to use open web technologies to create an online portfolio of your workuse visualization libraries (dimple.js and D3.js) to create graphics



            Read more
          



Lesson 1a Visualization Fundamentals (2 hours)Learn about the elements of great data visualization. In this lesson, you will meet data visualization experts, learn about data visualization in the context of data science, and learn how to represent data values in visual form.Lesson 1b D3 Building Blocks (4 hours)Learn how to use the open standards of the web to create graphical elements. You’ll learn how to select elements on the page, add SVG elements, and how to style SVG elements. Make use of all the Instructor Notes throughout this lesson if you have little to no experience with HTML and CSS.Mini-Project 1: RAW Visualization (2 hours)Create a data visualization using a software of your choice. We will provide recommendations for visualization software as well as data sets. We want you to get right into making data visualization so here’s your first chance!Lesson 2a Design Principles (2 hours)Which chart type should I use for my data? Which colors should I avoid when making graphics? How do I know if my graphic is effective? Investigate these questions, and learn about the World Cup data set which will be use throughout the rest of the course.Lesson 2b Dimple.js (4 hours)Learn how to create graphics using the Dimple JavaScript library. You will learn about this library as a gentle coding introduction before learning about D3.js. You will be able to produce great graphics with minimal code, and all of your graphics will come with interactivity without any extra effort on your part. Dimple, it's simple!Mini-Project 2: Take Two (2-5 hours)Find an existing data visualization, critique it for what it does well and what it doesn’t do well, and finally, recreate the graphic using a software tool of your choice. We recommend using Dimple.js, which is covered in Lesson 2b, but we don’t want you to feel constrained by the choice of tools. Use any tool that works for you.Special NoteAt this point in the course, you can start the final project. The remaining content of the course covers narrative structures, types of bias, and maps. All of the code  in Lesson 3 and Lesson 4 pertains to d3.js. If you'd like to learn d3.js and complete the final project using d3.js, then please continue. If you prefer to stop, you can complete the final project using dimple.js.Lesson 3 Narratives (5 hours)Learn how to incorporate different narrative structures into your visualizations and code along with Jonathan as you create a graphic for the World Cup data set. You’ll learn about different types of bias in the data visualization process and learn how to add context to your data visualizations. By the end of this lesson, you’ll have a solid foundation in D3.js.Lesson 4 Animation and Interaction (5 hours)Static graphics are great, but interactive graphics can be even better. Learn how to leverage animation and interaction to bring more data insights to your audience. Code along with Jonathan once again as you learn how to create a bubble map for the World Cup data set.Final Project: Making an Effective Data Visualization (2 hours or more)You will create a data visualization that conveys a clear message about a data set. You will use dimple.js or d3.js and collect feedback along the way to arrive at a polished product.NOTE: As a free student, you are welcome to complete the project to showcase your learning; however, only students enrolled in the Data Analyst Nanodegree are able to submit the final project for review and certificate. Interested in enrolling? Find out more!",Data Visualization and D3.js
https://www.classcentral.com/course/electrodynamics-introduction-12565,"The depth and breadth of electromagnetism, the foundation for many fields including materials science, electrical engineering, and physical chemistry, requires a long, steep, and steady learning curve. This course aims to bridge the gap between the fundamental principles taught in electromagnetism and its practical application to specific fields such as materials, physics, and chemistry related to energy storage and harvesting. 

The goal of Electrodynamics: An Introduction is to not only teach electromagnetism but also introduce some mathematical tools which can be used to solve problems in the subject.  Within these lecture notes, we review vector calculus and explain how to use fields to visualize the topics we cover.  This course is dynamic, as the lectures continuously build on previous notes and a variety of explanations are presented for each solution.  Since this is a lower level course, we will focus on the simple concept of electrostatics.  This has applications in exploring intermolecular forces, and qualities of capacitors.  Through this, we relate electromagnetism to more conventionally studied topics and its application to specific research topics related to energy storage and harvesting.
      


          Introduction and Basics of Electrostatics
    -In this module, electrodynamics is introduced by examining the different forces and explaining which are related to electric forces.  Furthermore, fields are defined and we differentiate between scalar and vector fields.  We cover laws that constitute electrodynamics, specifically Maxwell's equations and the Lorentz force.  After explaining how these topics can be illustrated, we also cover how relativity relates to the subject material.

Introduction to Differential Calculus of Vector Fields
    -This module mainly covers the mathematics behind differential forms of equations.  We introduce the ∇ operator and show how it can be used in mathematics.  Then, the ∇ operator is proved to be a vector.  The Maxwell equations are rewritten in derivative form, and the concepts of divergence and curl are introduced.  Finally, we examine the Laplace operator, and other forms of the ∇ operator applied twice.

Introduction to Vector Integral Calculus
    -This module explains line integrals and presents some equations where they are important.  We explain what the flux and circulation of a field are conceptually and how they can be obtain using the divergence and curl through Gauss'  and Stokes' theorems respectively.  Finally, we explain the qualities of divergence and curl free fields.

Introduction to Electrostatic Solutions
    -This module covers how to simplify Maxwell's equations in the scenario of electrostatics.  Then, we discuss how the electric potential can be used and why using a relative value is useful for certain calculations.  The flux out of different geometries is presented, as well as how to display field lines and equipotential surfaces.

The Application of Gauss' Law
    -This module focusses primarily on electric fields.  First, we talk about the mathematical requirements for equilibrium and the implications of finding equilibrium for point charges.  Then we move on to describe the electric field coming from different geometries.  Finally, we compare the electric fields inside and outside of a conductor and how they create the phenomenon of electric shielding.",Electrodynamics: An Introduction
https://www.classcentral.com/course/electrodynamics-analysis-of-electric-fie-12413,"This course is a continuation of Electrodynamics: An Introduction. Here, we will cover different methods of calculating an electric field. In addition, we will introduce polarization, dielectrics, and how electric fields create dipoles. 

Learners will 
•	Be able to apply symmetry and other tools to calculate the electric field.
•	Understand what susceptibility, polarization, and dipoles are.

Additionally, students will learn to visualize Maxwell equations in order to apply the derived mathematics to other fields, such as heat/mass diffusion and meso-scale electromechanical properties, and to create patents that could lead to potential innovations in energy storage and harvesting. The approach taken in this course complements traditional approaches, covering a fairly complete treatment of the physics of electricity and magnetism, and adds Feynman’s unique and vital approach to grasping a picture of the physical universe. Furthermore, this course uniquely provides the link between the knowledge of electrodynamics and its practical applications to research in materials science, information technology, electrical engineering, chemistry, chemical engineering, energy storage, energy harvesting, and other materials related fields.
      


          The Electric Field in Various Circumstances
    - The primary focus of the first portion of this module is the concept of dipole moments, both for a single molecule and an arbitrary distribution.  The equations for both the potential and the electric field of a dipole are derived within the first part of the lecture.  This lecture also describes the method of images and how it can be applied to solving the electric field from different geometries.

The Electric Field in Various Circumstances (cont'd)
    -In this module, we cover how to solve for 2D electric fields, and also introduce some basic applications for electrostatics.  We describe how imaginary numbers can be used to plot the electric field and equipotential surfaces.  Then, we discuss how concepts such as natural resonance,  potential distribution, and grid spacing can help design modern devices and experiments.

Electrostatic Energy
    -This module introduces the importance of electrostatic energy and describes how to evaluate it.  It also covers how to use the concept of virtual work and how that can be used to find force; specifically we examine this in respect to capacitors. Finally, we discuss where the electrostatic energy can be located.

Introduction to Dielectrics
    -In the first module concerning dielectrics, we discuss what constitutes a dielectric material and how their presence effects the operation of a capacitor.  Then, we cover many ways to characterize a dielectric such as susceptibility and displacement.  Finally, we investigate the forces on a dielectric with respect to the capacitor.

Dielectrics (cont'd)
    -This module starts by describing how to obtain polarization for molecules under an electric field. Then, we cover methods to solve for the dielectric constant, such as Clausius-Mossotti Equation and Onsager Equation.  Our last topic covered is the concept of ferroelectricity and how ferroelectric materials can be modeled by the Curie-Weiss law and other methods.",Electrodynamics: Analysis of Electric Fields
https://www.classcentral.com/course/programming-languages-part-b-6920,"[As described below, this is Part B of a 3-part course.  Participants should complete Part A first -- Part B ""dives right in"" and refers often to material from Part A.]

This course is an introduction to the basic concepts of programming languages, with a strong emphasis on functional programming. The course uses the languages ML, Racket, and Ruby as vehicles for teaching the concepts, but the real intent is to teach enough about how any language “fits together” to make you more effective programming in any language -- and in learning new ones.

This course is neither particularly theoretical nor just about programming specifics -- it will give you a framework for understanding how to use language constructs effectively and how to design correct and elegant programs. By using different languages, you will learn to think more deeply than in terms of the particular syntax of one language. The emphasis on functional programming is essential for learning how to write robust, reusable, composable, and elegant programs. Indeed, many of the most important ideas in modern languages have their roots in functional programming. Get ready to learn a fresh and beautiful way to look at software and how to have fun building it.

The course assumes some prior experience with programming, as described in more detail in the first module of Part A.  Part B assumes successful completion of Part A.

The course is divided into three Coursera courses: Part A, Part B, and Part C.  As explained in more detail in the first module of Part A, the overall course is a substantial amount of challenging material, so the three-part format provides two intermediate milestones and opportunities for a pause before continuing.  The three parts are designed to be completed in order and set up to motivate you to continue through to the end of Part C.  

Week 1 of Part A has a more detailed list of topics for all three parts of the course, but it is expected that most course participants will not (yet!) know what all these topics mean.
      


            Read more
          



          Introduction, Course-Wide Information, and Software Installation (Start Here)
    -Welcome! Start here!  Learn about this course and how it's organized. 

Section 5 and Homework 4 (First Module with Racket)
    -Let's get started programming with Racket and then learning idioms related to delaying evaluation.  The welcome message has a few additional comments about picking up a new language and how to approach the homework assignment, so let's get started...

Section 6 and Homework 5 (Second Module with Racket)
    -Welcome to the second week of Part B where we will focus on (a) building data structures in dynamically typed languages and (b) implementing programming languages with interpreters.  Most of the programming assignment is focused on (b) -- implementing a small programming language that has function closures.  As usual, start with the welcome message and enjoy!

Section 7 Including a Quiz
    -In the last module of Part B we will use our experience programming in ML and Racket to 
compare and contrast static typing and dynamic typing.  This is not only the most important difference between these two languages, but it is a fundamental topic in the study of programming languages.  Learning it can help you program more effectively in both kinds of languages.  After completing this week's quiz, don't forget to watch the Part B Wrap-Up and Part C Preview video.","Programming Languages, Part B"
https://www.classcentral.com/course/geology-7636,"Get an introduction to geological processes
Everything we use that has not been grown either contains or relies on materials that have been sourced by a geologist.
On this online course, you will discover the link between volcanoes and your mobile phone, or why tiny marine wildlife is at the core of the plastics industry.
You will explore basic geological processes, focusing on how, where and why different rocks and natural resources form across the Earth.
You will also look at some of the environmental and sustainability considerations that geologists need to take into account when extracting and processing these resources.
The course is open to anyone with an interest in geology and the natural environment. It will be particularly useful for anyone considering an environmental science degree course or teachers who are looking for additional geology and geography resources to use in the classroom.
You will need a camera capable of taking a digital photo – a smart phone is fine. You will also need a Flickr account – this is free and easy to use.",The Earth in My Pocket: an Introduction to Geology
https://www.classcentral.com/course/rails-with-active-record-4197,"You already know how to build a basic web application with the Ruby on Rails framework. Perhaps, you have even taken Course 1, ""Ruby on Rails: An Introduction"" (we highly recommend it) where you relied on external web services to be your “data layer”. But in the back of your mind, you always knew that there would come a time when you would need to roll up your sleeves and learn SQL to be able to interact with your own relational database (RDBMS). But there is an easier way to get started with SQL using the Active Record Object/Relational (ORM) framework. In this course, we will be able to use the Ruby language and the Active Record ORM framework to automate interactions with the database to quickly build the application we want.

In Rails with Active Record and Action Pack, we will explore how to interact with relational databases by using Active Record, a Ruby gem, which Rails uses by default for database access. We will then take a look at what role Active Record plays in the overall request-response cycle, when a client (the browser) requests data from the server, as well as how to submit the data to the server.  Of course, when accessing data, security is of paramount importance! We will talk about vulnerabilities such as SQL injection, as well as how to secure access to data by authenticating and authorizing users accessing the data. Take this course to build a Ruby on Rails application with Active Record to automate the detailed SQL interactions with our database.
      


            Read more
          



          Introduction to Active Record
    -In this module, we will begin exploring the database-interaction portion of Rails. We will start off with migrations that enable you to create and modify the schema of the database. We will then move on to discussing the Active Record gem Rails uses, which enables you to create, retrieve, update, and delete the data from the database. Before looking at Active Record, we will talk about some advanced Ruby features of meta-programming that will help facilitate our Active Record journey.

Deep Dive into Active Record
    -In this module, we will continue exploring Active Record and look at ways to code advanced queries without exposing ourselves to risk from SQL injection (as well as what SQL injection actually is). We will then look at expressing relationships between entities in Active Record and validating the data being saved to the database.

Introduction to Action Pack
    -In this module, we will introduce Rails' Action Pack, which is a combination of Action Controller and Action View. We will see how REST has influenced routing in a Rails application and also talk about partials, form helpers, and layouts.

Security and Nested Resources in Action Pack
    -In this module, we will talk about how to deal with nested resources in Rails. We will then talk about securing your app with a username and password combination for authentication purposes and making sure that users are only authorized to make changes to and view their own resources. We will finish off the module by discussing pagination and deploying to Heroku Paas (Platform as a Service).",Rails with Active Record and Action Pack
https://www.classcentral.com/course/converter-control-5415,"This course can also be taken for academic credit as ECEA 5702, part of CU Boulder’s Master of Science in Electrical Engineering degree.

This course teaches how to design a feedback system to control a switching converter. The equivalent circuit models derived in the previous courses are extended to model small-signal ac variations. These models are then solved, to find the important transfer functions of the converter and its regulator system. Finally, the feedback loop is modeled, analyzed, and designed to meet requirements such as output regulation, bandwidth and transient response, and rejection of disturbances.

Upon completion of this course, you will be able to design and analyze the feedback systems of switching regulators.

This course assumes prior completion of courses Introduction to Power Electronics and Converter Circuits.
      


          Ch 7: AC Equivalent Circuit Modeling
    -How to extend the converter steady-state equivalent circuits, derived in the previous courses, to obtain small-signal ac equivalent circuits that model the important converter and regulator system dynamics.

Ch 8: Converter Transfer Functions - Part 1
    -A review of the construction of Bode plots of the magnitude and phase of first-order, second-order, and higher-order transfer functions, with emphasis on techniques needed for design of regulator systems. Design-oriented analysis techniques to make approximations and gain insight into how to design ac systems having significant complexity.

Ch 8: Converter Transfer Functions - Part 2
    -Design-oriented analysis techniques to make approximations and gain insight into how to design ac systems having significant complexity. Graphical construction techniques.

Ch 9: Controller Design
    -Application of the material of Chapters 7 and 8 to design closed-loop regulators that employ switching converters. How to design a feedback system that accurately regulates its output while rejecting disturbances.",Converter Control
https://www.classcentral.com/course/udacity-javascript-basics-2660,"We're here to help you get you started with JavaScript!
In the twenty plus years since its inception, JavaScript has become the _lingua franca_ of the web, that's to say, it's become the main tool to create interactive content on the Internet.

In this course, you'll explore the JavaScript programming language by creating an interactive version of your résumé. You’ll learn the JavaScript programming fundamentals you need while building new elements and sections to enhance your résumé.

This course is also a part of our Front-End Web Developer Nanodegree.Why Take This Course?Today, front-end developers work with web designers to create the interactive experiences that make the web the addictive playground we know and love. As the size and influence of the web have expanded, so has the importance of ensuring a website offers users an unforgettable experience.

Perhaps your end goal is to create a HTML5 game, code the front-end for an app idea you have, or maybe you want to use one of the growing set of libraries that let you compile code written in another language or for another platform down to JavaScript. With JavaScript, you can do all these things and more.

###Project
You will create an interactive résumé that you can share to the world and show your growing skills at the time.

Having a good résumé is a key component of securing a better job. We'll give you the template styles and code to create a modern and mobile friendly résumé (also called a curriculum vitae/CV outside the United States) that you can modify and customize.
      


            Read more
          



          ### Lesson 1: Getting Up and Running

Learn about the tools we'll be using throughout the course and begin modifying web pages with a little bit of code.

- Introduction of résumé project
- Components of the résumé
- Introduction to browser developer tools
- Running commands on the console
- Appending elements to the page

### Lesson 2: Data Types

Dig deeper into JavaScript as we introduce you to the building blocks of the language as you write more complex code using variables and advanced data structures like JSON, Objects, and Arrays.

- Variables
- Strings
- Evaluating values
- Arrays
- Objects
- JSON
- Validating JSON

### Lesson 3: Flow Control

Finish the résumé while you learn how to make your code more modular and reusable by using conditional statements, loops, and functions.

- Conditional statements
- For and while loops
- Functions
- Encapsulation",JavaScript Basics
https://www.classcentral.com/course/wharton-quantitative-modeling-fundamenta-5448,"How can you put data to work for you? Specifically, how can numbers in a spreadsheet tell us about present and past business activities, and how can we use them to forecast the future? The answer is in building quantitative models, and this course is designed to help you understand the fundamentals of this critical, foundational, business skill. Through a series of short lectures, demonstrations, and assignments, you’ll learn the key ideas and process of quantitative modeling so that you can begin to create your own models for your own business or enterprise. By the end of this course, you will have seen a variety of practical commonly used quantitative models as well as the building blocks that will allow you to start structuring your own models. These building blocks will be put to use in the other courses in this Specialization.
      


          Module 1: Introduction to Models 
    -In this module, you will learn how to define a model, and how models are commonly used. You’ll examine the central steps in the modeling process, the four key mathematical functions used in models, and the essential vocabulary used to describe models. By the end of this module, you’ll be able to identify the four most common types of models, and how and when they should be used. You’ll also be able to define and correctly use the key terms of modeling, giving you not only a foundation for further study, but also the ability to ask questions and participate in conversations about quantitative models.

Module 2: Linear Models and Optimization
    -This module introduces linear models, the building block for almost all modeling. Through close examination of the common uses together with examples of linear models, you’ll learn how to apply linear models, including cost functions and production functions to your business. The module also includes a presentation of growth and decay processes in discrete time, growth and decay in continuous time, together with their associated present and future value calculations. Classical optimization techniques are discussed. By the end of this module, you’ll be able to identify and understand the key structure of linear models, and suggest when and how to use them to improve outcomes for your business. You’ll also be able to perform present value calculations that are foundational to valuation metrics. In addition, you will understand how you can leverage models for your business, through the use of optimization to really fine tune and optimize your business functions.



Module 3: Probabilistic Models
    -This module explains probabilistic models, which are ways of capturing risk in process. You’ll need to use probabilistic models when you don’t know all of your inputs. You’ll examine how probabilistic models incorporate uncertainty, and how that uncertainty continues through to the outputs of the model. You’ll also discover how propagating uncertainty allows you to determine a range of values for forecasting. You’ll learn the most-widely used models for risk, including regression models, tree-based models, Monte Carlo simulations, and Markov chains, as well as the building blocks of these probabilistic models, such as random variables, probability distributions, Bernoulli random variables, binomial random variables, the empirical rule, and perhaps the most important of all of the statistical distributions, the normal distribution, characterized by mean and standard deviation. By the end of this module, you’ll be able to define a probabilistic model, identify and understand the most commonly used probabilistic models, know the components of those models, and determine the most useful probabilistic models for capturing and exploring risk in your own business.

Module 4: Regression Models
    -This module explores regression models, which allow you to start with data and discover an underlying process. Regression models are the key tools in predictive analytics, and are also used when you have to incorporate uncertainty explicitly in the underlying data.  You’ll learn more about what regression models are, what they can and cannot do, and the questions regression models can answer. You’ll examine correlation and linear association, methodology to fit the best line to the data, interpretation of regression coefficients, multiple regression, and logistic regression. You’ll also see how logistic regression will allow you to estimate probabilities of success. By the end of this module, you’ll be able to identify regression models and their key components, understand when they are used, and be able to interpret them so that you can discuss your model and convince others that your model makes sense, with the ultimate goal of implementation.",Fundamentals of Quantitative Modeling
https://www.classcentral.com/course/udacity-data-wrangling-with-mongodb-1479,"In this course, we will explore how to wrangle data from diverse sources and shape it to enable data-driven applications. Some data scientists spend the bulk of their time doing this!Students will learn how to gather and extract data from widely used data formats. They will learn how to assess the quality of data and explore best practices for data cleaning. We will also introduce students to MongoDB, covering the essentials of storing data and the MongoDB query language together with exploratory analysis using the MongoDB aggregation framework.This is a great course for those interested in entry-level data science positions as well as current business/data analysts looking to add big data to their repertoire, and managers working with data professionals or looking to leverage big data.This course is also a part of our Data Analyst Nanodegree.Why Take This Course?At the end of the class, students should be able to:  Programmatically extract data stored in common formats such as csv, Microsoft Excel, JSON, XML and scrape web sites to parse data from HTML.  Audit data for quality (validity, accuracy, completeness, consistency, and uniformity) and critically assess options for cleaning data in different contexts.   Store, retrieve, and analyze data using MongoDB.This course concludes with a final project where students incorporate what they have learned to address a real-world data analysis problem.



            Read more
          



Lesson 1: Data Extraction FundamentalsAssessing the Quality of DataIntro to Tabular FormatsParsing CSVParsing XLS with XLRDIntro to JSONUsing Web APIsLesson 2: Data in More Complex FormatsIntro to XMLXML Design PrinciplesParsing XMLWeb ScrapingParsing HTMLLesson 3: Data QualityWhat is Data Cleaning?Sources of Dirty DataMeasuring Data QualityA Blueprint for CleaningAuditing Validity Auditing AccuracyAuditing CompletenessAuditing ConsistencyAuditing UniformityLesson 4: Working with MongoDBData Modelling in MongoDBIntroduction to PyMongoField QueriesProjection QueriesGetting Data into MongoDBUsing mongoimportOperators like $gt, $lt, $exists, $regexQuerying Arrays and using $in and $all OperatorsChanging entries: $update, $set, $unsetLesson 5: Analyzing DataExamples of Aggregation Framework The Aggregation PipelineAggregation Operators: $match, $project, $unwind, $groupMultiple Stages Using a Given OperatorLesson 6: Case Study - OpenStreetMap DataUsing iterative parsing for large datafilesOpen Street Map XML OverviewExercises around OpenStreetMap dataFinal Project Instructions",Data Wrangling with MongoDB
https://www.classcentral.com/course/biochemistry-6074,"##
Biochemistry brings together all of the sciences to study the chemical and physical processes that occur in living organisms. It truly is the science of life.
As a scientific discipline in its own right, biochemistry has a major impact on all areas of the life sciences and biochemists are in high demand among employers.
Get an introduction to biochemistry
This free online biochemistry course will outline the background and history of the field, and its contemporary significance in the life sciences. It’s ideal if you enjoy biology and chemistry at school, and are thinking about studying or working in biochemistry as a distinct subject.
By the end of the course, you will be able to:

discuss how biochemistry brings together the natural sciences, to describe the chemical basis of living systems;
describe the events and scientists that have been significant during the historical development of biochemistry;
describe the seminal experiments that led to significant advances in biochemical knowledge;
discuss where biochemistry will play a role in future scientific advances, such as bioenergy, pharmaceuticals and synthetic biology.
recognise the wide range of jobs and career opportunities that become possible as a biochemistry graduate.

Learn with expert biochemists from UEA and beyond
Throughout the course, you will learn with a range of staff from UEA’s Schools of Biological Sciences and Chemistry, and find out how biochemistry is underpinning developments in the life sciences at the Norwich Research Park (NRP), and Norfolk and Norwich University Hospital. You will also get the chance to see interviews with people using biochemistry in a wide range of careers.
This course will be of particular interest to 15 to 19 year olds who are studying biology and chemistry, and considering further studies in biochemistry.
No prior formal qualifications are required for this course. With a clear explanation of relevant details, the material will be understandable to all with a basic interest and background knowledge in biology and chemistry.



            Read more",Biochemistry: the Molecules of Life
https://www.classcentral.com/course/block-programming-k12-educators-abstract-12360,"How do gamers cause things to happen when they hit buttons on their controller?  How does the computer keep track of gamer's scores? 

This class teaches the concepts of nested loops, events, and variables.  For each concept, we'll start by helping you connect real-world experiences you are already familiar with to the programming concept you are about to learn.  Next, through a cognitively scaffolded process we'll engage you in developing your fluency with problem solving with nested loops, events, and variables in a way that keeps frustration at a minimum.  

Along the way you will learn about the common challenges or ""bugs"" students have with these concepts as well as ways to help them find and fix those concepts.  You'll also be guided in running classroom discussions to help students develop deeper understanding of these concepts.

Finally, you'll learn how to develop low-frustration learning experiences for learning programming via Parsons' Problems., Additionally, you will create an email to either a counselor, administrator or parent organization to help them understand the value of all students taking computer science.
      


          Course Orientation

Abstractions Part 1
    -Examine how abstraction is manifested in everyday things and look at an example using song lyrics. Practice your programming skills and apply your knowledge of parameters when writing method definitions in Snap programs. Learn some common debugging challenges/tips and create your own abstraction assignment.

Abstractions Part 2
    -Revisit the concept of abstractions with some non-interactive practice problems. Go through some especially tricky problems in a collaborative activity to reinforce the idea that computers do what you tell them to do, not what you hope they do!  Finally, we'll learn about the fundamentals of recursion and how block-based graphical environments can make learning recursion visual and easier!

Lists Part 1
    -Define lists and discuss uses and representations of lists. Unscramble programs in Snap to better understand the possible operations you can perform with lists. Identify common challenges that students face, create your own assignment, and learn debugging tips.

Lists Part 2
    -Revisit the concept of lists with some non-interactive practice problems. Discuss the common mistakes students make while initializing lists and how to better distinguish between index and data. Find an educational video about how lists are used. 

Equity & Pedagogy
    -Explore issues of culturally relevant teaching as specific to computer science classrooms -- and some ideas for making our computing classes more culturally relevant.  Modify an unplugged activity to be more culturally relevant -- and get some additional ideas from reviewing the work of others!","Computational Thinking for K-12 Educators: Abstraction, Methods, and Lists"
https://www.classcentral.com/course/edx-introduction-to-nodejs-9597,"Have you ever wanted to create a full-fledged web application, beyond just a simple HTML page? In this course, you will learn how to set up a web server, interact with a database and much more!
This course will start off by teaching you the basics of Node.js and its core modules. You will then learn how to import additional modules and configure your project using npm. From there, you will learn how to use Express to set up a web server and how to interact with a MongoDB database using Mongoose. By the end of the course you will have created several real-world projects such as a web scraper, a blogging API, and a database migration script.



Module 0:Brief overview on the benefits of using Node.js and how Node.js is used in modern web development. Module 1:Introduction to setting up a Node.js project and importing modules using npm, as well as using core modules to make HTTP requests and manipulate the file system. The module labs will have you build a web crawler and a CSV file to JSON file converter. Module 2:Introduction to using the Express framework to set up a web server, as well as implementing API routing, middleware, and URL parameters.The module labs will have you build a REST API for a blog using Express.  Module 3:Introduction to setting up a MongoDB database and connecting it to a Node.js server.The module labs will have you build a REST API that stores data in a MongoDB database. You will also build a node script to migrate data from JSON files to a MongoDB database. Module 4:Introduction to using Mongoose to model database schemas and interact with MongoDB databases easier.The module labs will have you build relational queries using Mongoose. You will also reimplement your REST API from module 2 using Mongoose as a database library.",Introduction to NodeJS
https://www.classcentral.com/course/edx-cs50-s-introduction-to-artificial-intelligence-with-python-18122,"AI is transforming how we live, work, and play. By enabling new technologies like self-driving cars and recommendation systems or improving old ones like medical diagnostics and search engines, the demand for expertise in AI and machine learning is growing rapidly. This course will enable you to take the first step toward solving important real-world problems and future-proofing your career.
CS50’s Introduction to Artificial Intelligence with Python explores the concepts and algorithms at the foundation of modern artificial intelligence, diving into the ideas that give rise to technologies like game-playing engines, handwriting recognition, and machine translation. Through hands-on projects, students gain exposure to the theory behind graph search algorithms, classification, optimization, reinforcement learning, and other topics in artificial intelligence and machine learning as they incorporate them into their own Python programs. By course’s end, students emerge with experience in libraries for machine learning as well as knowledge of artificial intelligence principles that enable them to design intelligent systems of their own.
Enroll now to gain expertise in one of the fastest-growing domains of computer science from the creators of one of the most popular computer science courses ever, CS50. You’ll learn the theoretical frameworks that enable these new technologies while gaining practical experience in how to apply these powerful techniques in your work.



            Read more",CS50's Introduction to Artificial Intelligence with Python
https://www.classcentral.com/course/research-data-management-and-sharing-5758,"This course will provide learners with an introduction to research data management and sharing. After completing this course, learners will understand the diversity of data and their management needs across the research data lifecycle, be able to identify the components of good data management plans, and be familiar with best practices for working with data including the organization, documentation, and storage and security of data. Learners will also understand the impetus and importance of archiving and sharing data as well as how to assess the trustworthiness of repositories. 

Today, an increasing number of funding agencies, journals, and other stakeholders are requiring data producers to share, archive, and plan for the management of their data. In order to respond to these requirements, researchers and information professionals will need the data management and curation knowledge and skills that support the long-term preservation, access, and reuse of data. Effectively managing data can also help optimize research outputs, increase the impact of research, and support open scientific inquiry. After completing this course, learners will be better equipped to manage data throughout the entire research data lifecycle from project planning to the end of the project when data ideally are shared and made available within a trustworthy repository.

This course was developed by the Curating Research Assets and Data Using Lifecycle Education (CRADLE) Project in collaboration with EDINA at the University of Edinburgh. 

This course was made possible in part by the Institute of Museum and Library Services under award #RE-06-13-0052-13. The views, findings, conclusions or recommendations expressed in this Research Data Management and Sharing MOOC do not necessarily represent those of the Institute of Museum and Library Services.

Hashtag: #RDMSmooc
      


            Read more
          



          Understanding Research Data
    -This week introduces multiple types of research data in an array of contexts as well as important data management concepts including metadata and the research data lifecycle. We will also define the concept of data management, identify the roles and responsibilities of key stakeholders, and examine various data management tasks throughout the research data lifecycle. 

Data Management Planning
    -This week provides an overview of Data Management Plans (DMPs) including the components of good DMPs, the DMP policies of several funding agencies, and information on data management planning tools.  

Working with Data
    -This week is brought to you by EDINA and the Data Library at the University of Edinburgh and is presented by Sarah Jones from the Digital Curation Centre. Sarah will introduce strategies for organizing research data including versioning and file naming conventions as well as data file formatting and transformations. She will also discuss why documenting data and data citation are important. Finally, she will present issues involved in storing, securing, and backing up research data.   

Sharing Data
    -This week examines the benefits and challenges of sharing research data. We will also discuss how to protect confidentiality and how data ownership can affect data sharing. Finally, we will examine different types of access restrictions that may be placed on data as well as how to enable data sharing through the application of a standard license.

Archiving Data
    -During the final week of the course, we will examine the preservation needs of research data, introduce the concepts of authenticity and integrity, and identify the different types of metadata and their role in data discovery and reuse. We will also discuss the role of trustworthy repositories as well as how repositories demonstrate their trustworthiness through audit and certification. Finally, we will present key archival standards and best practices for ensuring data remains accessible and understandable for the long-term.",Research Data Management and Sharing
https://www.classcentral.com/course/big-data-management-6466,"Once you’ve identified a big data issue to analyze, how do you collect, store and organize your data using Big Data solutions?  In this course, you will experience various data genres and management tools appropriate for each.  You will be able to describe the reasons behind the evolving plethora of new big data platforms from the perspective of big data management systems and analytical tools.  Through guided hands-on tutorials, you will become familiar with techniques using real-time and semi-structured data examples.  Systems and tools discussed include: AsterixDB, HP Vertica, Impala, Neo4j, Redis, SparkSQL. This course provides techniques to extract value from existing untapped data sources and discovering new data sources.

At the end of this course, you will be able to:
 * Recognize different data elements in your own work and in everyday life problems
 * Explain why your team needs to design a Big Data Infrastructure Plan and Information System Design
 * Identify the frequent data operations required for various types of data
 * Select a data model to suit the characteristics of your data 
 * Apply techniques to handle streaming data
 * Differentiate between a traditional Database Management System and a Big Data Management System
 * Appreciate why there are so many data management systems
 * Design a big data information system for an online game company

This course is for those new to data science.  Completion of Intro to Big Data is recommended.  No prior programming experience is needed, although the ability to install applications and utilize a virtual machine is necessary to complete the hands-on assignments.  Refer to the specialization technical requirements for complete hardware and software specifications.

Hardware Requirements: 
(A) Quad Core Processor (VT-x or AMD-V support recommended), 64-bit; (B) 8 GB RAM; (C) 20 GB disk free. How to find your hardware information: (Windows): Open System by clicking the Start button, right-clicking Computer, and then clicking Properties; (Mac): Open Overview by clicking on the Apple menu and clicking “About This Mac.” Most computers with 8 GB RAM purchased in the last 3 years will meet the minimum requirements.You will need a high speed internet connection because you will be downloading files up to 4 Gb in size. 

Software Requirements: 
This course relies on several open-source software tools, including Apache Hadoop. All required software can be downloaded and installed free of charge (except for data charges from your internet provider). Software requirements include: Windows 7+, Mac OS X 10.10+, Ubuntu 14.04+ or CentOS 6+ VirtualBox 5+.
      


            Read more
          



          Introduction to Big Data Modeling and Management
    -Welcome to this course on big data modeling and management. Modeling and managing data is a central focus of all big data projects. In these lessons we introduce you to the concepts behind big data modeling and management and set the stage for the remainder of the course. 

Big Data Modeling
    -Modeling big data depends on many factors including data structure, which operations may be performed on the data, and what constraints are placed on the models. In these lessons you will learn the details about big data modeling and you will gain the practical skills you will need for modeling your own big data projects.

Big Data Modeling (Part 2)
    -These lessons continue to shed light on big data modeling with specific approaches including vector space models, graph data models, and more. 

Working With Data Models
    -Data models deal with many different types of data formats. Streaming data is becoming ubiquitous, and working with streaming data requires a different approach from working with static data. In these lessons you will gain practical hands-on experience working with different forms of streaming data including weather data and twitter feeds. 

Big Data Management: The ""M"" in DBMS
    -Managing big data requires a different approach to database management systems because of the wide variation in data structure which does not lend itself to traditional DBMSs. There are many applications available to help with big data management. In these lessons we introduce you to some of these applications and provide insight into how and when they might be appropriate for your own big data management challenges. 

Designing a Big Data Management System for an Online Game
    -In these lessons we give you the opportunity to learn about big data modeling and management using a fictitious online game called ""Catch the Pink Flamingo"".",Big Data Modeling and Management Systems
https://www.classcentral.com/course/prostate-cancer-8070,"Welcome to Understanding Prostate Cancer. My name is Ken Pienta, Professor of Urology and Oncology at the Johns Hopkins School of Medicine. I have been studying prostate cancer and treating patients with prostate cancer for over 25 years.
Over 1,000,000 men worldwide and 230,000 men in the United States are diagnosed with prostate cancer every year. Three hundred thousand men worldwide and 30,000 men in the US are dying from prostate cancer every year. As people live longer, the incidence of prostate cancer is rising worldwide and prostate cancer continues to be a major health problem. Thanks to years of dedication and commitment to research we’ve made enormous advances in the treatment of prostate cancer, But there is still a lot of work to be done. In this Understanding Prostate Cancer course, I will provide an introduction to the biology of prostate cancer as well as how it is identified and treated at various stages of the disease. 

I've put together this course in order to introduce you to the essentials of prostate cancer.

By the time you finish this course you'll be able to
	Define risk factors for prostate cancer
	Understand current prostate cancer screening guidelines
	Understand prostate cancer staging
	Understand treatments for localized prostate cancer
	Understand treatments for advanced prostate cancer
	Understand treatments to alleviate the symptoms caused by prostate cancer

This Understanding Prostate Cancer Course should be helpful to anyone who wants to develop a deeper understanding of prostate cancer biology and treatment.  It should be useful to students who are interested in a deeper understanding of the science of cancer. It should also be helpful to health care providers, data managers, and educators who wish to develop a better understanding of prostate cancer and how it affects individuals.  The course is not designed for patients seeking treatment guidance. For those of you who might be thinking about a career in cancer research or patient care, I hope this course will inspire you to pursue that path! The course is divided into five modules organized to facilitate learning.

I'm glad that you decided to join this course. I hope that you will develop a basic understanding of prostate cancer. I hope that it will help you in whatever field you work. If you are a student, I hope that what you learn here will help you begin a career in cancer biology research and contribute to the worldwide effort to save lives.
      


            Read more
          



          Welcome to Understanding Prostate Cancer
    -Welcome to Understanding Prostate Cancer

Biology, Incidence, and Risk Factors for Prostate Cancer
    -in this module you will be able to learn about the biology, incidents, and risk factors of prostate cancer, as well as prostate cancer screening.

How Prostate Cancer is Found, Diagnosed, and Staged
    -In this module you will be able to examine how prostate cancer is found, diagnosed, and staged.

How Localized Prostate Cancer is Treated
    -In this module you will be able to learn how localized prostate cancer is treated and the side effects of treatment.

Treatment of Metastatic Prostate Cancer
    -In this module, you will be able to learn how advanced prostate cancer is treated. This includes chemotherapy, immunotherapy, and hormone therapy.

Other Treatments to Support the Health of Prostate Cancer Patients
    -In this module, you will learn supportive treatments for patients of prostate cancer.",Understanding Prostate Cancer
https://www.classcentral.com/course/cloud-applications-part1-2738,"Welcome to the Cloud Computing Applications course, the first part of a two-course series designed to give you a comprehensive view on the world of Cloud Computing and Big Data! 

In this first course we cover a multitude of technologies that comprise the modern concept of cloud computing. Cloud computing is an information technology revolution that has just started to impact many enterprise computing systems in major ways, and it will change the face of computing in the years to come.

We start the first week by introducing some major concepts in cloud computing, the economics foundations of it and we introduce the concept of big data. We also cover the concept of software defined architectures, and how virtualization results in cloud infrastructure and how cloud service providers organize their offerings. In week two, we cover virtualization and containers with deeper focus, including lectures on Docker, JVM and Kubernates. We finish up week two by comparing the infrastructure as a service offering by the big three: Amazon, Google and Microsoft. 
Week three moves to higher level of cloud offering, including platform as a service, mobile backend as a service and even serverless architectures. We also talk about some of the cloud middleware technologies that are fundamental to cloud based applications such as RPC and REST, JSON and load balancing. Week three also covers metal as a service (MaaS), where physical machines are provisioned in a cloud environment. 
Week four introduces higher level cloud services with special focus on cloud storage services. We introduce Hive, HDFS and Ceph as pure Big Data Storage and file systems, and move on to cloud object storage systems, virtual hard drives and virtual archival storage options. As discussion on Dropbox cloud solution wraps up week 4 and the course.
      


            Read more
          



          Course Orientation 
    -You will become familiar with the course, your classmates, and our learning environment. The orientation will also help you obtain the technical skills required for the course.

Module 1: Introduction to Cloud Computing
    -Welcome to the first module of the course! In this module, we will introduce the concept of cloud computing and the economical foundations that make cloud computing make sense. We then introduce some fundamental concepts including software defined architectures and cloud services. We end the module by introducing you to the low level cloud computing service offered, infrastructure as a service. 

Module 2: Foundations: Containers, Virtual Machine, JVM
    -Welcome to the second module! Here, we cover virtualization and containers with deeper focus, including lectures on Docker, JVM and Kubernates. We finish up week two by comparing the infrastructure as a service offering by the big three: Amazon, Google and Microsoft. 


Module 3: MAAS, PAAS, Web Services
    -Welcome to the third module, where we introduce Metal as a Service (provision real hardware in the cloud), Platform as a Service (provide a platform to run user code on) and Web Middleware as the glue technology that empowers cloud computing. 

Module 4: Storage: Ceph, SWIFT, HDFS, NAAS, SAN, Zookeeper
    -Welcome to the last and final module of the cloud computing course! So far we have covered various methods of running certain computations on the cloud. Now it's time to focus on data storage in the clouds. In this module, we introduce big data and cloud file systems such as HDFS and Ceph, cloud object stores such has Open Stack Swift or Amazon S3, virtualized block storage devices such as Amazon EBS and archival storage options like the Amazon Glacier. Finally, we conclude the module with introducing the DropBox cloud API that enables developers to quickly integrate cloud storage options in their applications. 

Course Conclusion
    -You will find out where to go next after completing this course and be able to share any thoughts you have on this course experience.","Cloud Computing Applications, Part 1: Cloud Systems and Infrastructure"
https://www.classcentral.com/course/metadata-732,"If you use nearly any digital technology, you make use of metadata. Use
an ATM today? You interacted with metadata about your account. Searched
for songs in iTunes or Spotify? You used metadata about those songs. We
use and even create metadata constantly, but we rarely realize it. Metadata
-- or data about data -- describes real and digital objects, so that those
objects may be organized now and found later.

Metadata is a tool that enables the information age functions performed
by humans as well as those performed by computers. Metadata is important
to many fields, particularly Computer Science; but this course is not purely
a Computer Science course. This course approaches Metadata from the perspective
of Information Science, which is a broad interdisciplinary field that studies
how people create and manage information.




          Unit 1: Organizing Information
Unit 2: Dublin Core
Unit 3: How to Build a Metadata Schema
Unit 4: Alphabet Soup: Metadata Schemas That You (Will) Know and Love
Unit 5: Metadata for the Web
Unit 6: Metadata for Networks
Unit 7: How to Create Metadata
Unit 8: How to Evaluate Metadata",Metadata: Organizing and Discovering Information
https://www.classcentral.com/course/nuclearscience-479,"The course, “A Look at Nuclear Science and Technology” is aimed at scientifically inclined individuals who want to learn more about nuclear energy and the nuclear power industry. It will address subjects such as: What is nuclear energy? What is its history? Who are its heroes? Why is it controversial? How do nuclear power plants work? What about nuclear weapons? What are the stereotypes and misconceptions? We expect many students who finish this class to want to go on for further study in a closely related field.
      


          “A Look at Nuclear Science and Technology” is an overview course that provides broad subject-area coverage to introduce students to application of theory to practical aspects of nuclear science and technology in the world today with special emphasis on commercial nuclear power. The course will begin with a general overview of nuclear physics and the practical applications covered by the field of nuclear engineering. The majority of the course will focus on the theory, design and operation of commercial nuclear power reactors. The course will also touch on contemporary issues regarding nuclear power generation including: the nuclear fuel cycle, the economics of nuclear power, and nuclear non-proliferation.The course will begin with a grand tour of the commercial nuclear fuel cycle and power reactors so the student will have some perspective before delving into the theory that is important to understanding the unique aspects of nuclear energy. The course then will return to the fundamentals of basic nuclear physics, reactor physics, energy removal and power conversion to prepare students for in-depth looks at the theory and function of commercial nuclear power reactors.This course is intended for students who have had little to no academic instruction in nuclear engineering. Some of my incentives to teach this class are (1) to stimulate interest and excitement about nuclear science and technology, and (2) to create a more informed citizenry on the subject of nuclear energy utilization in the future. Introduction – A Grand Tour of the Nuclear Fuel CycleAtomic and Nuclear Physics – The Einstein ConnectionNuclear Reactions and Radiation – The Life and Trials of Neutrons and the Things They CreateRadiation and Radiation Protection – Radiation and RealismFission Reactor Basics – Links in the Chain ReactionOverview of Power Reactors and Nuclear Systems – Over 440 in the World and GrowingNuclear Safety –Should I be frightened?Radiation and Radioisotopes in the World Today",A Look at Nuclear Science and Technology
https://www.classcentral.com/course/solidsciencemethods-2231,"Can we still put our trust in the social and behavioural sciences? Cases of social scientists exposed as frauds keep turning up and many disciplines are under fire for their failure to replicate key results. No wonder the integrity of our field is being questioned; sloppy science is starting to seem the norm rather than the exception!
As social scientist Daniel Kahneman suggests, it is time for the social sciences to clean house. We will try to answer his call with a series of courses that explain the scientific principles of research and how methodology and statistics can help to ensure that research is solid. We will explain the basics and put them into context by showing you how things can go horribly wrong when methods and statistics are abused. And we will teach you how to recognize these questionable research practices - after the fact - in published articles.
This first course, Solid Science: Research Methods (in the Social and Behavioral Sciences), will cover the fundamental principles of science, some history and philosophy of science, research designs, measurement, sampling and ethics. This basic material will lay the groundwork for the more technical stuff in subsequent courses. The course is comparable to a university level introductory course on quantitative research methods in the social sciences, but has a strong focus on research integrity. We will use examples from sociology, political sciences, educational sciences, communication sciences and psychology.
Please note that this course will focus on quantitative methods, qualitative methods will be treated in a separate course.



            Read more
          



This first course will cover the fundamental principles of science, some history and philosophy of science, research designs, measurement, sampling and ethics. This basic material will lay the groundwork for the more technical stuff in subsequent courses. The course is comparable to a university level introductory course on quantitative research methods in the social sciences, but has a strong focus on research integrity. We will use examples from sociology, political sciences, educational sciences, communication sciences and psychology.
Week 1: Origins of the scientific method
non-scientific and scientific ways to gain knowledge, types of scientific claims history of the scientific method (classical period, enlightenment, modern science) philosophical considerations: ontology and epistemology approaches to science (qualitative versus quantitative) warm-up assignments (not graded)Week 2: The scientific method the empirical cycle and testing hypotheses scientific criteria and causality threats to internal validity variables of interest and disinterest small assignments (graded)Week 3: Research designs true experiments, manipulation and randomization experimental, quasi-experimental, correlational designs factorial and repeated measures designs matching and ecological validity small assignments & paper on week 1 & 2 due (graded)Week 4: Measurement variables and operationalizations measurement levels and types, validity and reliability surveys, questionnaires and tests, items and scales other forms of measurement small assignments (graded)Week 5: Sampling threats to external validity random and non-random sampling random sampling methods sampling bias and error, sample size assignments & paper on on week 3 & 4 due (graded)Week 6: Practice, ethics & integrity research protocols and data management ethics towards participants and research integrity review and publication process questionable research practicessmall assignments (graded)Week 7: Study weektime to catch up and study for the final examtime to ask your final questionstime to work on last paperWeek 8: Exam weekpaper on week 5 & 6 due (graded), final exam (graded) and course evaluation",Solid Science: Research Methods
https://www.classcentral.com/course/recreational-math-10736,"Get an introduction to the fun, games and puzzles of recreational math
Math doesn’t have to be boring or difficult. In fact learning about recreational math can not only enhance your creative thinking but it can be exciting and useful in daily life.
During this course you will challenge your brain and have fun while learning about the math of various entertaining subjects such as magic squares, puzzles and games. You will also learn about famous recreational mathematicians.
The course is designed for anyone who enjoys popular science, recreational maths and solving maths puzzles and crosswords. There are no particular requirements. It will be especially useful for parents or teachers looking to inspire a love of math and do fun math activities with young people.","An Introduction to Recreational Math: Fun, Games and Puzzles"
https://www.classcentral.com/course/computational-thinking-problem-solving-12278,"Computational thinking is the process of approaching a problem in a systematic manner and creating and expressing a solution such that it can be carried out by a computer.  But you don't need to be a computer scientist to think like a computer scientist!  In fact, we encourage students from any field of study to take this course.  Many quantitative and data-centric problems can be solved using computational thinking and an understanding of computational thinking will give you a foundation for solving problems that have real-world, social impact.   

In this course, you will learn about the pillars of computational thinking, how computer scientists develop and analyze algorithms, and how solutions can be realized on a computer using the Python programming language.  By the end of the course, you will be able to develop an algorithm and express it to the computer by writing a simple Python program. 

This course will introduce you to people from diverse professions who use computational thinking to solve problems. You will engage with a unique community of analytical thinkers and be encouraged to consider how you can make a positive social impact through computational thinking.
      


          Pillars of Computational Thinking
    -Computational thinking is an approach to solving problems using concepts and ideas from computer science, and expressing solutions to those problems so that they can be run on a computer. As computing becomes more and more prevalent in all aspects of modern society -- not just in software development and engineering, but in business, the humanities, and even everyday life -- understanding how to use computational thinking to solve real-world problems is a key skill in the 21st century. 

Computational thinking is built on four pillars: decomposition, pattern recognition, data representation and abstraction, and algorithms. This module introduces you to the four pillars of computational thinking and shows how they can be applied as part of the problem solving process.

Expressing and Analyzing Algorithms
    -When we use computational thinking to solve a problem, what we’re really doing is developing an algorithm: a step-by-step series of instructions. Whether it’s a small task like scheduling meetings, or a large task like mapping the planet, the ability to develop and describe algorithms is crucial to the problem-solving process based on computational thinking. This module will introduce you to some common algorithms, as well as some general approaches to developing algorithms yourself. These approaches will be useful when you're looking not just for any answer to a problem, but the best answer. After completing this module, you will be able to evaluate an algorithm and analyze how its performance is affected by the size of the input so that you can choose the best algorithm for the problem you’re trying to solve.

Fundamental Operations of a Modern Computer
    -Computational thinking is a problem-solving process in which the last step is expressing the solution so that it can be executed on a computer. However, before we are able to write a program to implement an algorithm, we must understand what the computer is capable of doing -- in particular, how it executes instructions and how it uses data. This module describes the inner workings of a modern computer and its fundamental operations.  Then it introduces you to a way of expressing algorithms known as pseudocode, which will help you implement your solution using a programming language.

Applied Computational Thinking Using Python
    -Writing a program is the last step of the computational thinking process. It’s the act of expressing an algorithm using a syntax that the computer can understand. This module introduces you to the Python programming language and its core features. Even if you have never written a program before -- or never even considered it -- after completing this module, you will be able to write simple Python programs that allow you to express your algorithms to a computer as part of a problem-solving process based on computational thinking.",Computational Thinking for Problem Solving
https://www.classcentral.com/course/pla-3538,"Everyone involved in higher
education has questions. Students want to know how they’re doing and which
classes they should take. Faculty members want to understand their students’
backgrounds and to learn whether their teaching techniques are effective. Staff
members want to be sure the advice they provide is appropriate and find out whether
college requirements accomplish their goals. Administrators want to explore how
all of their students and faculty are doing and to anticipate emerging changes.
The public wants to know what happens in college and why.
Everyone has questions. We have
the chance to help them find answers. 
Learning analytics is about using
data to improve teaching and learning. You might wonder why there’s suddenly so
much conversation about this previously invisible topic.[1] After
all, institutions of higher education have maintained careful records of
student progress and outcomes for more than a century.  They have always been ready to provide a
transcript for every student, reporting all courses taken, grades received,
honors awarded, and degrees conferred. Institutional research offices provide
summaries of these student records to campus leaders, accreditation agencies,
and the public. Why learning analytics now?
Two major trends drive the
current emergence of learning analytics. First, data informing teaching and
learning are increasingly extensive and accessible. Second, innovative new analytic
approaches to digesting, visualizing, and acting on these data emerge every day.What’s special about this
course?Practical Learning Analytics has a specific goal: to help us
collectively ponder learning analytics in a concrete way. To keep it practical,
we will focus on using traditional student record data, the kinds of data every
campus already has. To make it interesting, we will address questions raised by
an array of different stakeholders, including campus leaders, faculty, staff,
and especially students. To provide analytic teeth, each analysis we discuss
will be supported by both realistic data and sample code.Who should take this course?Practical Learning Analytics should provide something for anyone
interested in higher education: current, former, or future students, policy
makers, academic advisors, data scientists, university administrators, ed-tech
entrepreneurs, faculty members, even the curious public. This course has been designed to
work for a wide variety of audiences. Its structure is modeled on something
everyone can enjoy: a smörgåsbord –
we’re going to treat the class like one big meal. After we set the table, each
guest may wander the room, taking either a small plate or a full entrée from a
series of courses we offer up. When everyone is full, we’ll gather again over
coffee to hear what people thought. There is no defined way to pursue such a
meal – each diner chooses what’s right for them. And there is no defined way to
take this course – every student must choose what’s right for them.
The course will open with a two
week introduction, exploring the landscape of learning analytics in higher
education and setting the table for the main event. This is followed by a four
week meal during which participants may choose among an array of five different
topics, each presented at two levels: a small plate providing a quick
introduction, or a more filling entrée. Those choosing small plates will still have
the opportunity to work with realistic data, analyzing it with code we provide.
Those choosing entrées will make creative contributions of their own: writing
new code for analysis or visualization of the data we provide, perhaps bringing
in data of their own. After this month of exploration, the final two weeks will
feature a concluding coffee. In them, we’ll review what students learned while
wandering through all five courses, share the best things class members
invented, and provide some concluding remarks.
[1]
Try searching for “learning
analytics” in the Google Ngram server…nothing comes up!



            Read more
          



The menu:
Our smörgåsbord will include five
major courses, each offered in both small plate and full entrée sizes. Each
course will provide both a realistic data set and a set of example R code which
can be used to conduct the basic analyses we will discuss. Small plate users
will watch a few video lectures about their topic, complete a short quiz on the
content, download the data and R code, and run an analysis to answer some simple
questions. Users who choose the entrée will go further, extending the code in
both instructor-specified and student defined ways. The really ambitious will
repeat and extend these analyses using their own, local data. An introductory
video for each course will outline what it includes and provide some sense of
what users at each level will experience.
To keep the focus on the
practical, the five courses are designed to explore analyses of interest to
different audiences: students, instructors, department leaders, campus-wide
leaders, and course designers.
LA for students: How to become the student you
want to be? Exploring courses, majors, comparing your performance to others
realistically and richly.LA for instructors: Performance prediction in a
course: up to and including grade penalties, placement analyses, performance
disparities and their correlates, course-to-course correlationLA for department leaders: Persistence in a
major, first through short course sequences and then from intention to degreeLA for college/university leaders:
Characterizing the student experience, program evaluation – observing
differences and probing impact, capturing more and better information,
comparing the experience of different groups.LA for course designers: What affects
performance – behavior measurement, establishing the evidence basis for advice,
then acting to affect performance with technological and human behavior change
techniques, putting real-time data to work – early warning systems and
personalized communication",Practical Learning Analytics
https://www.classcentral.com/course/basic-data-processing-visualization-pyth-13494,"This is the first course in the four-course specialization Python Data Products for Predictive Analytics, introducing the basics of reading and manipulating datasets in Python. In this course, you will learn what a data product is and go through several Python libraries to perform data retrieval, processing, and visualization. 

This course will introduce you to the field of data science and prepare you for the next three courses in the Specialization: Design Thinking and Predictive Analytics for Data Products, Meaningful Predictive Modeling, and Deploying Machine Learning Models. At each step in the specialization, you will gain hands-on experience in data manipulation and building your skills, eventually culminating in a capstone project encompassing all the concepts taught in the specialization.
      


          Week 1:  Introduction to Data Products
    -This week, we will go over the syllabus and set you up with the course materials and software. We will introduce you to data products and refresh your memory on Python and Jupyter notebooks.

Week 2: Reading Data in Python
    -This week, we will learn how to load in datasets from CSV and JSON files. We will also practice manipulating data from these datasets with basic Python commands.

Week 3: Data Processing in Python
    -This week, our goal is to understand how to clean up a dataset before analyzing it. We will go over how to work with different types of  data, such as strings and dates.

Week 4: Python Libraries and Toolkits
    -In this last week, we will get a sense of common libraries in Python and how they can be useful. We will cover data visualization with numpy and MatPlotLib, and also introduce you to the basics of webscraping with urllib and BeautifulSoup.

Final Project
    -Create your own Jupyter notebook with a dataset of your own choosing and practice data manipulation. Show off the skills you've learned and the libraries you know about in this project. We hope you enjoyed the course, and best of luck in your future learning!",Basic Data Processing and Visualization
https://www.classcentral.com/course/edx-visualizing-data-with-python-12530,"""A picture is worth a thousand words"". We are all familiar with this expression. It especially applies when trying to explain the insights obtained from the analysis of increasingly large datasets. Data visualization plays an essential role in the representation of both small and large-scale data. 
One of the key skills of a data scientist is the ability to tell a compelling story, visualizing data and findings in an approachable and stimulating way. 
In this course, you will learnhow to leverage a software tool to visualize datathat will also enable you to extract information, better understand the data, and make more effective decisions. 
You can start creating your own data science projects and collaborating with other data scientists using IBM Watson Studio. When you sign up, you get free access to Watson Studio. Start now and take advantage of this platform.



Module 1 -Introduction to Visualization Tools

Introduction to Data Visualization
Introduction to Matplotlib
Basic Plotting with Matplotlib
Dataset on Immigration to Canada
Line Plots

Module 2 -Basic Visualization Tools

Area Plots
Histograms
Bar Charts

Module 3 -Specialized Visualization Tools

Pie Charts
Box Plots
Scatter Plots
Bubble Plots

Module 4 -Advanced Visualization Tools

Waffle Charts
Word Clouds
Seaborn and Regression Plots

Module 5 -Creating Maps and Visualizing Geospatial Data

Introduction to Folium
Maps with Markers
Choropleth Maps",Visualizing Data with Python
https://www.classcentral.com/course/gis-mapping-spatial-analysis-capstone-13456,"In this capstone course, you will apply everything you have learned by designing and then completing your own GIS project. You will plan out your project by writing a brief proposal that explains what you plan to do and why. You will then find data for a topic and location of your choice, and perform analysis and create maps that allow you to try out different tools and data sets. The results of your work will be assembled into an Esri story map, which is a web site with maps, images, text, and video. The goal is for you to have a finished product that you can share, and that demonstrates what you have learned.
      


          Introduction to Story Maps

Data Discovery and Project Proposal

Data Acquisition and Preparation

Spatial Analysis

Map Design

Story Map","GIS, Mapping, and Spatial Analysis Capstone"
https://www.classcentral.com/course/global-health-human-animal-ecosystem-8336,"The University of Geneva, Institute Pasteur, University of Montreal and Centre Virchow-Villermé/University Paris Descartes welcome you to this MOOC on ""Global Health at the Human-Animal-Ecosystem Interface""!

Over the next 8 weeks, you will explore and learn about some of the major and current Global Health Challenges at the Human-Animal-Ecosystem Interface: zoonotic emerging infections (e.g. Ebola, Nipah, MERS, Avian Influenza), antimicrobial resistance, neglected tropical diseases (e.g. rabies, leishmaniasis, zoonotic TB), snakebite and other human-animal conflicts etc. You will learn new concepts from the field of epidemiology, social anthropology, disease ecology, veterinary sciences, global health policy etc. and approaches such as One Health, Eco-Health and Planetary Health. Also, you will learn about innovative tools and frameworks used to study and tackle some of these Global Health challenges of the Sustainable Development Goals era.

This MOOC proposes you a dynamic, international and interdisciplinary programme based on the One Health approach (human-animal-environmental dimensions) and involving more than 30 top experts from more than 20 academic and research institutions and international organisations based in Geneva, Paris, Montreal and the world. Policy makers from the World Health Organisation, clinicians from the University Hospitals of Geneva, epidemiologists from Institut Pasteur etc. will share with you their knowledge and experiences all along this MOOC. Video-lectures have been filmed in different parts of the world and settings (from the field to the lab and office) and will be combined with the latest open readings and interactive activities in the discussion forum, video-conferences etc.

This MOOC keeps evolving and enriching actively over time and two new sections on ""Health Benefits at the Human-Animal-Ecosystem Interface"" and ""Management of Ecosystems under Global Changes: Implication for Human Health"" have been added in May 2018. This latter section was developed in close collaboration with experts from World Health Organisation and the Convention on Biological Diversity and is introduced by Dr. Tedros Adhanom Ghebreyesus, WHO Director-General. 

The development of this MOOC was led by Dr. Rafael Ruiz de Castañeda, Dr. Isabelle Bolon and Prof. Antoine Flahault from the Institute of Global Health of the University of Geneva. The list of instructors is completed by Prof. Arnaud Fontanet (Institut Pasteur) and Prof. André Ravel (Faculty of Veterinary Medicine, University of Montreal). 

Watch our teaser here and let’s get started!
https://youtu.be/WT7-cC21uLU?list=PLnZ     (with subtitles in French and in Chinese)
      


            Read more
          



          Welcome! Key information on the MOOC
    -In this Module, we provide you a general description of the MOOC, including some videos and readings that give you an overview of the content, evaluation and activities. This MOOC is based on a highly interdisciplinary and international approach to health, please check the huge diversity of experts involved (see in the Syllabus & list of Experts). Learners following this MOOC have had opportunities to participate in a number of activities (join a workshop in Geneva and Basel for free, become teachers of African refugees, win a travel grant to attend a conference in Geneva,..). We shared with you these activities at the end of this introductory section. New opportunities such as these will be proposed through this MOOC in the future, we will keep you posted. Let's get started and do not hesitate to ask any doubts in the forum of the course! We will be pleased to help you!

Global Health at the Human-Animal-Ecosystem Interface: The Need for Intersectoral Approaches (Section 1)
    -In this section of the course, you will learn about some of the major current Global Health challenges at the Human-Animal-Ecosystem Interface and the need for cross-sectoral approaches to health, including One Health, Eco-Health and Planetary Health. Please watch video ""Introduction to Section 1"" for a more detailed description.

Emerging Infectious Diseases (Section 2)  
    -This section focuses on the current global threat posed by zoonotic emerging infections and the tools and challenges for studying and controlling them. Please watch video ""Introduction to Section 2"" for a more detailed description. Note that many of the topics addressed here (bushmeat, bird migration and avian influenza, etc) are re-discussed in the section 8 of the MOOC.

Antimicrobial Resistance &  Zoonotic Foodborne Infectious Diseases (Section 3)
    -Antimicrobial resistance is a current top priority in the Global Health agenda. In this section, you will learn about its global burden and the challenges for its control from the national to the global levels based on cross-sectoral approaches to health. Please watch video ""Introduction to Section 3"" for a more detailed description.

Zoonotic Neglected Infectious Diseases (Section 4)   
    -Neglected Tropical Diseases are not neglected in this MOOC and you will have here the opportunity to learn about their common determinants and the interventions and challenges to fight them. Please watch video ""Introduction to Section 4"" for a more detailed description.

Conflicts & Injuries (Section 5)  
    -So far we have mainly focused on zoonotic infections, but human-animal interactions can also involve other threats for human health. This section focuses on these conflicts and injuries, paying particular attention to snakebite and the current snakebite crisis. Please watch video ""Introduction to Section 5"" for a more detailed description.

 Innovation & Opportunities (Section 6)         
    -In this section, we propose you to learn about some innovative approaches, tools, frameworks etc. that offer interesting opportunities for application in Global Health at the Human-Animal-Ecosystem Interface: Citizen Science, Crowdsroucing, Digital Epidemiology and Big Data etc. Please watch video ""Introduction to Section 6"" for a more detailed description.

Health Benefits at the Human-Animal-Ecosystem Interface (Section 7)
    -So far, in this course we have mainly focused on health risks. In this section, we have also tried to bring the positive impacts on health that emerge from human-animal interactions and more widely from interactions with ecosystems. You will learn about the notion of Environmental Health from a historical perspective and the importance of ecosystem services for human health, including the benefits on health of owning companion animals. Please watch video ""Introduction to Section 7"" for a more detailed description.

Management of Ecosystems under Global Changes: Implication for Human Health (section 8) 
    -This section was created in close collaboration with the World Health Organization (WHO) and the Convention on Biological Diversity (CBD) with the goal of highlighting the importance of sustainable management of ecosystems for human health, particularly in the context of climate change. You will be introduced to core issues, challenges and opportunities at the intersection of food systems -including both agricultural biodiversity and sustainable fisheries- and human health against a backdrop of global environmental change. Differential gender impacts are also considered, with a dedicated lecture on the theme and as a cross-reference in other sub-themes. This section is introduced by the Director-General of WHO Dr. Tedros Adhanom Ghebreyesus and by Cristina Romanelli from the Secretariat for the Convention on Biological Diversity.

    Final Quiz",Global Health at the Human-Animal-Ecosystem Interface
https://www.classcentral.com/course/edx-discrete-time-signals-and-systems-part-2-frequency-domain-3191,"Technological innovations have revolutionized the way we view and interact with the world around us. Editing a photo, re-mixing a song, automatically measuring and adjusting chemical concentrations in a tank: each of these tasks requires real-world data to be captured by a computer and then manipulated digitally to extract the salient information. Ever wonder how signals from the physical world are sampled, stored, and processed without losing the information required to make predictions and extract meaning from the data?
Students will find out in this rigorous mathematical introduction to the engineering field of signal processing: the study of signals and systems that extract information from the world around us. This course will teach students to analyze discrete-time signals and systems in both the time and frequency domains. Students will learn convolution, discrete Fourier transforms, the z-transform, and digital filtering. Students will apply these concepts in interactive MATLAB programming exercises (all done in browser, no download required).
Part 1 of this course analyzes signals and systems in the time domain. Part 2 covers frequency domain analysis.
Prerequisites include strong problem solving skills, the ability to understand mathematical representations of physical systems, and advanced mathematical background (one-dimensional integration, matrices, vectors, basic linear algebra, imaginary numbers, and sum and series notation). Part 1 is a prerequisite for Part 2. This course is an excerpt from an advanced undergraduate class at Rice University taught to all electrical and computer engineering majors.



            Read more","Discrete Time Signals and Systems, Part 2: Frequency Domain"
https://www.classcentral.com/course/data-science-google-analytics-11667,"Get started with data science by learning to use Google Analytics
In a world where decisions are increasingly data-driven, an understanding of data science can take you a long way. On this course, you will learn how to be the bridge in your organisation between analytics experts and other functions.
You’ll be introduced to data science through Google Analytics, an industry standard. You’ll learn how to create and use tracking codes, and to view the types of data it produces. By the end of this data science course, you’ll have new practical skills you can use immediately and will be ready to take your next steps in data science.
This data science and Google analytics course is for anyone working in an organisation that does business online. It would also appeal to young people looking for their first job, as these in-demand data science skills will give you a strong head start.",Introduction to Data Science with Google Analytics: Bridging Business and Technical Experts
https://www.classcentral.com/course/machine-learning-applied-15163,"This course is for professionals who have heard the buzz around machine learning and want to apply machine learning to data analysis and automation. Whether finance, medicine, engineering, business or other domains, this course will introduce you to problem definition and data preparation in a machine learning project.

By the end of the course, you will be able to clearly define a machine learning problem using two approaches. You will learn to survey available data resources and identify potential ML applications. You will learn to take a business need and turn it into a machine learning application. You will prepare data for effective machine learning applications.

This is the first course of the Applied Machine Learning Specialization brought to you by Coursera and the Alberta Machine Intelligence Institute.
      


          Introduction to Machine Learning Applications
    -This week, you will learn about what machine learning (ML) actually is, contrast different problem scenarios, and explore some common misconceptions about ML. You will apply this knowledge by identifying different components essential to a machine learning business solution.

Machine Learning in the Real World
    -This week, you will learn how to translate a business need into a machine learning problem. We'll walk through some applied examples so you can get a feel for what makes a well-defined question for your QuAM. Narrowing down your question and making sure you have the data necessary to learn is critical to ML success!

Learning Data
    -This week is all about data. You will learn about data acquisition and understand the various sources of training data. We'll talk about how much data you need and what pitfalls might arise, including ethical issues.

Machine Learning Projects 
    -This week you will learn about the Machine Learning Process Lifecycle (MLPL). After understanding the definitions and components of the MLPL you will analyze the application of the MLPL on a case study.",Introduction to Applied Machine Learning
https://www.classcentral.com/course/inquirytechniques-955,"A revolution is underway in science classrooms. The demands of the new workplace and the ready access to information afforded by new technologies have radically changed the way we define a scientifically literate society. More than ever teachers need professional development that provides them with the resources they need and empowers them to take the action required to build classrooms where the next generation of scientifically literate students will flourish. Inquiry Science Learning: Perspectives and Practices consists of four courses, each designed to address a different strand in the development of skills teachers need to meet the demands of their career, including the following.Science LeadershipTechniques for SuccessScience ContentStudent-Centered InquiryIn this second course we will focus on helping teachers master techniques and strategies that create a learning environment that will empower students and enhance their mastery of science content and skills.



Week 1: Standards Dissection:Participants will learn how to analyze the verbiage of their science standards in order to turn the concepts within into meaningful learning experiences
Week 2: Assessment That Informs Teaching:Participants will learn how to evaluate and develop better multiple choice assessment items to provide useable dataWeek 3: Questioning Strategies:Participant will learn how to construct rich questions that will encourage all learners to participate in the inquiry processWeek 4: Prepared Environment:Participants will learn easy ways to change their classroom environment in order to promote independent exploration",Inquiry Science Learning: Perspectives and Practices 2 - Techniques for Success
https://www.classcentral.com/course/introduction-gis-mapping-13457,"Get started learning about the fascinating and useful world of geographic information systems (GIS)! In this first course of the specialization GIS, Mapping, and Spatial Analysis, you'll learn about what a GIS is, how to get started with the software yourself, how things we find in the real world can be represented on a map, how we record locations using coordinates, and how we can make a two-dimensional map from a three-dimensional Earth. In the course project, you will create your own GIS data by tracing geographic features from a satellite image for a location and theme of your choice. This course will give you a strong foundation in mapping and GIS that will give you the understanding you need to start working with GIS, and to succeed in the other courses in this specialization.

This course is for anyone who wants to learn about mapping and GIS. You don't have to have any previous experience - just your curiosity! The course includes both practical software training and explanations of the concepts you need to know to make informed decisions as you start your journey to becoming a GIS analyst.

You will need a Windows computer with ArcGIS Desktop installed.
      


          What is a GIS?

Introduction to ArcGIS

Mapping the real world with vector and raster data

Mapping Locations with Coordinate Systems

Flattening the Earth with Map Projections

Project: Creating Your Own Data",Introduction to GIS Mapping
https://www.classcentral.com/course/udacity-machine-learning-1-supervised-learning-1847,"This is the first course in the 3-course Machine Learning Series and is offered at Georgia Tech as CS7641.
Please note that this is first course is different in structure compared to most Udacity CS courses. There is a final project at the end of the course, and there are no programming quizzes throughout this course.
This course covers Supervised Learning, a machine learning task that makes it possible for your phone to recognize your voice, your email to filter spam, and for computers to learn a bunch of other cool stuff.
Supervised Learning is an important component of all kinds of technologies, from stopping credit card fraud, to finding faces in camera images, to recognizing spoken language. Our goal is to give you the skills that you need to understand these technologies and interpret their output, which is important for solving a range of data science problems. And for surviving a robot uprising.
Series Information: Machine Learning is a graduate-level series of 3 courses, covering the area of Artificial Intelligence concerned with computer programs that modify and improve their performance through experiences.

Machine Learning 1: Supervised Learning (this course)
Machine Learning 2: Unsupervised Learning
Machine Learning 3: Reinforcement Learning

If you are new to Machine Learning, we recommend you take these 3 courses in order.
The entire series is taught as a lively and rigorous dialogue between two eminent Machine Learning professors and friends: Professor Charles Isbell (Georgia Tech) and Professor Michael Littman (Brown University).
Why Take This Course?
In this course, you will gain an understanding of a variety of topics and methods in Supervised Learning. Like function approximation in general, Supervised Learning prompts you to make generalizations based on fundamental assumptions about the world.
Michael: So why wouldn't you call it ""function induction?""Charles: Because someone said ""supervised learning"" first.
Topics covered in this course include: Decision trees, neural networks, instance-based learning, ensemble learning, computational learning theory, Bayesian learning, and many other fascinating machine learning concepts.
In your final project, you will explore important techniques in Supervised Learning, and apply your knowledge to analyze how algorithms behave under a variety of circumstances.
Prerequisites and Requirements
A strong familiarity with Probability Theory, Linear Algebra and Statistics is required. An understanding ofIntro to Statistics, especially Lessons 8, 9 and 10, would be helpful.
Students should also have some experience in programming (perhaps through Introduction to CS) and a familiarity with Neural Networks (as covered in Introduction to Artificial Learning).
See the Technology Requirements for using Udacity



            Read more
          



Lesson 0: Machine Learning is the ROX

Definition of Machine Learning
Supervised learning
Induction and deduction
Unsupervised learning
Reinforcement learning

Lesson 1: Decision Trees

Classification and Regression overview
Classification learning
Example: Dating
Representation
Decision trees learning
Decision tree expressiveness
ID3 algorithm
ID3 bias
Decision trees and continuous attributes

Lesson 2: Regression and Classification

Regression and function approximation
Linear regression and best fit
Order of polynomial
Polynomial regression
Cross validation

Lesson 3: Neural Networks

Artificial neural networks
Perceptron units
XOR as perceptron network
Perceptron training
Gradient descent
Comparison of learning rules
Sigmoid function
Optimizing weights
Restriction bias
Preference bias

Lesson 4: Instance-Based Learning

Instance based learning before
Instance based learning now
K-NN algorithm
Won’t you compute my neighbors?
Domain K-NNowledge
K-NN bias
Curse of dimensionality

Lesson 5: Ensemble B&B

Ensemble learning: Boosting
Ensemble learning algorithm
Ensemble learning outputs
Weak learning
Boosting in code
When D agrees

Lesson 6: Kernel Methods and Support Vector Machines (SVM)s

Support Vector Machines
Optimal separator
SVMs: Linearly married
Kernel methods

Lesson 7: Computational Learning Theory

Computational Learning Theory
Learning theory
Resources in Machine Learning
Defining inductive learning
Teacher with constrained queries
Learner with constrained queries
Learner with mistake bounds
Version spaces
PAC learning
Epsilon exhausted
Haussler theorem

Lesson 8: VC Dimensions

Infinite hypothesis spaces
Power of a hypothesis space
What does VC stand for?
Internal training
Linear separators
The ring
Polygons
Sampling complexity
VC of finite H

Lesson 9: Bayesian Learning

Bayes Rule
Bayesian learning
Bayesian learning in action!
Noisy data
Best hypothesis
Minimum description length
Bayesian classification

Lesson 10: Bayesian Inference

Joint distribution
Adding attributes
Conditional independence
Belief networks
Sampling from the joint distribution
Recovering the joint distribution
Inferencing rules
Naïve Bayes
Why Naïve Bayes is cool

Supervised Learning Final Project: Using Machine Learning to Analyze Datasets",Machine Learning 1—Supervised Learning
https://www.classcentral.com/course/edx-sensing-planet-earth-from-core-to-outer-space-5241,"What do your senses tell you about planet Earth? Do we know enough about our planet? What do we need to know more about, and how can we be sure that global change is really taking place?
This course aims at answering these questions – and many more.
In this energy and earth science course we will take you on a journey through different fields of Earth sciences, including the solid Earth, the atmosphere, and the biosphere. Our experts will give you first-hand insights why, where, and how measurement techniques are applied and they will explain to you how sensors in space, on aircraft, and on the ground work.
You will be given insights on how to use data from various sensors in order to improve your understanding of our living planet. Simple experiments will show you how easy it is to sense Earth’s environment by yourself, and world-renowned experts will explain why it is so important that we study our planet.
Join us and let’s sense planet Earth together!",Sensing Planet Earth – from Core to Outer Space
https://www.classcentral.com/course/udacity-introduction-to-operating-systems-3419,"Introduction to Operating Systems is a graduate-level introductory course in operating systems. This course teaches the basic operating system abstractions, mechanisms, and their implementations. The core of the course contains concurrent programming (threads and synchronization), inter process communication, and an introduction to distributed operating systems. The course is split into four sections: (1) Introduction, (2) Process and Thread Management, (3) Resource Management and Communication, and (4) Distributed Systems.Why Take This Course?The goals of this course are three-fold.Students will understand the rationale behind the current design and implementation decisions in modern OS’s (like Linux) by considering the historic evolution of various OS constructsStudents will be exposed to theoretical knowledge regarding operating systems principles and implementationStudents will gain knowledge via experimenting and evaluating various OS aspects in a practical manner



The Course Wiki serves as the syllabus for Introduction to Operating Systems. But, for a high-level view of the course, we have listed the lessons:Part 1: IntroductionLesson 1: Course OverviewLesson 2: Introduction to Operating SystemsPart 2: Process and Thread ManagementLesson 1: Processes and Process ManagementLesson 2: Threads and ConcurrencyLesson 3: Threads Case Study: PThreadsLesson 4: Thread Implementation ConsiderationsLesson 5: Thread Performance ConsiderationsPart 3: Resource Management and CommunicationLesson 1: SchedulingLesson 2: Memory ManagementLesson 3: Inter-Process CommunicationLesson 4: Synchronization ConstructsLesson 5: I/O ManagementLesson 6: Resource VirtualizationPart 4: Distributed SystemsLesson 1: Remote ServicesLesson 2: Distributed File SystemsLesson 3: Distributed Shared MemoryLesson 4: Data Center Technologies",Introduction to Operating Systems
https://www.classcentral.com/course/introduction-data-science-18764,"In this Specialization learners will develop foundational Data Science skills to prepare them for a career or further learning that involves more advanced topics in Data Science. The specialization entails understanding what is Data Science and the various kinds of activities that a Data Scientist performs. It will familiarize learners with various open source tools, like Jupyter notebooks, used by Data Scientists. It will teach you about methodology involved in tackling data science problems. The specialization also provides knowledge of relational database concepts and the use of SQL to query databases. Learners will complete hands-on labs and projects to apply their newly acquired skills and knowledge. Upon receiving the certificate for completion of the specialization, you will also receive an IBM Badge as a Specialist in Data Science Foundations. LIMITED TIME OFFER: Subscription is only $39 USD per month and gives you access to graded materials and a certificate.



          Course 1: What is Data Science? - The art of uncovering the insights and trends in data has been around since ancient times. The ancient Egyptians used census data to increase efficiency in tax collection and they accurately predicted the flooding of the Nile river every year. Since then, people working in data science have carved out a unique and distinct field for the work they do. This field is data science. In this course, we will meet some data science practitioners and we will get an overview of what data science is today. LIMITED TIME OFFER: Subscription is only $39 USD per month for access to graded materials and a certificate.Course 2: Open Source tools for Data Science- What are some of the most popular data science tools, how do you use them, and what are their features? In this course, you'll learn about Jupyter Notebooks, RStudio IDE, Apache Zeppelin and Data Science Experience. You will learn about what each tool is used for, what programming languages they can execute, their features and limitations. With the tools hosted in the cloud on Cognitive Class Labs, you will be able to test each tool and follow instructions to run simple code in Python, R or Scala. To end the course, you will create a final project with a Jupyter Notebook on IBM Data Science Experience and demonstrate your proficiency preparing a notebook, writing Markdown, and sharing your work with your peers. LIMITED TIME OFFER: Subscription is only $39 USD per month for access to graded materials and a certificate.Course 3: Data Science Methodology- Despite the recent increase in computing power and access to data over the last couple of decades, our ability to use the data within the decision making process is either lost or not maximized at all too often, we don't have a solid understanding of the questions being asked and how to apply the data correctly to the problem at hand. This course has one purpose, and that is to share a methodology that can be used within data science, to ensure that the data used in problem solving is relevant and properly manipulated to address the question at hand. Accordingly, in this course, you will learn: - The major steps involved in tackling a data science problem. - The major steps involved in practicing data science, from forming a concrete business or research problem, to collecting and analyzing data, to building a model, and understanding the feedback after model deployment. - How data scientists think! LIMITED TIME OFFER: Subscription is only $39 USD per month for access to graded materials and a certificate.Course 4: Databases and SQL for Data Science- Much of the world's data resides in databases. SQL (or Structured Query Language) is a powerful language which is used for communicating with and extracting data from databases. A working knowledge of databases and SQL is a must if you want to become a data scientist. The purpose of this course is to introduce relational database concepts and help you learn and apply foundational knowledge of the SQL language. It is also intended to get you started with performing SQL access in a data science environment. The emphasis in this course is on hands-on and practical learning . As such, you will work with real databases, real data science tools, and real-world datasets. You will create a database instance in the cloud. Through a series of hands-on labs you will practice building and running SQL queries. You will also learn how to access databases from Jupyter notebooks using SQL and Python. No prior knowledge of databases, SQL, Python, or programming is required. Anyone can audit this course at no-charge. If you choose to take this course and earn the Coursera course certificate, you can also earn an IBM digital badge upon successful completion of the course. LIMITED TIME OFFER: Subscription is only $39 USD per month for access to graded materials and a certificate.",Introduction to Data Science
https://www.classcentral.com/course/edx-monitoring-volcanoes-and-magma-movements-13227,"The course gives an introduction to volcano monitoring techniques, magma movements and volcano unrest.  It also presents some aspects of why volcanoes are dangerous and volcanic hazards. Volcano monitoring relies on diverse approaches to infer the state of a volcano so many different instruments and techniques are used to monitor volcanoes. Predicting eruptions or forecasting future activity of a volcano is based on monitoring data. If activity level rises above normal the volcano is in a state of unrest. Magma often intrudes in the roots of volcanoes prior to eruptions. This process generates earthquakes as stress level is increased and ground deformation as the volcano expands in response to additional mass in its subsurface. Seismology and geodetic measurements on the surface of the volcano are thus key to monitoring subsurface conditions. As magma, molten rock inside volcanoes, approaches the surface it releases volcanic gas that finds its way to the surface, and geothermal activity can change.  In addition to ground-based techniques, satellite observations are extensively used. The main monitoring techniques for volcanoes are explained in the course, with the aim that students understand both the concept of volcanic unrest and how it can be monitored, how eruptions can be monitored, and signs of volcanic eruptions as seen on instruments. Understanding the possibilities and limitations of present-day volcano monitoring for detecting magma movements is an important step in understanding volcanoes, evaluating hazards and for giving warnings of impending eruptions. The course thus provides information on how scientists predict future activity of volcanoes and volcanic eruptions. Monitoring data are interpreted in terms of models of subsurface processes such as magma accumulation during volcano unrest, and magma withdrawal during eruptions. The course gives an introduction to such models, used to infer the volume and location of magma movements in volcano roots, in particular those based on mapping ground deformation. The course presents examples of monitoring data and interpretations from recent eruptions and periods of volcanic unrest in Iceland and around the world, including the 2010 eruption of Eyjafjallajökull that closed Europe’s airspace.
      


            Read more
          



Module 1: Introduction, volcanic plumbing systems and volcano seismology. We explore models of volcano interiors and how magma (molten rocks) finds its way to the surface, often through a complicated volcanic plumbing system.  We learn about how seismology can track earthquakes due to magma movements and increased stress in volcano roots.Module 2: Volcano geodesy. We get an introduction to techniques that can measure ground deformation on volcanoes with millimeter-level accuracy.  This includes both geodetic measurements using Global Navigation and Satellite Systems (GNSS) and interferometric analysis of synthetic aperture radar satellite images (InSAR), as well as other techniques.Module 3: Magma, volcanic gas and eruptions. We learn about the properties of magma and gain an understanding of volcanic gas, how it can be measured and what it can tell us. We learn how one can monitor eruptions and measure how much magma is erupted.  Module 4: Volcano deformation models. We are introduced to models used to interpret ground deformation data, in terms of sources of increased pressure, or sources of increased volume of magma, at depth in volcanoes.Module 5: Case studies of volcano unrest and eruptions. We look at monitoring data from selected eruptions, including the 2010 Eyjafjallajökull eruption in Iceland that closed Europe’s airspace. We gain an understanding of what these data could tell us about magma movements in volcano roots.Module 6: More case studies and summary. We are exposed to more case studies of volcano unrest and eruptions. We sum up the content of the course by exploring the critical elements of a volcano monitoring network and how joint interpretation of diverse data sets is essential.",Monitoring Volcanoes and Magma Movements
https://www.classcentral.com/course/edx-the-science-and-practice-of-yoga-8393,"Concerned about how the digital age is impacting your well-being? Looking for ways to find balance? This course takes the ancient practice of yoga and translates it into modern day science with practical applications.
You will learn how to practice yoga on the mat as well as in your everyday life using aspects of yoga that are immediately applicable to you. Having taught yoga to thousands of people just like you, we have reduced the practice down to the nectar of what really works.
Your team of instructors brings a dynamic blend of science and practice to the course. Stacy and Dave Dockins own four yoga studios in Texas and have trained hundreds of instructors to teach yoga as a life-transforming practice rooted in mindfulness. Dr. Catherine Spann and Dr. George Siemens are researching what it means to be human in a digital age at the University of Texas at Arlington’s LINK Research Lab. With years of experience in online education and psychological research, they bring expertise in learning and well-being in the digital age.
This course is for anyone interested in learning the science and practice of yoga. No previous yoga experience is needed! We welcome those who are interested in learning the basics of yoga postures as well as experienced yoga practitioners or instructors looking to deepen their practice.
By signing up for this course, you will have the opportunity to meet and discuss yoga and meditation with people from across the world. Encourage friends, family, and colleagues to sign up with you!



            Read more
          



Week 1: The Practice of Yoga
Introduction to yoga, postures, meditation, and beginning your personal practice.
Week 2: Being Well in a Digital Age
Introduction to the stressors of hectic modern technological society and the ways these impact our health.
Week 3: The Science of Yoga
An overview of the research around yoga and how it impacts us mentally and physically.
Week 4: Stress: Survive and Thrive
An overview of the stress response and using mindfulness and self-compassion to counteract stress
Week 5: Linking Body and Mind
Details the relationship between mind and body and the interconnectedness of physical and mental health.
Week 6: The Yoga of Social Connection
How connectedness to others, to the yoga practice, and to ourselves improves our quality of life.",The Science and Practice of Yoga
https://www.classcentral.com/course/edx-sustainable-tourism-society-environmental-aspects-10356,"Tourism is already one of the world's largest industries and it's still experiencing incredible growth. Of all the industries of major importance worldwide, Travel and Tourism directly contribute $1.4 trillion (U.S.) to the global economy. One out of ten of the world's total jobs are in travel and tourism and that number is growing.
Join this course if you want to learn where this growth is coming from and what the effects will be on the social and natural environment. Prepare yourself to be challenged with more critical reflections of an industry steeped in comfort and enjoyment.
You will also discover that tourism is more than just a powerful economic force. Tourism activities affect the environment of travel destinations and influence cultures worldwide. Tourism is very sensitive to global transformations such as changing consumer behaviour, economic developments, climate change, epidemics, or acts of terrorism. Tourism is in fact a complex phenomenon.
To explore the development of the tourism phenomenon and begin to build your own reflections on the industry, you'll be exposed to a variety of weekly insights throughout the online course. These include historical backgrounds, a variety of social science approaches, common theoretical constructs, related systemic observations, and exposure to environmental-, social- and economic implications of tourism.
Based on weekly writing exercises, you'll be challenged to form your own argument for a specific tourism development of your choice. You'll also help others in providing and receiving meaningful feedback on their critical reflections of tourism phenomena.
Join this MOOC if you want to explore tourism and understand what tourism does to our living environment, our behaviour and our cultural inheritance.
The effects of Covid-19 corona virus on the tourism industry
There is no doubt that the tourism industry is being affected by the Covid-19 corona virus outbreak. How will we recover, and will we fully recover? How does corona effects the tourists and their behaviour? And how can we pick up after this? How do we take it from here? Since it’s so relevant, we will address these questions in our Tourism MOOCs and make room for this on our discussion platform and case studies.



            Read more
          



Module 1: Introduction & Overview 
What is tourism, and how can you study it from a social sciences point of view? 
Module 2: History of global tourism development
Where does tourism come from? We go back in time to understand where our contemporary tourism practices originate. 
Module 3: Scientific approaches and systemic observations
What are typical social science approachesto tourism; including behavioral, cultural, and more critical observations? And to what kind of observations do these approaches lead? 
Module 4: Key theories and global flows
Take notice of a set of typical theoretical concepts used in tourism studies, and become acquainted with how global tourism developments run parallel with rapidly developing flows of people, goods, technology, information,and capital. 
Module 5: Environmental impacts of tourism
Take the main economic, socio-cultural, and environmental interactions and impacts generated by and in tourism. 
Module 6: Synthesis and looking forward
Finalize your own argument related to a tourism development of your choice, and become familiar with the science of sustainable tourism.",Sustainable Tourism: Society & Environmental Aspects
https://www.classcentral.com/course/mooc-ed-teaching-the-computer-science-discoveries-course-13673,"Computer Science Discoveries (CSD) is an introductory computer science curriculum for students in Grades 6 through 10 that takes a wide lens on computer science by covering topics such as programming, physical computing, HTML/CSS, and data. The curriculum inspires students as they build their own websites, apps, games, and physical computing devices. CSD is designed to be taught as two single-semester courses or a year-long introductory course. All curriculum resources and tutorials are free and available at Code.org.
CSD covers the following topics: problem solving, programming, web development, animations and games, the design process, data and society, and physical computing.
 



Session 1: What Is Computer Science?
The first session introduces you to computer science as a field of study and to computational thinking as a form of critical thinking that leverages concepts integral to computer science. It provides background information that will serve as a foundation for a deeper understanding of CSD, its curriculum values, and its pedagogical approach.
 
Session 2: Getting Oriented to the CSD Curriculum
This session will familiarize you with the CSD curriculum resources and features to prepare you to more easily find and utilize all the resources you need to teach CSD.
 
Session 3: The Lead Learner Model
This session focuses on the importance of your role as the lead learner in the CSD classroom and strategies for effectively implementing it.
 
Session 4: Broadening Participation in Computer Science
The final session introduces you to the ""why"" behind empowering students to learn computer science and computational thinking skills. It also prepares you to build a diverse and equitable CSD classroom by providing strategies to address well-known equity gaps within the field.",Teaching the Computer Science Discoveries Course
https://www.classcentral.com/course/nlpintro-3332,"This course provides an introduction to the field of Natural Language Processing. It includes relevant background material in Linguistics, Mathematics, Probabilities, and Computer Science. Some of the topics covered in the class are Text Similarity, Part of Speech Tagging, Parsing, Semantics, Question Answering, Sentiment Analysis, and Text Summarization.
The course includes quizzes, programming assignments in Python, and a final exam.

Course Syllabus

Week One (Introduction 1/2) (1:35:31)
Week Two (Introduction 2/2) (1:36:26)
Week Three (NLP Tasks and Text Similarity) (1:42:52)
Week Four (Syntax and Parsing, Part 1) (1:48:14)
Week Five (Syntax and Parsing, Part 2) (1:50:29)
Week Six (Language Modeling and Word Sense Disambiguation) (1:40:33)
Week Seven (Part of Speech Tagging and Information Extraction) (1:33:21)
Week Eight (Question Answering) (1:16:59)
Week Nine (Text Summarization) (1:33:55)
Week Ten (Collocations and Information Retrieval) (1:29:40)
Week Eleven (Sentiment Analysis and Semantics) (1:09:38)
Week Twelve (Discourse, Machine Translation, and Generation) (1:30:57)


The course assignments will all be in Python.


Course Format

The class will consist of lecture videos, which are typically between 10 and 25 minutes in length. The lectures contain 1-2 integrated quiz questions per video. Grading is based on three programming assignments, weekly quizzes, and a final exam.
      


            Read more
          



Week One: Introduction 1/2In Week One, you will be watching an introductory lecture that covers the motivation for NLP, examples of difficult cases, as well as the first part of the Introduction to Linguistics needed for this class. Week Two: Introduction 2/2Week Two will cover Parts of Speech, Morphology, Text Similarity, and Text Preprocessing. I will also introduce NACLO, the North American Computational Linguistics Olympiad (www.nacloweb.org), a competition for high school students interested in NLP and Linguistics.Week Three: NLP Tasks and Text SimilarityWeek Three will cover Vector Semantics, Text Similarity, and Dimensionality Reduction. I will also go through a long list of sample NLP tasks (e.g., Information Extraction, Text Summarization, and Semantic Role Labeling) and introduce each of them briefly. Week Four: Syntax and Parsing, Part 1Week Four will cover the basics of Syntax and Parsing, including CKY parsing and the Earley parser.Week Five: Syntax and Parsing, Part 2Week Five will continue with topics related to parsing, including Statistical, Lexicalized, and Dependency Parsing as well as Noun Sequence Parsing, Prepositional Phrase Attachment, and Alternative Grammatical Formalisms.Week Six: Language ModelingWeek Six will cover Probabilities, Language Modeling, and Word Sense Disambiguation (WSD). The first two, along with some material coming up in Week Seven, will be the basis for Assignment 2. The WSD unit will be needed later for Assignment 3.Week Seven: Part of Speech Tagging and Information ExtractionWeek Seven includes the Noisy Channel Model, Hidden Markov Models, Part of Speech Tagging (all needed for the second programming assignment) and a short introduction to Information Extraction.Week Eight: Question AnsweringWeek Eight covers different topics related to Question Answering, including Question Type Classification and Evaluation of Question Answering Systems.Week Nine: Text SummarizationWeek Nine covers Text Summarization and related topics such as Sentence Compression.  Week Ten: Collocations and Information RetrievalWeek Ten covers Information Retrieval (including Document Indexing, Ranking, Evaluation), Text Classification and Text Clustering, as well as a short lecture on Collocations.Week Eleven: Sentiment Analysis and SemanticsWeek Eleven covers Semantics and related topics such as Sentiment Analysis, Semantic Parsing, and Knowledge Representation. Week Twelve: Discourse, Machine Translation, and Generation (Includes Final Exam)Week Twelve briefly covers Discourse Analysis, Dialogue, Machine Translation, and Text Generation.",Introduction to Natural Language Processing
https://www.classcentral.com/course/edx-the-computing-technology-inside-your-smartphone-2809,"We use our smartphones to communicate, to organize our lives, to find information, and to entertain ourselves. All of this is possible because a smartphone contains a powerful computer processor, which is the subject of this course. This computer science course starts by moving step-by-step through the fundamental layers of computing technology, from binary numbers to application software, and then covers advanced performance techniques and the details of actual smartphone processors.
Learn about:

Digital logic
Computer organization
Instruction sets
Application Software
Advanced performance techniques
Actual smartphone processors

This Course also provides students with the technical knowledge and the Jade design tool experience to succeed in the more advanced MITx 6.004 MOOC - Computation Structures course sequence.



Week 1: Introduction and Digital Logic

Overview
Inside Smartphone
Big Ideas
Numbers

Week 2: Digital Logic (cont'd)

Operations
Transistors and Gates

Week 3: Digital Logic (cont'd)

Muxes and Decoders
Adders

Week 4: Digital Logic (cont'd)

Storage
Finite State Machines

Week 5: Computer Organization

Stored Program Computer
LC-3 Instructions
LC-3

Week 6: Computer Organization (cont'd)

Instructional Set Architecture
ISA 2

Week 7: Computer Organization (cont'd)

ARM ISA
LC-3 Control

Week 8: Programming

Programming to Solve Problems
Assembly Language
Input/Output (I/O)
C Programming

Week 9: Performance 

Pipelining
Hazards
Instruction Level Parallelism
Thread Level Parallelism
Data Level Parallelism

Week 10: Performance (cont'd)

Caches
Multicore
Permanent Storage
Snapdragon
Conclusion",The Computing Technology Inside Your Smartphone
https://www.classcentral.com/course/buddhist-meditation-1342,"Tibetan Buddhist Meditation and the Modern World explores the immense variety of meditation practices past and present. We present their histories, their philosophical underpinnings, their transformations in the modern global world, and we give you a chance to reflect upon meditation practices through secular contemplations designed just for this course. 

We use a traditional, if overly simplistic, way of grouping Buddhist philosophical systems and ritual-contemplative practices into “three vehicles”, three programs of theory and practice supporting the personal journey from suffering to enlightenment. This scheme became normative in India and Tibet: (i) the Lesser Vehicle (Hīnayāna), (ii) the Great Vehicle (Mahāyāna), and (iii) the Adamantine Vehicle (Vajrayāna), also referred to as “esoteric Buddhism” or “Buddhist tantra”. To this, we will add a fourth Vehicle which is explicit in many Tibetan materials, though no standard term ever emerged that was accepted by all sectarian traditions - we will thus term it as the “Natural Vehicle” or “Post Tantra”. We follow an indigenous Tibetan tradition in terms of characterizing each with a specific orientational paradigm - repression, refinement, transformation, and natural freedom. These twelve meditative traditions constitute the framework for the course’s discussion of the main streams of Tibetan Buddhist meditation.

The five modules of the present course, dedicated to ""Lesser Vehicle"" practices and perspectives, treat the first five of these twelve types. Each module in turn has four components: (i) the specific Buddhist meditation in its traditional presentation and practice; (ii) modern scientific research into its efficacy and dynamics, or on practices, principles, and processes related to this type of meditation in our analysis; (iii) the fact, problems, and opportunities of modern secular adaptations in a variety of educational, professional, and personal settings; and (iv) secular practices for experimentation, which are either direct adaptations or new practices designed to give an experiential sense of some of the principles underlying the Buddhist meditative practice.
      


            Read more
          



Course IntroductionThe Content, Structure, and Instructors of the Course. This class is the first in a four part series on Buddhism.  The other classes will focus on the Greater Vehicle, Adamantine Vehicle, and Natural Vehicle.Ordinary Preliminary PracticesTibetan perspectives on the foundations of contemplative practice; early Buddhist meditations; the beginnings of Western Buddhist meditation; and an introduction to the science of meditation. Includes lectures by Dr. Clifford Saron, Khenpo Tsultrim Lodro, and Tsoknyi Rinpoche, as well as an interview with David McMahan. Contemplative labs with Anne Klein and Anam ThubtenMindfulness Meditation (smṛti)An introduction to Mindfulness meditation practice and the contemporary Mindfulness-Based Stress Reduction (MBSR). Includes lectures by Dr. Clifford Saron, Khenpo Tsultrim Lodro, and Tsoknyi Rinpoche, as well as an interview with Jim Coan. Contemplative labs with Anne Klein, Anam Thubten, and Susan Bauer-Wu.Calm Meditation An introduction to Calm meditation and its use in contemporary research environments. Includes lectures by Dr. Clifford Saron and Khenpo Tsultrim Lodro, as well as an interview with Tish Jennings. Contemplative labs with Anne Klein, Anam Thubten, and Susan Bauer-WuInsight MeditationAn introduction to Insight meditation and its use in the contemporary development of contemplative pedagogy. Includes lectures by Dr. Clifford Saron, Khenpo Tsultrim Lodro, and Tsoknyi Rinpoche, as well as interviews with Rhonda Magee, Erik Braun, and David Mick. Contemplative labs with Anne Klein, Anam Thubten, and Susan Bauer-WuThe Diverse Objects of Early Buddhist MeditationAn introduction to the diverse objects of early Buddhist meditation. Includes lectures by Dr. Clifford Saron and Khenpo Tsultrim Lodro, as well as an interview with Sharon Salzberg. Contemplative labs with Anne Klein, Anam Thubten, and Susan Bauer-Wu",Tibetan Buddhist Meditation and the Modern World: Lesser Vehicle
https://www.classcentral.com/course/advanced-machine-learning-signal-process-11597,">>> By enrolling in this course you agree to the End User License Agreement as set out in the FAQ.  Once enrolled you can access the license in the Resources area 
      


          Setting the stage

Supervised Machine Learning

Unsupervised Machine Learning

Digital Signal Processing in Machine Learning",Advanced Machine Learning and Signal Processing
https://www.classcentral.com/course/data-collection-methods-6087,"This course presents research conducted to increase our understanding of how data collection decisions affect survey errors. This is not a “how–to-do-it” course on data collection, but instead reviews the literature on survey design decisions and data quality in order to sensitize learners to how alternative survey designs might impact the data obtained from those surveys.

The course reviews a range of survey data collection methods that are both interview-based (face-to-face and telephone) and self-administered (paper questionnaires that are mailed and those that are implemented online, i.e. as web surveys). Mixed mode designs are also covered as well as several hybrid modes for collecting sensitive information e.g., self-administering the sensitive questions in what is otherwise a face-to-face interview. The course also covers newer methods such as mobile web and SMS (text message) interviews, and examines alternative data sources such as social media. It concentrates on the impact these techniques have on the quality of survey data, including error from measurement, nonresponse, and coverage, and assesses the tradeoffs between these error sources when researchers choose a mode or survey design.
      


          Module 1: Introduction, Classic Modes of Survey Data Collection 
    -In this lesson, you will be introduced to some key concepts about survey data collection methods that we will rely on throughout the course.  By the end of this lesson, you should be well acquainted with the major sources of survey error and how these are affected -- usually in the form of tradeoffs -- by the particular mode used to administer questions and capture responses.

Module  2: Self-administration, Online Data Collection
    -This second lesson focuses on modes in which survey respondents self-administer questions and provide their responses directly to researchers.  By the end of Lesson 2, you will understand the pros and cons of self-administered modes from the TSE perspective.

Module 3: Interviewers and Interviewing
    -In this lesson, we explore the various roles interviewers take on beside asking questions and collecting answers, as well as some of the different approaches to interviewing that have been proposed and how they affect the accuracy of responses.  By the end of Lesson 3, you will appreciate the benefits and costs of collecting data in interviews and will be able to contrast them with the costs and benefits of self-administration. 

Module 4: Emerging modes, new data sources
    -In this lesson, we focus on some new data collection modes such as mobile web surveys and SMS text interviews, as well as alternative data sources such as sensor data, administrative data, and social media.  By the end of this lesson, you will have a sense of the issues to which survey methodologists and survey researchers are devoting much of their attention these days. You will be able to weigh the pros and cons of these new methods and data sources.","Data Collection: Online, Telephone and Face-to-face"
https://www.classcentral.com/course/edx-ancient-egyptian-civilization-6014,"We will examine the role of Egyptian women and their positions as monarchs and goddesses, the invention of papyrus and Egypt’s first writings as well as ancient Egypt’s achievements in medicine. There will also be a brief summary of the famous architecture of ancient Egypt including pyramids, tombs and temples.



Week 1: Beginnings 
This is a brief introduction to the historical background that contextualized ancient Egypt, and an overview of the achievements of one of the most famous figures: the great Imhotep, whose fame as architect and physician is universally acknowledged.

Week 2: Writing and Numerals in Ancient Egypt
An introduction to the invention of writing, and papyrus, as well as the major types of scripts in ancient Egypt, and the numeric system they invented and employed.

Week 3: Architecture and Astronomy in Ancient Egypt 
An overview of this civilization’s famous architectural legacy, and an examination of all its forms such as pyramids, Mastaba and rock-cut tombs, and temples. This section also includes an introduction to astronomy in ancient Egypt.

Week 4: Women in Ancient Egypt 
Women in the time of the Pharaohs played an important role in society and were rulers and goddesses. This unit will give a brief description of the role of women in society and their position as monarchs and goddesses.

Week 5: Medicine in Ancient Egypt 
This week will explore the achievements of ancient Egyptians in medicine, and their developing it into a science, as well as the significance of the Medical Papyri that were discovered, and what these indicate about the Egyptians’ achievements in medicine.",Ancient Egyptian Civilization
https://www.classcentral.com/course/data-in-database-15235,"Big Data analytics tools are increasingly critical for providing meaningful information for making better business decisions.
Big data technologies bring significant cost advantages when it comes to storing and managing large amounts of data. Understanding how to query a database to extract data will empower better analysis of large, complex datasets. Knowledge of Indexing mechanisms makes possible high-speed, selective retrieval of large amounts of information.
      


          Big Data and Data Processing
    -Database management systems are critical to businesses and organizations. They provide an efficient method for handling different types of data in the era of big data. A university database, for example, stores millions of student and course records. The relational database management system ensures that the university can define entity relationships and logically maintain its data over time. 

Entity Relationship Model to Relational Model
    -We live in an era where data is the critical factor in decision-making. To provide that critical factor, we must be able to extract data from database management systems. This week, you will learn how Entity Relationship (ER) models visually show the various entities (tables) and the relationships between them. You are also provided with an introduction to SQL, the standard language for relational database management systems.

Relational Model and Relational Algebra
    -Databases use relational algebra operators to execute SQL queries; this week, you will learn about relational algebra as the mathematical query language for relations. 

Data Storage and Indexing
    -In the first part of this week, you will learn how indexes are important for looking up information (Imagine searching for your order in Amazon without an index!) and optimizing query performance. 

As the week continues, we discuss transaction locks and database recovery. Transaction locks are critical to data consistency. All organizations think about recovery mechanisms for databases, and have some in place in the event of a crash. We close out this week with a discussion on database recovery.",Data in Database
https://www.classcentral.com/course/geometric-algorithms-12815,"Course Information: In many areas of computer science such as robotics, computer graphics, virtual reality, and geographic information systems, it is necessary to store, analyze, and create or manipulate spatial data. This course deals with the algorithmic aspects of these tasks: we study techniques and concepts needed for the design and analysis of geometric algorithms and data structures. Each technique and concept will be illustrated on the basis of a problem arising in one of the application areas mentioned above.

Goals:
At the end of this course participants should be able
- to decide which algorithm or data structure to use in order to solve a given basic geometric problem,
- to analyze new problems and come up with their own efficient solutions using concepts and techniques from the course.

Prerequisites:
In order to successfully take this course, you should already have a basic knowledge of algorithms and mathematics. Here's a short list of what you are supposed to know:
- O-notation, Ω-notation, Θ-notation; how to analyze algorithms
- Basic calculus: manipulating summations, solving recurrences, working with logarithms, etc.
- Basic probability theory: events, probability distributions, random variables, expected values etc.
- Basic data structures: linked lists, binary search trees, etc.
- Graph terminology
- Programming skills for practical assignments

Most of the material in this course is based on the following book:
M. de Berg, O. Cheong, M. van Kreveld, and M. Overmars. Computational Geometry: Algorithms and Applications (3rd edition). Springer-Verlag, 2008.
It is not mandatory to buy this book. However if participants want to know more than is offered in this course or want to have another look at the material discussed in the lectures, we recommend buying this book.

The video lectures contain a few very minor mistakes. A list of these mistakes can be found under resources. If you think you found an error, report a problem by clicking the square flag at the bottom of the lecture or quiz where you found the error.
      


            Read more
          



          Plane Sweep Algorithms
    -In this module we will discuss an algorithm for line segment intersection that does not only depend on the input size, i.e. the number of line segments, but also on the output size, i.e. the number of intersections. This algorithm uses the Plane Sweep technique, which is applicable to many algorithmic problems in the Euclidean plane.

Voronoi diagrams and Delaunay triangulations
    -In this module we will introduce the notions of Voronoi diagrams and Delaunay triangulations and its properties. Furthermore we will an algorithm for constructing Delaunay triangulations using the technique of randomized incremental construction. We will see how to analyze these types of algorithms.

Orthogonal range searching
    -In this module we will introduce the problem of range searching. We will first look at the one dimensional case and later on generalize to higher dimensions. We will see two data structures that allow for range searching, namely KD Trees and Range Trees. We will compare them by looking at construction time, space usage and query time.",Geometric Algorithms
https://www.classcentral.com/course/swayam-machine-learning-ml-12945,"The scientific discipline of Machine Learning focuses on developing algorithms to find patterns or make predictions from empirical data. It is a classical sub-discipline within Artificial Intelligence (AI). The discipline is increasingly used by many professions and industries to optimize processes and implement adaptive systems. The course places machine learning in its context within AI and gives an introduction to the most important core techniques such as decision tree based inductive learning, inductive logic programming, reinforcement learning and deep learning through decision trees.INTENDED AUDIENCE: Interested studentsPREREQUISITES : Relevant applied math and statistics, core computer sciencelINDUSTRY SUPPORT : Broad industrial interest at present, i.e. for autonomous vehicles, robots, intelligent assistants and general datamining



COURSE LAYOUT Week 1: Introduction to the Machine Learning courseWeek 2: Characterization of Learning ProblemsWeek 3: Forms of RepresentationWeek 4: Inductive Learning based on Symbolic Representations and Weak TheoriesWeek 5: Learning enabled by Prior TheoriesWeek 6: Machine Learning based Artificial Neural NetworksWeek 7: Tools and Resources + Cognitive Science influencesWeek 8: Examples, demos and exam preparations","Machine Learning,ML"
https://www.classcentral.com/course/edx-computational-probability-and-inference-6830,"Probability and inference are used everywhere. For example, they help us figure out which of your emails are spam, what results to show you when you search on Google, how a self-driving car should navigate its environment, or even how a computer can beat the best Jeopardy and Go players! What do all of these examples have in common? They are all situations in which a computer program can carry out inferences in the face of uncertainty at a speed and accuracy that far exceed what we could do in our heads or on a piece of paper.
In this data analysis and computer programming course, you will learn the principles of probability and inference. We will put these mathematical concepts to work in code that solves problems people care about. You will learn about different data structures for storing probability distributions, such as probabilistic graphical models, and build efficient algorithms for reasoning with these data structures.
By the end of this course, you will know how to model real-world problems with probability, and how to use the resulting models for inference.
You don’t need to have prior experience in either probability or inference, but you should be comfortable with basic Python programming and calculus.
 
“I love that you can do so much with the material, from programming a robot to move in an unfamiliar environment, to segmenting foreground/background of an image, to classifying tweets on Twitter—all homework examples taken from the class!” – Previous Student in the residential version of this new online course.



            Read more
          



Week 1: Introduction to probability and computation
A first look at basic discrete probability, how to interpret it, what probability spaces and random variables are, and how to code these up and do basic simulations and visualizations.
Week 2: Incorporating observations
Incorporating observations using jointly distributed random variables and using events. Three classic probability puzzles are presented to help elucidate how to interpret probability: Simpson’s paradox, Monty Hall, boy or girl paradox.
Week 3: Introduction to inference, and to structure in distributions 
The product rule and inference with Bayes' theorem. Independence-A structure in distributions. Measures of randomness: entropy and information divergence. Mini-project: movie recommendations.
Week 4: Expectations, and driving to infinity in modeling uncertainty
Expected values of random variables. Classic puzzle: the two envelope problem. Probability spaces and random variables that take on a countably infinite number of values and inference with these random variables.
Week 5: Efficient representations of probability distributions on a computer
Introduction to undirected graphical models as a data structure for representing probability distributions and the benefits/drawbacks of these graphical models. Incorporating observations with graphical models.
Week 6: Inference with graphical models, part I
Computing marginal distributions with graphical models in undirected graphical models including hidden Markov models. Mini-project: robot localization, part I.
Week 7: Inference with graphical models, part II
Computing most probable configurations with graphical models including hidden Markov models. Mini-project: robot localization, part II.
Week 8: Introduction to learning probability distributions
Learning an underlying unknown probability distribution from observations using maximum likelihood. Three examples: estimating the bias of a coin, the German tank problem, and email spam detection.

Week 9: Parameter estimation in graphical models
Given the graph structure of an undirected graphical model, we examine how to estimate all the tables associated with the graphical model. 
Week 10: Model selection with information theory
Learning both the graph structure and the tables of an undirected graphical model with the help of information theory. Mutual information of random variables.
Week 11: Final project part I
Mystery project
Week 12: Final project part II
Mystery project, cont’d",Computational Probability and Inference
https://www.classcentral.com/course/udacity-introduction-to-python-programming-8577,"In this course, you'll learn the fundamentals of the Python programming language, along with programming best practices. You’ll learn to represent and store data using Python data types and variables, and use conditionals and loops to control the flow of your programs. You’ll harness the power of complex data structures like lists, sets, dictionaries, and tuples to store collections of related data. You’ll define and document your own custom functions, write scripts, and handle errors. Lastly, you’ll learn to find and use modules in the Python Standard Library and other third-party libraries.Why Take This Course?Python is a powerful programming language used in a variety of professions, ranging from data science to web development. It's in the top 10 for ""Most Popular"" and ""Most Loved"" technologies (according to StackOverflow's 2016 Developer Survey), making it a relatively friendly language for beginners. Learning Python will enable you to program pretty much anything.



Lesson 1: Why Python Programming


Receive an overview of what you’ll be learning and doing in the course
Understand why you should learn programming with Python


Lesson 2: Data Types and Operators


Represent data using Python's data types: integers, floats, booleans, strings, lists, tuples, sets, dictionaries, compound data structures
Perform computations and create logical statements using Python’s operators: Arithmetic, Assignment, Comparison, Logical, Membership, Identity
Declare, assign, and reassign values using Python variables
Modify values using built-in functions and methods
Practice whitespace and style guidelines


Lesson 3: Control Flow


Write conditional expressions using if statements and boolean expressions to add decision making to your Python programs
Use for and while loops along with useful built-in functions to iterate over and manipulate lists, sets, and dictionaries
Skip iterations in loops using break and continue
Condense for loops to create lists efficiently with list comprehensions 


Lesson 4: Functions


Define your own custom functions
Create and reference variables using the appropriate scope
Add documentation to functions using docstrings
Define lambda expressions to quickly create anonymous functions
Use iterators and generators to create streams of data


Lesson 5: Scripting


Install Python 3 and set up your programming environment
Run and edit python scripts
Interact with raw input from users
Identify and handle errors and exceptions in your code
Open, read, and write to files
Find and use modules in Python Standard Library and third-party libraries
Experiment in the terminal using a Python Interpreter",Introduction to Python Programming
https://www.classcentral.com/course/power-sample-size-14413,"Power and Sample Size for Longitudinal and Multilevel Study Designs, a five-week, fully online course covers innovative, research-based power and sample size methods, and software for multilevel and longitudinal studies.  The power and sample size methods and software taught in this course can be used for any health-related, or more generally, social science-related (e.g., educational research) application.  All examples in the course videos are from real-world studies on behavioral and social science employing multilevel and longitudinal designs. The course philosophy is to focus on the conceptual knowledge to conduct power and sample size methods. The goal of the course is to teach and disseminate methods for accurate sample size choice, and ultimately, the creation of a power/sample size analysis for a relevant research study in your professional context. 

Power and sample size selection is one of the most important ethical questions researchers face. Interventional studies that are too large expose human volunteer research participants to possible, and needless, harm from research. Interventional studies that are too small will fail to reach their scientific objective, again bringing possible harm to research participants, without the possibility of concomitant gain from the increase in knowledge. For observational studies in which there are no possible harms to the participants, such as observational studies, proper power ensures good stewardship of both time and money.

Most National Institutes of Health (NIH) study sections will only fund a grant if the grantee has written a compelling and accurate power and sample size analysis. The Institute of Education Sciences (IES), the statistics, research, and evaluation arm of the U.S. Department of Education, also offers competitive grants requiring a compelling and accurate power and sample size analysis (Goal 3: Efficacy and Replication and Goal 4: Effectiveness/Scale-Up). 

At the end of the online course, learners will be able to: 
•	Use a framework and strategy for study planning 
•	Write study aims as testable hypotheses
•	Describe a longitudinal and multilevel study design
•	Write a statistical analysis plan 
•	Plan a sampling design for subgroups, e.g. racial and ethnic
•	Demonstrate the feasibility of recruitment
•	Describe expected missing data and dropout
•	Write a power and sample size analysis that is aligned with the planned statistical analysis

This is a five-week intensive and interactive online course. We will use a mix of instructional videos, software demonstration videos, online discussion forums, online readings, quizzes, exercise assignments, and peer-review assignments. The final course project is a peer-reviewed research study you design for future power or sample size analysis.
      


            Read more
          



          Week 1: Introduction to Multilevel and Longitudinal Designs
    -This first module introduces all course participants to the online course, its structure, its learning objectives, and your peers within the course. As noted, the course is composed of multiple activities to reach the learning objectives. Next, we review basic statistical concepts (e.g., hypothesis testing), and explore the fundamentals of both multi-level and longitudinal studies.  Conceptual knowledge is covered to provide a framework for analyzing and synthesizing research study designs. This module lays a foundation for subsequent learning. The module concludes with an introduction to the GLIMMPSE software for conducting your own power and sample size analyses. You will walk through a fully guided exercise problem to solve for power for a single level cluster design.

Week 2: Foundations of Complex Multilevel and Longitudinal Designs
    -In the second module, we are going to dive into the many facets of research design, and important considerations related to power and sample size analysis. Specifically, we will examine between, within, and interactions; type 1 error, type 2 error, and power; and standard deviation, variance, and correlation structure.  We will explore the appropriate statistical tests for use in specific models, criteria for evaluating these different tests, and how to choose an appropriate test for a data analysis problem. Finally, we will note how clusters of observations or multivariate designs can induce correlation. This module provides the details for specifying research designs, and the beginning steps in aligning the research design to sample size and power analysis. The module concludes with summarizing research designs for GLIMMPSE software. You will walk through a guided exercise problem to solve for sample size analysis for a longitudinal study. 

Week 3: Model Assumptions, Alignment, Missing Data, and Dropout
    -The third module includes a wide variety of topics related to power and sample size analysis. First, we examine multivariate and mixed models, their assumptions, and how this assumption impact power.  After we focus on aligning the features of data analysis and power analysis as well as the consequences of misalignment. Then we focus on missing data from sources like participant drop-out, machine failures or data entry errors; and how to account for missing data by adjusting your sample size. This module highlights several important features to consider in power and sample size analysis. To conclude the module, you will walk through an exercise problem to solve for power for a multilevel study independently. 

Week 4: Inputs to Analysis, Recruitment Feasibility, and Multiple Aims
    -Our emphasis in the fourth module includes the many sources of inputs for power and sample size analysis from the empirical literature, internal pilot studies, planned pilot studies, and computer simulations. Each of these approaches is discussed in detail in relation to power and sample size analysis, including the overall benefits and challenges associated with each approach.  Next we talk about recruitment feasibility and its critical importance to sample size calculations by discussing some key factors such as health, socioeconomic, and demographic factors that can be predictive of recruitment difficulty. Next, we deal with research studies that address multiple aims (e.g., hypotheses) and how to address this situation in your sample size analysis.  Lastly, you will walk through a fully independent exercise problem to solve for sample size analysis for a multilevel study with longitudinal repeated measures.

Week 5: Ethics and Using Power and Sample Size Analysis to Get Funded
    -The fifth and final module first introduces the ethics of sample size analysis, including overpowered and underpowered research studies and the importance of early planning. Next, we walk through the process of structuring a sample size section of a proposal in a grant application.  Then we dive into power curves again and discuss how to decide to incorporate a graphic to best tell your story. After, we explore subgroup analyses such as gender or race, and how to incorporate these design features into a power and sample size analysis. We close our last lecture on searching and applying for funding opportunities, and how a clear design and analysis plan improves your chances for funding. As this is our last module, you will walk through a fully independent exercise problem to solve for sample size analysis for a planned subgroup analysis. You will review at minimum two of your peers’ research design and sample size analyses documents, and finally, complete the final exam in the course.",Power and Sample Size for Multilevel and Longitudinal Study Designs
https://www.classcentral.com/course/data-modeling-regression-analysis-busine-13713,"The course will begin with what is familiar to many business managers and those who have taken the first two courses in this specialization. The first set of tools will explore data description, statistical inference, and regression. We will extend these concepts to other statistical methods used for prediction when the response variable is categorical such as win-don’t win an auction. In the next segment, students will learn about tools used for identifying important features in the dataset that can either reduce the complexity or help identify important features of the data or further help explain behavior. 
      


          Module 0:  Get Ready & Module 1: Introduction to Analytics and Evolution of Statistical Inference
    -This session is an overview of the business data analytics process and its components. We introduce you to different modeling paradigms and invite you to match problems to modeling paradigms. The module concludes with an overview of Rattle (an interface for the statistical package R) and its use for univariate analysis. 

Module 2: Dating with Data
    -This session focuses on identifying relationships between dependent and independent variables using a regression model. The goal is to find the best fitted model to the data to learn about the underlying relationship of variables in the population.  

Module 3: Model Development and Testing with Holdout Data
    -This session introduces the student to use of a holdout data set for evaluating model performance. Methods of improving the model are discussed with emphasis on variable selection. Nuances of modeling discrete predictor variables and response variables are discussed. 

Module 4: Curse of Dimensionality
    -There has been a tremendous increase in the way data generation via sensors, digital platforms, user-generated content, etc. are being used in the industry. For example, sensors continuously record data and store it for analysis at a later point. In the way data gets captured, there can be a lot of redundancy. With more variables, comes more trouble! There may be very little (or no) incremental information gained from these sources. This is the problem of a high number of unwanted dimensions. To avoid this pitfall, data transformation and dimension reduction comes to the rescue by examining and extracting fewer dimensions while ensuring that it conveys the full information concisely.",Data Modeling and Regression Analysis in Business
https://www.classcentral.com/course/grow-from-soil-to-data-12198,"##
How can citizen science create positive change in the world? Join this online course to discover soil and food growing data and results generated by citizen scientists like you who are collaborating with the GROW Observatory. Become familiar with datasets, learn to identify patterns, errors and insights that can create change from the local to the global.
You will explore the potential of art to communicate complex scientific data and concepts and become one of the first to experience the work of GROW’s artist in residence.
This course is for you if you are interested in any of the following subjects: soil, food growing, agriculture, ecosystems and the environment, technology, earth observation, sensors, environmental governance. Participants won’t need any prior experience but it might be of particular relevance to small farmers, community and urban growers, gardeners, land managers, allotment growers, fab lab users, environmental NGOs, people interested in food production and citizen science, as well as teachers in science and environment-related subjects.",Citizen Science: From Data to Action
https://www.classcentral.com/course/healthcaresafety-822,"ENROLLMENT OPTIONSThose interested in participating in this course have three options:Free Enrollment:  Click “Sign Up” to enroll in course for FREE and earn a statement of accomplishment upon completion.Signature Track Enrollment:  Click
 “Signature Track” and follow the enrollment steps.  You will be 
required to pay a $39 non-refundable fee.  Upon course completion you 
will receive a verified certificate, which employers can search. What’s this?Continuing Nursing Education (CNE) Credit:  For healthcare professionals interested in earning Continuing Nurse Education (CNE) contact hours you must:Complete Signature Track enrollment. Complete
 registration process through Johns Hopkins University School of 
Nursing. You will be required to pay an additional non-refundable fee of
 $60 in addition to the $39 fee for signature track. SIGNING UP FOR CNE CREDITIf
 you’re interested in signing up for CNE Credit and have already signed 
up for Signature Track, click this link to register for CNE: https://www.regonline.com/scienceofsafetyABOUT THE COURSEAlmost everyone will be a patient at some point in their lives. Estimates suggest that over 98,000 patients die in US hospitals each year due to medical errors; making medical errors a leading cause of death. Adverse events in healthcare often result from problems in the complex systems of care. Improving patient safety demands a complex system-wide effort, involving a wide range of actions in performance improvement, environmental safety and risk management. Healthcare professionals and consumers must partner in these efforts.The content of this course has been adapted from the intensive five-day Patient Safety Certificate Program offered by the Johns Hopkins Armstrong Institute for Patient Safety and Quality as well as the Helene Fuld Fellows Program undergraduate course content from the Johns Hopkins University School of Nursing.
      


            Read more
          



WEEK I: Overview: In this module, an overview of the science of safety and an introduction to a culture of safety in healthcare will be provided.
Patient Safety Q&ACreating a Culture of SafetyThe Science of Safety
WEEK 2: Enabling and Contextual Factors Influencing Patient Safety and Quality: Enabling and contextual factors, including communication, teamwork, and healthcare human factors, that influence patient safety and quality will be explored in this module.  Complementary presentations by JHU faculty will introduce strategies to enhance communication and teamwork.
Leadership to Enhance CommunicationCommunication Toolkit I: Effective CommunicationCommunication Toolkit II: Teamwork Human and Environmental Factors: Contribution to ErrorPatient Involvement in Patient SafetyIncreasing Family Participation in Care
WEEK 3: Methods to Improve Safety and Quality: Given the system complexity and various sources of healthcare safety and quality defects, multiple methodologies are required to improve safety and quality.  In addition, sound measurement approaches are required to know whether risk has been reduced.  In this module, several examples of available methodologies to improve safety as well as measurement strategies will be examined.Understanding CUSP and the CUSP TeamLearning from Defects in Patient CareUsing Event Reports to Design Safer SystemsMeasuring Success in Safety InitiativesDisclosing Adverse EventsPatient Centered Care
WEEK 4: Translating Evidence Into Practice and Leading Change: In this module learners will explore the TRiP Model for translating evidence into practice, review an integrated approach to improving the reliability of care, and distinguish the technical and adaptive challenges of safety and quality improvement.
Translating Evidence into PracticeLeading ChangeThe Need for Improvement ScienceWhat Can You Do to Improve Patient Safety?The Business Case for Patient SafetyQ
and A  ""Ask us anything""
WEEK 5: Summary
and future challenges 
Meet the Patient Safety ExpertsPatient Safety FellowshipOpportunities for Learning at the Armstrong InstituteOpportunities for Learning at the JHU School of Nursing",The Science of Safety in Healthcare
https://www.classcentral.com/course/computer-simulations-17986,"Big data and artificial intelligence get most of the press about computational social science, but maybe the most complex aspect of it refers to using computational tools to explore and develop social science theory. This course shows how computer simulations are being used to explore the realm of what is theoretically possible. Computer simulations allow us to study why societies are the way they are, and to dream about the world we would like to live in. This can be as intuitive as playing a video game. Much like the well-known video game SimCity is used to build and manage an artificial city, we use agent-based models to grow and study artificial societies. Without hurting anyone in the real world, computer simulations allow us explore how to make the world a better place. We play hands-on with several practical computer simulation models and explore how we can combine hypothetical models with real world data. Finally, you will program a simple artificial society yourself, bottom-up. This will allow you to feel the complexity that arises when designing social systems, while at the same time experiencing the ease with which our new computational tools allow us to pursue such daunting endeavors.
      


          Getting Started and Computer Simulations
    -In this module, you will be able to define theoretical computer simulations, specifically agent-based models (ABM). You will be able to recall how and why agent-based models can be useful and you'll be able to examine Schelling's famous segregation model.

Artificial Societies: Sugarscape
    -In this module, you will be able to identify how to mix different models to create new and more complex models. You will be able to explore how to create sophisticated versions of artificial societies. You'll also be able to examine an artificial society called Sugarscape.

Computer Simulations and Characteristics of ABM
    -In this module, you will be able to discover how one uses computer simulations to solve practical problems. You will be able to discuss agent-based models (ABM) and identify how ABM can be used in social science.

Model Thinking and Coding Artificial Societies
    -In this module, you will be able to describe what agent-based models are. You will be able to identify their capabilities and limitations. You will be able to define and use vocabulary and terminology around model thinking. You'll also be able to code using NetLogo and be able to grow your own artificial society.",Computer Simulations
https://www.classcentral.com/course/edx-machine-learning-with-python-from-linear-models-to-deep-learning-11483,"Machine learning methods are commonly used across engineering and sciences, from computer systems to physics. Moreover, commercial sites such as search engines, recommender systems (e.g., Netflix, Amazon), advertisers, and financial institutions employ machine learning algorithms for content recommendation, predicting customer behavior, compliance, or risk. 
As a discipline, machine learning tries to design and understand computer programs that learn from experience for the purpose of prediction or control. 
In this course, students will learn about principles and algorithms for turning training data into effective automated predictions. We will cover: 

Representation, over-fitting, regularization, generalization, VC dimension;
Clustering, classification, recommender problems, probabilistic modeling, reinforcement learning;
On-line algorithms, support vector machines, and neural networks/deep learning.

Students will implement and experiment with the algorithms in several Python projects designed for different practical applications. 
This course is part of theMITx MicroMasters Program in Statistics and Data Science. Master the skills needed to be an informed and effective practitioner of data science. You will complete this course and three others from MITx, at a similar pace and level of rigor as an on-campus course at MIT, and then take a virtually-proctored exam to earn your MicroMasters, an academic credential that will demonstrate your proficiency in data science or accelerate your path towards an MIT PhD or a Master's at other universities. To learn more about this program, please visit https://micromasters.mit.edu/ds/.
If you have specific questions about this course, please contact us atsds-mm@mit.edu.



            Read more
          



Lectures : 

Introduction
Linear classifiers, separability, perceptron algorithm
Maximum margin hyperplane, loss, regularization
Stochastic gradient descent, over-fitting, generalization
Linear regression
Recommender problems, collaborative filtering
Non-linear classification, kernels
Learning features, Neural networks
Deep learning, back propagation
Recurrent neural networks
Recurrent neural networks
Generalization, complexity, VC-dimension
Unsupervised learning: clustering
Generative models, mixtures
Mixtures and the EM algorithm
Learning to control: Reinforcement learning
Reinforcement learning continued
Applications: Natural Language Processing

Projects : 

Automatic Review Analyzer
Digit Recognition with Neural Networks
Reinforcement Learning",Machine Learning with Python-From Linear Models to Deep Learning
https://www.classcentral.com/course/intro-to-quantum-computing-8706,"Get an introduction to the key concepts of quantum computing
In this course, we will discuss the motivation for building quantum computers, cover the important principles in quantum computing, and take a look at some of the important quantum computing algorithms.
We will finish with a brief look at quantum computing hardware and the budding quantum information technology industry.
Key concepts will be explained graphically, with minimal mathematics but some deep thinking required.
[* Note in Japanese] 本コースでは、ビデオの日本語字幕および全テキストの日本語PDFが提供されています。
[* Note in Thai] คอร์สนี้มีคำบรรยายวิดีโอภาษาไทยและคำอธิบายเพิ่มเติมภาษาไทยในรูปแบบ PDF ประกอบ
Anyone interested in quantum computing at the “popular science” level.
High school students, college students, and computer professionals interested in developing a qualitative understanding of quantum computing in order to understand the future of computing will benefit.
We recommend that you be comfortable with exponents, vectors, sine waves and the basic concepts of probability. There are some equations, but we have endeavored to keep them as few and clear as possible.
While the mathematics is not too hard, some concepts will be new to most learners, and require some mental stretching. Be prepared to exercise your brain!
*คลิกที่นี่สำหรับหน้าภาษาไทย",Understanding Quantum Computers
https://www.classcentral.com/course/swayam-digital-land-surveying-and-mapping-dls-m-7983,"The objective of the course is to provide basics of digital surveying and mapping of earth surface using total station, GPS and mapping software. The course starts with introduction to land surveying followed by fundamentals of total station and its working & measurements for land surveying. Then, fundamentals, working & measurements using GPS for land surveying will be discussed. Followed by mapping fundamentals, digital surveying procedure, working, data reduction etc. Finally, the course will deals with working and demonstration of a digital land surveying and mapping of an area.This course will uncover all the major topics in pericyclic reactions and organic photochemistry. In addition to lectures there will be tutorial sessions and assignments in this course.INTENDED AUDIENCE : Diploma/Degree students in Civil Engineering/Geo-spatial technology, Master/Doctoral students in Geomatics/Geo- spatial technology, Field surveyors, Professional persons dealing with Land surveying, It is an application based Course., It is a core course for Civil Engineering, Geo-spatial Technology, Geography etc and an elective course for all domains in which Land surveying may be applied.PREREQUISITES : Basics of Physics and mathematics upto 12th standard and familiarity with use of computerINDUSTRY SUPPORT : http://dir.indiamart.com/impcat/topographic-survey-services.html 
      


COURSE LAYOUT Week 1:Fundamentals of Land Surveying & GPSWeek 2:Global Positioning System (GPS)Week 3:Global Positioning System (GPS)Week 4:TOTAL STATION(TS)Week 5:TS & DIGITAL LAND SURVEYING (DLS)Week 6:DLS& DIGITAL MAPPING (DM)Week 7:DM & DIGITAL DATA MANIPULATION (DDM)Week 8:DIGITAL LAND SURVEYING AND MAPPING (DLS&M)",Digital Land Surveying and Mapping(DLS&M)
https://www.classcentral.com/course/women-children-health-3817,"Learn about how we can safeguard the health of women and young people
Each year, there are roughly 10 million mostly preventable newborn, child, adolescent, maternal, and foetal deaths. These demographics are some of the most vulnerable around the world and urgently need better health outcomes.
On this course you’ll learn from experts at the World Health Organisation and the MARCH Centre how to analyse the latest data and evidence pertaining to the human life cycle – from birth to adulthood.
You’ll understand how this ‘lifecycle thinking’ can help us take action over women’s health and children’s health in the context of the Sustainable Development Goals for 2030.
This course is designed for healthcare professionals, undergraduate students taking a healthcare or science-related degree, medical students and postgraduates wishing to complement their studies, and anyone else with an interest in the topic.","Improving the Health of Women, Children and Adolescents"
https://www.classcentral.com/course/comparative-political-economy-1676,"In today’s world, politics and economics are interconnected, but what is the nature of this connectivity? What are the power relationships that shape the world economy today and create new challenges for international institutions facing globalization? What makes some countries wealthier than others? Do we face cultural diversity or fragmentation? Does the type of governance effect economic development and social change or is it the other way around? How do we measure it and how trustworthy is the data?  These issues and many more will be examined in this course along with a wide library of sources and a biting criticism.
      


Introduction into this courseIntroduction to this course, the instructor and his team. We would also like to hear from you. In addition we introduce Political Economy. Provides a framework for analysing the interface between choices made in politics and economics and the nature of power in eachData used in Political EconomyBasic Data. Reviews the basic data of population, output and development used to make international comparisons between countries.TrustTrust. Argues for the centrality of trust in explanations of differences in wealth and poverty between nations but highlights difficulties in measuring it and in explaining the direct of causality.Society and FragmentationInequality and Fragmentation. Examines how society can be fragmented along lines of religion, language, ethnicity and incomeGovernanceGovernance. Argues that good governance provides a transparent and stable environment for risk assessment and decision-making and contributes to welfare and growth. The question is how to get it. Economic DevelopmentDevelopment Assistance. Assesses the motivations for development assistance but raises doubts about the extent to which it can overcome local issues.FinalThe description goes here","Configuring the World, part 1: Comparative Political Economy"
https://www.classcentral.com/course/server-side-development-4229,"This course deals with all things server-side. We base the entire course around the NodeJS platform. We start with a brief overview of the Web protocols: HTTP and HTTPS. We examine NodeJS and NodeJS modules: Express for building web servers. On the database side, we review basic CRUD operations, NoSQL databases, in particular MongoDB and Mongoose for accessing MongoDB from NodeJS. We examine the REST concepts and building a RESTful API. We touch upon authentication and security. Finally we review backend as a service (BaaS) approaches, including mobile BaaS, both open-source and commercial BaaS services.

At the end of this course, you will be able to:

- Demonstrate an understanding of server-side concepts, CRUD and REST
- Build and configure a backend server using NodeJS framework
- Build a RESTful API for the front-end to access backend services


This course will close for new learner enrollment on Aug 3, 2017 PST. If you have already enrolled, you will continue to see it on your Coursera Dashboard as long as you remain enrolled.

This specialization is being shut down since we have launched the new Full Stack Web and Multiplatform Mobile App Development Specialization https://www.coursera.org/specializations/full-stack-mobile-app-development with all new courses on Bootstrap 4, Angular, Ionic Ver. 3 and Cordova, NativeScript Version 3 and Server-side Development with NodeJS, Express and MongoDB. Interested students should move to the new specialization.

You may wish to consider the new Server-side with NodeJS, Express and MongoDB that will launch in September 2017.
      


            Read more
          



Introduction to Server-side DevelopmentIn this module you will be introduced to Node, Node modules and the Node HTTP server. You will learn about the Express framework and how to set up a REST API using Express.Data, Data, Where art Thou Data?This module looks in detail at data storage with MongoDB, the popular NoSQL database. You will learn first about Express generator for scaffolding an Express application. Then you will learn about MongoDB. You will learn how to interact with MongoDB from a Node application. Then you will learn the Mongoose ODM to create schemas and models, and interact with MongoDB server.Halt! Who goes there?This module is dedicated to user authentication. We first develop a full-fledged REST API server with Express, Mongo and Mongoose. Thereafter we examine basic authentication and session-based authentication briefly. We then develop token-based authentication with the support of JSON web tokens and the Passport module.Backend as a Service (BaaS)In this module we learn about Mongoose population, a way of cross-referencing documents and populating the documents from other documents. We then review secure communication using HTTPS. We look at Backend as a Service (BaaS) and take a brief look at Loopback.",Server-side Development with NodeJS
https://www.classcentral.com/course/data-structures-5475,"A good algorithm usually comes together with a set of good data structures that allow the algorithm to manipulate the data efficiently. In this course, we consider the common data structures that are used in various computational problems. You will learn how these data structures are implemented in different programming languages and will practice implementing them in our programming assignments. This will help you to understand what is going on inside a particular built-in implementation of a data structure and what to expect from it. You will also learn typical use cases for these data structures.

A few examples of questions that we are going to cover in this class are the following:
1. What is a good strategy of resizing a dynamic array?
2. How priority queues are implemented in C++, Java, and Python?
3. How to implement a hash table so that the amortized running time of all operations is O(1) on average?
4. What are good strategies to keep a binary tree balanced? 

You will also learn how services like Dropbox manage to upload some large files instantly and to save a lot of storage space!
      


          Basic Data Structures
    -In this module, you will learn about the basic data structures used throughout the rest of this course.  We start this module by looking in detail at the fundamental building blocks: arrays and linked lists. From there, we build up two important data structures: stacks and queues. Next, we look at trees: examples of how they’re used in Computer Science, how they’re implemented, and the various ways they can be traversed. Once you’ve completed this module, you will be able to implement any of these data structures, as well as have a solid understanding of the costs of the operations, as well as the tradeoffs involved in using each data structure.

Dynamic Arrays and Amortized Analysis
    -In this module, we discuss Dynamic Arrays: a way of using arrays when it is unknown ahead-of-time how many elements will be needed. Here, we also discuss amortized analysis: a method of determining the amortized cost of an operation over a sequence of operations. Amortized analysis is very often used to analyse performance of algorithms when the straightforward analysis produces unsatisfactory results, but amortized analysis helps to show that the algorithm is actually efficient. It is used both for Dynamic Arrays analysis and will also be used in the end of this course to analyze Splay trees.

Priority Queues and Disjoint Sets
    -We start this module by considering priority queues which are used to efficiently schedule jobs, either in the context of a computer operating system or in real life, to sort huge files, which is the most important building block for any Big Data processing algorithm, and to efficiently compute shortest paths in graphs, which is a topic we will cover in our next course. For this reason, priority queues have built-in implementations in many programming languages, including C++, Java, and Python. We will see that these implementations are based on a beautiful idea of storing a complete binary tree in an array that allows to implement all priority queue methods in just few lines of code. We will then switch to disjoint sets data structure that is used, for example, in dynamic graph connectivity and image processing. We will see again how simple and natural ideas lead to an implementation that is both easy to code and very efficient. By completing this module, you will be able to implement both these data structures efficiently from scratch.

Hash Tables
    -In this module you will learn about very powerful and widely used technique called hashing. Its applications include implementation of programming languages, file systems, pattern search, distributed key-value storage and many more. You will learn how to implement data structures to store and modify sets of objects and mappings from one type of objects to another one. You will see that naive implementations either consume huge amount of memory or are slow, and then you will learn to implement hash tables that use linear memory and work in O(1) on average! In the end, you will learn how hash functions are used in modern disrtibuted systems and how they are used to optimize storage of services like Dropbox, Google Drive and Yandex Disk!

Binary Search Trees
    -In this module we study binary search trees, which are a data structure for doing searches on dynamically changing ordered sets. You will learn about many of the difficulties in accomplishing this task and the ways in which we can overcome them. In order to do this you will need to learn the basic structure of binary search trees, how to insert and delete without destroying this structure, and how to ensure that the tree remains balanced.

Binary Search Trees 2
    -In this module we continue studying binary search trees. We study a few non-trivial applications. We then study the new kind of balanced search trees - Splay Trees. They adapt to the queries dynamically and are optimal in many ways.",Data Structures
https://www.classcentral.com/course/swayam-introduction-to-internet-of-things-10093,"Internet of Things (IoT) is presently a hot technology worldwide. Government, academia, and industry are involved in different aspects of research, implementation, and business with IoT. IoT cuts across different application domain verticals ranging from civilian to defence sectors. These domains include agriculture, space, healthcare, manufacturing, construction, water, and mining, which are presently transitioning their legacy infrastructure to support IoT. Today it is possible to envision pervasive connectivity, storage, and computation, which, in turn, gives rise to building different IoT solutions. IoT-based applications such as innovative shopping system, infrastructure management in both urban and rural areas, remote health monitoring and emergency notification systems, and transportation systems, are gradually relying on IoT based systems. Therefore, it is very important to learn the fundamentals of this emerging technology.INTENDED AUDIENCE : CSE, IT, ECE, EE, Instrumentation Engg, Industrial EngineeringPREREQUISITES : Basic programming knowledge



COURSE LAYOUT Week 1: Introduction to IoT: Part I, Part II, Sensing, Actuation, Basics of Networking: Part-IWeek 2: Basics of Networking: Part-II, Part III, Part IV, Communication Protocols: Part I, Part IIWeek 3: Communication Protocols: Part III, Part IV, Part V, Sensor Networks: Part I, Part IIWeek 4: Sensor Networks: Part III, Part IV, Part V, Part VI, Machine-to-Machine CommunicationsWeek 5: Interoperability in IoT, Introduction to Arduino Programming: Part I, Part II, Integration of Sensors and Actuators with Arduino: Part I, Part IIWeek 6: Introduction to Python programming, Introduction to Raspberry Pi, Implementation of IoT with Raspberry PiWeek 7: Implementation of IoT with Raspberry Pi (contd), Introduction to SDN, SDN for IoTWeek 8: SDN for IoT (contd), Data Handling and Analytics, Cloud ComputingWeek 9: Cloud Computing(contd), Sensor-CloudWeek 10: Fog Computing, Smart Cities and Smart HomesWeek 11: Connected Vehicles, Smart Grid, Industrial IoTWeek 12: Industrial IoT (contd), Case Study: Agriculture, Healthcare, Activity Monitoring",Introduction to Internet of Things
https://www.classcentral.com/course/textanalytics-2736,"This course will cover the major techniques for mining and analyzing text data to discover interesting patterns, extract useful knowledge, and support decision making, with an emphasis on statistical approaches that can be generally applied to arbitrary text data in any natural language with no or minimum human effort. 

Detailed analysis of text data requires understanding of natural language text, which is known to be a difficult task for computers. However, a number of statistical approaches have been shown to work well for the ""shallow"" but robust analysis of text data for pattern finding and knowledge discovery. You will learn the basic concepts, principles, and major algorithms in text mining and their potential applications.
      


          Orientation
    -You will become familiar with the course, your classmates, and our learning environment. The orientation will also help you obtain the technical skills required for the course.

Week 1
    -During this module, you will learn the overall course design, an overview of natural language processing techniques and text representation, which are the foundation for all kinds of text-mining applications, and word association mining with a particular focus on mining one of the two basic forms of word associations (i.e., paradigmatic relations).   

Week 2
    -During this module, you will learn more about word association mining with a particular focus on mining the other basic form of word association (i.e., syntagmatic relations), and start learning topic analysis with a focus on techniques for mining one topic from text. 

Week 3
    -During this module, you will learn topic analysis in depth, including mixture models and how they work, Expectation-Maximization (EM) algorithm and how it can be used to estimate parameters of a mixture model, the basic topic model, Probabilistic Latent Semantic Analysis (PLSA), and how Latent Dirichlet Allocation (LDA) extends PLSA. 

Week 4
    -During this module, you will learn text clustering, including the basic concepts, main clustering techniques, including probabilistic approaches and similarity-based approaches, and how to evaluate text clustering. You will also start learning text categorization, which is related to text clustering, but with pre-defined categories that can be viewed as pre-defining clusters.   

Week 5
    -During this module, you will continue learning about various methods for text categorization, including multiple methods classified under discriminative classifiers, and you will also learn sentiment analysis and opinion mining, including a detailed introduction to a particular technique for sentiment classification (i.e., ordinal regression). 

Week 6
    -During this module, you will continue learning about sentiment analysis and opinion mining with a focus on Latent Aspect Rating Analysis (LARA), and you will learn about techniques for joint mining of text and non-text data, including contextual text mining techniques for analyzing topics in text in association with various context information such as time, location, authors, and sources of data. You will also see a summary of the entire course.",Text Mining and Analytics
https://www.classcentral.com/course/edx-mechanical-behavior-of-materials-part-1-linear-elastic-behavior-4012,"All around us, engineers are creating materials whose properties are exactly tailored to their purpose. This course is the first of three in a series of mechanics courses from the Department of Materials Science and Engineering at MIT. Taken together, these courses provide similar content to the MIT subject 3.032: Mechanical Behavior of Materials.
The 3.032x series provides an introduction to the mechanical behavior of materials, from both the continuum and atomistic points of view. At the continuum level, we learn how forces and displacements translate into stress and strain distributions within the material. At the atomistic level, we learn the mechanisms that control the mechanical properties of materials. Examples are drawn from metals, ceramics, glasses, polymers, biomaterials, composites and cellular materials.
Part 1 covers stress-strain behavior, topics in linear elasticity and the atomic basis for linear elasticity, and composite materials.
Part 2 covers stress transformations, beam bending, column buckling, and cellular materials.
Part 3 covers viscoelasticity (behavior intermediate to that of an elastic solid and that of a viscous fluid), plasticity (permanent deformation), creep in crystalline materials (time dependent behavior), brittle fracture (rapid crack propagation) and fatigue (failure due to repeated loading of a material).



Week 1: Normal and shear stress Normal and shear strain Hooke's law for isotropic materialsWeek 2:   3D stress states Stress strain curves for engineering materials Strain energyWeek 3: Anisotropic materials and symmetry Composite materialsWeek 4: Bonding between atoms; energetic basis for linear elasticity; Thermal strain; origins of thermal strain Rubber elasticity: entropic basis for non-linear elasticityWeek 5:   Final Quiz","Mechanical Behavior of Materials, Part 1: Linear Elastic Behavior"
https://www.classcentral.com/course/electrodynamics-electric-magnetic-fields-12510,"This course is a continuation of Electrodynamics: An Introduction and Electrodynamics: Analysis of Electric Fields. Here, we will introduce magnetostatics and relate it to the material we learned previously.  In addition, we will cover the basics of the electromotive force and how it can be used to build different devices. 

Learners will 
•	Be able to use solutions from electric fields and relate them to other subjects (heat transfer, diffusion, membrane modeling)
•	Understand Maxwell's equations in the context of magnetostatics
•	Be introduced to energy and quantum mechanics relating to magnetic forces

By relating the concepts in this lecture to other fields, such as heat/mass diffusion, and describing their potential applications, we hope to make this course applicable to our students careers. Because this course covers both basic concepts and device construction, we have designed it to be useful for researchers and industry professionals alike. The approach taken in this course complements traditional approaches, covering a fairly complete treatment of the physics of electricity and magnetism, and adds Feynman’s unique and vital approach to grasping a picture of the physical universe. Furthermore, this course uniquely provides the link between the knowledge of electrodynamics and its practical applications to research in materials science, information technology, electrical engineering, chemistry, chemical engineering, energy storage, energy harvesting, and other materials related fields.
      


            Read more
          



          Electrostatic Analogs 
    -This module covers the how electrodynamic solutions can be used to find solutions applicable to other fields.  We describe how electrodynamics is comparable to heat transfer, membrane physics, neutron diffusion, and other natural phenomenon.  Through these comparisons, understanding of other physics can be realized.

Magnetostatics
    -This module introduces magnetostatics, and the magnetic field outside of different geometries, and how relativity can be used to understand magnetic forces.  To lead into this, we will describe how to characterize current in a wire and while doing this, attention will again be drawn to the similarities between electrostatics and magnetostatics

The Magnetic Field in Various Situations
    -This lecture introduces the concept of the magnetic vector potential, which is analogous to the electric potential.  We explain the distribution of the magnetic potential and how to use it when solving for the electric field.  The magnetic dipole is also introduced and the Biot-Savart law is described.

Assessing the Vector Potential
    -In the first part of this module, we explore the topic of energy and work in the context of electrodynamics.  Then we explain the usefulness of the magnetic vector potential (A) and why it is a real field.  Finally, we tie these concepts with quantum mechanical electrodynamics, and reveal equations that are useful beyond the scope of statics.

Induced Currents
    -In the final module, we mostly cover the electromotive force, induced currents, and how they may be applied to create devices.  We show how forces, electric currents, and magnetism all interact in order to operate machinery.",Electrodynamics: Electric and Magnetic Fields
https://www.classcentral.com/course/udacity-intro-to-java-programming-831,"In this introductory course, you'll learn and practice essential computer science concepts using the Java programming language. You'll learn about Object Oriented Programming, a technique that allows you to use code written by other programmers in your own programs. You'll put your new Java programming skills to the test by solving real-world problems faced by software engineers.Why Take This Course?Java is one of the most popular programming languages used by software developers today. It is the core language used in developing Android apps, and is also commonly used in back-end web development. If you’re new to programming and want to enter either of these fields, this course is a great place to get started.

Even if you don’t have a career trajectory in mind, Java programming is a great option for first-time coders due to its popularity and ease of use. This course will provide you with a solid foundation in computer science and Object Oriented Programming concepts, as well as set you on the path for success as a software engineer.
      


          ### Lesson 1: Introduction to Computers, Programming Languages, Algorithms, and the Java Programming Environment

### Lesson 2: Introduction to Classes and Objects

### Lesson 3: Graphics

### Lesson 4: Fundamental Data Types

### Lesson 5: Decisions

### Lesson 6: Iterations

### Lesson 7: Arrays, ArrayLists and Simple Array Algorithms

### Lesson 8: Methods (Parameter Passing, Instance vs. Static Methods)

### Lesson 9: Inheritance",Intro to Java Programming
https://www.classcentral.com/course/edx-so-you-want-to-become-a-biomedical-engineer-6500,"Want to become a biomedical engineer but not sure where to focus or how to get there? This engineering course will give you an overview of this wildly popular and vast field, as you learn about more than two dozen areas of focus and get a peek at some of the cool and exciting advances going on at top institutions. Along the way, you’ll meet more than three dozen biomedical engineers—from top names in the field to those just starting their careers.
Through exercises, you’ll get to think like a BME and experience the various areas to see which fits your interests and talents.
Finally, once you have a better sense of where you’d like to focus, our educational and career advice will help show you how to get there.
While targeted to students exploring a career in biomedical engineering, anyone curious about this fascinating field will find something of interest: from the thinking processes of pilots and baseball batters to an inside view of a beating heart to developments in bionics, exoskeletons, and nanotechnology.
Join us on a journey through the world of biomedical engineering.
Verified students are eligible to earn Continuing Education Units (CEUs) and Professional Development Hours (PDHs), valid toward continuing education requirements for many professional certifications.



LESSON 1: Introduction

Overview
Course Structure

LESSON 2: Biomedical Engineering Defined

What is a BME
A Very Broad Field
How BMEs Differ from Other Engineers
Is BME Right for You?
Helping You Get There

LESSON 3: The Big Picture

A Multidisciplinary Field
A Simple History of Science
What Biomedical Engineering Provides

LESSON 4: Practical Applications

Introduction
Clinical Engineering
	
Working in the Clinical Setting


Rehabilitation Engineering
	
Neural Prostheses
Working with Patients
Exoskeletons 


Performance Enhancement
	
Monitoring Pilot Fatigue


How They Got Here

LESSON 5: Starting from Physiology

Introduction
Cardiac Engineering
	
Reanimating Human Hearts
Lessons from Hibernating Bears


Physiological Systems Modeling
	
Modeling Neural Circuits for Parkinson’s and Epilepsy Control


How They Got Here

LESSON 6: Neural Engineering

Introduction
	
Multi-Scale Engineering


Brain-Machine Interfaces
	
Addressing Pilot-Induced Oscillations
Sensory Feedback with Neural Implants
Non-Invasive Signaling


Conclusion
How They Got Here

LESSON 7: Biomedical Imaging

Introduction
Functional Brain Imaging
Cardiac Imaging
How They Got Here

LESSON 8: Biomedical Image Processing

Introduction
Image Analysis
How They Got Here

LESSON 9: Electronics & Instrumentation

Instrumentation, Sensors & Measurement
	
Sleep Monitoring
Home Robot for Fall Detection


Biosignal Processing
	
Cardio Seismography
Monitoring the Brain Under Anesthesia
Seizure Control


Wearable Biomedical Sensors
How They Got Here

LESSON 10: Biomedicine Meets Computers

Introduction
Bioinformatics
	
YOU on a Chip
Systems Medicine
Tracking Bacteria Propagation


Biomedical and Health Informatics
	
Monitoring Premature Infants
Mining Data from Wearables
Telemedicine


How They Got Here

LESSON 11: Mechanics Meets Biology & Medicine

Introduction
Biomechanics
Biorobotics
Surgical Robotics
How They Got Here

LESSON 12: Materials Go Very Small

Introduction
BioMEMS
Micro & Nanotechnology
How They Got Here

LESSON 13: BME Intersects Cells & Tissues

Introduction
Drug Design & Delivery
	
The Langer Lab
Tales of Two Startups


Biomaterials
Tissue Engineering
How They Got Here

LESSON 14: Additional Areas

Genetic Engineering & Synthetic Biology
Cellular & Molecular Biomechanics
Agricultural & Environmental Engineering

LESSON 15: Where the Rubber Meets the Road

Introduction
Let the Need Drive the Research
Getting to Market

LESSON 16: Designing Your Career

What You Can Do with a BME Degree
Selecting a Career Path
Working in Industry
Entrepreneurship
Career Advice

LESSON 17: Planning Your Education

Selecting Your Major
How Much Education You’ll Need
What Courses To Take
Academic Advice
	
Which Classes to Take
Degree Programs
Which Degree is Right for You
For Those Going to Med School
How Far You Should Go
Try Things On
Your Attitude Towards Learning


Gaining Real-World Experience
	
Why Work in a Lab
Getting into a Lab
The Lab Environment
Poster Halls



LESSON 18: Advice and Inspiration

What Inspires Me
Where to Learn More
Advantages of Society Membership
My Personal Goal
Conclusion",So You Want to Become a Biomedical Engineer
https://www.classcentral.com/course/data-analytics-accountancy-2-10515,"Welcome to Data Analytics Foundations for Accountancy II!  I'm excited to have you in the class and look forward to your contributions to the learning community.

To begin, I recommend taking a few minutes to explore the course site. Review the material we’ll cover each week, and preview the assignments you’ll need to complete to pass the course. Click Discussions to see forums where you can discuss the course material with fellow students taking the class.

If you have questions about course content, please post them in the forums to get help from others in the course community. For technical problems with the Coursera platform, visit the Learner Help Center.

Good luck as you get started, and I hope you enjoy the course!
      


          Course Orientation
    -You will become familiar with the course, your classmates, and our learning environment. The orientation will also help you obtain the technical skills required for the course.

Module 1: Introduction to Machine Learning
    -This module provides the basis for the rest of the course by introducing the basic concepts behind machine learning, and, specifically, how to perform machine learning by using Python and the scikit learn machine learning module. First, you will learn how machine learning and artificial intelligence are disrupting businesses. Next, you will learn about the basic types of machine learning and how to leverage these algorithms in a Python script. Third, you will learn how linear regression can be considered a machine learning problem with parameters that must be determined computationally by minimizing a cost function. Finally, you will learn about neighbor-based algorithms, including the k-nearest neighbor algorithm, which can be used for both classification and regression tasks.

Module 2: Fundamental Algorithms
    -This module introduces several of the most important machine learning algorithms: logistic regression, decision trees, and support vector machine. Of these three algorithms, the first, logistic regression, is a classification algorithm (despite its name). The other two, however, can be used for either classification or regression tasks. Thus, this module will dive deeper into the concept of machine classification, where algorithms learn from existing, labeled data to classify new, unseen data into specific categories; and, the concept of machine regression, where algorithms learn a model from data to make predictions for new, unseen data. While these algorithms all differ in their mathematical underpinnings, they are often used for classifying numerical, text, and image data or performing regression in a variety of domains. This module will also review different techniques for quantifying the performance of a classification and regression algorithms and how to deal with imbalanced training data.

Module 3: Practical Concepts in Machine Learning
    -This module introduces several important and practical concepts in machine learning. First, you will learn about the challenges inherent in applying data analytics (and machine learning in particular) to real world data sets. This also introduces several methodologies that you may encounter in the future that dictate how to approach, tackle, and deploy data analytic solutions. Next, you will learn about a powerful technique to combine the predictions from many weak learners to make a better prediction via a process known as ensemble learning. Specifically, this module will introduce two of the most popular ensemble learning techniques: bagging and boosting and demonstrate how to employ them in a Python data analytics script. Finally, the concept of a machine learning pipeline is introduced, which encapsulates the process of creating, deploying, and reusing machine learning models. 

Module 4: Overfitting & Regularization
    -This module introduces the concept of regularization, problems it can cause in machine learning analyses, and techniques to overcome it. First, the basic concept of overfitting is presented along with ways to identify its occurrence. Next, the technique of cross-validation is introduced, which can mitigate the likelihood that overfitting can occur. Next, the use of cross-validation to identify the optimal parameters for a machine learning algorithm trained on a given data set is presented. Finally, the concept of regularization, where an additional penalty term is applied when determining the best machine learning model parameters, is introduced and demonstrated for different regression and classification algorithms.

Module 5: Fundamental Probabilistic Algorithms
    -This module starts by discussing practical machine learning workflows that are deployed in production environments, which emphasizes the big picture view of machine learning. Next this module introduces two additional fundamental algorithms: naive Bayes and Gaussian Processes. These algorithms both have foundations in probability theory but operate under very different assumptions. Naive Bayes is generally used for classification tasks, while Gaussian Processes are generally used for regression tasks. This module also discusses practical issues in constructing machine learning workflows.

Module 6: Feature Engineering
    -This module introduces an important concept in machine learning, the selection of the actual features that will be used by a machine learning algorithm. Along with data cleaning, this step in the data analytics process is extremely important, yet it is often overlooked as a method for improving the overall performance of an analysis. This module beings with a discussion of ethics in machine learning, in large part because the selection of features can have (sometimes) non-obvious impacts on the final performance of an algorithm. This can be important when machine learning is applied to data in a regulated industry or when the improper application of an algorithm might lead to discrimination. The rest of this module introduces different techniques for either selecting the best features in a data set, or the construction of new features from the existing set of features.

Module 7: Introduction to Clustering
    -This module introduces clustering, where data points are assigned to larger groups of points based on some specific property, such as spatial distance or the local density of points. While humans often find clusters visually with ease in given data sets, computationally the problem is more challenging. This module starts by exploring the basic ideas behind this unsupervised learning technique, as well as different areas in which clustering can be used by businesses. Next, one of the most popular clustering techniques, K-means, is introduced. Next the density-based DB-SCAN technique is introduced. This module concludes by introducing the mixture models technique for probabilistically assigning points to clusters.

Module 8: Introduction to Anomaly Detection
    -This module introduces the concept of an anomaly, or outlier, and different techniques for identifying these unusual data points. First, the general concept of an anomaly is discussed and demonstrated in the business community via the detection of fraud, which in general should be an anomaly when compared to normal customers or operations. Next, statistical techniques for identifying outliers are introduced, which often involve simple descriptive statistics that can highlight data that are sufficiently far from the norm for a given data set. Finally, machine learning techniques are reviewed that can either classify outliers or identify points in low density (or outside normal clusters) areas as potential outliers.",Data Analytics Foundations for Accountancy II
https://www.classcentral.com/course/edx-introduction-to-lifestyle-medicine-12209,"This course is credit eligible through Doane University's Open Learning Academy. The  Open Learning Academy's 3-4 credit hour courses are designed to provide learners with foundational coursework for undergraduate level programs. It is strongly encouraged that you consult with your institution of choice to determine how these credits will be applied to their degree requirements prior to transferring the credit._______________________________________________________________________Lifestyle factors including poor nutrition and physical inactivity are critical determinants of health, causing a pandemic of chronic diseases, premature death and unsustainable healthcare costs. Currently, 50 percent of Americans live with one or more chronic illnesses in which diet, exercise and stress play a key role. Lifestyle Medicine is the science and application of 49 healthy lifestyles as interventions for the prevention and treatment of lifestyle-related diseases such as heart disease, diabetes, stroke, obesity, some neurological conditions and some cancers. It is the evidence-based specialty bridging the science of physical activity, nutrition, stress management and resilience; sleep hygiene and other healthy habits to individuals through clinical practice in healthcare.BIOL-212x Introduction to Lifestyle Medicine from DoaneX is a credit-eligible course. Learners have the opportunity to experience this same rigorous university-level course on a flexible schedule and earn academic credit when they pass the course with a C or better.Credit details:Number of credit hours for BIOL-212x Introduction to Lifestyle Medicine: 3 credit hours. Cost: $500 (USD) - pay for credit earned after passing the course with a C or better.Eligibility:

Learner must enroll in the Verified Certificate option.
Learner must abide to all course and academic integrity policies throughout the entire course.
Learner must receive a passing grade of a C or better.




            Read more",Introduction to Lifestyle Medicine
https://www.classcentral.com/course/biological-psychology-11038,"Explore the intriguing world of biological psychology
On this course, you’ll explore a fascinating branch of psychology, which looks at the connection between behaviour and human biological functions, in particular, the nervous system.
You’ll examine the role that genetics, heredity, genetic disorders, the nervous system and the brain and spinal cord plays in shaping our bodies and behaviour.
You’ll also investigate the role that neurotransmitters and heritable diseases play in our behaviour and you’ll leave the course with your own unique perspectives on some of the most biological psychology research.
This introductory course is for anyone interested in psychology - you don’t need any past experience.
It might be of particular use to learners who have already completed a Bachelor degree in other disciplines who are interested in expanding their science and research skills.
Complete this course, then the program
This course is part of the Introduction to Psychology Program, based on the first unit of Monash University’s fully online Graduate Diploma of Psychology (GDP).
Learners who successfully complete the seven courses in the Program and who are accepted into the Graduate Diploma of Psychology will receive one unit of academic credit.",Introduction to Psychology: Biological Psychology
https://www.classcentral.com/course/intro-to-data-exploration-11220,"This course answers the questions, What is data visualization and What is the power of visualization? It also introduces core concepts such as dataset elements, data warehouses and exploratory querying, and combinations of visual variables for graphic usefulness, as well as the types of statistical graphs, tools that are essential to exploratory data analysis.
      


          Getting Started

Introduction to Data Exploration Components

Exploratory Querying and Visual Variables Used in Data Exploration and Visualization

Statistical Graphics: Design Principles for the Most Widely Used Data Visualization Charts

 STATISTICAL GRAPHICS: DESIGN PRINCIPLES FOR Box Charts and QQ Plots",Introduction to Data Exploration and Visualization
https://www.classcentral.com/course/spatialcomputing-1766,"From Google Maps to consumer global positioning system (GPS) devices, spatial technology shapes many lives in both ordinary and extraordinary ways. Thanks to spatial computing, a hiker in Yellowstone and a taxi driver in Manhattan can know precisely where
    they are, discover nearby points of interest and learn how to reach their destinations. Spatial computing technology is what powers the Foursquare check-in, the maps app on your smartphone, the devices used by scientists to track endangered species,
    the routing directions that help you get from point A to point B, the precision agriculture technology that is revolutionizing farming, and the augmented reality devices like Google Glass that may soon mediate our interaction with the real world.
This course introduces the fundamental ideas underlying spatial computing services, systems, and sciences. Topics covered will include the nature of geospatial information, proper statistical frameworks for working with geospatial data, key algorithms
    and data structures, spatial data mining, and cartography/geovisualization. We will also address applied topics such as where to find spatial data, how to use powerful open source software to analyze and map spatial data, and frameworks for building
    location-based services.
    


Three Ways to Enjoy this Course:


This course is designed to support three different types of students and educational goals:
    

Curiosity Track: Most of us interact with spatial technologies every day. This track is for students who wish to learn about one or two spatial computing topics, but not commit to an entire course. Curiosity track students are not interested in
    a certificate of accomplishment.
    

Concepts Track: This track is for students who want to learn about spatial computing concepts in order to make informed choices, but who are not programmers and do not have extensive experience with statistical methods. For example, concepts track
    students will learn about Tobler’s First Law of geography and map projections, but will not delve into the quantifications of either. Students who complete the concepts track with sufficiently high scores will receive a Statement of Accomplishment.
    

Technical Track: This track builds on the concepts track, but adds math and programming. For example, we will cover spatial statistical indicators like Moran’s I and Ripley’s K when discussing Tobler’s First Law and will have students calculate
    the distance between two points using two different coordinate systems and open-source APIs. Students who complete the technical track with sufficiently high scores will receive a Distinguished Statement of Accomplishment.
    




            Read more
          



Topics Covered:

Module 1 - Introduction


Course Introduction
Defining Spatial Computing
Course Structure
Interviews with Johannes Schöning, Loren Terveen and Martin Raubal

Module 2 - Spatial Query Languages

What is a Query? Query Language?
An example database with 3 tables
SQL overview
SELECT statement with 1 table
Multi-table SELECT statement
Why spatial extensions are needed
1-table spatial queries
Trends

Module 3 - Spatial Networks

Motivation, Societal use cases
Example spatial networks
Conceptual and mathematical models 
Need for SQL extensions
CONNECT statement
RECURSIVE statement
Storage and data structures
Algorithms for connectivity query
Algorithms for shortest path
Interviews with Dev Oliver and Betsy George

Module 4 - Spatial Data Mining

Motivation, Spatial Pattern Families
Spatial data types and relationships 
Limitations of Traditional Statistics
Location Prediction model
Hotspots 
Spatial outliers
Colocations and Co-occurrences
Summary:  What is special about mining spatial data?

Module 5 - Volunteered Geographic Information (VGI)

Introduction to Volunteered Geographic Information
Producing VGI
Pros and Cons of VGI
Interview with Michael Goodchild

Module 6 - Positioning

Introduction to Positioning
Overview of GPS
Overview of Wifi and Cellular Positioning
Introduction to Content-based Positioning
Geoparsing 
Location-field Positioning

Module 7 - Cartography

Introduction to Cartography
Overview of Maps and Mapping
Reference Maps
Thematic Maps
Spatialization

Module 8 - Future Directions

Introduction 
Spatial Databases: Representative projects
Data Mining: Representative projects
Advances in Cartography
Advances in Positioning
Interviews with Vipin Kumar, Wan Bae, Mohammed Mokbel and Len Kne",From GPS and Google Maps to Spatial Computing
https://www.classcentral.com/course/iversity-why-do-people-migrate-part-1-facts-5396,"This course provides a general introduction to the conditions of refugees, asylum seekers and irregular migrants worldwide (data, regions, etc.) and an overview of the terminology used. It then analyses specific cases in the most relevant geographical contexts, including the asylum seekers arriving in Europe through the Mediterranean, the undocumented Mexican migrants crossing the US border, the Syrian refugees in Turkey and the Rohingya in Australia. In discussing these cases, we will explore the dilemmas behind humanitarian protection and irregular migration for labour purposes.
The course is based on video lectures, didactic videos and podcast interviews with international experts. Assignments consist of short quizzes for each unit and a journal exercise at the end of the course. Suggestions for further reading will be included in order to achieve a more in-depth understanding.
To learn more about the theories that explain international migration, check out Part 2: Theories



CHAPTER 1 – INTRODUCTIONUnit 1.1 – What are irregular migration and asylum?Unit 1.2 – Let us talk about words!
CHAPTER 2 – EUROPE AND THE MIDDLE EASTUnit 2.1 – Irregular border crossings towards the EUUnit 2.2 – Refugee status in EuropeUnit 2.3 – The case of Syrian refugees in Turkey
CHAPTER 3 – AMERICASUnit 3.1 – Irregular Latin-American migrants in US agricultureUnit 3.2 – Gender and irregular migration in Latin America
CHAPTER 4 – ASIA AND OCEANIAUnit 4.1 – Maritime arrivals in AustraliaUnit 4.2 – The case of Rohingya refugees",Why Do People Migrate? Part 1: Facts
https://www.classcentral.com/course/swayam-introduction-to-machine-learning-5288,"With the increased availability of data from varied sources there has been increasing attention paid to the various data driven disciplines such as analytics and machine learning. In this course we intend to introduce some of the basic concepts of machine learning from a mathematically well motivated perspective. We will cover the different learning paradigms and some of the more popular algorithms and architectures used in each of these paradigms.INTENDED AUDIENCE : This is an elective course. Intended for senior UG/PG students. BE/ME/MS/PhDPREREQUISITES : We will assume that the students know programming for some of the assignments.If the students have done   introductory courses on probability theory and linear algebra it would be helpful. We will review some of the basic   topics in the first two weeks as well.INDUSTRY SUPPORT : Any company in the data analytics/data science/big data domain would value this course. 
      


COURSE LAYOUT Week 0:   Probability Theory, Linear Algebra, Convex Optimization - (Recap)Week 1:   Introduction: Statistical Decision Theory - Regression, Classification, BiasVarianceWeek 2:   Linear Regression, Multivariate Regression, Subset Selection, Shrinkage Methods, Principal Component  Regression, Partial Least squaresWeek 3:  Linear Classification, Logistic Regression, Linear DiscriminantAnalysisWeek 4:  Perceptron, Support Vector MachinesWeek 5:  Neural Networks - Introduction, Early Models, Perceptron Learning, Backpropagation, Initialization,  Training & Validation, Parameter Estimation - MLE, MAP, Bayesian EstimationWeek 6:  Decision Trees, Regression Trees, Stopping Criterion & Pruning loss functions, Categorical Attributes, Multiway  Splits, Missing Values,Decision Trees - InstabilityEvaluation MeasuresWeek 7:  Bootstrapping & Cross Validation, Class Evaluation Measures,ROC curve, MDL,Ensemble Methods - Bagging,  Committee Machines and Stacking, BoostingWeek 8:   Gradient Boosting, Random Forests, Multi-class Classification,Naive Bayes, Bayesian NetworksWeek 9:   Undirected Graphical Models, HMM, Variable Elimination, Belief PropagationWeek 10:  Partitional Clustering, Hierarchical Clustering, Birch Algorithm, CURE Algorithm, Density-based ClusteringWeek 11:  Gaussian Mixture Models, Expectation MaximizationWeek 12:  Learning Theory, Introduction to Reinforcement Learning,Optional videos (RL framework, TD learning,Solution Methods, Applications)",Introduction to Machine Learning
https://www.classcentral.com/course/independent-jdk-8-massive-open-and-online-course-lambdas-and-streams-introduction-3844,"Java SE 8 (JDK 8) introduced a fundamentally new way of programming in Java with the introduction of Lambda expressions.Lambda provides a simple way to pass functionality as an argument to another method, such as what action should be taken when someone clicks a button, or how to sort a set of names. Lambda expressions enable you to do this, to treat functionality as a method argument, or code as data.You may have heard about Lambda expressions, and are curious what impact it will have on you as a Java developer.This course is designed to answer your questions and more.Have you ever wondered what Lambda expressions are in Java?Have you ever wanted to write parallel code in Java without worrying about threads and locking?Have you ever wanted to process collections of data without using loops?Have you ever wanted to do functional programming in Java?All of these questions will be answered in this practical hands-on MOOC. This course introduces two major new changes to the Java platform: Lambda expressions and the Stream API.",JDK 8 Massive Open and Online Course: Lambdas and Streams Introduction
https://www.classcentral.com/course/recoveringthepast-700,"Archaeology is, among human sciences, the discipline with the strongest importance for the rediscovery, but also for the preservation and protection of cultural heritage, as Humankind’s universal patrimony. You will be introduced to the way we ourselves reflect on and are engaged with the study of human past: from the practical and material recovery of ancient traces in the field to the study and interpretation. On the other hand, the discovery of human past implies the correct conservation and presentation for both experts and general public: the study and protection of the past we share every day prevent from any possible destruction, misuse, abuse and thus cancellation of human memory.
“Recovering the Humankind's Past and Saving the Universal Heritage” presents to a large public Archaeology as a historical discipline: through an inter-disciplinary perspective you will follow the evolution and change of archaeology to the moment when natural sciences contributed to make the historical reconstructions scientifically sound; the aid of informatics and of virtual reconstructions gives new fascination to the already strong suggestion of Archaeology, as the discipline of discovery par excellence. Within this frame, Ebla, which is the glory of the Sapienza school of Oriental archaeology, will have an exemplary meaning in the course development as a long lasting experience on the field and an excellent example of the scientific results of combined researches and disciplines.

Moreover, the course will focus on actual, innovative instruments to preserve, monitor and give value to cultural heritage through a multidisciplinary approach, based on a deep archaeological and historical knowledge but also on ICT technologies. The wide adoption of ICT technologies in our daily life is also impacting in the way in which we interact with our cultural heritage in particular in terms of preservation and dissemination of cultural objects.

In this course you will  learn the basic techniques  to digitize cultural objects and obtain 3D digital copies of a physical objects such as statues, vases or archaeological sites.  We will also discuss how to structure the raw data in order to facilitate and make effective the access to digital contents. In particular, we will present the European Data Model, a framework for collecting, connecting and enriching data on cultural objects provided by a number of museum, archives, sites and libraries in Europe.
      


            Read more
          



          COURSE INFORMATION & COLLABORATIVE ACTIVITIES
    -The inter-disciplinary perspective of Archaeology, the Ebla discovery, the use of ICT technologies and the introduction of the Europeana Data Model as a framework for collecting, connecting and enriching data will be the focus of the course.

Week 1 - The recovery of the human past and the protection of the universal heritage. 
    -We will start our enquiry by discussing how ancient societies kept memory of their own past, an aspect which, in fact, was fundamental to their identity. Shifting towards modern times, we will then reflect how the material past is preserved and how we refer to it. 
Homework available since 

Week 2 - The birth of archaeology and its role in the contemporary world. 
    -The study of the past of the planet marked the first serious reflections on humankind’s past, although archaeology was in fact considered the practice to collect objects. “New Archaeology” represents the first major revolution, promptly followed by the more structured and aggressive “Processual Archaeology"". The opening towards different disciplines implied the “loss of innocence” for archaeology, bringing at the same time scientific methods into the reconstructions of the past.
Homework available since 

Week 3 - The birth of archaeology and its role in the contemporary world. 
    -Field archaeology entails discovery, but is a matter of fact that discovering brings a great responsibility because it is a process of destruction. Digging means observing, recording, interpreting. Archaeological excavation is an harmonious trade-off between an intellectual and a manual labor. In fact, archaeological interpretation is a path shifting between identity and alterity.
Homework available since 

Week 4 - The birth of archaeology and its role in the contemporary world. 
    -Material remains of the past and their state of recovery vary according also to environments. Surface surveys lead to a more intense knowledge of territories, visualizing archaeologicallandscapes in a variety of ecological situations.  The objectives of archaeological research have been moulded in the historical development of the discipline. Historical sources have always been a sourceof inspiration for research, opening new problems. Chronology is a construct depending on dating tools, and scientific methods have been employed in determining an absolute chronology.
Homework available since 

Week 5 - The birth of archaeology and its role in the contemporary world. 
    -This module focuses on scientific research and knowledge dissemination.The specificities of the past pose a problem in respect of popularization and simplification. The operational chain is made of exploration, dig, publication, conservation, dissemination, protection. However, the need for a legitimacy of the present has led also to political readings of the retrieval of the past. Present cultural identity is grounded in the retrieved past. The “past of the other” has often been refused throughout history down to modern times. Our perception of the past is made manifest in its material and virtual reconstruction starting from ruins. Further, “excessive exploitation” of the past represent a modern destruction. The archaeological excavation of Ebla (Syria) will be analyzed as case study. It is in fact an example of a research framed within historical archaeology, which, in the course of fifty years of research, turned into a global perspective.
Homework available since Dic.: Quiz week 5

Week 6 - Digitizing Cultural Objects and 3D virtual reconstruction 
    -In this module, Emanuel Demetrescu will explain us the last methodologies and techniques in the field of 3D acquisition and reconstruction of cultural heriatage. These applications improve the knowledge and preservation and have a central role in the way we can communicate cultural heritage to the society. Making digital copies from real objects now has several very fun and precise technologies that are also available to everybody at very low cost budget. Demetrescu will show us how to use these tools to make our own models and share them with others. The virtual reconstruction of no-more-exstant objects (like a lost temple) will be the argument of the last part of the module: a state of the art of the methodologies will help us to understand how to approach such a process from a scientific point of view (archaeological method).
Homework available since 1 Jan.: Quiz week 6

Week 7 - Digitizing Cultural Objects and 3D virtual reconstruction 
    -In this module, Andrea Vitaletti will show us the basic techniques to effectively manage the  unprecedented amount of digital contents on cultural objects nowadays offered by cultural heritage providers. Raw data,  need to be organized in structured information in order to effectively support advanced functionalities, such as  indexing and searching. We will  present the basic techniques to structure the data in order to facilitate the access to digital contents and we will focus on  the European Data Model, a framework for collecting, connecting and enriching data on cultural objects provided by a number of museum, archives, sites and libraries in Europe. 
Homework available since 

Week 8 - Digitizing Cultural Objects and 3D virtual reconstruction 
    -This module deals with some basic issues and principles. All heritages are “equal among them”. Heritages are a property of humankind and not of the single countries. Heritages need to be protected and preserved in their context. But many threats are posed to heritages: illegal digging is a serious risk, as well as actions due to hatred for the “other” and his heritage. As a consequence of what stated above, damages to heritage are a crime against all humankind. International Organizations are engaged in protecting the heritage, the future of which represents a contribution to dialogue and peace. 
Homework available since",Recovering the Humankind's Past and Saving the Universal Heritage
https://www.classcentral.com/course/what-is-social-4205,"The “What Is Social?"" MOOC is for business owners, executives, and marketing professionals who want to significantly improve their abilities to grow their social strategy using effective, proven methodologies. This hands on, ""how to"" program won’t just tell you how to grow your professional persona using social – you will actually do it! This course is the first in the six-course specialization, Social Media Marketing: How to Profit in a Digital World. 

While the course can be audited for free, paid learners will receive additional content beyond the course basics. For MOOC 1, the toolkit includes a special video from Alessandro Acquisti on Big Data and a set of studies done by IBM on engagement and social marketing strategies with bottom-line profits. 

This course has been designed to give you the tools, insights, knowledge, and skills to immediately impact your organization. In addition, we will help you network with thought leaders in social.  After completing this course, you and your organization’s staff will be able to position, engage, and grow relationships with the consumers of highest value to you.

Today, we are living in a period of massive disruption. New technologies are changing the way people engage with each other and with the organizations that interest them. This course will start you on the path to growing your own social strategy using effective, proven methodologies.

Additional MOOC 1 faculty include: 
* Judy Ungar Franks (President, The Marketing Democracy, Ltd. & Lecturer, Medill Integrated Marketing Communications, Northwestern)
      


            Read more
          



          Introduction to Social Marketing
    -In this first module, you will learn about the goals, structure, and deliverables of the Social Marketing Specialization MOOCs, as well as gain an understanding of how the MOOCs in the Specialization will each build on one another to create a truly unique and immediately applicable experience. 

Social Trends
    -In this module, you will learn not only how the digital revolution has disrupted the marketplace, but also how you can make sense of this disrupted digital world.  

The Business of Social
    -In this module, you will learn how to view social as holistic, consumer/stakeholder focused, flexible, global, real-time and integrated. You will then complete a peer review assignment which will ask you to define your target audience on social. 

Social Overview
    -In this module, you will learn to understand the importance of big data and how to deal with all of the quickly changing social sites used today. You will also learn the difference between social networks and communities as well as the reasons that they form.  Then, you will set up the social sites that you will use throughout the Specialization.",What is Social?
https://www.classcentral.com/course/io-efficient-algorithms-16913,"Operations on data become more expensive when the data item is located higher in the memory hierarchy. An operation on data in CPU registers is roughly a million times faster than an operation on a data item that is located in external memory that needs to be fetched first. These data fetches are also called I/O operations and need to be taken into account during the design of an algorithm. The goal of this course is to become familiar with important algorithmic concepts and techniques needed to effectively deal with such problems. We will work with a simplified memory hierarchy, but the notions extend naturally to more realistic models. 

Prerequisites:
In order to successfully take this course, you should already have a basic knowledge of algorithms and mathematics. Here's a short list of what you are supposed to know:
- O-notation, Ω-notation, Θ-notation; how to analyze algorithms
- Basic calculus: manipulating summations, solving recurrences, working with logarithms, etc.
- Basic probability theory: events, probability distributions, random variables, expected values etc.
- Basic data structures: linked lists, stacks, queues, heaps
- (Balanced) binary search trees
- Basic sorting algorithms, for example MergeSort, InsertionSort, QuickSort
- Graph terminology, representations of graphs (adjacency lists and adjacency matrix), basic graph algorithms (BFS, DFS, topological sort, shortest paths)

The material for this course is based on the course notes that can be found under the resources tab.  We will not cover everything from the course notes. The course notes are there both for students who did not fully understand the lectures as well as for students who would like to dive deeper into the topics.

The video lectures contain a few very minor mistakes. A list of these mistakes can be found under resources. If you think you found an error, report a problem by clicking the square flag at the bottom of the lecture or quiz where you found the error.
      


            Read more
          



          Introduction 
    -In this module we give an introduction to the course I/O-efficient algorithms. We discuss the so-called I/O-model, which consists of an internal memory of limited size, an external memory of unlimited size and where data transfer between these two happens in blocks of a given size.  We give a simple example showing that the actual running time of an algorithm working on data in external memory is greatly influenced by its I/O-behavior. Finally, we discuss the basics of analyzing algorithms in the I/O-model.

Designing cache-aware and cache-oblivious algorithms
    -In this module we discuss two techniques to design I/O-efficient algorithms, using the matrix-transposition problem as a running example. The first technique is a ""tile-based"" approach and leads to a cache-aware algorithm. The second technique uses a recursive approach and leads to a cache-oblivious algorithm. 

Replacement Policies
    -When we want to read something from external memory while the internal memory is full we need to make room by evicting a block from internal memory. The block which should be evicted is decided by the replacement policy. In this module we introduce LRU and some other some well-known replacement policies, and investigate the I/O-efficiency of LRU compared to an optimal replacement policy. 

I/O-efficient sorting
    -In this module we analyze the I/O-efficiency of MergeSort and discuss how to adapt it to make it more  I/O-efficient.

I/O-efficient data structures
    -In this module we introduce some I/O-efficient data structures: B-trees and buffer trees, and an I/O-efficient  priority queue based on buffer trees.

Time-Forward Processing
    -In this module we discuss time-forward processing, a technique that can be used to evaluate so-called local functions on a directed acyclic graph.",I/O-efficient algorithms
https://www.classcentral.com/course/corrosion-15237,"If you have ever encountered rusty car bodies, leaking pipes, tarnished silverware or the green patina of a copper roof then you have experienced corrosion in action. This course, from the Corrosion@Manchester team in collaboration with AkzoNobel, will teach you why metals corrode, what the environmental consequences are, how much corrosion costs and how corrosion can be controlled. It is designed for students, householders, teachers, professionals and anyone in-between.

The aim of the course is to introduce the complex world of corrosion and corrosion control. While a full appreciation of corrosion science involves elements of materials science, electrochemistry and physics while corrosion engineering requires a practical knowledge of corrosion failures and engineering design this course does not need an extensive background knowledge. The course mirrors elements of the Corrosion Control Engineering teaching programme at The University of Manchester for final-year undergraduates and masters-level postgraduates and is used as a supplementary learning resource by our students.
      


          Week 1: Principles of Corrosion
    -In Week 1 we show you the scientific and engineering concepts that are important to an understanding of corrosion in practise. Section 1 provides a brief outline of what corrosion is, how much it costs and how corrosion engineers can help. Section 2 lists, with examples, the eight types of corrosion and shows the important of good engineering design on corrosion control. Section 3 focuses on materials properties and introduces how the corrosion of metals (zinc) may be understood. Section 4 looks directly at the economic and social consequences of corrosion. In section 5 we pick up the pace to focus on the science of electrochemical corrosion. Finally, in section 6, we wind up with a selection of corrosion failures chosen from the Corrosion@Manchester museum.

Week 2: Cathodic Protection
    -This week, will discuss how cathodic protection works and how it can be applied in practice to protect metallic structures.Firstly, we’ll discuss some of the basic principles behind cathodic protection, and we will see how some of the concepts you have learned in the other units are applied in a cathodic protection scenario.Subsequently, we’ll discuss some aspects related to the design of cathodic protection systems, such as for example the criteria that have to be satisfied to achieve a good level of corrosion protection, or the method used to assess the requirements for an existing structure in terms of cathodic protection current.Finally, we’ll touch on cathodic protection of reinforced concrete structures, discussing the factors that contribute to good concrete quality and discussing how we can protect the reinforcement steel bars by using cathodic protection.This week’s material is split into 6 sessions. Each session lasts approximately 20 minutes; at the end of each session, there will be a quiz to test your knowledge.

Week 3: Surface Engineering
    -In Week 3, we will introduce Surface Engineering. The learning materials for this week are organised into five sections. Throughout the week, we will clarify what surface engineering is and why surfaces are important. We will look into how coatings protect surfaces from corrosion and will discuss coating design criteria. We will also consider various Surface Engineering techniques. Finally, we will turn our attention to industrial applications of coatings for corrosion protection, coating performance and failure mechanisms. 

Week 4: Oilfield Corrosion and Control
    -Week 4 provides an introduction to oilfield corrosion science and engineering. You will learn about pertinent corrosion phenomena, as well as other degradation processes, along with approaches to minimise facility degradation. Specific topics include: types of oilfield equipment; sweet/sour corrosion; seawater corrosion; scaling; erosion; corrosion prediction; corrosion inhibition; corrosion management. All content in this section is section is licensed under Creative Commons Atrribution-NonCommercial-NoDerivs 3.0 Unported License",Protecting the World: Introducing Corrosion Science and Engineering
https://www.classcentral.com/course/computer-networking-10222,"This course is designed to provide a full overview of computer networking. We’ll cover everything from the fundamentals of modern networking technologies and protocols to an overview of the cloud to practical applications and network troubleshooting. 

By the end of this course, you’ll be able to:
● describe computer networks in terms of a five-layer model
● understand all of the standard protocols involved with TCP/IP communications
● grasp powerful network troubleshooting tools and techniques
● learn network services like DNS and DHCP that help make computer networks run
● understand cloud computing, everything as a service, and cloud storage
      


          Introduction to Networking
    -Welcome to the Networking course of the IT Support Professional Certificate! In the first week of this course, we will cover the basics of computer networking. We will learn about the TCP/IP and OSI networking models and how the network layers work together. We'll also cover the basics of networking devices such as cables, hubs and switches, routers, servers and clients. We'll also explore the physical layer and data link layer of our networking model in more detail. By the end of this module, you will know how all the different layers of the network model fit together to create a network.

The Network Layer
    -In the second week of this course, we'll explore the network layer in more depth. We'll learn about the IP addressing scheme and how subnetting works. We'll explore how encapsulation works and how protocols such as ARP allow different layers of the network to communicate. We'll also cover the basics of routing, routing protocols, and how the Internet works. By the end of this module, you'll be able to describe the IP addressing scheme, understand how subnetting works, perform binary math to describe subnets, and understand how the Internet works. 

The Transport and Application Layers
    -In the third week of this course, we'll explore the transport and application layers. By the end of this module, you'll be able to describe TCP ports and sockets, identify the different components of a TCP header, show the difference between connection-oriented and connectionless protocols, and explain how TCP is used to ensure data integrity.

Networking Services
    -In the fourth week of this course, we'll explore networking services. We'll learn about why we need DNS and how it works. We'll also show you why DHCP makes network administration a simpler task. By the end of this module, you'll be able to do describe how DNS and DHCP work, how NAT technologies help keep networks secure, and how VPNs and proxies help users connect and stay secured.

Connecting to the Internet
    -In the fifth week of this course, we'll explore the history of the Internet, how it evolved, and how it works today. We'll understand the different ways to connect to the Internet through cables, wireless and cellar connections, and even fiber connections. By the end of this module, you'll be able to define the components of WANs and outline the basics of wireless and cellular networking.

Troubleshooting and the Future of Networking
    -Congratulations, you've made it to the final week in the course! In the last week of this course, we'll explore the future of computer networking. We'll also cover the practical aspects of troubleshooting a network using popular operating systems. By the end of this module, you'll be able to detect and fix a lot of common network connectivity problems using tools available in Microsoft Windows, MacOS, and Linux operating systems.",The Bits and Bytes of Computer Networking
https://www.classcentral.com/course/antimicrobial-934,"Presented by:The Division of Infectious Diseases in the Department of Medicine at Stanford University School of Medicine >>>> NEWS FLASH ! <<<This course is now OPEN for ENROLLMENT at:https://med.stanford.edu/cme/courses/online/antimicrobial.htmlDates & Durations:Ongoing registration for this self-paced course is available untilNovember 22nd , 2015Estimated Time to Complete: Six hoursCME Processing Fee: $20CME Credits Offered: 6.0To Obtain CME Credits*:Review the information below, then click the Join for Free button to register and access the course material. If you have already registered for this activity, click the Go to Course button.View all of the videos, then follow the link at the end of the last video to register for CME and pay the $20 CME Processing Fee.Complete the CME course evaluation, CME post-assessment and CME post-test.75% of case-based post-test questions must be answered correctly in order to receive a CME certificate that will be emailed to the address provided within 2 weeks from the date of receipt.Learners will have 3 attempts to pass the post-test.The Stanford University School of Medicine designates this enduring material for a maximum of 6.0 AMA PRA Category 1 Credit(s)™. Physicians should claim only the credit commensurate with the extent of their participation in the activity.*Participation in discussion forums, chat rooms, homework assignments and additional readings are not certified for AMA PRA Category 1 Credit™.Intended AudienceThis course will offer a practical approach to prescribing antibiotic therapy and development of antimicrobial stewardship to physicians and pharmacists across all specialties and settings.Course DescriptionAntibiotics are among the most frequently prescribed classes of drugs and it is estimated that approximately 50% of antibiotic use, in both the outpatient and inpatient settings, is inappropriate. At the same time, in contrast to any other class of drugs, every antibiotic use has a potential public health consequence – inappropriate use may not harm only the individual patient, but contributes to societal harm by exerting an unnecessary selective pressure that may lead to antibiotic resistance among bacteria. This course will offer a number of illustrative cases, recognizable to the practicing physician in his or her practice to engage the learners in the thought processes that lead to optimal decision making, improved outcomes of individual patients, and harm reduction vis-a-vis the bacterial ecology.Learning ObjectivesDevelop skills to apply IDSA guidelines in treating common infections such as acute rhino-sinusitis.Apply evidence based antibiotic management to treat sepsis.Implement principles of antimicrobial stewardship when providing care to special populations and in various settings.Apply evidence based antibiotic management to surgical patients requiring antibiotic prophylaxis.Apply evidence based antibiotic stewardship program in the outpatient setting.Accreditation StatementThe Stanford University School of Medicine is accredited by the Accreditation Council for Continuing Medical Education (ACCME) to provide continuing medical education for physicians.AMA Credit Designation StatementThe Stanford University School of Medicine designates this enduring material for a maximum of 6.0 AMA PRA Category 1 Credit(s)™. Physicians should claim only the credit commensurate with the extent of their participation in the activity.DisclosuresThe following Course Director has indicated that he has a relationship with industry to disclose relative to the content of this activity during the planning phase. This relationship no longer exists and as a faculty member he has nothing to disclose:Stan Deresinski, MD FIDSAPfizer: Advisory Board memberClinical Professor, MedicineInfectious DiseaseAntimicrobial Stewardship Program Medical Director Stanford UniversityThe following speakers have indicated that they have a relationship with industry to disclose relative to the content of this activity:Thomas File, Jr MD MACP FIDSA FCCPProfessor of Internal MedicineHead ID SectionNortheastern Ohio Universities Colleges of Medicine and PharmacyRootstown, OhioChief, Infectious Disease ServiceSumma Health System Akron, OhioAstellas Pharma, Cubust, Durata, GSK, Merck: Advisory Board memberPfizer, Boehringer Ingelheim, Gilead, Tobotec: ResearchBayer AG, DalishSankyo, Forest: ConsultingJason Newland, MDMedical Director, Patient Safety and System Reliability; Associate Professor of Pediatrics,University of Missouri-Kansas City School of MedicineChildren’s Mercy Hospital Kansas CityPfizer: ResearchThe following planners, speakers and authors have indicated that they have no relationships with industry to disclose relative to the content of this activity Stan Deresinski, MD FIDSA	Clinical Professor, MedicineInfectious DiseaseAntimicrobial Stewardship Program Medical DirectorStanford UniversitySpeakerLucy Tompkins, MD PhD FIDSAHospital EpidemiologistInfectious DiseaseCo-Course Director, Content Reviewer, and SpeakerElizabeth Robilotti, MD MPHInstructor, Infectious DiseasesAntimicrobial Stewardship Program Principal Planner and SpeakerEmily Mui, PharmD, BCPSInfectious Disease PharmacistAntimicrobial Stewardship ProgramStanford UniversityPlannerNiaz Banaei MDAssistant Professor of Pathology and Medicine (Infectious Diseases)Director, Clinical Microbiology LaboratorySpeakerAnne Liu MDClinical Assistant Professor, Pediatrics - Immunology and AllergyClinical Assistant Professor, Medicine - Infectious DiseasesPediatric Allergy & Immunology ClinicSpeakerKavita Trivedi MD	Public Health Medical OfficerHealthcare Associated Infections ProgramCenter for Health Care QualityCalifornia Department of Public HealthCollaborator and SpeakerSasha Madison, MPH Manager, Infection Prevention and Control Department Stanford Hospital and ClinicsSpeaker R. Michael Buckley, M.D.Executive DirectorPennsylvania HospitalProfessor of Clinical MedicinePerelman School of MedicineUniversity of PennsylvaniaSpeakerConan MacDougall, PharmD, MAS, BCPSAssociate Professor of Clinical PharmacyUniversity of California San Francisco School of PharmacySpeakerKristi Kuper, PharmD, BCPSGSPC Clinical Pharmacy ManagerVHA Performance ServicesSpeakerPreeti N. Malani, MD, MSJAssociate Professor of Internal MedicineDivisions of Infectious Diseases and Geriatric and Palliative MedicineUniversity of Michigan Medical SchoolVeterans Affairs Ann Arbor Healthcare SystemSpeakerTechnical Design and DevelopmentMike McAuliffeStanford EdTech Pauline BeckerStanford EdTech Relly BrandmanCourseraContact InformationFor further information regarding the content, CME credit or if you experience any technical difficulties with this enduring material please send an email to cmeonline@stanford.eduCommercial Support AcknowledgementStanford University School of Medicine has received and has used undesignated program funding from Pfizer, Inc. to facilitate the development of innovative CME activities designed to enhance physician competence and performance and to implement advanced technology. A portion of this funding supports this activity.California Assembly Bill 1195 – Cultural and Linguistic CompetencyCalifornia Assembly Bill 1195 requires continuing medical education activities with patient care components to include curriculum in the subjects of cultural and linguistic competency. It is the intent of the bill, which went into effect July 1, 2006, to encourage physicians and surgeons, CME providers in the State of California and the Accreditation Council for Continuing Medical Education to meet the cultural and linguistic concerns of a diverse patient population through appropriate professional development. The planners and speakers of this CME activity have been encouraged to address cultural issues relevant to their topic area. The Stanford University School of Medicine Multicultural Health Portal also contains many useful cultural and linguistic competency tools including culture guides, language access information and pertinent state and federal laws. You are encouraged to visit the portal: lane.stanford.edu/portals/cultural.htmlPrivacycme.stanford.edu/policies/privacy.htmlTerms of Usewww.stanford.edu/site/terms



            Read more
          



Unit 1: The Basic Clinical Science of Antimicrobial Use:•	Introduction to Antimicrobial Stewardship•	The Story of Penicillin•	Principles of Antimicrobial Use•	Principles of Antibacterial Pharmacokinetics & Pharmacodynamics•	Sepsis Case Study: Application of Principles•	Introduction to Bacterial Resistance•	Antibiotic Resistance: Gram Positive Resistance Beyond PCN•	Antimicrobial Resistance: Mycobacterial, Viral and Fungal Resistant •	Acute Bacterial Skin and Skin Structure Infections•	Antibiotic Allergies•	Cystitis•	Upper Respiratory Tract Infections•	Community Acquired Pneumonia in the Outpatient SettingUnit 2: Practical Aspects of Antimicrobial Stewardship and Application to Special Circumstances and Populations:•	Antibiotic Stewardship Interventions•	Convincing the C-Suite•	Measurements and Metrics•	Incorporating Clinical Decision Support into Stewardship•	Diagnostics •	Infection Prevention and Antimicrobial Stewardship•	Surgical Site Prophylaxis •	Out-Patient Parenteral Therapy•	Antimicrobial Stewardship in Pediatrics •	Antimicrobial Stewardship and Transplant Infectious Diseases•	Antimicrobial Stewardship: Long-term Care•	Antimicrobial Use at the end of life•	Conclusion",Antimicrobial Stewardship: Optimization of Antibiotic Practices
https://www.classcentral.com/course/disasterprep-481,"Have you ever viewed a news report depicting the aftermath of a devastating natural disaster? The damage to human life and property are both staggering and heartbreaking. All parts of the world face the possibility of floods, hurricanes, tornados, fires, landslides, earthquakes, tsunamis, and other natural phenomena. Are you prepared if disaster would strike you? This course will help you prepare!

The course is appropriate for any learner who is proactive about developing the core competencies of disaster readiness and survival planning. It is especially useful if you are seeking techniques that can ensure your personal protection, as well as the safety of your family, property, and belongings, during a natural disaster. In addition, it offers essential preparation for a variety of emergency situations and inconveniences, even if you do not live in major tornado, flood, hurricane, tsunami, or earthquake zone. For instance, could you and your loved ones manage without access to potable water, electricity, fuel, and banking facilities? If you are unsure of your ability to respond in any of these possible scenarios, this course is for you!

Throughout the course, you will be introduced to the Disaster Cycle, specifically the Mitigation and Recovery phases, and will create an extensive personal preparedness plan for survival in the absence of common amenities, such as food and water, shelter, and communication. You will also acquire practical, easy-to-apply strategies for maintaining a healthy attitude during disaster which can allow you to remain calm, avoid panic, and draw upon inner and outer resources in dire circumstances. Although death may be an inevitable outcome of extreme circumstances, a balanced outlook can provide comfort for all parties involved. Finally, issues of how institutions and governments can aid in disaster are also discussed.
If you are interested in this topic you may be interested in other online programs at the University of Pittsburgh School of Nursing. Learn more about those programs by visiting our website: http://www.online.pitt.edu/programs/school-of-nursing/
      


            Read more
          



          Introduction & Disaster Cycle
    -A disaster can be defined in several ways, but in all cases is a destructive event that overwhelms all available resources. A disaster may originate as natural or manmade and may be intentional or accidental. A natural disaster is caused by the forces of nature such as a hurricane, tornado, or earthquake. A manmade disaster may be the result of a terrorist act or industrial accident. Depending on the scope of the disaster, the available resources may be local, state, federal, or multinational. In this module, I will introduce the phases of the disaster cycle. The disaster cycle is a process that we constantly review and strive to improve for the future. It is important for you to understand each phase because clear expectations will enable you to develop an effective plan to keep you and your family safe. At the end of the module, be sure to complete the quiz. 

Personal Preparedness Basics
    -There are a few extreme circumstances such as a 30 foot wall of water during a tsunami or a 10-point Richter scale earthquake that are so severe it is impossible to prepare for the disaster.  However, in most cases people can take a few steps to ensure their survivability during a disaster.  Personal preparedness involves being both physically and mentally prepared to meet basic needs for at least three days without outside help. Last module, we talked about the disaster cycle including mitigation, response, and recovery.  In this module, our focus centers on the response phase.  The disaster has hit and you are taking steps to survive and to be as safe and comfortable as possible. In the lectures, I will focus on food, shelter, water, and light in a disaster situation.  In addition, we have on-site instructional videos that highlight survival skills such as fire-building and water purification.  Do we have any campers in the class?  For those of you who are campers, these skills will be a familiar review of basic wilderness survival techniques.  The lectures will also give you ideas of supplies that you might want to include in your disaster kit.  Take notes during the lectures to prepare for the discussion and quiz.

Personal Preparedness Safety
    -As we have discussed, disasters significantly overwhelm community resources and it is critical that you have a plan.  In the last module, we considered the basics of food, shelter, and water in your personal preparedness plan.  In this module, we move on to the topics of security, first aid, and tools. Safety is a major concern for you and your family in post-disaster situations.  Use common precautions such as drinking plenty of water, wearing protective gloves and shoes, washing your hands often, and avoiding exhaustion.  Depending on the situation, you may have to deal with washed out roads, broken glass, contaminated water, downed power lines, or serious gas leaks.

Attitudes and Awareness
    -Disasters are understandably stressful situations that trigger panic, fear, confusion, and uncertainty. During a disaster, you lose control of many aspects of your life.  Your family may not be together.  You may not be able to access food, water, shelter, transportation, or communication.  Since we do not have control of many variables, there is no point in worrying about possible disasters; however, having a clear, detailed plan in place will lessen anxiety and strengthen our ability to make timely, rational decisions if a disaster occurs.  Disaster planning takes us “back to basics” and what is most important to our survival. 
A positive attitude and heightened awareness will help you cope with an emergency situation.  In this module's lesson, we focus on attitude and awareness, discuss an awareness-building activity, and submit your disaster preparedness plans.  In the next module, you will peer-review the plans and provide feedback to you classmates.

International Perspectives
    -In this module, we welcome guest speaker Dr. Kenichi Ogura who will discuss disaster planning in Japan.  Dr. Ogura works at the Center for Emergency Medicine in Kanazawa Medical University Hospital. I am confident you will find Dr. Ogura’s presentation very helpful as the Japanese culture plans for disaster preparedness based on extensive research in earthquake and tsunami science.  They have spent a great deal of money developing early warning systems and constructing buildings based on strict safety codes.   Be sure to read the Time magazine article prior to viewing Dr. Ogura’s presentation. In addition, we will compare and contrast the emergency resources available in your countries.  These resources will help you to recognize the role that culture plays in disaster planning.  Note that you are also required to review three Personal Disaster Preparedness Plans from other students and provide feedback to them.

Support and Medical Considerations
    -During Module 6, we will explore triage as a necessary but difficult task during disaster management.  Triage is using the available resources to effectively treat the maximum number of patients with the greatest chance of survival. The process requires the clinician to quickly prioritize patients’ treatment plans based on the severity of their conditions.  Triage is part of everyday life in a hospital setting, but all patients ultimately receive the treatment that they need.  During a disaster, the goal is to ensure that best positive outcome for the most victims.In addition, we will consider disaster preparedness on a larger scale.  Perhaps you are responsible for a group of people beyond yourself or your immediate family.  You might be responsible for children in a day care setting, employees in a business, customers in a store, or even pets in a kennel.  What are the major issues to consider?  What supplies and equipment do you need to have available? The activity for this module involves reviewing the feedback you received from your peers and revising your Personal Disaster Preparedness Plan.  The discussion focuses on an ethical dilemma that occurred at Memorial Hospital in New Orleans during the Katrina hurricane (2009). Lastly, double-check that you have completed all of the quizzes.

Wilderness Survival
    -In the last module we talked about how disasters can displace you and your family from the comforts of your home, leaving you without food, water, and electricity. However, if you were left without shelter, or forced to take refuge in the natural habitat, are you equipped to survive? In this module we will review a set of wilderness survival techniques commonly known to many campers. Topics will include basic fire-building, water purification, constructing temporary shelters, and practical knives that can assist.",Disaster Preparedness
https://www.classcentral.com/course/covid-19-19029,"Welcome to ‘Science Matters: Let's Talk about COVID-19’, from the Abdul Latif Jameel Institute for Disease Emergency Analytics (J-IDEA) at Imperial College London.

The outbreak of the novel Coronavirus Disease (COVID-19) is the most significant public health emergency of the 21st century so far. As the epidemic spreads, people around the world want to understand the science behind the most pressing questions: how many people have been infected? How dangerous is the virus? When will a vaccine be available? How can the epidemic be contained, and the damages mitigated? What is the economic impact? What’s the role of social media and local communities in the epidemic response? 

Researchers at J-IDEA and other research institutes at Imperial College London have been at the forefront of the response to the COVID-19 emergency, with clinical, epidemiological and social science analyses informing the outbreak response. They are generating robust empirical evidence that governments and international agencies are using around the world to plan their responses. 

On this course, you will hear directly from our world class experts about the theory behind the analyses of COVID-19 and its spread, while learning how to interpret new information using core principles of public health, epidemiology, medicine, health economics, and social science. You will be able to watch regular situation reports about the state of the epidemic, provided by the researchers of J-IDEA and its director Professor Neil Ferguson. 

If you want to learn even more about these topics, a number of free MOOCs are available from Imperial College London. We also offer a fully online Global Master of Public Health for those of you who want to delve even deeper and join our professional community. 

Please note that we are creating all the content in real time as new information breaks, and that new material will be uploaded as it becomes available. The contents of the course are available free of charge.
      


            Read more
          



          Introduction to Science Matters: Let's talk COVID-19
    -Join us to learn more about the science underpinning the analyses of the novel coronavirus pandemic, now referred to as COVID-19. 

COVID-19 Situation Reports: Updates on the Ongoing State of the Epidemic
    -This module will include regular updates about the current state of the epidemic from the leading researchers of the Abdul Latif Jameel Institute for Disease and Emergency Analytics (J-IDEA) and the MRC Centre for Infectious Disease Analysis (MRC GIDA), including Prof Neil Ferguson. Don't forget to check out the Sit.Reps discussion forum.

How to Forecast an Epidemic: Epidemiology and Infectious Disease Modelling
    -This module will cover a number of the essential principles of epidemiology and infectious disease modelling. You will hear from our experts who will explain the basic reproductive number is used to understand transmissibility, about how the case fatality rate is estimated, how phylogenetic analysis can be used to understand the epidemiology of COVID 19 and about the relative sensitivity of international COVID-19 surveillance. Don't forget to check out this module's discussion forum.

Health Systems and Economic Impacts
    -This session is being created in real time as the epidemic unfolds. This section will be updated with up to date materials once they become available.

Community Engagement and Response
    -This session is being created in real time as the epidemic unfolds. This section will be updated with up to date materials once they become available.

Development of a Vaccine in Real-Time Epidemics
    -This session is being created in real time as the epidemic unfolds. This section will be updated with up to date materials once they become available.

The Clinical Presentations of COVID-19
    -This session is being created in real time as the epidemic unfolds. This section will be updated with up to date materials once they become available.

Summary Module
    -This session is being created in real time as the epidemic unfolds. This section will be updated with up to date materials once they become available.",Science Matters: Let's Talk About COVID-19
https://www.classcentral.com/course/network-security-database-vulnerabilitie-13873,"This course gives you the background needed to understand basic network security.  You will learn the about Local Area Networks, TCP/IP, the OSI Framework and routing basics.  You will learn how networking affects security systems within an organization.  You will learn the network components that guard an organization from cybersecurity attacks.

In addition to networking, you will learn about database vulnerabilities and the tools/knowledge needed to research a database vulnerability for a variety of databases including SQL Injection, Oracle, Mongo and Couch.  

You will learn about various security breach types associated with databases and organizations that define standards and provide tools for cybersecurity professionals.

This course is intended for anyone who wants to gain a basic understanding of Network Security/Database Vulnerabilities or as the fourth course in a series of courses to acquire the skills to work in the Cybersecurity field as a Jr Cybersecurity Analyst.
      


          TCP/IP Framework
    -In this module, you will learn about the TCP/IP Framework, Ethernet and Lan Networks, and the basics around routing and switching.  You will also learn about address translation and the basic differences between Intrusion Detection and Intrusion Prevention Systems.  Finally, you will learn about network packets.

Basics of IP Addressing and the OSI Model
    -In this module, you will learn the basics of IP Addressing and how it affects the network traffic routing.  You will about application and transport protocols.  You will learn about firewalls and additional information in regards to Intrusion Detection and Intrusion prevention systems.  Finally, you will learn the concepts of high availability and clustering.

Introduction to Databases
    -In this module you will learn to define data source and model types as well as types of data.  You will also review how to use best practices to secure your organizations data.  Finally, you will get an in depth look at use cases around an example of a Data Protection solution, IBM Security Guardium.

Deep Dive - Injection Vulnerability
    -In this module you will hear an IBM Subject Matter expert discuss the common vulnerability of Injection.  You will learn the basics around OS Command Injection and SQL Injection.",Network Security & Database Vulnerabilities
https://www.classcentral.com/course/understanding-obesity-7635,"In this course, we’ll look at the facts and misconceptions around obesity and discuss key physiological and psychological concepts around the brain’s control of appetite and body weight. We’ll consider the biological and environmental pressures that make it easy to gain weight (and hard to lose it!). Most importantly, we'll give you the opportunity to reflect on your own knowledge and assumptions around the subject.

We deliver course materials as a mixture of videos, audio-only MOOCcasts, and a selection of short readings. There are  short weekly quizzes, a peer-reviewed exercise, and discussion activities on the forum. These will help you prepare for the final project. In it, you are invited to demonstrate your evidence-informed understanding and express how you'll develop it beyond the course.

The course features Citizen Science projects. We'll collect data from you (anonymously, of course) and use it to drive participant-led discussions of controversial ideas. In this way, we hope to explore ideas around diet and obesity.  These projects also give a taste of how scientific evidence is collected and interpreted by scientists, and give some indication how much there still is to discover and understand.
      


          Week 1: What we know, and how we know it.
    -This week we'll discuss what we know about diet, appetite and obesity. But, and perhaps more importantly, we'll point out the gaps in our knowledge.

Physiology and Stress
    -This week we discuss some aspects of the physiology of obesity and learn how so-called ""food addiction"", stress and early-life experience can affect our eating choices. 

Included is an optional assignment where you can explore barriers to healthy eating. This assignment is not graded but does use the same interface as the Week 4 assessment. As such, you may find it useful to use it as practice for the ""real thing"".

Psychology and Behaviour
    -This week we discuss some aspects of the psychology of appetite control and learn how portion sizes and food insecurity might affect our behaviours.

Consolidation and Discussion
    -This week online material will be posted ad hoc as we consolidate and discuss what we've already learned. This week's main tasks are a quiz on the scientific method and the peer-reviewed assignment.  Please note you can attempt the Week 4 quiz only once.",Understanding Obesity
https://www.classcentral.com/course/using-data-geographic-mapping-sas-va-17975,"In this course, you learn about the data structure needed for geographic mapping and forecasting, how to use SAS Data Studio to restructure data for analysis, and how to create geo maps and forecasts in SAS Visual Analytics.
      


          Course Overview and Introduction to Advanced Topics
    -In this module, you learn about the business scenario that you will follow for this course and where the files are located in SAS Viya for Learners.

Restructuring Data for Geographic Mapping
    -In this module, you learn more about geographic maps in Visual Analytics.

Restructuring Data for Forecasting
    -In this module, you learn more about forecasting in Visual Analytics.",Using Data for Geographic Mapping and Forecasting in SAS Visual Analytics
https://www.classcentral.com/course/soc101-354,"We live in a world that is changing very quickly. Sociology gives us the tools to understand our own lives and those quite remote from us. The premise of this class is that in order to benefit from the sociological perspective, we need to learn how to ask certain basic questions. We need to know how to seek answers through methods that strive to be systematic and generalizable.We will begin with some of the essential questions: How are the things that we take to be natural socially constructed? How do we live today? How determined is social life? Does the individual make a difference? How is social order possible? Then we will ask what techniques are available to make sense of these questions.  We will review comparative, historical, demographic, experimental, and ethnographic methods. Along the way, we will study core concepts including ethnocentrism, social networks, community, unanticipated consequences, social capital, race, class, and gender.  We will strive to understand how interaction in micro-level contexts affects larger social processes and how such macro-level processes influence our day to day lives. We will learn to conceive of inequality by asking how race, class, and gender work in tandem. We will address one of the crises of recent sociology -- whether we can actually isolate the effects of social context. We will think about how social science is changing at a time when we are literally swimming in oceans of data generated by the internet.
      


Week 1: The Sociological Imagination
Week 2: Three Sociological Questions
Week 3: Methods of Sociological Research
Week 4: Us and Them
Week 5: Isolation, Groups, and Networks
Week 6: Cities
Week 7: Social Interaction and Everyday Life",Introduction to Sociology
https://www.classcentral.com/course/edx-minds-and-machines-4504,"What is the relationship between the mind and the body? Can computers think? Do we perceive reality as it is? Can there be a science of consciousness?
This course explores these questions and others. It is a thorough, rigorous introduction to contemporary philosophy of mind.
According to many scientists and philosophers, explaining the nature of consciousness is the deepest intellectual challenge of all. If you find consciousness at all puzzling, this is a great place to start learning more.



Overview. This class is an introduction to philosophy of mind. Here are some of the questions we’llbe thinking about:

Are you an “immaterial soul”, distinct from your brain and body?
Alternatively, are you simply a material or physical animal, living in an entirely physical world?
If we (somehow) made a brain that was a perfect molecule-for-molecule replica of your brain,and (somehow) kept it alive in a tank, would the tank-creature have the same mental life as you?
Do we see ordinary physical objects like lemons and iPhones? And assuming that we do see them at all, do we see them as they really are?
Can consciousness be given a scientific explanation?

Schedule.Part 1 – Minds and ComputersLecture 1: IntroductionLecture 2: The Chinese RoomLecture 3: The Chinese Room, Continued; ArgumentsLecture 4: The Chinese Room, ContinuedLecture 5: Turing Machines and the Turing TestLecture 6: The Turing TestAssessment 1: First Argument Analysis (10%)Part 2 – From Dualism to FunctionalismLecture 7: DualismLecture 8: Dualism, ContinuedLecture 9: BehaviorismLecture 10: The Identity TheoryLecture 11: The Identity Theory, ContinuedLecture 12: Kripke’s ObjectionLecture 13: FunctionalismLecture 14: Functionalism, ContinuedAssessment 2: Midterm Exam (30%)Part 3 – Minds and BrainsLecture 15: KnowledgeLecture 16: BeliefLecture 17: Belief, ContinuedPart 4 – PerceptionLecture 18: PerceptionLecture 19: The Argument from Illusion, and Color PerceptionLecture 20: ColorAssessment 3: Second Argument Analysis (10%)Part 5 – ConsciousnessLecture 21: Color, Continued; Nagel on BatsLecture 22: Nagel on Bats, Continued; the Knowledge ArgumentLecture 23: The Knowledge Argument, Continued; Chalmers’ DualismLecture 24: Chalmers’ Dualism, Continued; Tye on TransparencyLecture 25: Consciousness Wrap-UpAssessment 4: Final Exam (50%)",Minds and Machines
https://www.classcentral.com/course/internet-of-things-communication-4173,"Have you wondered how “Things” talk to each other and the cloud? Do you understand the alternatives for conveying latency-sensitive real time data versus reliable signaling data? Building on the skills from the Sensing and Actuation course, we will explore protocols to exchange information between processors. 

In this course, you will learn how VoIP systems like Skype work and implement your own app for voice calls and text messages.  You will start by using the Session Initiation Protocol (SIP) for session management. Next, you will learn how voice codecs such as Adaptive Multi Rate (AMR) are used in 3G networks and use them for voice traffic in your app. 

Learning Goals: After completing this course, you will be able to:

1.	Implement session initiation, management and termination on your DragonBoard™ 410c using SIP.
2.	Discover other users and exchange device capabilities.
3.	Compare and contrast narrowband and wideband codecs and experience the voice quality differences between them.
4.	Implement and demonstrate VoIP calls using the DragonBoard 410c.
      


          Introduction
    -Welcome to the Internet of Things! Before diving into this course give us a chance to let you know what it is all about! We will walk you through a module by module outline that will give you highlights on the interesting aspects of the course.

Terminology/Cheat Sheet (Beginner)
    -In this course, you will see a lot of new words and acronyms you might not be familiar with. If you feel comfortable with your knowledge of tech terminology, feel free to skip these lessons since they will not affect the overall integrity of the course. If you see something that you want to know a little more about, feel free to watch the video to gain insight on some basic concepts. We do expect you to know the majority of this material before going into the next module, we would recommend going through the lessons as a quick brush up.

VOIP in a Nutshell
    -This module will take a high level look at what VoIP is in a nutshell. Essentially, we would like to talk a little more in depth about the key terms you may have seen in module 1. We will also go over a great open source VoIP application called Linphone, and explain a variety of ways you can use this open source code to expand on a VoIP application we will be making later on in the course. We will take a look at SIP and look at some online resources that might help you to understand the inner working of VoIP.

Codecs
    -In this module our esteemed Professor Harinath Garudadri will talk about coders and decoders (Codecs). This will allow us to make better use of the communications in the data plane.We want to look at the motivation behind using Codecs, the different ways to take advantage of redundancies when using codecs and finally the ability to take advantage of different receiver / transmitter combinations. If we are able to understand the way that information is sent and received over the data plane we can create and use the right codecs.

Make your own VoIP application
    -The main part of this module will focus on you making your very own VoIP application on the Android operating system. In order to do this, you might have to brush up on some of the materials in Course 2. You will be required to use Android Studio to push the application onto your board. You will need to know how to use Git, adb and possibly fastboot in order to accomplish this. We will provide you with the code for your application, but remember, the code we are giving you is only a template that can be used to build a bigger and better application with a wide variety of functions. Once we have built your application and pushed it to your board, we will sit together and brainstorm everything we have seen in the last few courses and take a look at what we are now capable of building in the IoT market.",Internet of Things: Communication Technologies
https://www.classcentral.com/course/reasonandpersuasion-980,"In this course we study the ancient, Socratic art of blowing up your beliefs as you go, to make sure they're built to last. We spend six weeks studying three Platonic dialogues - ""Euthyphro"", ""Meno"", ""Republic"" Book I - then two weeks pondering a pair of footnotes to Plato: contemporary moral theory and moral psychology. 

Platonic? Socratic? Socrates was the teacher, but he said he never did. Plato was the student who put words in his teacher's mouth. You'll get a feel for it.

We have a book: the new 4th edition of ""Reason and Persuasion"", by the instructor (and his wife, Belle Waring, the translator.) It contains the Plato you need, plus introductory material and in-depth, chapter-length commentaries. (Don't worry! John Holbo knows better than to read his book to the camera. The videos cover the same material, but the presentation is different.) 

The book is offered free in PDF form - the whole thing, and individual chapter slices. It is also available in print and other e-editions. See the course content for links and information.

The course is suitable for beginning students of Plato and philosophy, but is intended to offer something to more advanced students as well. We seek new, odd angles on old, basic angles. Tricky! The strategy is to make a wide-ranging, interdisciplinary approach.  Lots of contemporary connections, to make the weird bits intuitive; plus plenty of ancient color, still bright after all these years. So: arguments and ideas, new possibilities, old stories, fun facts. Plus cartoons. 

The results can get elaborate (some book chapters and some lesson videos run long.) But each video comes with a brief summary of its contents. The lessons progress. I put them in this order for reasons. But there's no reason you can't skip over and around to find whatever seems most interesting. There are any number of self-contained mini-courses contained in this 8-week course. You are welcome to them.

Plato has meant different things to different people. He's got his own ideas, no doubt. (Also, his own Ideas.) But these have, over the centuries, been worn into crossing paths for other feet; been built up into new platforms for projecting other voices. (Plato did it to Socrates, so fair is fair.) So your learning outcome should be: arrival somewhere interesting, in your head, where you haven't been before. I wouldn't presume to dictate more exactly.
      


            Read more
          



          Plato's Euthyphro I: Bad Dads, Good Arguments
    -We start with Plato's ""Euthyphro"", a short dialogue in which Socrates debates the nature of holiness with a priest, Euthyphro. (The Bad Dad is Euthyphro's. Maybe. If he's a murderer. Do you think he's a murderer?) But mostly the videos for this first week and general and introductory. Plato, Socrates. Who are they? How should I read? For more detail, click ""Advice About Reading"", under ""Overview"", below.

Plato's Euthyphro II: Two Problems
    -This is our second week reading ""Euthyphro"". (But we hardly got into it last week!) The two problems are: 1) Should Euthyphro do? 2) What is holiness? Mostly the dialogue concerns 2) but 1) is there for a reason. Suppose a friend asks you for advice: 'I think dad murdered someone. What should I do?' Probably you wouldn't pull down the dictionary and look up 'holiness', right? But why not? Food for thought. This lesson also contains quite a bit of background about ancient Greek religion and law.

Plato’s Meno: What is Virtue?
    -We're moving on to our next dialogue, Plato's ""Meno"". Meno is a slick fellow: sophist-in-training. He wants to know whether Socrates thinks virtue can be taught. Socrates doesn't even know what it is! Meno doesn't see the problem. He can talk about this stuff! But his tongue gets stung numb by the Socratic stingray. Overall, the dialogue has a peculiar virtue-geometry-virtue structure. And we meet two more characters: the boy, who learns geometry; the sturdy citizen, Anytus, who doesn't trust sophists. In this first ""Meno"" lesson, we don’t get past the poetry that introduces the geometry. (What's with that?) We consider difficulties defining ‘virtue’, and whether definitions are a good thing to ask for. We consider some oddities about virtue. Why does everything think they know what it is? And: is there any science around here?

Plato's Meno: Virtue - Geometry - Virtue.
    -We are still working on Plato’s “Meno”. This week we get to the geometry lesson and  Socrates’ tentative definition/formula for success: virtue is mindfulness. That means: when you do things, you do them for the right reasons, and with knowledge of those reasons. That sounds good, but it’s kind of a high bar for humans to clear. Could it turns out that there is such a thing as virtue, only none of us have it? 

Plato's Republic, Book I: Again, With Fathers and Sons
    -We move on to Plato's ""Republic"". The subject is justice. Socrates investigates the nature of justice by envisioning a kind of Utopia, an ideal society, in which justice shall be evident because it is writ large – in the fabric of the City – and small – in the interstices of our very Souls. But we don’t get to that in our actual Plato reading, which is only Book I of ""Republic"". That’s like Chapter 1. There are 10 Books in all. In Book I Socrates debates three figures – the father, son and the sophist – each of whom has rather inadequate notions of justice, so it seems. Why read Book I by itself (apart from the fact that we obviously don’t have time to read the whole thing?) It works pretty well as a stand-alone text. It’s self-contained, even though Book 2 cracks it open to start over again. (Maybe originally it was written to stand alone, and only later Plato wrote the rest as a sequel? That’s just guessing.) In my commentary, and in the video lectures, I try to tell you what you need to know about ""Republic"", as a whole, to help frame this first bit of it.

Plato's Republic, Book I: Thrasymachus.
    -We finish up “Republic”, Book I. We have gotten to Thrasymachus, the main attraction. He’s attractive-repulsive, as a person. ‘Justice is the advantage of the stronger!’ In this Lesson I lay out his views. I think it’s best to see him as suspended between a few theoretical possibilities, not really settled on one. But he’s definitely an egoist. But egoism and justice aren’t the same thing, are they? I relate the Thrasymachus material to the rest of “Republic”, in which a refined version of Thrasymachus’ view eventually receives a long, considerate response from Socrates. He builds Utopia to refute Thrasymachus. So the guy must be important.


Moral Psychology
    -We're done with Plato! Well, not really. The point is to prove we'll never be done with him! But we're moving on to contemporary moral psychology. This lesson is on moral psychology. How does the moral mind think – work, function? The moral brain. (Psychologists are natural scientists. They figure your mind is your brain although that identification can get puzzling, we shall see.) I discuss one figure in particular: Jonathan Haidt. A popular writer, with good ideas. Also, some bad ones (I say) so that makes it livelier. He knocks Plato. I try to knock back, sometimes on Plato’s behalf. Plato is obviously very concerned with moral psychology. So many colorful, mythic images of all that! Haidt ventures more than a short distance into philosophy, when he sallies forth to correct philosophers, ancient and modern, for doing bad psychology. All very interesting. And I hope, like me, you find having a bit of Plato under your belt, at this point, helps you to organize your thoughts, see positions and patterns. In the first lesson I compared studying Plato to learning chess gambits. No one knows how to win, outright. But some strategies are more ... winning. (But there are always standard defenses.) l A lot of scientific progress has been made in the study of the human mind. But there are a lot of deep, stubbornly un-dissolved conceptual mysteries hereabouts. That means a lot of ancient debate patterns – same old lines, same old counters to the old lines - stay relevant. It’s important to be able to say: hey, we learned something new today! But also: ah, this debate is a version of that old thing we’ve been batting back and forth for centuries! (Even though it’s got new stuff stuck on – fMRI data, or what have you.) Being able to see the old and the new isn’t everything, but it’s a start. Let’s get started.

Ethics and Ethnos
    -One more week on moral psychology. We’re almost done! This week we’re still talking about Jonathan Haidt, but then I shift to consider as well, the work of another psychologist, who is also a philosopher (by training): Joshua Greene. I talk about his popular book, ""Moral Tribes: Emotion, Reason, and the Gap Between Us And Them"". (By ‘popular’ I mean: written for a popular, i.e. non-scholarly specialist audience. I think it sold ok, too. But I don’t really have knowledge of that.) Per the title, it’s about tribalism, which is a big theme in ""Reason and Persuasion"", from ""Euthyphro"" to ""Republic"". Aristotle said we are political animals, by which he meant: living in a Greek style polis is the best! But you know what’s way more popular? Being an ethnic animal. (Greek ethnoi = tribe.)  We have an instinct to stick with ‘our own’: family, friends, party, country. How much do we know about what’s going on in the brain, when we are like that? How should the facts about our instincts figure in our moral philosophies?",Reason and Persuasion: Thinking Through Three Dialogues By Plato
https://www.classcentral.com/course/sensors-circuit-interface-12049,"This course can also be taken for academic credit as ECEA 5340, part of CU Boulder’s Master of Science in Electrical Engineering degree.

After taking this course, you will be able to:
●	Understand how to specify the proper thermal, flow, or rotary sensor for taking real-time process data. 
●	Implement thermal sensors into an embedded system in both hardware and software.
●	Add the sensor and sensor interface into a microprocessor based development kit.
●	Create hardware and firmware to process sensor signals and feed data to a microprocessor for further evaluation.
●	Study sensor signal noise and apply proper hardware techniques to reduce it to acceptable levels.

You will need to buy the following components to do the two course projects based on the videos in this module. Note that if you have already purchased the PSOC 5LP PROTOTYPING KIT, you do not need to buy it again. 
These parts may be purchased off the Digikey web site, www. Digikey.com. Or, you may obtain the specs from the site, and purchase them elsewhere.

These are the part numbers typed out, so you can copy and paste them into the Digikey web site. You will need one of each part.

428-3390-ND
NHD-0216BZ-RN-YBW-ND
570-1229-ND
A105970CT-ND
      


          Thermal Sensors
    -In module 1 you will learn how to specify and use temperature sensors in an embedded circuit. First, you will learn about common types of sensors and actuators found in common products such as smart phones and automobiles. Then you will get a high-level overview of analog and digital interfaces, followed by a deep dive into thermistors, RTD’s, and thermocouples. For each of these three types of thermal sensors, we define the core theory and formulae, give you examples of how commercial sensors are packaged, and explain what you need to know to purchase them on a web site. 

Sensor Development Kit and Prototyping
    -In module 2 you will learn how to design a complete temperature sensor system within a development kit environment. We will teach you how to assign internal components to the schematic. This includes pins, amplifiers, MUX’s, DAC’s, and ADC’s. Then you will learn how to wire in external parts: resistors, thermistors in particular, to the kit. Finally, you will take a deep dive into interfacing a thermistor and associated front end components to the development kit. This includes lessons on using the schematic portion of the kit, as well as writing application software in c code.

Rotary and Flow Sensors
    -In module 3 you will learn how rotary sensors work and how to specify them for purchase. In our videos rotary sensors include both optical encoders and resolvers. You will also learn the design intricacies of flow sensors, along with their appropriate applications. The videos will discuss variable area, differential pressure, vortex, ultrasonic, turbine, thermal mass flow, and coriolis flow meters. 

Amplifiers and Sensor Noise
    -In module 4 you will learn the theory and practical application of amplifiers and circuit noise. You will review how gain is calculated in inverting, non-inverting, summing, differential, and instrumentation amplifiers. We will then contrast theoretical vs. real-world amplifier performance, and give examples of how commercial chips specs are interpreted. Then we will discuss the causes of noise in sensor circuits, how the noise affects sensor accuracy, and some steps you can take to reduce noise in your sensor circuit designs. 

Course Project
    -This module contains the materials you need to complete the thermistor lab assignment.",Sensors and Sensor Circuit Design
https://www.classcentral.com/course/edx-introduction-to-deep-earth-science-3759,"Have you ever imagined what is deep under the ground? What is happening deep inside the earth? How has the earth evolved into its present state? This course is an introduction to earth science, focusing on the deep earth. We will learn how temperature and chemical compositions inside the Earth are inferred from limited observations combined with laboratory experiments. We will also explore the fate of water on the early Earth related to advanced research questions. Upon finishing this course, you will learn how scientists interpret the unknown and use the scientific method to address immeasurable research challenges.
No specific knowledge is needed. Join this course and let’s imagine the inside of the Earth together.



Week 1. Introduction to the solid EarthWeek 2. Plate TectonicsWeek 3. Chemical composition of our planetWeek 4. Temperature inside the EarthWeek 5. Earth’s water",Introduction to Deep Earth Science
https://www.classcentral.com/course/randomness-736,"This cross-disciplinary course deals with the undetermined, the unpredictable -- or what appears to be such. Among the questions that will be addressed are:How is randomness defined?How has randomness, often seen as a nuisance, become a useful resource for communication and computing? How is it generated?How can physicists make the astounding claim that there is real randomness in nature?Can our apparently free acts be predicted by monitoring the activity of the brain?



          Lecture 1: Basic of randomnessHistory of randomnessThe fair coin as ideal caseDefinitions of randomnessLecture 2: Randomness as a resourceReview of various tasks in which randomness is usedRandomized algorithms and de-randomizationCryptography: randomness for secrecyZero-knowledge proofsLecture 3: Characterizing a source of randomnessThe biased coin and other weaker sources of randomnessAmount of randomness: min-entropyExtraction of randomnessLecture 4: Noise as a random number generatorDefinition of ""noise""Thermal noise: example of a resistorHow to extract random numbers from thermal fluctuationsLecture 5: Deterministic chaosPhysical (in)determinismDefinition and examples of chaosLecture 6: Quantum physics, a first encounterOverview of quantum physicsSingle-particle interferences (Mach-Zehnder, double slit)UncertaintyLecture 7: Intrinsic randomness and its practical usesBell's theorem and its implicationElements of quantum information scienceLecture 8: Introduction to free will in scienceMeasurement independenceQuanta in the brain?Libet's experiments","Unpredictable? Randomness, Chance and Free Will"
https://www.classcentral.com/course/edx-machine-learning-fundamentals-8216,"Do you want to build systems that learn from experience? Or exploit data to create simple predictive models of the world?
In this course, part of the Data Science MicroMasters program, you will learn a variety of supervised and unsupervised learning algorithms, and the theory behind those algorithms.
Using real-world case studies, you will learn how to classify images, identify salient topics in a corpus of documents, partition people according to personality profiles, and automatically capture the semantic structure of words and use it to categorize documents.
Armed with the knowledge from this course, you will be able to analyze many different types of data and to build descriptive and predictive models.
All programming examples and assignments will be in Python, using Jupyter notebooks.",Machine Learning Fundamentals
https://www.classcentral.com/course/mind-of-the-universe-genetic-privacy-10675,"Should all our genetic information be made public in order to eradicate genetic diseases from this world?
Who owns your genetic data once it becomes publicly accessible? What is your responsibility to family members when you know more about genetic diseases than they do? Who decides what kind of genetic information is relevant to a person? And what does genetic privacy mean to you?

In this challenge with Robert Zwijnenberg (Professor in Art and Science Interactions) you will critically reflect upon the issue of genetic privacy. You will dive into the ethical questions that come up with the disclosure of genetic data in biobanks and through genetic tests. This course encourages you to think about the cultural, philosophical and political tensions present in the debate around genetic privacy. You are invited to identify and listen to the viewpoints and values provided by the different stakeholders that shape this debate: corporations, researchers, consumers and patients. Furthermore, you will go off the beaten track by exploring the issue from the unique perspective of art and culture. After a lot of thinking, supplementing, deleting and adjusting, you will be asked to share a recommendation on how to regulate practices of disclosing genetic information, while taking into consideration the concept of genetic privacy. Your advice could serve as an eye-opener for policy makers!

This online learning experience is a spin-off of The Mind of the Universe documentary series created by the Dutch broadcasting company VPRO and professor Robbert Dijkgraaf, Princeton University. A number of universities in the Netherlands have used the open source material of the documentary series as a starting point to create similar experiences.
      


            Read more
          



          What is on Your Mind?
    -In this module, we will introduce the subject of genetic privacy. In a time in which more and more genetic material and information is being stored in biobanks, research labs and private companies, the urgency to consider the concept of ‘genetic privacy’ becomes all the more pronounced. We will discuss different practices dedicated to the disclosure and application of genetic data, and we ask you to reflect on your initial stance towards these practices. 

Open up Your Mind
    -This part of the course will stimulate you to reflect critically on the different types of practices that work with genetic data, among which the Personal Genome Project initiated by George Church. You will get familiar with the ethical questions that these practices could raise. Furthermore, you will be  encouraged to think about what the concept of genetic privacy means to you personally. What actually is genetic privacy? And what are the borders of its definition? How can we define the border between individual autonomy and public interest? Where do you place this border yourself? 

Connect your mind
    -This week we will enrich the ethical debate around genetic privacy by viewing the subject from the perspective of art and culture. We will see how artworks and cultural objects can foreground the ambiguities, emotions and (cultural) assumptions often neglected in mainstream debates around biotechnological developments. Moreover, we will explore the potential of art to allow new publics to arise in the discourse around genetic research. In this module, we would like to make you aware of how your own emotions and expectations might influence your stance on the subject. From there on, you can get to a more nuanced point of view towards the issue of genetic privacy.

Make up your mind
    -Different groups of people with sometimes opposing interests take part in the public debate around the disclosure and application of genetic data. For example, patients, consumers, researchers, corporations, or politicians. These groups, or stakeholders, bring forward diverse arguments to advocate their position. Their arguments are often formed by emotions, gut feelings and cultural values. In order to regulate the disclosure of genetic data, while taking into consideration the notion of genetic privacy, we have to identify the different stakeholders and their values present in this debate. 

Finalization
    -We have come to the final phase of this course: the phase of finalization. Make sure to have completed your policy advice and to have published it on the discussion board. And for those who did the honours track, also share with us your infographic, video or other type of visual. Feel free to post some last, concluding, remarks or insights on this week's discussion board.",Mind of the Universe - Genetic Privacy: should we be concerned?
https://www.classcentral.com/course/advanced-algorithms-and-complexity-5474,"You've learned the basic algorithms now and are ready to step into the area of more complex problems and algorithms to solve them. Advanced algorithms build upon basic ones and use new ideas. We will start with networks flows which are used in more typical applications such as optimal matchings, finding disjoint paths and flight scheduling as well as more surprising ones like image segmentation in computer vision. We then proceed to linear programming with applications in optimizing budget allocation, portfolio optimization, finding the cheapest diet satisfying all requirements and many others. Next we discuss inherently hard problems for which no exact good solutions are known (and not likely to be found) and how to solve them in practice. We finish with a soft introduction to streaming algorithms that are heavily used in Big Data processing. Such algorithms are usually designed to be able to process huge datasets without being able even to store a dataset.
      


          Flows in Networks
    -Network flows show up in many real world situations in which a good needs to be transported across a network with limited capacity. You can see it when shipping goods across highways and routing packets across the internet. In this unit, we will discuss the mathematical underpinnings of network flows and some important flow algorithms. We will also give some surprising examples on seemingly unrelated problems that can be solved with our knowledge of network flows.

Linear Programming
    -Linear programming is a very powerful algorithmic tool. Essentially, a linear programming problem asks you to optimize a linear function of real variables constrained by some system of linear inequalities. This is an extremely versatile framework that immediately generalizes flow problems, but can also be used to discuss a wide variety of other problems from optimizing production procedures to finding the cheapest way to attain a healthy diet. Surprisingly, this very general framework admits efficient algorithms. In this unit, we will discuss some of the importance of linear programming problems along with some of the tools used to solve them.

NP-complete Problems
    -Although many of the algorithms you've learned so far are applied in practice a lot, it turns out that the world is dominated by real-world problems without a known provably efficient algorithm. Many of these problems can be reduced to one of the classical problems called NP-complete problems which either cannot be solved by a polynomial algorithm or solving any one of them would win you a million dollars (see Millenium Prize Problems) and eternal worldwide fame for solving the main problem of computer science called P vs NP. It's good to know this before trying to solve a problem before the tomorrow's deadline :) Although these problems are very unlikely to be solvable efficiently in the nearest future, people always come up with various workarounds. In this module you will study the classical NP-complete problems and the reductions between them. You will also practice solving large instances of some of these problems despite their hardness using very efficient specialized software based on tons of research in the area of NP-complete problems.

Coping with NP-completeness
    -After the previous module you might be sad: you've just went through 5 courses in Algorithms only to learn that they are not suitable for most real-world problems. However, don't give up yet! People are creative, and they need to solve these problems anyway, so in practice there are often ways to cope with an NP-complete problem at hand. We first show that some special cases on NP-complete problems can, in fact, be solved in polynomial time. We then consider exact algorithms that find a solution much faster than the brute force algorithm. We conclude with approximation algorithms that work in polynomial time and find a solution that is close to being optimal. 

Streaming Algorithms (Optional)
    -In most previous lectures we were interested in designing algorithms with fast (e.g. small polynomial) runtime, and assumed that the algorithm has random access to its input, which is loaded into memory. In many modern applications in big data analysis, however, the input is so large that it cannot be stored in memory. Instead,  the input is presented as a stream of updates, which the algorithm scans while maintaining a small summary of the stream seen so far. This is precisely the setting of the streaming model of computation, which we study in this lecture. The streaming model is well-suited for designing and reasoning about small space algorithms. It has received a lot of attention in the literature, and several powerful algorithmic primitives for computing basic stream statistics in this model have been designed, several of them impacting the practice of big data analysis. In this lecture we will see one such algorithm (CountSketch), a small space algorithm for finding the top k most frequent items in a data stream.",Advanced Algorithms and Complexity
https://www.classcentral.com/course/edx-environmental-studies-a-global-perspective-t1-2018-6474,"This environmental studies course is intended to introduce you to some of the basic principles in environmental studies, and how those are manifested in urban, rural and natural areas throughout the world.
Through observation, discussion, and creation of digital content, you will explore and share environmental challenges facing your local environment and create a global learning and action community.
Rather than simply offering a long list of the problems we face, this course will take a solutions-focused approach.



Module 1: Why study the environment – and what is Environmental Studies?
Introduction and overview
What is environmental studies? It’s not environmental science, nor is it sustainability. It IS a combination of arts, social science, and science (social, political, economic, health and ecological), and how these contribute to environmental issues and solutions.
Why study it? Because it brings together many different disciplines, environmental studies helps us tackle some of the world’s most important and complex problems, such as resource use, energy consumption and food security. Our species depends on it!
Module 2: Systems and Cycles
Planet formation/rock cycle
Climate and weather cycles
Biological cycles – population, dynamics and nutrients
Urban systems and cycles
Module 3: Resources and Energy
Biotic and geologic resources and biodiversity
Soil and water resources
Forms of energy
Use of energy
Module 4: People and Populations
Population basics
Populations over time and space
Populations of the Global South
Environmental Justice
Module 5: Present challenges
Challenges we face as a species - staying alive
Consequences of resource use (pollution, depletion, waste, degradation)
Module 6: Solutions and the future
Types of environmental problems
Solutions and actions
UNESCO and UN Sustainability Goals
Future (humans and the planet beyond 2050)",Environmental Studies: A Global Perspective (T1 2018)
https://www.classcentral.com/course/wharton-crowdfunding-9664,"Crowdfunding, the practice of raising small amounts of money from large numbers of people, has enabled people around the world to start new businesses, fund initiatives, and raise money for themselves and others. Yet, not all crowdfunding efforts reach their desired goal. Why do some succeed, while others fail? This course will reveal the science behind successful crowdfunding, drawing on data from hundreds of thousands of campaigns. You’ll learn different types of crowdfunding approaches, and receive detailed advice on what to do (and what not to do) when crowdfunding. You’ll also have the unique opportunity to go behind-the-scenes with key players in the field with exclusive interviews from the founder of Indiegogo to successful campaign creators, to get the information you need to set your crowdfunding initiative up for success.
      


          Module 1
    -This module was designed to give you a deep understanding of what crowdfunding is and what it does. You’ll learn the definition of crowdfunding, compare the two most prevalent types—equity and reward-based—and understand how crowdfunding is different from other approaches to raising capital. You’ll explore critical components of crowdfunding, and discover the importance of community and social networks in a successful crowdfunding campaign. By the end of this module, you’ll gain a better understanding of how crowdfunding works, and use your power of social connections to ensure success for your campaign.

Module 2
    -In this module, you’ll explore how to prepare for a successful campaign, including how much time you should expect to spend and how much money you should seek to raise. By looking at the different types of rewards and reward levels, you’ll be able to weigh the benefits and costs of reward types for your campaign, and find the right balance that will work for your budget. Then you’ll learn about both successful strategies and common pitfalls in preparing for your crowdfunding campaign, such as the use of helpers or consultants. By the end of this module, you’ll have built effective strategies for preparing and budgeting your crowdfunding campaign, and be able to tackle any issue that your campaign might face in achieving its goal.

Module 3
    -This module was designed to help you develop and manage a live crowdfunding effort, from pitching your idea to ensuring long-term success. By discussing examples of both high-quality and low-quality pitches, you’ll learn what makes messages memorable and be able to craft an effective pitch for your campaign. You’ll assess the differing benefits of showing prototypes and teaser trailers, and explore some of the biggest challenges that entrepreneurs have faced when delivering their projects and how to avoid them. By the end of this module, you’ll be able to employ a toolbox of approaches to craft a convincing pitch, and be prepared with the best solution to any situation.

Module 4
    -In this module, you’ll examine some of the science behind crowdfunding, including how crowds think, and how fraud and failure is spotted. By looking at examples of studies done on collective thinking and decision-making, you’ll learn about Linus’ Law and how the crowd exerts rational criteria when determining which campaigns are fraudulent or worthy of support. You’ll gain a better understanding of your backers and better leverage their influence to bring success to your own campaign. You’ll explore who is successful in crowdfunding campaigns, and the experience of women to see the value of sharing common ground with your backers. By the end of this module, you’ll have a deeper understanding of the components for success in crowdfunding campaigns, and be able to leverage them to successfully fund your startup or other ventures.",Crowdfunding
https://www.classcentral.com/course/videogameslearning-850,"Video games are one of the fastest trending topics in media, education, and technology. Research across fields as disparate as science, literacy, history, visual processing, curriculum, and computer science suggests that video games aren’t just fun –
they can actually be good for your mind as well. In this course, we will discuss current research on the kinds of thinking and learning that go into video games and gaming culture. We’ll investigate the intellectual side of digital gameplay, covering
topics that range from perception and attention in Left 4 Dead 2 to the development of historical understanding in Civilization to collaborative learning in massively multiplayer online games like World of Warcraft. Throughout the course, we examine the
inherent tensions between contemporary youth culture and traditional education and new developments in games for learning that promise to help bridge that growing divide.

If you do have questions about the course itself, please direct your inquiries to vglcoursera@gmail.com.

Data from this course is being used for quality assurance and for educational research purposes. All data from minors will be excluded from use in educational research purposes. See Coursera’s Terms of Use for a description of the data captured from course
activity. Please contact outreach@learninggamesnetwork.org with any questions or concerns. If you do not wish to have your data from this course used for educational research purposes, you may dis-enroll from this course.



            Read more
          



          Week One – Introduction: Games and Learning?!Week Two – Game Design for Learning?Week Three – Game Culture & LearningWeek Four – Games & CognitionWeek Five – Games & Content Subject MatterWeek Six – Games & The Institution of Education",Video Games and Learning
https://www.classcentral.com/course/incident-response-recovery-risks-sscp-10340,"Risk Identification, Monitoring, and Analysis: In the Risk Identification, Monitoring, and Analysis session, you will learn how to identify, measure, and control losses associated with adverse events. You will review, analyze, select, and evaluate safeguards for mitigating risk.You will learn processes for collecting information, providing methods of identifying security events, assigning priority levels, taking the appropriate actions, and reporting the findings to the correct individuals. After collection of the details from monitoring, we can analyze to determine if the system is being operated in accordance with accepted industry practices, and in compliance with organization policies and procedures.        
 Incident Response and Recovery: In the Incident Response and Recovery Session, you will gain an understanding of how to handle incidents using consistent, applied approaches in order to resolve. Once an incident is identified, action will be necessary in order to resolve. We will examine processes such as damage recovery, data integrity and preservation, and the collection, handling, reporting, and prevention. You will be introduced to the Business Continuity Plan (BCP) and Disaster Recovery Plan (DRP) concepts and how they can be utilized in order to mitigate damages, recover business operations, and avoid critical business interruption. Through the use of the DRP, you will understand the procedures for emergency response and post-disaster recovery.    

 Course Objectives  

1.  Describe the risk management process
2. Perform security assessment activities
3. Describe processes for operating and maintaining monitoring systems
4. Identify events of interest
5. Describe the various source systems
6. Interpret reporting findings from monitoring results
7. Describe the incident handling process
8. Contribute to the incident handling process based upon role within the organization
9. Describe the supporting role in forensics investigation processes
10. Describe the supporting role in the business continuity planning process
11. Describe the supporting role in the disaster recovery planning process
      


            Read more
          



          Understand the Risk Management Process
    -Module Topic: Risk Visibility and Reporting, Risk management Concepts, Risk Assessment, Risk Treatment, Audit Findings. In Risk visibility and Reporting, you will learn about risk register, creating a risk register, risk register, and risk management steps. In Risk Management Concepts, you will learn about, key terms, and generic risk model with key factors - NIST SP 800-30 R1. In risk Assessment, you will learn about NIST SP 800- 30 R1 risk assessment methodology, Step 1. prepare for the assessment, Step 2. conduct the assessment, Step 2a. identify threat sources, step 2b. identify potential threat events, step 2c. identify vulnerabilities and predisposing conditions, step 2d. determine likelihood, step 2e. determine impact, step 2f. risk determination, risk level matrix, risk levels, step 3. communicating and sharing risk assessment information, step 4. maintaining the risk assessment, and risk assessment activity. In Risk Treatment, you will learn about, risk mitigation, example control: passwords, control selection, residual risk, risk transference, risk avoidance, and risk acceptance. In audit Findings, you will learn about auditors, types of audits, audit methodologies, auditor responsibilities, audit scope, documentation, and response to audit.      

Perform Security Assessment Activities
    -Module Topics: Participate in Security and Test Results, Penetration Testing.                                              In Participate in Security  and Test Results, you will learn about vulnerability scanning and analysis, vulnerability testing software categories, vulnerability testing qualities, potential problems, host scanning, host security considerations, traffic types, security gateway types, wireless networking testing,  potential security issues, searching for rogue access points, locking down the enterprise, wireless tools, war dialing, and war driving. In Penetration Testing you will learn about penetration testing modes, white box / hat, gray box / hat, black box / hat, phase 1: preparation, reporting, phase 2: reconnaissance and network mapping techniques, reconnaissance, social engineering and low-tech reconnaissance, whois attacks, DNS zone transfers, network mapping, network mapping techniques, firewalking, basic built-in tools, phase 3: information evaluation and risk analysis, phase 4: active penetration, phase 5: analysis and reporting, penetration testing high-level steps.

Operate and Maintain Monitoring Systems & Analyze and Report Monitoring Results
    -Module Topics: Events of Interest, Logging, source Systems, Security Analytics, metrics, and Trends, Visualization, Event Data Analysis, Communication of Findings. In Events of Interest you will learn about, monitoring terminology, Intrusion Detection System (IDS)/Intrusion Prevention System (IPS), comparing IDS and IPS, types of IDS/IPS devices, deploying HIDS and NIDS, implementation issues for monitoring, monitoring control, other considerations, sample questions to consider, collecting data for incident response, monitoring response techniques, attackers, attacker motivations, intrusions, events, types of monitoring, and file integrity checkers, continuous/compliance monitoring. In Logging, you will learn about reviewing host logs, reviewing incident logs, log anomalies, log management, clipping levels, filtering, log consolidation, log retention, centralized logging (syslog and log aggregation), syslog, distributed log collectors, hosted logging services, configuring event sources (s-flow, NetFlow, sniffer), Cosco NetFlow, What is an IP Flow, IP packet attributes, understanding network behavior, how to access the data produced by NetFlow, How does the router or switch determine which flows to export to the NetFlow collector server, format of the export data, sFlow, event correlation systems (security, information, and event management (SIEM)), SIEM functions, compliance, enhanced network security and improved IT/security operations, and full packet capture. In Source System, you will learn about comprehensive application, middleware, OS, and infrastructure monitoring, hyper capabilities, and operations manager. Analyze and Report Monitoring: In Security Analytics, Metrics, and Trends, you will learn about security baseline, network security baseline, metrics and analysis (MA), systems security engineering capability maturity model (SSE-CMM), and potential metrics. In visualization topic, you will learn about data visualization tools. In Event Data Analysis, you will learn about logs, log management, log management recommendations, and Potential uses of server log data. In Communication of Findings, you will learn about checklist for report writers and reviewers.    

Incident Response and Recovery
    -Module Topics: Preparation, Detection and Analysis, Containment, Eradication, and Recovery, Post-Incident Activity, Implementation of Countermeasures. In Introduction, you will learn about incident response, and basic definitions. In preparation, you will learn about elements of an incident response policy, incident response plan, training, incident response tools, communication planning, communication with law enforcement, media, requirements for effective incident handling, the incident response team, core team areas, centralized and decentralized teams, team structure, team conditions that support success, and other considerations. In Detection and Analysis, you will learn about Intrusion Detection Systems (IDS) and Intrusion Prevention Systems (IPS), types of intrusion systems, intrusion detection techniques, false positives and false negatives, anti-malware systems, security information event management (SIEM), Incident analysis, packet sniffers, Inline SSL decryption devices, incident documentation, records, assessing risk, response, containment strategy considerations, Delaying containment, areas of focus, defining an incident, triage, and notification. In Containment, Eradication, and Recovery, you will learn about common containment activities, and eradication. In post-incident activity, you will learn about effective incident response. In implementation of Countermeasures, you will learn about implementation steps.   

Understand and Support Forensic Investigations & Business Continuity and Disaster Recovery Plan
    -Module Topic: Forensic Investigations, Emergency Response Plans and Procedures, Disaster Recovery Planning, Interim or Alternate processing Strategies, Backup and Redundancy Implementation, System and Data Availability, Testing and Drills. Understand and Support Forensic Investigations: In Forensic Investigations, you will learn about crime scene, live evidence, Locard's principle, criminal behavior, incident response team, general guidelines, rules of thumb, evidence gathering, Hash algorithms, criminal charges, documentation, five rules of evidence, media analysis, network analysis, software analysis, author identification, content analysis, context analysis, hardware/embedded device analysis, NIST recommendations, and incident response. Understand and Support Business Continuity Plan: In Emergency Response Plans and Procedures, you will learn about business continuity planning, establish a business continuity program, Business Impact Analysis (BIA), key concepts, maximum tolerable downtime (MTD), Recovery Time Objective (RTO), Recovery Point Objective (RPO), Financial and Nonfinancial impacts, stakeholder input, BIA completion process, BIA project stages, Identify critical IT resources, Identify disruption impacts, and development recovery priorities. In Disaster Recovery Planning, you will learn about Identity types of potential disasters, assets, personnel considerations, and related documents. In Interim or Alternate Processing Strategies, you will learn about cold site, warm site, hot site, multiple processing sites, and mobile sites. In Backup and Redundancy Implementation, you will learn about full backup, differential backup, incremental backup, evaluating alternatives, Off-site storage, electronic vaulting, and remote journaling. In System and Data Availability, you will learn about clustering, high-availability clustering, load-balancing clustering, redundant array of independent disks (RAID), data redundancy techniques, and RAID levels. In Testing and Drills, you will learn about checklist test, structured walkthrough test, simulation testing, parallel testing, full interruption testing, and plan review and maintenance.      

Case Study
    -This assignment is based on a case study that will require the student to put into practice the knowledge they have gained through the course. It requires the basic understanding of the topics and the ability to relate those topics to the real world. The objective of review is to determine whether the student has understood the concepts and has performed the necessary analysis to ensure a complete and thorough answer.

Exam","Identifying, Monitoring, and Analyzing Risk and Incident Response and Recovery"
https://www.classcentral.com/course/information-systems-audit-17979,"Information systems (IS) are important assets to business organizations and are ubiquitous in our daily lives. 

With the latest IS technologies emerging, such as Big Data, FinTech, Virtual Banks, there are more concerns from the public on how organizations maintain systems’ integrity, such as data privacy, information security, the compliance to the government regulations. Management in organizations also need to be assured that systems work the way they expected. IS auditors play a crucial role in handling these issues.

In the course “Information Systems Auditing, Controls and Assurance”, you will explore risks of information systems, and how to mitigate the risks by proper IS Controls. You will also get familiar with the IS Audit procedures and how they are applied during the IS development throughout the Systems Development Life Cycle (SDLC). 

Finally, you will get to observe how we can make the system changes more manageable using formal IS Management practices, such as Change Management Controls and Emergency Changes. 

The conversations between the course instructor - Prof. Percy Dias, and the IS auditing practitioner will give you a concrete idea on how IS auditors perform their duties, the qualities to become IS auditors and future prospects of IS auditing industry.

This course is suitable for students and graduates from Information Systems, Information Technology and Computer Science, and IT practitioners who are interested to get into the IS auditing field. It is also a good starting point for learners who would like to pursue further studies for IS audit certifications – such as Certified Information Systems Auditor (CISA).
      


            Read more
          



          Introduction to Information Systems (IS) Auditing
    -IS Auditing is related to risks, controls and assurance. In the first module, Prof. Dias introduces what risk is about. Getting deeper to risk, the 3-step risk management process is elaborated. To manage risks, controls need to be established. Prof. Dias also demonstrates with daily examples on what the controls are.

Perform IS auditing
    -You may have heard of financial auditing, do you know the difference between IS auditing and financial auditing? You are going to explore more about IS auditing through the conversation between Prof. Dias and the IS audit practitioner. Prof. Dias then explains the general IS audit procedures and two major testings that IS auditors/compliance officers have to conduct. Prof. Dias also explains the procedure to obtain evidence in order to produce justified audit reports.

Business Application Development and the Roles of IS Auditors
    -IT practitioners develop business applications following the Systems Development Life Cycle (SDLC). IS auditors are in place to ensure the controls are implemented to mitigate the risks of developing application systems throughout the SDLC. Prof. Dias is going to review what IT practitioners usually do, and further elaborate the role that IS auditors play in different phases of SDLC.

IS Maintenance and Control
    -Information systems seldom remain static, it is common for users to make change requests to add new features, or refine existing functions some time after the information system launches. Organizations should follow a formal procedure to make the changes in their systems manageable.  Prof. Dias is going to give you an overview on the change management controls which organizations should follow. Different kinds of maintenance practices, and Emergency Controls are also discussed in this module. Finally, Percy's conversations with the IS audit practitioner give you better insights on the future development of IS audit and how IS audit support the newly emerged FinTech industry.","Information Systems Auditing, Controls and Assurance"
https://www.classcentral.com/course/edx-bias-and-discrimination-in-ai-18144,"Engage in this course pertaining to a highly impactful yet, too rarely discussed, AI-related topic. You will learn from international experts in the field, also speakers at IVADO’s International School on Bias and Discrimination in AI, which took place in Montreal, and explore the social and technical aspects of bias, discrimination and fairness in machine learning and algorithm design.
The main focus of this course is: gender, race and socioeconomic-based bias as well as bias in data-driven predictive models leading to decisions. The course is primarily intended for professionals and academics with basic knowledge in mathematics and programming, but the rich content will be of great use to whomever uses, or is interested in, AI in any other way. These sociotechnical topics have proven to be great eye-openers for technical professionals!
The total duration of the video content available in this course is 7:30 hours, cut into relevant segments that you may watch at your own pace. There are also comprehensive quizzes at the end of each segment to measure your understanding of the content.
IVADO is a scientific and economic data science hub bridging industrial, academic and governmental partners with expertise in digital intelligence. One of its missions is to contribute to the advancement of digital knowledge and train new generations of bias-aware data scientists.
Welcome to this enlightening journey in the world of ethical AI!



Module 1 The concepts of bias and fairness in AI 

Different Types of Bias
Fairness criteria and metrics 

Module 2 Fields where problems were diagnosed

Privacy, labour and legal system
Public policy and Health

Module 3 Institutional attempts to mitigate bias and discrimination in AI

Canada's Algorithmic Impact Assessment Framework
The Montreal Declaration for Responsible AI

Module 4 Technical attempts to mitigate bias and discrimination in AI

Fairness constraints in graph embeddings
Gender bias in text",Bias and Discrimination in AI
https://www.classcentral.com/course/edx-data-science-inference-and-modeling-10349,"Statistical inference and modeling are indispensable for analyzing data affected by chance, and thus essential for data scientists. In this course, you will learn these key concepts through a motivating case study on election forecasting. 
This course will show you how inference and modeling can be applied to develop the statistical approaches that make polls an effective tool and we'll show you how to do this using R. You will learn concepts necessary to define estimates and margins of errors and learn how you can use these to make predictions relatively well and also provide an estimate of the precision of your forecast. 
Once you learn this you will be able to understand two concepts that are ubiquitous in data science: confidence intervals, and p-values. Then, to understand statements about the probability of a candidate winning, you will learn about Bayesian modeling. Finally, at the end of the course, we will put it all together to recreate a simplified version of an election forecast model and apply it to the 2016 election.",Data Science: Inference and Modeling
https://www.classcentral.com/course/financial-risk-management-with-r-17317,"This course teaches you how to calculate the return of a portfolio of securities as well as quantify the market risk of that portfolio, an important skill for financial market analysts in banks, hedge funds, insurance companies, and other financial services and investment firms. Using the R programming language with Microsoft Open R and RStudio, you will use the two main tools for calculating the market risk of stock portfolios: Value-at-Risk (VaR) and Expected Shortfall (ES). You will need a beginner-level understanding of R programming to complete the assignments of this course.
      


          Introduction to R, Data Retrieval, and Return Calculation
    -This module goes over the versions of R (R Studio and Microsoft Open R), the data source (FRED at the Federal Reserve Bank of St. Louis), and the calculation of returns.

Risk Management under Normal Distributions
    -This module covers how to calculate value-at-risk (VaR) and expected shortfall (ES) when returns are normally distributed.

Risk Management under Non-normal Distributions
    -This module covers how to test for normality of returns, and how to calculate value-at-risk (VaR) and expected shortfall (ES) when returns are not normally distributed.

Risk Management under Volatility Clustering
    -This module covers how to test for the presence of volatility clustering, and how to calculate value-at-risk (VaR) and expected shortfall (ES) when returns exhibit volatility clustering.",Financial Risk Management with R
https://www.classcentral.com/course/edx-mechanical-behavior-of-materials-part-2-stress-transformations-beams-columns-and-cellular-solids-4011,"All around us, engineers are creating materials whose properties are exactly tailored to their purpose. This course is the second of three in a series of mechanics courses from the Department of Materials Science and Engineering at MIT. Taken together, these courses provide similar content to the MIT subject 3.032: Mechanical Behavior of Materials.
The 3.032x series provides an introduction to the mechanical behavior of materials, from both the continuum and atomistic points of view. At the continuum level, we learn how forces and displacements translate into stress and strain distributions within the material. At the atomistic level, we learn the mechanisms that control the mechanical properties of materials. Examples are drawn from metals, ceramics, glasses, polymers, biomaterials, composites and cellular materials.
Part 1 covers stress-strain behavior, topics in linear elasticity and the atomic basis for linear elasticity, and composite materials.
Part 2 covers stress transformations, beam bending, column buckling, and cellular materials.
Part 3 covers viscoelasticity (behavior intermediate to that of an elastic solid and that of a viscous fluid), plasticity (permanent deformation), creep in crystalline materials (time dependent behavior), brittle fracture (rapid crack propagation) and fatigue (failure due to repeated loading of a material).



Week 1: Equivalent stresses for varying orientations Principal stresses, maximum shear stress Mohr’s circles Week 2:   Stresses in beams Shear and bending moment diagrams in beams Strain energy Week 3: Beam deflection Column buckling Cellular solids Week 4:   Final Quiz","Mechanical Behavior of Materials, Part 2:  Stress Transformations, Beams, Columns, and Cellular Solids"
https://www.classcentral.com/course/edx-enabling-technologies-for-data-science-and-analytics-the-internet-of-things-4911,"The Internet of Things is rapidly growing. It is predicted that more than 25 billion devices will be connected by 2020.
In this data science course, you will learn about the major components of the Internet of Things and how data is acquired from sensors. You will also examine ways of analyzing event data, sentiment analysis, facial recognition software and how data generated from devices can be used to make decisions.",Enabling Technologies for Data Science and Analytics: The Internet of Things
https://www.classcentral.com/course/valuingcompanies-4006,"This course is a theoretically sound and practical exposure to valuation. As the final course of the Specialization, it will be useful to anyone in executing or critically evaluating company analyses conducted by experts. This course has been redesigned to make it a capstone experience. We have put together everything you have learned in the first three courses, modified frameworks and first applied them to carefully crafted real world situations (or mini-cases) and then presented you with a capstone project to value one of the most well-known companies of the past three decades. This Capstone Project will make you appreciate how finance is both a science and an art form.
      


Overview of Specialization & CourseThis module contains detailed videos and syllabi of both the Specialization and this course. This specialization has been designed to enable you to learn and apply the powerful tools of modern finance to both personal and professional situations. The courses within progress linearly and build on each other and it is important for you to get an understanding of why this specialization may be relevant to your goals, again both personal and professional. Please review the videos and syllabi as they will give you a sense of the specialization and how this specific course fits within. The teaching style and philosophy of the instructors is also presented to you (hopefully) in sufficient detail. Most importantly, it will give you enough information for you to make a decision about whether you want to take this course, by itself or as part of a specialization.Module 1The first module of this course will modify the frameworks introduced in the entire specialization to value companies, where a company is essentially a complex collection of “projects.” We will tackle the difficult but critical first step of identifying a comparable company and analyzing it. A complete valuation framework needed to value a company will follow this analysis. Module 2Module 2 contains  a mega example of valuation showcasing the application of alternative methods and preparing you for the Capstone Project at the end of this course and for the real world beyond. The first two modules will enable learners to test their understanding of advanced valuation techniques in two ways: (a) through a set of final exams that capture the key elements of valuation and (b) a Capstone Project that involves the valuation of a real-world company using real data.
Module 3This module/week will be spent on a short wrap up video of the course and time for assimilation and review by learners to take the final exams. In the past, learners have really valued this time and hence it is built into this new structure/platform as well. Please note there are two finals that cover materials of Modules 1 & 2, and you need to attempt both.Module 4This module contains the first part of a multi-part Capstone Project designed with the specific purpose of showcasing both the science and the art of financial analysis. It is the natural end to a Specialization that begins with the building blocks of finance, is followed by a modification of the framework to incorporate the complexity of regulations and the tax code, and ends with a capstone-like experience in the last course with rich applications to complex projects and companies. The Capstone Project is therefore a natural end to the Specialization and will involve a detailed valuation analysis of a real company. You are strongly encouraged to spend a lot of time on this project, researching on the web and trying to put together everything you have learned. All the questions you are required to answer as part of this project, though machine-graded, provide you an opportunity to learn about businesses and the critical relation between that understanding and the art and science of valuation.Module 5This module contains the second part of a multi-part Capstone Project designed with the specific purpose of showcasing both the science and the art of financial analysis. It is the natural end to a Specialization that begins with the building blocks of finance, is followed by a modification of the framework to incorporate the complexity of regulations and the tax code, and ends with a capstone-like experience in the last course with rich applications to complex projects and companies. The Capstone Project is therefore a natural end to the Specialization and will involve a detailed valuation analysis of a real company. You are strongly encouraged to spend a lot of time on this project, researching on the web and trying to put together everything you have learned. All the questions you are required to answer as part of this project, though machine-graded, provide you an opportunity to learn about businesses and the critical relation between that understanding and the art and science of valuation.Module 6This module contains the third part of a multi-part Capstone Project designed with the specific purpose of showcasing both the science and the art of financial analysis. It is the natural end to a Specialization that begins with the building blocks of finance, is followed by a modification of the framework to incorporate the complexity of regulations and the tax code, and ends with a capstone-like experience in the last course with rich applications to complex projects and companies. The Capstone Project is therefore a natural end to the Specialization and will involve a detailed valuation analysis of a real company. You are strongly encouraged to spend a lot of time on this project, researching on the web and trying to put together everything you have learned. All the questions you are required to answer as part of this project, though machine-graded, provide you an opportunity to learn about businesses and the critical relation between that understanding and the art and science of valuation.",Valuing Projects and Companies
https://www.classcentral.com/course/sustainability-social-ecological-systems-8795,"In this course you will become familiar with the ideas of the water-energy-food nexus and transdisciplinary thinking.  

You will learn to see your community or country as a complex social-ecological system and to describe its water, energy and food metabolism in the form of a pattern, as well as to map the categories of social actors.  
We will provide you with the tools to measure the nexus elements and to analyze them in a coherent way across scales and dimensions of analysis. In this way, your quantitative analysis will become useful for informed decision-making. You will be able to detect and quantify dependence on non-renewable resources and externalization of environmental problems to other societies and ecosystems (a popular ‘solution’ in the western world).  Practical case studies, from both developed and developing countries, will help you evaluate the state-of-play of a given community or country and to evaluate possible solutions. Last but not least, you will learn to see pressing social-ecological issues, such as energy poverty, water scarcity and inequity, from a radically different perspective, and to question everything you’ve been told so far.

ACKNOWLEDGEMENT
Part of the results and case studies presented have been developed within two projects: MAGIC and PARTICIPIA. However, the course does not reflect the views of the funding institutions or of the project partners as a whole, and the case studies were presented purely with an educational and illustrative purpose.
      


            Read more
          



          Introduction
    -Welcome to our course on the sustainability of social-ecological systems! Before getting started, we suggest you take a couple of minutes to read the information about the course and about the platform as given below.  


Module 1. Introducing the basic concepts
    -In this first week we will look at the nexus from a different perspective: What is the nexus? Why is it getting all this attention right now? Is it just a buzzword, or something more? We will start by explaining what the nexus means in terms of complexity and propose the basic concepts needed for a metabolic analysis of the nexus. It might take a while to get your head around these concepts, but they are essential to understand what comes next. Finally, we will give examples of “elephants in the room” in the sustainability discourse – to show you that mainstream narratives are not always right.

Module 2. Acknowledging the poor quality of existing quantitative analyses
    -This week is all about narratives, framing and complexity. You will see how different narratives affect quantitative assessments, and why numbers aren’t always right. We will delve deeper into the theoretical basis of complex systems, and propose alternative ways of doing sustainability analysis, through the use of grammars. 

Module 3. The challenge of food accounting
    -Having introduced the basis of metabolic analysis and complex systems, we will now focus on the different elements of the nexus, starting with food. We will start by answering some seemingly basic questions: what do we mean by food, and how can it be accounted? Which qualities of food can and cannot be accounted for in terms of numbers? Practical examples will guide you along the way, and by the end of the week you will see why the current agricultural system is unsustainable to its core.

Module 4. The challenge of energy accounting
    -This week we will look at energy. As we did for food, we will start by looking at the problems of energy accounting, and setting a framework to allow us to carry out energy analyses across levels and scales. You will see why energy accounting is one of the most problematic aspects of sustainability, and through the example of the Energiewende we will explore how this affects policy.

Module 5. The challenge of water accounting
    -This week is all about water. By now you should be familiar with the concept of grammar, and we will see how building one for water can help in dealing with its many dimensions. Through the example of an analysis of the Mauritius Islands, you will become familiar with the many aspects of water accounting, and by the end of the week you will understand the importance of water in nexus analysis, especially when it comes to policymaking. 

Module 6. The metabolic pattern of social-ecological systems across multiple scales and dimensions
    -We talked about scales and dimensions a lot, and this week we will explore and understand these concepts better. You will learn to account for human activity, an essential fund that is often left out from quantitative analysis, and how GIS tools can be incorporated with the methods you have learnt so far. This week is heavy on theory, to prepare you for week 7 which is all about applications. 

Module 7. Applications of MuSIASEM 2.0
    -How can the theoretical concepts explained so far be applied to practical examples? After introducing the basic building blocks of relational analysis needed for our applications, we will look at two real case examples: a nexus analysis of vegetable production in Almeria, and of a wind-powered desalination plant in the Canary Islands. By the end of this week you should be able to build processors and set up nexus analyses.

Module 8. Time for ""something completely different"": from the Cartesian dream to quantitative story-telling via evidence based policy 
    -We are ending the course with something a bit different (thanks to our guest lecturer Andrea Saltelli). This week we leave quantitative assessments behind, and take some time to reflect upon why it is important to do analyses in a different way. We will introduce the concepts of post-normal science and quantitative story-telling – this will allow you to think deeply about how you frame your analyses in the future.","Sustainability of Social-Ecological Systems: the Nexus between Water, Energy and Food"
https://www.classcentral.com/course/hadron-collider-machine-learning-9609,"The Large Hadron Collider (LHC) is the largest data generation machine for the time being. It doesn’t produce the big data, the data is gigantic. Just one of the four experiments generates thousands gigabytes per second. The intensity of data flow is only going to be increased over the time. So the data processing techniques have to be quite sophisticated and unique. In this course we’ll introduce students into the main concepts of the Physics behind those data flow so the main puzzles of the Universe Physicists are seeking answers for will be much more transparent. Of course we will scrutinize the major stages of the data processing pipelines, and focus on the role of the Machine Learning techniques for such tasks as track pattern recognition, particle identification, online real-time processing (triggers) and search for very rare decays. The assignments of this course will give you opportunity to apply your skills in the search for the New Physics using advanced data analysis techniques. Upon the completion of the course you will understand both the principles of the Experimental Physics and Machine Learning much better.

Do you have technical problems? Write to us: coursera@hse.ru
      


           Introduction into particle physics for data scientists
    -This module starts with a mild introduction into particle physics, and it explains basic notions, so you will understand the structure and the principal terms that physicists are using to describe the forces and particles that comprise the fundamental level of our universe. Also, we'll describe main stages of data collection and analysis that happens at LHC experiment. Each step is associated with specific machine learning challenges and some of which we are going to cover later. The final part of the module describes a very high-level example of data analysis that shows how simple data analysis techniques can be used for discovery of an elementary particle.

Particle identification
    -This module is about detectors in high energy physics. It describes several detector designs, different detector systems, how they work and what particle parameters they measure. Several cases in high energy physics where machine learning can be successfully applied are demonstrated.

Search for New Physics  in Rare Decays
    -In this module, we explain how new physics search can be mediated through a search for rare processes. We describe the main steps physicists have to follow to find rare decay. At first search for such phenomena may look like a perfect task for machine learning algorithms. However, there are several constraints that one have to keep in mind during training and application of a classifier.

Search for Dark Matter Hints with  Machine Learning at new CERN experiment
    -We start this module with explanation what Dark Matter phenomenon is about and what are the general strategies for Dark Matter search. Then we boil down the topic towards one of the CERN proposed experiments - SHiP. Given the design of the experiment, we consider the signatures that Dark Matter particles may produce. Of course, Machine Learning algorithms can be applied to discriminate such signatures from the background. We'll see how clustering algorithms can improve the signal visibility even further.

Detector optimization
    -This module covers several cases of detector design optimization in high energy physics experiments using Bayesian optimization with Gaussian processes.",Addressing Large Hadron Collider Challenges by Machine Learning
https://www.classcentral.com/course/open2study-big-data-for-better-performance-893,"In a digital world, data has gone ‘big’ – ushering in the age of the zettabyte. This course shows you how big data equals business opportunity. Find out what ‘big data’ means and where it comes from – including ordinary transactions and social interactions. See how smart businesses use data to target their offerings and get ahead of market trends. Consider how marketing data can be based on false assumptions such as the ‘last click myth’.
Consider the promises and threats of big data for organisations and individuals, such as the capacity of data to track a customer along the pathway to purchase; and the issues of democracy and privacy that arise when data is collected and used.
What will I learn?

Define big data and outline ways in which it is remapping the future of marketing:

Define the measurement units of big data
Recognise different types of data
Provide examples of where big data is created

Identify the basic attributes of big data:

Categorise data according to its level of refinement
Provide examples of data analytics that achieve refinement
Outline positive and negative social impacts of data proliferation

Outline business challenges and opportunities in managing and using big data:

Distinguish between brand-centric and customer-centric uses of data
Identify the key stakeholders within organisations in data management
Provide examples of targeted data acquisition for marketing benefit

Outline ways in which effective marketing can exploit big data

Define media attribution and outline its importance to marketing strategy
List some common tools in the marketing toolkit, and outline their purposes

Provide examples of marketing strategies that can capture trackable data in order to improve the quality of attribution.

This course requires approximately 2 - 4 hours of study per week, but can vary depending on the student. This includes watching videos, and taking quizzes and assessments.
If you pass this course you'll receive a Certificate of Achievement. While this certificate isn't a formal qualification or credit, you can use it to demonstrate your interest in learning about this area to potential employers or educational institutions.
Where could this lead me?
If you're wondering what your future could look like in this area, here are some potential careers you could head towards.

Business or Commercial analyst
Learning analyst
Analytics and Customer insights
Analytics consultant
Marketing & Analytics manager




            Read more
          



          



MODULE 1: INTRODUCTION TO BIG DATA

 
 



MODULE 2: BIG DATA AND MARKETING

 
 



MODULE 3: PRINCIPLES OF MARKETING WITH BIG DATA

 
 



MODULE 4: BIG DATA AND PREDICTIVE MARKETING",Big Data for Better Performance
https://www.classcentral.com/course/big-data-emerging-technologies-11987,"Every time you use Google to search something, every time you use Facebook, Twitter, Instagram or any other SNS (Social Network Service), and every time you buy from a recommended list of products on Amazon.com you are using a big data system. In addition, big data technology supports your smartphone, smartwatch, Alexa, Siri, and automobile (if it is a newer model) every day. The top companies in the world are currently using big data technology, and every company is in need of advanced big data technology support. Simply put, big data technology is not an option for your company, it is a necessity for survival and growth. So now is the right time to learn what big data is and how to use it in advantage of your company. This 6 module course first focuses on the world’s industry market share rankings of big data hardware, software, and professional services, and then covers the world’s top big data product line and service types of the major big data companies. Then the lectures focused on how big data analysis is possible based on the world’s most popular three big data technologies Hadoop, Spark, and Storm. The last part focuses on providing experience on one of the most famous and widely used big data statistical analysis systems in the world, the IBM SPSS Statistics. This course was designed to prepare you to be more successful in businesses strategic planning in the upcoming big data era. Welcome to the amazing Big Data world!
      


          Big Data Rankings & Products
    -The first module “Big Data Rankings & Products” focuses on the relation and market shares of big data hardware, software, and professional services. This information provides an insight to how future industry, products, services, schools, and government organizations will be influenced by big data technology. To have a deeper view into the world’s top big data products line and service types, the lecture provides an overview on the major big data company, which include IBM, SAP, Oracle, HPE, Splunk, Dell, Teradata, Microsoft, Cisco, and AWS. In order to understand the power of big data technology, the difference of big data analysis compared to traditional data analysis is explained. This is followed by a lecture on the 4 V big challenges of big data technology, which deal with issues in the volume, variety, velocity, and veracity of the massive data. Based on this introduction information, big data technology used in adding global insights on investments, help locate new stores and factories, and run real-time recommendation systems by Wal-Mart, Amazon, and Citibank is introduced.

Big Data & Hadoop
    -The second module “Big Data & Hadoop” focuses on the characteristics and operations of Hadoop, which is the original big data system that was used by Google. The lectures explain the functionality of MapReduce, HDFS (Hadoop Distributed FileSystem), and the processing of data blocks. These functions are executed on a cluster of nodes that are assigned the role of NameNode or DataNodes, where the data processing is conducted by the JobTracker and TaskTrackers, which are explained in the lectures. In addition, the characteristics of metadata types and the differences in the data analysis processes of Hadoop and SQL (Structured Query Language) are explained. Then the Hadoop Release Series is introduced which include the descriptions of Hadoop YARN (Yet Another Resource Negotiator), HDFS Federation, and HDFS HA (High Availability) big data technology.

Spark
    -The third module “Spark” focuses on the operations and characteristics of Spark, which is currently the most popular big data technology in the world. The lecture first covers the differences in data analysis characteristics of Spark and Hadoop, then goes into the features of Spark big data processing based on the RDD (Resilient Distributed Datasets), Spark Core, Spark SQL, Spark Streaming, MLlib (Machine Learning Library), and GraphX core units. Details of the features of Spark DAG (Directed Acyclic Graph) stages and pipeline processes that are formed based on Spark transformations and actions are explained. Especially, the definition and advantages of lazy transformations and DAG operations are described along with the characteristics of Spark variables and serialization. In addition, the process of Spark cluster operations based on Mesos, Standalone, and YARN are introduced.

Spark ML & Streaming
    -The fourth module “Spark ML & Streaming” focuses on how Spark ML (Machine Learning) works and how Spark streaming operations are conducted. The Spark ML algorithms include featurization, pipelines, persistence, and utilities which operate on the RDDs (Resilient Distributed Datasets) to extract information form the massive datasets. The lectures explain the characteristics of the DataFrame-based API, which is the primary ML API in the spark.ml package. Spark ML basic statistics algorithms based on correlation and hypothesis testing (P-value) are first introduced followed by the Spark ML classification and regression algorithms based on linear models, naive Bayes, and decision tree techniques. Then the characteristics of Spark streaming, streaming input and output, as well as streaming receiver types (which include basic, custom, and advanced) are explained, followed by how the Spark Streaming process and DStream (Discretized Stream) enable big data streaming operations for real-time and near-real-time applications.

Storm
    -The fifth module “Storm” focuses on the characteristics and operations of Storm big data systems. The lecture first covers the differences in data analysis characteristics of Storm, Spark, and Hadoop technology. Then the features of Storm big data processing based on the nimbus, spouts, and bolts are described followed by the Storm streams, supervisor, and ZooKeeper details. Further details on Storm reliable and unreliable spouts and bolts are provided followed by the advantages of Storm DAG (Directed Acyclic Graph) and data stream queue management. In addition, the advantages of using Storm based fast real-time applications, which include real-time analytics, online ML (Machine Learning), continuous computation, DRPC (Distributed Remote Procedure Call), and ETL (Extract, Transform, Load) are introduced.

IBM SPSS Statistics Project
    -The sixth and last module “IBM SPSS Statistics Project” focuses on providing experience on one of the most famous and widely used big data statistical analysis systems in the world. First, the lecture starts with how to setup and use IBM SPSS Statistics, and continues on to describe how IBM SPSS Statistics can be used to gain corporate data analysis experience. Then the data processing statistical results of two projects based on using the IBM SPSS Statistics big data system is conducted. The projects are conducted so the student can discover new ways to use, analyze, and draw charts of the relationship between datasets, and also compare the statistical results using IBM SPSS Statistics.",Big Data Emerging Technologies
https://www.classcentral.com/course/information-visualization-fundamentals-11819,"The main goal of this specialization is to provide the knowledge and practical skills necessary to develop a strong foundation on information visualization and to design and develop advanced applications for visual data analysis.

This course aims at introducing fundamental knowledge for information visualization. The main goal is to provide the students with the necessary “vocabulary” to describe visualizations in a way that helps them reason about what designs are appropriate for a given problem. This module also gives a broad overview of the field of visualization, introducing its goals, methods and applications.

A learner with some or no previous knowledge in Information Visualization will get a sense of what visualization is, what it is for and in how many different situations it can be applied; will practice to describe data in a way that is useful for visualization design; will familiarize with fundamental charts to talk about the concept of visual encoding and decoding.
      


          Introduction to Information Visualization

Data Abstraction

Fundamental Graphs and Data Transformation

Graphical Components and Mapping Strategies",Information Visualization: Foundations
https://www.classcentral.com/course/stanford-openedx-patient-engagement-design-2454,"Engage and Empower Me: Patient Engagement Design is an online course brought to you by the Stanford AIM Lab and Medicine X at Stanford University.
Our goal is to educate you about participatory medicine and empower you to create a more inclusive, collaborative healthcare system for patients. In this course, you will learn the science of habit formation, behavior change, and decision-making. You will gain knowledge about how human-centered design can empower people and help them make healthy choices. Finally, you will discover how social media platforms can be used to create robust patient communities and how self-tracking devices can provide day-to-day data points that motivate people to make positive changes.
PREREQUISITES
This course is open to patients, healthcare providers, caregivers, entrepreneurs and anyone interested in how we can engage patient perspectives to improve health outcomes for all. Patient Engagement Design is for anyone who shares the goal of creating a healthier, activated population, and an inclusive, empathic healthcare system. We look forward to assisting you as you progress through this course and encourage you to reach out with feedback. There are no prerequisites.",Patient Engagement Design
https://www.classcentral.com/course/regtech-11726,"This course ""FinTech Security and Regulation (RegTech)"" help you to understand RegTech and to become more confident and persuasive in your ability to analyze and make recommendations to executives within the finance industry regarding how to react to these changes, e.g. Regulations to cryptocurrencies like BitCoin & Initial Coin Offering (ICO). It presents the views of several professors from the top business school in Asia as well as perspectives from industry professionals.

You will learn about how FinTech and RegTech disrupt and transform finance industry, such as challenges in protecting data and security with digital forensics, risk management and corporate governance in banking industry in terms of Know Your Customer (KYC) and Anti Money Laundering (AML), and how governments in different countries take initiatives in FinTech and RegTech.
      


          Introduction to FinTech Security & Regulation
    -In this module, learners will examine the relationship between security and regulation as twin methodologies for managing and reducing risk in financial services. Issues explored will include  ""What is RegTech?"", ""What is InsurTech?"", and how can we determine when regulation and security are enough or too much to achieve important social & business objectives.

Risk Management & Government Control
    -In this module, we explore some of the tools government use to regulate financial markets and discuss  potential challenges for FinTech innovators in complying with these regulations. Some basic terms commonly used in finance such as AML & KYC are defined and described. We examine the role of different  government agencies as well as alternative social objectives that influence the development of regulations over time.

Fraud,  Crimes, & Security 
    -In this module, we discuss the issues and challenges of preventing and detecting fraud and crime in financial markets. Topic discuss will include data theft and related security technologies, human challenges in implementing effective security, and electronic evidence & digital forensics issues. Recommendations for FinTech firms are provided to reduce risk of fraud and crime.  

Global Trends and  Government Initiatives in RegTech
    -In this module, learners will explore a variety of government initiatives related to FinTech & RegTech. Topics included open banking APIs in Europe, crypto-currency & ICO regulations, evolution of FinTech regulations in US & Europe, China regulations on FinTech, and regulatory issues in HK, Singapore & other jurisdictions. 

Peer-graded Final Project
    -In this module, learners will complete a final project for the course involving research on regulatory decisions in multiple countries regarding a specific area of FinTech. Building on what they have discovered, learners will prepare  a short video/written pitch recommending FinTech policies to a regulator in a smaller jurisdiction dealing with FinTech challenges and opportunities.",FinTech Security and Regulation (RegTech)
https://www.classcentral.com/course/udacity-model-building-and-validation-3256,"This course will teach you how to start from scratch in answering questions about the real world using data. Machine learning happens to be a small part of this process. The model building process involves setting up ways of collecting data, understanding and paying attention to what is important in the data to answer the questions you are asking, finding a statistical, mathematical or a simulation model to gain understanding and make predictions. All of these things are equally important and model building is a crucial skill to acquire in every field of science. The process stays true to the scientific method, making what you learn through your models useful for gaining an understanding of whatever you are investigating as well as make predictions that hold true to test. We will take you on a journey through building various models. This process involves asking questions, gathering and manipulating data, building models, and ultimately testing and evaluating them.Why Take This Course?Many of you may have already taken a course in machine learning or data science or are familiar with machine learning models.In this course we will take a more general approach, walking through the questioning, modeling and validation steps of the model building process. The goal is to get you to practice thinking in depth about a problem and coming up with your own solutions. Many examples we will attempt may not have one correct answer but will require you to work through the problems applying the methods we hope to illustrate throughout this class.



            Read more
          



Lesson 1 - Introduction to the QMV ProcessLearn about the Question, Modeling, and Validation (QMV) process of data analysis. Understand the basics behind each step and apply the QMV process to analyze on how Udacity employees choose candies!Lesson 2 - Question PhaseWe will drill in on the questioning phase of the QMV process. We’ll teach you how to turn a vague question into a statistical one that can be analyzed with statistics and machine learning. You will also analyze a Twitter dataset and try to predict when a person will tweet next! Lesson 3 - Modeling PhaseBuilding upon lesson 2, you will learn how to build rigorous mathematical, statistical, and machine learning models so you can make accurate predictions. You look through the recently released U.S. medicare dataset for anomalous transactions.Lesson 4 - Validation PhaseSo how do you tell if your model is doing well? In this lesson, we will teach you some of the fundamental and important metrics that you can use to grade the performance of the models that you’ve build. You will analyze the AT&T connected cars data set and see if you can tell which driver is which by analyzing their driving patterns.Final Project - Identify Hacking Attempts from Network Flow LogsYou will create a program that examines log data of net flow traffic, and produces a score, from 1 to 10, describing the degree to which the logs suggest a brute force attack is taking place on a server.",Model Building and Validation
https://www.classcentral.com/course/getting-started-app-development-9803,"In this course, application developers learn how to design and develop cloud-native applications that seamlessly integrate managed services from the Google Cloud Platform. Through a combination of presentations, demos, and hands-on labs, participants learn how to apply best practices for application development and use the appropriate GCP storage services for object storage, relational data, caching, and analytics. Learners can choose to complete labs in their favorite language: Node.js, Java, or Python.

Prerequisites and prework:

• Completed Google Cloud Platform Fundamentals or have equivalent experience
• Working knowledge of Node.js, Java, or Python
• Basic proficiency with command-line tools and Linux operating system environments
      


          Introduction to Getting Started With Application Development
    -This module introduces the specialization and the course structure.

Best Practices for Application Development
    -This module introduces best practices for application development.

Google Cloud Client Libraries, Google Cloud SDK, and Google Firebase SDK
    -This module introduces the Google Cloud Client Libraries, Google Cloud SDK, and Google Firebase SDK.

Data Storage Options
    -This module introduces the various data storage options available to your applications in GCP.

Best Practices for Using Cloud Datastore
    -This module covers best practices for using Cloud Datastore.

Best Practices for Using Cloud Storage
    -This module covers best practices for using Cloud Storage.

Wrap Up
    -This module reviews the concepts covered in the course.",Getting Started With Application Development
https://www.classcentral.com/course/networking-security-architecture-vmware--11688,"This 8 week online course equips learners with the basics of network virtualization with VMware NSX.

To get the most of this course, you should have familiarity with generic IT concepts of routing, switching, firewalling, disaster recovery, business continuity, cloud and security.

At the end of the course, you will be able to:
•	Understand network virtualization basics
•	Describe NSX business value and use cases
•	Explain how NSX is different from traditional networking
•	Summarize networking and security solution architecture with VMware NSX around these key areas:
          + Micro-segmentation
          + Automation with OpenStack
          + Automation with VMware vRealize Automation
          + Disaster Recovery and Business Continuity
          + Operational Transformation
•	Demonstrate understanding through hands-on experience
•	Develop a learning plan for network virtualization certification

If you are new to network virtualization, download our Network Virtualization for Dummies guide. 
http://learn.vmware.com/36350_NSX_ITAutomation_Reg?src=af_5acfd24cebb90&cid=70134000001YR9b

All Hands on Labs referenced in this course are OPTIONAL and available for FREE. Direct links to free labs can be found on the Resources Tab or you can access our full library at https://labs.hol.vmware.com/HOL/catalogs/catalog/877
      


          Introduction & Networking and Security Architecture with VMware NSX
    -We'll introduce you to the course and VMware NSX, as well as provide a brief history of how VMware has evolved into the company that it is today.

NSX Architecture Components
    -This module explains the architectural components that make up VMware NSX.  These components are the foundation for understanding how VMware NSX is deployed into a data center.

Security Solutions with VMware NSX
    -This module dives into VMware NSX as a security platform that provides a defensive in depth solution.  The content compares traditional security solutions with the in-kernel firewall provided by VMware NSX.  In addition, this module covers application behavior monitoring and the ecosystem of partners that integrate with VMware NSX to provide a comprehensive security solution.

Application Continuity Solutions (part 1 of 2)
    -This module provides details on using VMware NSX to create highly available data center designs.

Application Continuity Solutions (part 2 of 2)
    -The content covers stretched clusters and disaster recovery designs using VMware NSX.  In addition, this module takes a look at how VMware Cloud on Amazon Web Services allows public cloud solutions to be managed the same way an on-prem data center is managed. 

Operations (part 1 of 2)
    -The Operations modules explain the evolution of people, process and tooling.

Operations (part 2 of 2)
    -The content covers process automation with VMware NSX using common cloud management platforms like OpenStack and vRealize Automation.  In addition the content describes the need for new tooling that provides converged and correlated data of new data center technologies.  Finally, the module explains the importance a growth mindset and the evolution of IT organizations away from rigid, well-defined silos to a more collaborative, cross-functional workforce.

SUPPLEMENTAL MATERIALS",Networking and Security Architecture with VMware NSX
https://www.classcentral.com/course/edx-comparative-research-designs-and-methods-11416,"This course is part of the IPSAMOOC project, a joint venture Federica Weblearning - IPSA, the International Political Science Association
Emile Durkheim, one of the founders of modern empirical social science, once stated that the comparative method is the only one that suits the social sciences. But Descartes hadposited that ""comparaison n'est pas raison,"" which means that comparison is not reason (or theory) by itself. So what's the right answer? 
This course provides an introduction and overview of systematic comparative analysis in the social sciences, and shows you how to use this method for constructive explanation and theory building. 
A major portion of the course is devoted to new approaches and software that have been developed in recent yearsto handle highly complex cases. Such cases includecomparisons of EU member states, Latin American political systems,and particular policy areas. Procedures such as Qualitative Comparative Analysis (QCA) and related methods are able to reduce complexity and to arrive at ""configurational"" solutions based on set theory and Boolean algebra. These are more meaningful in this context thancommonly used, broad-based statistical methods. 
Inthe last section, these methods are contrasted with more common statistical comparative methods at the macro-level. We'll discuss various states or societies and their respective strengths and weaknesses.",Comparative Research Designs and Methods
https://www.classcentral.com/course/coursera-getting-started-in-cryo-em-3544,"This class covers the fundamental principles underlying cryo-electron microscopy (cryo-EM) starting with the basic anatomy of electron microscopes, an introduction to Fourier transforms, and the principles of image formation. Building upon that foundation, the class then covers the sample preparation issues, data collection strategies, and basic image processing workflows for all 3 basic modalities of modern cryo-EM: tomography, single particle analysis, and 2-D crystallography.

Philosophy:
The course emphasizes concepts rather than mathematical details, taught through numerous drawings and example images.  It is meant for anyone interested in the burgeoning fields of cryo-EM and 3-D EM, including cell biologists or molecular biologists without extensive training in mathematics or imaging physics and practicing electron microscopists who want to broaden their understanding of the field.  The class is perfect as a primer for anyone who is about to be trained as a cryo-electron microscopist, or for anyone who needs an introduction to the field to be able to understand the literature or the talks and conversations they will hear at cryo-EM meetings.

Pre-requisites:
The recommended prerequisites are college-freshman-level math, physics, and biochemistry.

Pace: 
There are 14.5 hours of lecture videos total separated into 40 individual “modules” lasting on average 20 minutes each.  Each module has at the end a list of “concept check” questions you can use to test your knowledge of what was presented. As the modules are grouped into seven major subjects, one reasonable plan would be to go through one major subject each day.  That would mean watching a couple hours of lecture and spending another hour or so thinking through the concept check questions each day for a week.  Another reasonable plan would be to go through one module each day for a little over a month, or even three modules a week (Monday, Wednesday, and Friday) for a 3-month term.

It is likely that as you then move on to actually begin using a cryo-EM or otherwise engage in the field, you will want to repeat certain modules.
      


            Read more
          



          Welcome
    -Welcome to the course!

Currents, Coils, Knobs and Names: Basic anatomy of the electron microscope

Fourier Transforms and Reciprocal Space for Beginners

Image Formation

Fundamental Challenges in Biological EM

Single Particle Analysis

Tomography

2-D Crystallography",Getting started in cryo-EM
https://www.classcentral.com/course/swayam-programming-data-structures-and-algorithms-2778,"This is a course on programming, data structures and algorithms. The learner is assumed to have no prior experience of programming, but is expected to be at the level of a second year undergraduate college student in science or engineering. The course will run over ten weeks with about 2-3 hours of lectures per week.
At the end of each week, the learner is expected to write some programs and submit them for grading. These programming problems are classified as easy, moderate or difficult. The easy problems, typically, are repeats from the lecture. The moderate and difficult ones will require increasing levels of initiative from the learner. In addition, at the end of each week the learner is expected to answer a set of objective-type assessment questions. 




Introduction to Computers and Programming
Writing your first program
Variables and operators and expressions
Variable declarations, more operators, precedence
Input, Output Statements
Conditionals
Loops
Arrays and Multidimensional arrays
Pointers
Functions
Running time of a program
Computing time complexity
Polynomial evaluation and multiplication
Searching: Linear and Binary
Finding minimum and maximum
Sorting I: Insertion, Merge
Sorting II: Counting, Radix
Finding i-th smallest number
Structures and User-defined data types
Brief introduction to C++: Classes and objects
Data Structures: Abstract Data Type
Lists
Stacks: Last In First Out
Queues: First In First Out
Trees
Tree traversal
Heaps
Graphs and Representation
Greedy algorithms
Dynamic programming
Matrix Chain Multiplication
Dijkstra's Algorithm
Strings
Boyer-Moore String Matching Algorithm
File I/O
Modular Programming","Programming, Data Structures and Algorithms"
https://www.classcentral.com/course/edx-data-science-ethics-4905,"As patients, we care about the privacy of our medical record; but as patients, we also wish to benefit from the analysis of data in medical records. As citizens, we want a fair trial before being punished for a crime; but as citizens, we want to stop terrorists before they attack us. As decision-makers, we value the advice we get from data-driven algorithms; but as decision-makers, we also worry about unintended bias. Many data scientists learn the tools of the trade and get down to work right away, without appreciating the possible consequences of their work.
This course focused on ethics specifically related to data science will provide you with the framework to analyze these concerns. This framework is based on ethics, which are shared values that help differentiate right from wrong. Ethics are not law, but they are usually the basis for laws.
Everyone, including data scientists, will benefit from this course. No previous knowledge is needed.",Data Science Ethics
https://www.classcentral.com/course/launching-machine-learning-10621,"Starting from a history of machine learning, we discuss why neural networks today perform so well in a variety of data science problems. We then discuss how to set up a supervised learning problem and find a good solution using gradient descent. This involves creating datasets that permit generalization; we talk about methods of doing so in a repeatable way that supports experimentation.

Course Objectives:
Identify why deep learning is currently popular
Optimize and evaluate models using loss functions and performance metrics
Mitigate common problems that arise in machine learning
Create repeatable and scalable training, evaluation, and test datasets
      


          Introduction
    -In this course you’ll get foundational ML knowledge so that you understand the terminology that we use throughout the specialization. You will also learn practical tips and pitfalls from ML practitioners here at Google and walk away with the code and the knowledge to bootstrap your own ML models.

Practical ML
    -In this module, we will introduce some of the main types of machine learning and review the history of ML leading up to the state of the art so that you can accelerate your growth as an ML practitioner.

Optimization
    -In this module we will walk you through how to optimize your ML models.

Generalization and Sampling
    -Now it’s time to answer a rather weird question: when is the most accurate ML model not the right one to pick?  As we hinted at in the last module on Optimization -- simply because a model has a loss metric of 0 for your training dataset does not mean it will perform well on new data in the real world. 

Summary",Launching into Machine Learning
https://www.classcentral.com/course/edx-fundamentals-of-nanoelectronics-part-b-quantum-transport-3960,"Nanoelectronic devices are an integral part of our life, including the billion-plus transistors in every smartphone, each of which has an active region that is only a few hundred atoms in length.
This nanotechnology course explains the fundamentals of nanoelectronics and mesoscopic physics.
Even with NO prior background in quantum mechanics, you should learn about cutting-edge developments and concepts that will prepare you for a future in nanotechnology and nanoelectronics.
Indeed we hope you will be excited to join the field and help invent the new devices that will shape the electronics of this century and meet its challenges.
Second in a two part series, this nanotechnology course provides an introduction to more advanced topics, including the Non-Equilibrium Green’s Function (NEGF) method widely used to analyze quantum transport in nanoscale devices. We will explore a number of topics within nanoelectronics, taking a more in depth look at quantum transport, gaining greater insight into the application of the Schrodinger Equation, and learning the basics of spintronics.
“The course was just awesome!”
- Student from Part A
This course is the latest in a series offered by the nanoHUB-U project which is jointly funded by Purdue and the National Science Foundation with the goal of transcending disciplines through short courses accessible to students in any branch of science or engineering. These courses focus on cutting-edge topics distilled into short lectures with quizzes and practice exams.



            Read more","Fundamentals of Nanoelectronics, Part B:  Quantum Transport"
https://www.classcentral.com/course/edx-fundamentals-of-clinical-trials-924,"This course will provide an introduction to the scientific, statistical, and ethical aspects of clinical trials research. Topics include the design, implementation, and analysis of trials, including first-in-human studies (dose-finding, safety, proof of concept, and Phase I), Phase II, Phase III, and Phase IV studies. All aspects of the development of a study protocol will be addressed, including criteria for the selection of participants, treatments, and endpoints, randomization procedures, sample size determination, data analysis, and study interpretation. The ethical issues that arise at each phase of therapy development will be explored.
This course contains 12 modules. The modules will be released Monday of each week, with the exception of some holiday weeks. Most students should plan to spend 4 – 6 hours on each module. Students will have until February 14, 2014 to earn a HarvardX certificate.
Before your course starts, try the new edX Demo where you can explore the fun, interactive learning environment and virtual labs. Learn more.
HarvardX requires individuals who enroll in its courses on edX to abide by the terms of the edX honor code : https://www.edx.org/edx-terms-service. HarvardX will take appropriate corrective action in response to violations of the edX honor code, which may include dismissal from the HarvardX course; revocation of any certificates received for the HarvardX course; or other remedies as circumstances warrant. No refunds will be issued in the case of corrective action for such violations. Enrollees who are taking HarvardX courses as part of another program will also be governed by the academic policies of those programs.
HarvardX pursues the science of learning. By registering as an online learner in an HX course, you will also participate in research about learning. Read our research statement : http://harvardx.harvard.edu/research-statement to learn more.
Harvard University and HarvardX are committed to maintaining a safe and healthy educational and work environment in which no member of the community is excluded from participation in, denied the benefits of, or subjected to discrimination or harassment in our program. All members of the HarvardX community are expected to abide by Harvard policies on nondiscrimination, including sexual harassment, and the edX Terms of Service. If you have any questions or concerns, please contact harvardx@harvard.edu and/or report your experience through the edX contact form : https://www.edx.org/contact-us.



            Read more",Fundamentals of Clinical Trials
https://www.classcentral.com/course/gcp-infrastructure-core-services-8763,"This accelerated on-demand course introduces participants to the comprehensive and flexible infrastructure and platform services provided by Google Cloud Platform with a focus on Compute Engine. Through a combination of video lectures, demos, and hands-on labs, participants explore and deploy solution elements, including infrastructure components such as networks, systems and applications services. This course also covers deploying practical solutions including customer-supplied encryption keys, security and access management, quotas and billing, and resource monitoring.

Prerequisites:
To get the most out of this course, participants should have:
• Completed Google Cloud Platform Fundamentals: Core Infrastructure or have equivalent experience
• Completed Essential Cloud Infrastructure: Foundation or have equivalent experience
• Basic proficiency with command-line tools and Linux operating system environments
• Systems Operations experience including deploying and managing applications, either on-premises or in a public cloud environment

>>> By enrolling in this course you agree to the Qwiklabs Terms of Service as set out in the FAQ and located at: https://qwiklabs.com/terms_of_service 
      


          Introduction
    -In this module we introduce the Architecting with Google Compute Engine course series. This course series is defined for cloud solution architects, DevOps engineers, and anyone who's interested in using GCP, to create new solutions or to integrate existing systems, application environments, and infrastructure with a focus on Compute Engine.

Module 1: Cloud IAM
    -In this module, we cover Cloud Identity and Access Management (or Cloud IAM). Cloud IAM is a sophisticated system built on top of email-like address names, job-type roles, and granular permissions. If you're familiar with IAM from other implementations, look for the differences that Google has implemented to make IAM easier to administer and more secure. 


Module 2: Storage and Database Services
    -In this module, we cover storage and database services in GCP. Every application needs to store data, whether it's business data, media to be streamed, or sensor data from devices. 

Module 3: Resource Management
    -In this module, we will cover Resource Management. Resources in GCP are billable, so managing them means controlling cost. There are several methods in place for controlling access to the resources, and there are quotas that limit consumption. 


Module 4: Resource Monitoring
    -In this module, we’ll give you an overview of the resource monitoring options in GCP. The features covered in this module rely on Stackdriver, a service that provides monitoring, logging, and diagnostics for your applications.",Essential Google Cloud Infrastructure: Core Services
https://www.classcentral.com/course/programming-fundamentals-9574,"Programming is an increasingly important skill, whether you aspire to a career in software development, or in other fields. This course is the first in the specialization Introduction to Programming in C, but its lessons extend to any language you might want to learn. This is because programming is fundamentally about figuring out how to solve a class of problems and writing the algorithm, a clear set of steps to solve any problem in its class. This course will introduce you to a powerful problem-solving process—the Seven Steps—which you can use to solve any programming problem. In this course, you will learn how to develop an algorithm, then progress to reading code and understanding how programming concepts relate to algorithms.
      


          Introduction
    -This module introduces a powerful process for solving any programming problem—the Seven Steps. You will learn how to approach a programming problem methodically, so you can formulate an algorithm that is specific and correct. You will work through examples with sequences of numbers and graphical patterns to develop the skill of algorithm development.

Reading Code
    -In this module, you will learn to read code—this means you will be able to execute a piece of code by hand, and clearly illustrate what each statement does and what the state of the program is. Understanding how to read code is the only way to be sure you can write correct code. By the end of this module, you will be able to read and understand code with functions, conditional statements, iteration, and other fundamental techniques.

Types
    -Everything is a number to a computer, but types determine the size and interpretation of numbers. In this module you will learn about types beyond integers, both their conceptual representations, and their hardware representations in binary. You will learn basic data types, ""non-number"" types, and complex, custom types, as well as some important caveats, so you will avoid type-related programming mistakes.

Project
    -You have learned a lot about designing algorithms and the programming concepts that will help you implement them. For this project, you will develop and test your own algorithm for sorting data. This module will reinforce the importance of being specific when you write an algorithm and provide an opportunity for you to do so yourself, for a very common computational task: sorting.",Programming Fundamentals
https://www.classcentral.com/course/quantitative-formal-modeling-1-4864,"Welcome to Quantitative Formal Modeling and Worst-Case Performance Analysis. In this course, you will learn about modeling and solving performance problems in a fashion popular in theoretical computer science, and generally train your abstract thinking skills.   

After finishing this course, you have learned to think about the behavior of systems in terms of token production and consumption, and you are able to formalize this thinking mathematically in terms of prefix orders and counting functions. You have learned about Petri-nets, about timing, and about scheduling of token consumption/production systems, and for the special class of Petri-nets known as single-rate dataflow graphs, you will know how to perform a worst-case analysis of basic performance metrics, like throughput, latency and buffering.

Disclaimer: As you will notice, there is an abundance of small examples in this course, but at first sight there are not many industrial size systems being discussed. The reason for this is two-fold. Firstly, it is not my intention to teach you performance analysis skills up to the level of what you will need in industry. Rather, I would like to teach you to think about modeling and performance analysis in general and abstract terms, because that is what you will need to do whenever you encounter any performance analysis problem in the future. After all, abstract thinking is the most revered skill required for any academic-level job in any engineering discipline, and if you are able to phrase your problems mathematically, it will become easier for you to spot mistakes, to communicate your ideas with others, and you have already made a big step towards actually solving the problem. Secondly, although dataflow techniques are applicable and being used in industry, the subclass of single-rate dataflow is too restrictive to be of practical use in large modeling examples. The analysis principles of other dataflow techniques, however, are all based on single-rate dataflow. So this course is a good primer for any more advanced course on the topic.

This course is part of the university course on Quantitative Evaluation of Embedded Systems (QEES) as given in the Embedded Systems master curriculum of the EIT-Digital university, and of the Dutch 3TU consortium consisting of TU/e (Eindhoven), TUD (Delft) and UT (Twente). The course material is exactly the same as the first three weeks of QEES, but the examination of QEES is at a slightly higher level of difficulty, which cannot (yet) be obtained in an online course.
      


            Read more
          



          Introduction
    -This course is part of a Blended Master Programme in Embedded Systems. 

Modeling systems as token consumption/production systems
    -In this module/week you will learn to draw a model of a token consumption/production system, and communicate your interpretation of this model with others in an informal manner. At the end of this model, you will be able to draw your own models, and explain your interpretation of them in general terms. Also, you will know about the standard Petri-net interpretation of consumption/production systems, and will be able to point out particular patterns in Petri-net models. Finally, you will be able to refine a consumption/production model into a model that contains sufficient information to allow worst-case performance analysis. This is all tested using a peer-reviewed assignment. 

Syntax and semantics
    -In this module/week, you will be really training your abstract thinking skills. After finishing this module, you will have learned how to formalize the behavior of any dynamical system as a prefix order, and how to formalize the interpretation of a consumption/production system as a counting function on such a prefix order. You understand how the Petri-net interpretation puts certain restrictions on these counting functions, and how you can exploit those restrictions to prove properties about Petri-net interpretations, without knowing the actual interpretation itself. At the end of the module, you will practice the formalization of performance metrics as logical properties of counting functions, by recognizing right and wrong examples of formalization. 

Those who are already familiar with Petri-net theory, may find that the prefix order semantics that I introduce in this course is slightly different from what they are used to. Traditional Petri-net semantics is usually based on markings, transition systems, or the execution trees thereoff. Execution trees are a particular example of a prefix order, but in general prefix orders offer the added flexibility that they do not restrict the user to discrete interpretations of behavior only. This is particularly suitable when seeking connection between theoretical computer science and an application field like embedded systems, from which this course originates, where also the continuous behavior of physical systems has to be taken into account.

Performance analysis
    -In this module/week you will learn to exploit the structure of single-rate dataflow graphs to perform worst-case analysis of performance metrics like throughput, latency and buffering. After this week, you know how to calculate the maximum cycle mean of a dataflow graph, how to construct a periodic schedule for it, how to optimize this schedule for latency analysis, and how to determine the size of buffers with back-pressure such that the worst-case analysis remains valid. If you understood the material of the previous module/week, the proofs presented in this week will give you a deeper understanding of the mathematical underpinning of these methods.

One final example
    -In this last week, we just discuss one more example, following the outline of the peer-reviewed assignment of the first module/week. It's just a little summary, combining everything we have learned so far, and there is some additional reading material to trigger an appetite for further discovery.",Quantitative Formal Modeling and Worst-Case Performance Analysis
https://www.classcentral.com/course/edx-introduction-to-data-analytics-for-managers-8525,"Through a combination of lectures, business case studies, and hands-on learning this course provides an introduction to data analytics techniques and their application in business.
The case studies explored will illustrate how companies are leveraging different sources of data, including “big data,” with different analytical techniques, to improve performance. You will receive hands-on learning through a free web-based graphical development environment that will allow you to practice using some of these tools themselves. You will also gain an understanding of the many possibilities for applying data science in business, and will be able to consider additional learning opportunities to gain further depth.
This course is an excellent resource for managers who see the opportunity to use data analytics in business but do not have the skills and background to engage with data analytics themselves.",Introduction to Data Analytics for Managers
https://www.classcentral.com/course/fundamentals-of-revenue-management-4301,"With a fixed capacity, a highly disposable product and high fixed costs, hotels are a natural candidate for the application of revenue management. Originally developed by the airlines in the 1970s, these analytics-based techniques help predict consumer behavior at the hotel’s market level so that the hotel can sell each room each night at the optimum price. 

With modern-day rising acquisition costs and distribution complexities, revenue management techniques have increasingly been adopted by both small and large hotel companies, making a comprehensive understanding of segmentation, forecasting and pricing an essential requirement for today’s hospitality professionals. The purpose of this course is to provide a core understanding of the fundamentals of revenue management, which ties into the larger picture of revenue strategy. The course is structured to provide an insightful look into Revenue Management.

Created in conjunction with Duetto, this course is hosted by a group of revenue management leaders in both theory and with hands-on experience at properties around the world. Upon completion of the course students should be empowered with industry best practices, which can be applied across the vast diversification the hotel industry to empower those to optimize profits. Duetto delivers powerful revenue strategy solutions to the world’s leading hotels and casinos, combining unparalleled expertise with world-class cloud-based technology.

Acknowledgement: Bela Nagy, Agnes Roquefort , Jonathon Liu, Frederic Toitot, Pierrick La Masne, Markus Keller - ACCOR Simone Truscello -  ACE HOTELS. Richard Valtr - MEWS SYSTEM. Jean-Luc Chrétien - FAST BOOKING. Jeannette Ho - FAIRMONT RAFFLES HOTELS & RESORTS. Chinmai Sharma - TAJ HOTEL & RESORTS. Cindy Estis Green - KALIBRI LABS. Jason Thielbar - RED LION. Christopher Cooper - ROCCO FORTE. Rom Hendler - SANDS. Rafi Rejerano - AB Hotels. Riko Van Santen - KEMPINKI HOTELS & RESORTS. Vinod Sukhija - BANYAN TREE HOTELS & RESORTS. Olivier Flement - WALT DISNEY COMPANY. Cidalia Pinto Coehlo - LOUVRE HOTELS. Trevor Stuart-Hill - REVENUE MATTERS. Vincent Cusma, Marco Benvenuti, Eric Stoessel, Gayle Ehrean, Nevin Reed - DUETTO.  Claire Bertrand, Vincent Chatain, Jessica Moses, Benjamin Six (ESSEC Business School), Emilie Dupré (IMAGE-IN), Gregory Halidy (TRIPLAY)
      


            Read more
          



          Getting Started with Revenue Management
    -Welcome!  In this first module, you will understand what revenue management is, why it’s important, simple steps to get started, how revenue management can increase profit through booking curve management and how effective yielding can improve a hotel’s profits.  Moving forward, we’ll share best practices and better prepare you for today’s complex digital age.

Introduction to Segmentation
    -In this second module we will discuss segmentation 101, four things to consider while determining segmentation, as well as our best practices in regards to working with properties who need to go through a re-segmentation exercise, and presenting you with some key takeaways.

Introduction to Forecasting & Budgeting
    -In this third module, you will have an overview of forecasting and its basic  terminology, explore forecasting goals, trends and tools, and understand how to link forecasting and budgeting together.

Introduction to Pricing
    -This last module should help tie together concepts from the previous three modules to give you a practical understanding of the fundamentals of revenue management. You will understand why pricing is important, the difference between common pricing strategies, and what are the 7 most common pricing mistakes.  After that we will revisit the topic of Big Data, automated systems, and system connectivity as it and discuss best practices for pricing.",The Fundamentals of Revenue Management: The Cornerstone of Revenue Strategy
https://www.classcentral.com/course/mathletics-4421,"Learn how probability, math, and statistics can be used to help baseball, football and basketball teams improve, player and lineup selection as well as in game strategy.
      


          Before you start...

Module 1
    -You will learn how to predict a team’s won loss record from the number of runs, points, or goals scored by a team and its opponents. Then we will introduce you to multiple regression and show how multiple regression is used to evaluate baseball hitters. Excel data tables, VLOOKUP, MATCH, and INDEX functions will be discussed.  

Module 2
    -You will concentrate on learning important Excel tools including Range Names, Tables, Conditional Formatting, PivotTables, and the family of COUNTIFS, SUMIFS, and AVERAGEIFS functions.  You will concentrate on learning important Excel tools including Range Names, Tables, Conditional Formatting, PivotTables, and the family of COUNTIFS, SUMIFS, and AVERAGEIFS functions.  

Module 3
    -You will learn how Monte Carlo simulation works and how it can be used to evaluate a baseball team’s offense and the famous DEFLATEGATE controversy.

Module 4
    -You will learn how to evaluate baseball fielding, baseball pitchers, and evaluate in game baseball decision-making. The math behind WAR (Wins above Replacement) and Park Factors will also be discussed. Modern developments such as infield shifts and pitch framing will also be discussed.

Module 5
    -You will learn basic concepts involving random variables (specifically the normal random variable, expected value, variance and standard deviation.) You will learn how regression can be used to analyze what makes NFL teams win and decode the NFL QB rating system. You will also learn that momentum and the “hot hand” is mostly a myth. Finally, you will use Excel text functions and the concept of Expected Points per play to analyze the effectiveness of a football team’s play calling.

Module 6
    -You will learn how two-person zero sum game theory sheds light on football play selection and soccer penalty kick strategies. Our discussion of basketball begins with an analysis of NBA shooting, box score based player metrics, and the Four Factor concept which explains what makes basketball teams win.

Module 7
    -You will learn about advanced basketball concepts such as Adjusted plus minus, ESPN’s RPM, SportVu data, and NBA in game decision-making.

Module 8
    -You will learn how to use game results to rate sports teams and set point spreads. Simulation of the NCAA basketball tournament will aid you in filling out your 2016 bracket. Final 4 is in Houston!

Module 9
    -You will learn how to rate NASCAR drivers and get an introduction to sports betting concepts such as the Money line, Props Bets, and evaluation of gambling betting systems.

Module 10
    -You will learn how Kelly Growth can optimize your sports betting, how regression to the mean explains the SI cover jinx and how to optimize a daily fantasy sports lineup. We close with a discussion of golf analytics.

Final Exam
    -Final exam has 10 questions.  Please download and open Excel files before taking the exam.  You will be referred to Excel files during the exam.  Each question is wort 1 point.  You need to answer 6 questions or more correctly to pass the exam.",Math behind Moneyball
https://www.classcentral.com/course/big-data-visualisation-5423,"##
Data visualisation is an important visual method for effective communication and analysing large datasets. Through data visualisations we are able to draw conclusions from data that are sometimes not immediately obvious and interact with the data in an entirely different way.
This course will provide you with an informative introduction to the methods, tools and processes involved in visualising big data. We will also take the time to examine briefly the use of visualisation throughout history dating back as far as 17000 BC.
We have designed the course for people from different fields who want to learn how to produce visualisations that help us better understand real-world big data problems. You will gain the most from the practical exercises if you are comfortable with computer programming however you don’t need to have any prior experience using the software listed below.
We will use a variety of tools so that you become comfortable engaging with different software and confident trialing new packages to find those that best meet your needs. Please review the product websites below to ensure your system meets the minimum requirements for the tools we will be using.

Tableau: You can use the free trial for a period of 2 weeks. Please do not start the trial until you are ready to do the Tableau exercises.
MATLAB Online: MathWorks will provide you with a license to use MATLAB online for the duration of the course.
D3.js: The D3 JavaScript library is available under BSD license.

You can still learn effectively even if you don’t have access to all of these tools as you will be able to see what they can do for you.



            Read more",Big Data: Data Visualisation
https://www.classcentral.com/course/edx-foundations-of-data-analysis-part-2-inferential-statistics-4804,"In the second part of a two part statistics course, we’ll learn how to take data and use it to make reasonable and useful conclusions. You’ll learn the basics of statistical thinking – starting with an interesting question and some data. Then, we’ll apply the correct statistical tool to help answer our question of interest – using R and hands-on Labs. Finally, we’ll learn how to interpret our findings and develop a meaningful conclusion.
We will cover basic Inferential Statistics – integrating ideas of Part 1. If you have a basic knowledge of Descriptive Statistics, this course is for you. We will learn how to sample data, examine both quantitative and categorical data with statistical techniques such as t-tests, chi-square, ANOVA, and Regression.
Both parts of the course are intended to cover the same material as a typical introductory undergraduate statistics course, with an added twist of modeling. This course is also intentionally devised to be sequential, with each new piece building on the previous topics. Once completed, students should feel comfortable using basic statistical techniques to answer their own questions about their own data, using a widely available statistical software package (R).
This course will consist of:

Instructional videos for statistical concepts broken down into manageable topics
Guided questions to help your understanding of the topic
Weekly tutorial videos for using R
Scaffolded learning with Pre-Labs (using R), followed by Labs where we will answer specific questions using real-world datasets
Weekly wrap-up questions challenging both topic and application knowledge

With these new skills, learners will leave the course with the ability to use basic statistical techniques to answer their own questions about their own data, using a widely available statistical software package (R). Learners from all walks of life can use this course to better understand their data, to make valuable informed decisions.
Join us in learning how to look at the world around us. What are the questions? How can we answer them? And what do those answers tell us about the world we live in?



            Read more
          



Week One: Introduction to Data

Why study statistics?
Variables and data
Getting to know R and RStudio

Week Two: Sampling

Why study statistics?
The sampling distribution
Central limit theorem
Confidence intervals

Week Three: Hypothesis Testing (One and Two Group Means)

What makes a hypothesis test?
Errors in testing
Alpha and critical values
Single sample test
Independent t-test and Dependent t-test

Week Four: Hypothesis Testing (Categorical Data)

The chi-square test
Goodness-of-Fit
Test-of-Independence

Week Five: Hypothesis Testing (More Than Two Group Means)

The ANOVA
One-way ANOVA
Two-way ANOVA

Week Six: Hypothesis Testing (Quantitative data)

Correlation
Simple (single variable) regression
Multiple regression",Foundations of Data Analysis - Part 2: Inferential Statistics
https://www.classcentral.com/course/edx-from-goddard-to-apollo-the-history-of-rockets-part-1-5047,"Learn about one of the greatest engineering efforts in human history: NASA’s Project Apollo and the space race to put a man on the moon.
Apollo 11 landed on the moon in 1969, just eleven years after the first successful satellite launch (_Sputnik _in 1957) and forty-three years after Robert Goddard’s launch of the world’s first liquid fueled rocket. But the history of rocket development actually can be traced back more than 2,000 years to the experiments of Archytas, an ancient Greek Philosopher.
This aerospace history course will take you back in time and trace the many developments in technology that transformed rockets from celebratory accouterments to weapons and finally to launchpads for human space travel. It is a story of technology, but ultimately the emphasis on this course is about people. Some are very well-known, but others not so.
You will learn how the Chinese introduced rockets as weapons, how early experimenters succeeded through trial and error, how scientific advancement provided the foundation for rocket development and space travel, and how rocket use spread throughout the world prior to the modern era. Finally, you will be introduced to the contributions of rocket pioneers such as Tsiolkovsky, Oberth and Goddard who dreamed of and paved the way for space travel. The course culminates with an introduction of German rocket development in the early 1930s and the emergence the genius rocket engineer Wehner von Braun. 
Verified students are eligible to earn Continuing Education Units (CEUs) and Professional Development Hours (PDHs), valid toward continuing education requirements for many professional certifications.



            Read more
          



Module 1: Fireworks and Weapons 
Introduction to early rocket development, the first rocket pioneers and how rockets evolved from fireworks to weapons. The lesson covers early technological development, how the advancement of science influenced rocket design and the introduction of rockets to the United States.
 Module 2: Rockets for War and Fiction 
Introduction to the proliferation of rockets around the world by the British and the integration of rockets into the US army prior to civil war. Focus is on the technological limitations of rockets that limited their military effectiveness and how fiction writers captured the imagination of the public and future rocket pioneers with dreams of space travel.
 Module 3: The Rocket Visionaries 
Introduction to the rocket visionaries Konstantin Eduardovich Tsiolkovsky, Robert Esnault-Pelterie and Hermann Oberth who were inspired by Jules Verne’s “From the Earth to the Moon” novel. The lesson reviews the contributions of these visionaries and describes how they were actually predictors for the rocket designs to follow.
 Module 4: The Rocket Builders 
Introduction to the two rocket builders considered the fathers of modern rocketry, Robert Goddard and Wernher von Braun. The lesson traces Goddard’s experiments and successes in launching liquid fueled rockets and his legacy on rocket development. Learn how von Braun, a budding rocket genius, comes to the attention of the German military and soon will lead a rocket program that is the precursor to the space age.","From Goddard to Apollo: The History of Rockets, Part 1"
https://www.classcentral.com/course/independent-foundations-of-machine-learning-13622,"Bloomberg presents ""Foundations of Machine Learning,"" a training course that was initially delivered internally to the company's software engineers as part of its ""Machine Learning EDU"" initiative. This course covers a wide variety of topics in machine learning and statistical modeling. The primary goal of the class is to help participants gain a deep understanding of the concepts, techniques and mathematical frameworks used by experts in machine learning. It is designed to make valuable machine learning skills more accessible to individuals with a strong math background, including software developers, experimental scientists, engineers and financial professionals.
The 30 lectures in the course are embedded below, but may also be viewed in this YouTube playlist. The course includes a complete set of homework assignments, each containing a theoretical element and implementation challenge with support code in Python, which is rapidly becoming the prevailing programming language for data science and machine learning in both academia and industry. This course also serves as a foundation on which more specialized courses and further independent study can build.
Please fill out this short online form to register for access to our course's Piazza discussion board. Applications are processed manually, so please be patient. You should receive an email directly from Piazza when you are registered. Common questions from this and previous editions of the course are posted in our FAQ.
The first lecture, Black Box Machine Learning, gives a quick start introduction to practical machine learning and only requires familiarity with basic programming concepts.
PREREQUISITES
The quickest way to see if the mathematics level of the course is for you is to take a look at this mathematics assessment, which is a preview of some of the math concepts that show up in the first part of the course.

Solid mathematical background, equivalent to a 1-semester undergraduate course in each of the following: linear algebra, multivariate differential calculus, probability theory, and statistics. The content of NYU's DS-GA-1002: Statistical and Mathematical Methodswould be more than sufficient, for example.
Python programming requiredfor most homework assignments.
Recommended:At least one advanced, proof-based mathematics course
Recommended:Computer science background up to a ""data structures and algorithms"" course




            Read more",Foundations of Machine Learning
https://www.classcentral.com/course/converter-circuits-5411,"This course can also be taken for academic credit as ECEA 5701, part of CU Boulder’s Master of Science in Electrical Engineering degree.

This course introduces more advanced concepts of switched-mode converter circuits. Realization of the power semiconductors in inverters or in converters having bidirectional power flow is explained. Power diodes, power MOSFETs, and IGBTs are explained, along with the origins of their switching times. Equivalent circuit models are refined to include the effects of switching loss. The discontinuous conduction mode is described and analyzed. A number of well-known converter circuit topologies are explored, including those with transformer isolation.

The homework assignments include a boost converter and an H-bridge inverter used in a grid-interfaced solar inverter system, as well as transformer-isolated forward and flyback converters.

After completing this course, you will:
●  Understand how to implement the power semiconductor devices in a switching converter
●  Understand the origins of the discontinuous conduction mode and be able to solve converters operating in DCM
●  Understand the basic dc-dc converter and dc-ac inverter circuits
●  Understand how to implement transformer isolation in a dc-dc converter, including the popular forward and flyback converter topologies

Completion of the first course Introduction to Power Electronics is the assumed prerequisite for this course.
      


            Read more
          



          Ch 4.1: Switch Realization
    -How to implement the switches using transistors and diodes, including applications having bidirectional power flow or ac outputs.

Ch 4.2: Power Semiconductor Switches
    -Basics of power semiconductor switches, including the origins of switching times and switching loss. How to incorporate switching loss into equivalent circuit models. MOSFETs, IGBTs, and gate driver considerations.

Ch 5: Discontinuous Conduction Mode
    -The discontinuous conduction mode (DCM) arising from unidirectional switch realization. Analysis of mode boundaries and output voltage.

Ch 6: Converter Circuits
    -Some well-known converter circuits and their origins. How to incorporate transformer isolation into a dc-dc converter. Analysis and equivalent circuit modeling of transformer-isolated converters.",Converter Circuits
https://www.classcentral.com/course/bacterial-genomes-bioinformatics-11201,"##
Join us in our quest to discover what makes microbes dangerous.  Use bioinformatics to probe genomes, to explore and represent DNA and protein sequences.  Then, use databases to find protein sequences’ conserved domains and investigate their functions.
The course will be of interest to undergraduates, post-graduates, researchers, bioinformaticians, biomedical researchers, microbiologists, healthcare professionals and all those who are interested in learning about the underlying mechanisms of bacterial disease, DNA sequences and protein data, or how to use online analytical tools to probe genomes.
The topics covered in this course are applicable to the genomes of all organisms. It is not essential to have previous knowledge or experience in bioinformatics. Scientific terminology is explained. The opportunity to use online computational tools in the context of bacterial genomes will also be of interest to teachers and their 16-18-year-old science and computing students.
No specific software, hardware, or other resources are required.",Bacterial Genomes: From DNA to Protein Function Using Bioinformatics
https://www.classcentral.com/course/research-proposal-initiating-research-9095,"Market Research is a growing and important field that is used in many industries around the world. Given all the data that is collected whether by organizations, industries, social media, governments, etc., it’s important that someone can review and sift through all the noise to provide valuable insights. And that’s where you come in as a market researcher. This course will only scratch the surface and provide you a foundational understanding of this field.

In this course, you will be able to define market research and identify some tools used in the industry. You will be able to discuss the importance of secondary and internal research in terms of the planning process. You will be able to define what primary research is and identify the various ways to conduct primary research. You will be able to focus on an actual research plan or proposal for your peer review project. You will be able to compose a response to a request for a proposal or research plan and be able to address the various components of the proposal and package it in a professional manner.
      


          Getting Started and Introduction to Market Research
    -In this module, you will be able to define what market research is and identify the tools that are used. You will be able to discuss the various motivations behind a research inquiry and what goes into a market research request. You will define the services, the roles and the qualities of a market researcher. You will also be able to identify constraints to help you ask the right questions. Finally, you will be able to respond to a market research proposal.


Secondary and Internal Research
    -In this module, you will be able to recognize the importance of secondary and internal research in the planning process. You will be able to assess the value and credibility of the secondary and internal data you have at your disposal. You will also be able to identify a starting point should a new client approach you. You will recognize the pros and cons of each method of research. And you will be able to budget appropriately and decide what type of market researcher you need or want to be for a given project.

Primary Research Introduction
    -In this module, you will be able to discuss various primary research methods for collecting data. You will be able to define what primary research is and be able to choose the appropriate method for your proposal. You will be able to consider various sampling and survey methods and even the less used observational method.

Research Plan or Proposal
    -In this module, you will be able to write a research proposal for a client. You will be able to recognize and take action when a proposal has been requested. You will be able to collect and compose the necessary proposal requirements and be able to professionally package your proposal. You will be able to apply strategies on how to follow-up with a client about your proposal and be able to take action when you are awarded the bid.",Research Proposal: Initiating Research
https://www.classcentral.com/course/arduino-7785,"For many years now, people have been improving their tools, studying the forces of nature and bringing them under control, using the energy of the nature to operate their machines. Last century is noted for the creation of machines which can operate other machines. Nowadays the creation of devices that interact with the physical world is available to anyone. 
Our course consists of a series of practical problems on making things that work independently: they make their own decisions, act, move, communicate with each other and people around, and control other devices. We will demonstrate how to assemble such devices and programme them using the Arduino platform as a basis.
After this course, you will be able to create devices that read the data about the external world with a variety of sensors, receive and forward this data to a PC, the Internet and mobile devices, and control indexing and the movement. The creation of such devices will involve design, the study of their components, the assemblage of circuit boards, coding and diagnostics. Along with the creation of the devices themselves, you will perform visualization on a PC, create a web page that will demonstrate one of your devices, and figure out how an FDM 3D-printer is configured and how it functions.   
Besides those keen on robotics or looking to broaden their horizons and develop their skills, the course will also be useful to anyone facing the task of home and industrial automation, as well as to anyone engaged in industrial design, advertising and art. 
The course does not require any special knowledge from the participants and is open even to students of upper secondary school. Programming skills and the level of English allowing to read technical documentation would be an advantage, but this is not obligatory.
The entire course is dedicated to practice, so the best way for you would be to get hold of some electronics, follow the illustrated examples and experiment on your own.

The kits can be purchased here: kits.cyberphysica.ru.

Taught by: Alexey Perepelkin, head of Robotics department in the Laboratory of innovative educational technologies at MIPT
Taught by: Dmitry Savitsky, researcher in the Laboratory of innovative educational technologies at MIPT
      


            Read more
          



          Week 1
    -Welcome to the course! During Week 1, we are going to introduce you to the course (go through the Introduction, that’s very important). Then we shall start our work: getting acquainted with Arduino, the development environment and our first components. You will learn how to assemble circuits on a breadboard and will write your first program and assemble your first device. Don’t forget about the DIY section, which is also very important

Week 2
    -It’s time to learn how to receive data with the help of sensors. During Week 2, we will teach you how to read off digital and analog signals, exchange data with a computer, create more complex algorithms, and use new output devices.

Week 3
    -During Week 3, you will learn to explore the world around you with the help of a distance sensor, and visualize data on a computer. You are also going improve your programming skills by creating a device with moving components. 

Week 4
    -After going through Week 4, you will be able to connect your device to a network, plan its creation beforehand , control heavy loads, and power your device correctly.

Week 5.
    -Let’s turn one wheel and then two wheels at once, and the robot car will start moving. It’ll be moving along the line or under your control. It could as well be just messing with your hand with which you are trying to control it. 

Week 6
    -Having learnt to create a step motor, you can create devices which can perform very precise actions. For example, a 3D printer, which we will study in detail and then use to print some components.",Building Arduino robots and devices
https://www.classcentral.com/course/compartsprocessing-1697,"In this 5-week course we’ll introduce the fundamentals of programming. This is the first part of a class which has been taught for seventeen years at Stony Brook University, and is an accessible introduction to combining arts and computing. The other two portions are Introduction to Computational Arts: Image Manipulation and Introduction to Computational Arts: Sound Art.For programming we’ll be using the free and open source programming language and integrated development environment, Processing. The course will provide the essentials of programming in a visual context, allowing you to visualize, design, and create generative art with Processing.You will complete both technical assignments and an artistic project, and learn how to participate in an aesthetic critique. We’ll cover the history of generative  art in the Twentieth and 21st Centuries to give context for your artistic endeavors.Peer review is integral to the success of this class; we will also teach you how to give constructive criticism. By the end of the 5 weeks you should have a strong foundation for how computers work and deal with data.Additionally, you’ll create an online portfolio of digital art projects, and be able to communicate ideas about art.  Each week you’ll watch two video series - one on the theory and one on the practice. There will be technical assignments and artistic projects which will be peer reviewed. We’re looking forward to working with you.



Introduction to Computational Arts: ProcessingJan 2014Consortium for Digital Arts & Technology (CDACT)Stony Brook University and CourseraCOURSE INFORMATION InstructorsDr. Margaret Schedel & Timothy VallierCourse DescriptionThis multidisciplinary production class serves as an introduction to, and exploration of electronic media in the arts. Lectures will cover concepts and presentations of artists working in various capacities with computers, as well as tutorials on specific software packages.PrerequisiteNo prerequisites or prior knowledge needed. Familiarity with computers is helpful but not necessary.Course RequirementsInternet connectionWindows or Apple computerAbility to install software on your machine (admin account)Processing software: http://processing.org/Digication e-Portfolio account (links and details will be provided) or other web-based sharing Course Learning Outcomes Learners who successfully complete this course will have learned the basic skills of Processing, Students will be learn to give critical feedback to their peers about technical and artistic matters through a grounding in the history of technology and the arts. A digital portfolio will showcase your work from this course.Outcomes:Understand the basics of computers, input and output devices, memory, and disks as demonstrated through quizzes and projectsNavigate file systems in Windows and Mac OS XDemonstrate creative/conceptual awareness of generative design through peer critiqueInstall and set-up a digital environment using Processing language.Generate and manipulate type, image and sound, incorporating principles of color, shape and gridsCreate a multi-media Processing Sketch and host on a websiteTextbook & Course MaterialsRequired Text  No required textsOptional Texts:PROCESSING: Generative Design: Visualize, Program, and Create with Processingby Hartmut Bohnacker (Author), Benedikt Gross (Author), Julia Laub (Author), Claudius Lazzeroni (Editor) ISBN-13: 978-1616890773 Publisher: Princeton Architectural PressWEB:HTML and CSS: Design and Build Websites by Jon Duckett ISBN-13: 978-1118008188Publisher: WileyGRADING POLICY & COURSE REQUIREMENTSGrading Assignments and your final project are graded through a peer-review process; quizzes are multiple-choice and are graded by the computer. Your work on the assignments, projects will be graded by your peers using unique rubrics for each task. Quizzes (5) 30%Assignments (4) 40%Project (1) 30 %Quizzes After watching each video lecture series, you will take a multiple choice quiz which will count towards your final grade. You can only take these quizzes ONCE. We are using this MOOC to flip the classroom and we do not give our students multiple chances.  There are also “in-video questions,” and you must answer these questions correctly in order to advance the video, but these questions are NOT graded, you can re-do the “in-video” quiz as many times as you need to.AssignmentsAssignments are purely technical; each module will include a detailed explanation of how to complete and grade each assignment. There will be one assignment (which may have multiple components)  every week that there is no project due.  Each assignment should take you no more than one hour.ProjectThe final project is both aesthetic and technical; there will be an explanation of how to grade the project but you must remember that art is subjective. You can expect the project to take at  least 4 hours to complete. Disclaimer: “The course schedule, policies, procedures, and assignments in this course are subject to change in the event of extenuating circumstances, by mutual agreement, and/or to ensure better student learning.” COURSE SCHEDULEWeek 1 Introduction to Computing and ProcessingWeek 2 Drawing in Processing: Arguments, Functions, and PrimitivesWeek 3 Dynamic Drawing: Code blocks, text, and loops.Week 4 External Input and Interactive SketchesWeek 5 Sound, Images, and Publishing",Introduction to Computational Arts: Processing
https://www.classcentral.com/course/edx-distributed-machine-learning-with-apache-spark-5851,"Machine learning aims to extract knowledge from data, relying on fundamental concepts in computer science, statistics, probability and optimization. Learning algorithms enable a wide range of applications, from everyday tasks such as product recommendations and spam filtering to bleeding edge applications like self-driving cars and personalized medicine. In the age of ‘big data’, with datasets rapidly growing in size and complexity and cloud computing becoming more pervasive, machine learning techniques are fast becoming a core component of large-scale data processing pipelines.
This statistics and data analysis course introduces the underlying statistical and algorithmic principles required to develop scalable real-world machine learning pipelines. We present an integrated view of data processing by highlighting the various components of these pipelines, including exploratory data analysis, feature extraction, supervised learning, and model evaluation. You will gain hands-on experience applying these principles using Spark, a cluster computing system well-suited for large-scale machine learning tasks, and its packages spark.ml and spark.mllib. You will implement distributed algorithms for fundamental statistical models (linear regression, logistic regression, principal component analysis) while tackling key problems from domains such as online advertising and cognitive neuroscience.",Distributed Machine Learning with Apache Spark
https://www.classcentral.com/course/uva-darden-bcg-pricing-strategy-practice-8353,"In this project-centered course, Darden's Ron Wilcox and BCG's Thomas Kohler will walk you through a real-world case, from problem statement to detailed analyses. You'll use all three lenses (cost, customer value, and competition) to recommend an optimal price—and then adjust to market disruptions. Utilizing the concepts, tools and techniques taught in previous Specialization courses—from basic techniques of economics to knowledge of customer segments, willingness to pay, and customer decision making to analysis of market prices, share, and industry dynamics—you will practice setting profit maximizing prices to improve price realization. You'll finish the course with a portfolio-building project that demonstrates your pricing prowess.
      


          Retail Market Dynamics
    -Welcome to the course! We'll kick off the week with an overview of the project, which centers around Philips introduction of an eco-friendly light bulb. Once you've read the case, Thomas and Ron will guide you as you apply the cost lens to analyze the economics of the LED light bulb Philips has introduced to the market. After you've analyzed the economics of the case, Ron and Thomas will debrief to make sure you are on the right track. You will also hear from BCG pricing experts, who will share their lessons and tips gleaned from years of helping clients in multiple industries optimize their prices and improve the bottom line. 

Customer Value and Conjoint Analysis
    -This week, we will dig deeper into customer value using conjoint analysis to determine the price sensitivity of consumers and businesses. Thomas and Ron will show you how to graph the conjoint data to easily compare these two markets--and you'll do additional analysis of the conjoint data to learn more about what consumers value. Using your analysis, you'll hone your pricing recommendation.

Price Recommendation
    -This week, you will pull everything together to make a pricing recommendation for Philips. You will recommend which markets they should serve (B2B, B2C, or both) and how they should price their LED bulbs. You'll learn how to lay out your thought process and rationale in a tightly edited slide deck that presents your recommendations in a compelling way.

Curveball
    -This week, you will respond to new developments in the LED light bulb market: a new competitor and new regulations. Just like in real life, you'll need to adjust your strategy when the competitive landscape changes and new regulations emerge and reconsider the retail marketplace and reevaluate the B2B market. You'll also head out into your own ""real world"" and do some detective work about the LED bulb market in your area and relate those finding to the case. We'll finish the course with BCG pricing experts sharing their insights into what makes pricing such a rewarding field.",Pricing Strategy in Practice
https://www.classcentral.com/course/nutrition-391,"This course covers the basics of normal nutrition for optimal health outcomes
    and evidence-based diets for a variety of diseases. Participants will learn
    the fundamentals of nutrition science and build upon these to explore emerging
    diet therapies, to analyze nutrition research and to plan well-balanced
    meals and dietary interventions for both healthy individuals and those
    with a number of diseases and health conditions. 
      


Module 1:         Introduction to Nutrition Science


 
If you are what you eat, you should probably know something about how
    to eat! In this introductory module, you will learn about the field of
    nutrition science, the basics of nutrition research and some important
    terms that will set the stage for the remainder of the class. This module
    ends with a global look at meal planning guides and tools and provides
    you with an opportunity to determine your own individual nutrient needs.
 
Module 2:         Heart Disease


 
Heart disease is the number one cause of death around the world. Your
    food choices make a difference when it comes to heart disease. This module
    we cover the risk factors for heart disease and explore different dietary
    avenues for the prevention and management of heart disease, hypertriglyceridemia,
    hypertension and stroke. Dietary foci include vegetarian diets, the DASH
    diet and the Mediterranean diet.
 
Module 3:         Diabetes


 
Globally, it is estimated that 438 million people – or roughly 8% of the
    world’s population – will have diabetes by 2030. This module looks at the
    role of nutrition in the prevention and management of pre-diabetes and
    Types 1, 2 and gestational diabetes. Additional topics include evidence-based
    recommendations for physical activity with diabetes, meal planning, carbohydrate
    counting and the roles of dietary fiber and the glycemic index in blood
    sugar control.
 
Module 4:         Cancer


 
Diet and cancer are certainly linked; but the degree to which food intake
    impacts the development and progression of cancer is still not entirely
    understood. We will look at the diet-related risk factors in cancer development
    as well as evidence-based guidelines for the nutritional management of
    cancer and treatment-related side effects. Additional emphasis is placed
    on emerging cancer nutrition research and debunking diet and cancer myths.
 
Module 5:         Obesity and Weight Management


 
Global statistics for obesity did not exist 50 years ago. Now, you can’t
    turn around without exploding obesity statistics smacking you in the face!
    We will explore the complex and interrelated factors that contribute to
    rising obesity rates, discuss various approaches to weight loss and weight
    maintenance and strategize for future solutions to this global epidemic.
 
Module 6:         Disorders of the GI Tract


 
A healthy digestive tract is crucial for optimal nutrition status. Impairments
    in any segment of the gastrointestinal (GI) tract can quickly undermine
    proper nutrient digestion, absorption and utilization. In this module we
    will look at how a healthy gut should work, and what to do when the digestive
    process is disrupted. Specific GI focus areas include celiac disease and
    gluten free foods, diverticular disease, peptic ulcer disease, inflammatory
    bowel disease, dysphagia, gas, constipation and malabsorptive disorders
    and look at the roles of dietary fiber and probiotics and prebiotics in
    gut health.",Nutrition for Health Promotion and Disease Prevention
https://www.classcentral.com/course/iversity-digital-and-social-media-marketing-3849,"With budgets for digital marketing constantly growing, organisations are facing a major skills shortage. The need for individuals who understand business combined with technical knowledge in Digital Marketing has never been greater. This course is based on European case studies showing current digital and social media marketing practices across Europe. Europe is one of the largest regions for digital and social marketing used but there are many local preferences and this course will help you to navigate these complexities. This course combines practical skills and theoretical knowledge with the goal of teaching you the skills to improve digital and social media marketing in organisations.



1. Why is Digital and Social Media Marketing important today and in the future?1.1. Introduction to strategic planning1.2 SWOT analysis1.3. Developing SMART objectives for strategy and campaigns1.4. Digital Business Maturity Model1.5. The consumer journey to online purchase1.6. Introduction to core concepts and technologies of digital and social media marketing1.7. Introduction to online branding
2. Understanding the different nature of digital channels based on geographic, demographic and digital fit for a campaign2.1 Search Engines - differences in countries - based on the case study examples2.2 Social Media platforms differences in countries and how to they can be used2.3 Email marketing and how it can be used2.4 Affiliate marketing and how it can be used2.5 Mobile marketing and how it could be used2.6 Paid channels overview - search and social2.7 Communities focused engagement
3. Buyer persona development3.1 The importance of understanding who the target audience is and how search and social help to develop this understanding3.2 Planning integration of search and social media3.3 Keyword research for buyer persona3.4 Social media channels for buyer persona3.5 Develop keyword plan for a campaign3.6 PPC keyword vs organic keyword plan3.7 Develop social media editorial calendar
4. How campaigns fit into a wider implementation of the overall organisation strategy4.1 Example company campaign plan4.2 Key elements of campaign management - Gantt chart4.3 Risk management4.4 Digital project management tools and techniques4.5 Project plan monitoring and review4.6 Marketing automation4.7 PPC campaign planning
5. Choosing the right digital profiles for the right audience5.1 Facebook5.2 YouTube5.3 Twitter5.4 LinkedIn5.5 PPC optimisation5.6 What makes content to go Viral?5.7 How to create content viral?
6. The importance of ongoing monitoring and learning from your engagement6.1 Understanding of Social Capital and its importance case study6.2 Accessing data in Google Analytics6.3 Accessing data from Facebook6.4 Accessing data from Twitter6.5 Using spreadsheets to analyse and populate reports6.6 Learning from digital results6.7 PPC report",Digital and Social Media Marketing
https://www.classcentral.com/course/sas-statistics-13367,"This introductory course is for SAS software users who perform statistical analyses using SAS/STAT software. The focus is on t tests, ANOVA, and linear regression, and includes a brief introduction to logistic regression.
      


          Course Overview and Data Setup
    -In this module you learn about the course and the data you analyze in this course. Then you set up the data you need to do the practices in the course. 

Introduction and Review of Concepts
    -In this module you learn about the models required to analyze different types of data and the difference between explanatory vs predictive modeling. Then you review fundamental statistical concepts, such as the sampling distribution of a mean, hypothesis testing, p-values, and confidence intervals. After reviewing these concepts, you apply one-sample and two-sample t tests to data to confirm or reject preconceived hypotheses.

ANOVA and Regression
    -In this module you learn to use graphical tools that can help determine which predictors are likely or unlikely to be useful. Then you learn to augment these graphical explorations with correlation analyses that describe linear relationships between potential predictors and our response variable. After you determine potential predictors, tools like ANOVA and regression help you assess the quality of the relationship between the response and predictors.

More Complex Linear Models
    -In this module you expand the one-way ANOVA model to a two-factor analysis of variance and then extend simple linear regression to multiple regression with two predictors. After you understand the concepts of two-way ANOVA and multiple linear regression with two predictors, you'll have the skills to fit and interpret models with many variables.

Model Building and Effect Selection
    -In this module you explore several tools for model selection. These tools help limit the number of candidate models so that you can choose an appropriate model that's based on your expertise and research priorities.

Model Post-Fitting for Inference
    -In this module you learn to verify the assumptions of the model and diagnose problems that you encounter in linear regression. You learn to examine residuals, identify outliers that are numerically distant from the bulk of the data, and identify influential observations that unduly affect the regression model. Finally, you learn to diagnose collinearity to avoid inflated standard errors and parameter instability in the model.

Model Building for Scoring and Prediction
    -In this module you learn how to transition from inferential statistics to predictive modeling. Instead of using p-values, you learn about assessing models using honest assessment. After you choose the best performing model, you learn about ways to deploy the model to predict new data.

Categorical Data Analysis
    -In this module you look for associations between predictors and a binary response using hypothesis tests. Then you build a logistic regression model and learn about how to characterize the relationship between the response and predictors. Finally, you learn how to use logistic regression to build a model, or classifier, to predict unknown cases.",Statistics with SAS
https://www.classcentral.com/course/edx-batteries-fuel-cells-and-their-role-in-modern-society-9383,"In today's world, we see game-changing movements in transportation and energy markets. A better understanding of the processes involved can help you to find your own role in these incipient shifts and take advantage of monumental changes down the road. 
This course is an elementary introduction to batteries and fuel cell, the cornerstone of electromobility and renewable energy, the main drivers of sustainable development. Learning the lessons of history, understanding the main driving forces, and gaining the basic knowledge of the key technologies will build your basic all-around comprehension of the subject. 
This course aims tobridgescience and society. For students focused on science, it will help illustrate the demands of society and industry. For learners from industry, business, or from generalist backgrounds, it will be the lucid introduction to the subject. 
The short course will not make you an expert in batteries, fuels cells, and electric vehicles, but will help you incommunicating with scientists and engineers and make your further education (or self-education) more productive. The main focus of the course is on batteries - namely, lithium-ion batteries - and electric vehicles as the key market.



Week 1. History of electric vehicles
1.1. Lessons of history. EV dawn
1.2. Lessons of history. EV falling down
1.3. Lessons of history. EV oblivion
1.4. Technical remark. How electric vehicle beats gasoline car
1.5.Supporting materials. EV vs. gasoline cars in winter
1.6.Nowadays. EV revival? 
Week 2. EV revival or why governments care so much about EVs and clean energy
2.1. EV revival. Ecology - air pollution
2.2. EV revival. Ecology – well-to-wheel pollutions
2.3. EV revival. Politics
2.4. EV revival. Economics
2.5. EV revival. Age of electricity
2.6. Important remark. How clean are EVs
2.7. You may be interested. Peak oil 
Week 3. Engineering. Electric Vehicles and batteries
3.1. EV and hybrids. Classification and how it works
3.2. Choosing the battery you need. Five main characteristics
3.3. Electric buses. Two solutions
3.4. Electric trucks, ships, aircraft
3.5. Related technology. Wheel-hub-motors or how to make car waltzing
3.6. Related technology. Wireless charging
3.7. Related technology. Autonomous driving
3.8. Battery producers 
Week 4. Science. Chemical power sources
4.1. Brief history of electrochemistry
4.2. Basic principles of batteries and fuel cells
4.3. Fuel cells. Motivation
4.4. Fuel cells. Classification
4.5. Fuel cells. Comparison
4.6. Fuel cells. More details
4.7. Energy sources and energy storage 
Week 5. Science. Different types of batteries
5.1. Lead acid batteries
5.2. NiCd, NiMH, NiFe
5.3. Li-ion batteries
5.4. Conventional and all-solid-state lithium-ion batteries 
Week 6. Electrode materials for lithium-ion batteries
6.1. Positive electrode materials. Layered LCO, NMC, NCA and others
6.2. Positive electrode materials. Olivine LFP and others
6.3. Positive electrode materials. Spinel LMO, LNMO and others
6.5. Negative electrode materials. Carbon based material
6.6. Negative electrode materials. Spinel LTO
6.8. What is next?","Batteries, Fuel Cells, and their Role in Modern Society"
https://www.classcentral.com/course/music-ensembles-731,"Learn and practice the basic principles of running an effective music ensemble rehearsal.  Techniques and strategies are applicable to a variety of ensembles, including bands, orchestras, choirs, and chamber groups.
      


          An Introduction to Rehearsing
    -This week, Module 1, we’ll discuss basic philosophical issues such as: What we do in rehearsals, what skills are needed, and the idea of the conductor as “the composer’s advocate.” I will also introduce the concept of Macro-Micro-Macro, which serves as the overarching principle of rehearsals. Then we will move on to basic conducting technique.

Communicating with the Ensemble
    -Module 2 begins with a discussion about repertoire: how to define quality music and how to choose a balanced, musically nourishing program. Building on the topics of Module 1, this week’s conducting technique videos focus on the grammar for starting and stopping pieces. In the rehearsal technique videos, the overarching topic is how to communicate with the ensemble to convey musical intent. Essentially, the idea is to give musical instruction, but there are a range of strategies we must master to be effective in all situations.This week introduces those strategies and organizes them according to modes of instruction, including performance technique, adjectives, analogy, and modeling.

Introducing the Rehearsal Toolkit
    -Week 3’s material begins with more left hand technique, expanding on the concepts introduced in Module 2 and continuing with gestures to show dynamics. The section on rehearsal technique begins with an explanation of the ‘Rehearsal Toolkit,” a collection of ideas, or “tools,” each designed to fix a musical issue. Rehearsal tools are meant to supplement the modes of instruction that were discussed last week. In other words, in addition to using direct vocabulary, modeling, and metaphor and analogy, these tools can elicit musical responses when gesture and words fail. A caveat: all of these approaches depend on the musicians having the technique required to perform the repertoire. This may seem obvious, but the fanciest baton twirl and colorful analogy are meaningless to help, say, a trumpeter, perform staccato if he does not tongue properly and employ good embouchure. Fundamentals must be taught, either in or out of the rehearsal, and the appropriate method depends on the level and age of the musician in the ensemble.Module 3 concludes with multi-purpose tools, including singing and “bopping.” These are the Swiss-Army knives of rehearsal technique, each useful for a variety of issues, from articulation to balance to rhythm. As you acquire the tools discussed in this module, also consider what else you can put in your toolbox. What techniques do you currently use? What tools can you borrow from other musicians? The more options we have in rehearsal the more likely we will be to solve a musical problem.

Articulation, Balance, and Tone
    -Module 4 begins with perhaps the most crucial task a conductor undertakes: score study. Score study is the umbrella term for the process of thoroughly learning a score-- not just knowing how to sing the melody or memorizing phrases and meters--but learning every aspect of the music that may come to bear on our ability to interpret, conduct, rehearse, and perform it. Unlike many grammatical aspects of conducting, score study is a time-consuming, immersive activity for which it is normal to develop one’s own process, assuming the end result is a deep understanding of the work.

After score study, Module 4 moves back to the grammar of conducting, particularly technique for conducting articulations. Please note that this week also contains a very brief introduction to the three types of fermatas. In Module 5 we’ll cover them in detail. These are topics for which regular practice and self-evaluation will be necessary to develop gestures that are clear to the ensemble and second-nature to the conductor.

Finally, we will return to “The Rehearsal Toolkit” and explore strategies for rehearsing articulation, balance, and tone. This final topic includes a video on using the piano to demonstrate harmonies and other musical features to the ensemble. Particularly in educational settings, it is important for the conductor to do more than treat the ensemble as his personal musical instrument. Instead, find opportunities to lead ensembles to an understanding of the music it is performing, a goal that only score study makes possible.

Phrasing
    -Module 5 begins with a discussion about score marking, a topic that is controversial by some ways of thinking. One school of thought suggests that scores should never be marked with cues and other information, since doing so reflects a deficit in score study on the piece. Another school believes that judicious marking enhances our efficiency in rehearsal and allows for better connection with the ensemble. This module also includes detailed explanations of the three types of fermatas that were introduced in Module 4: caesura, release-in-tempo, and continuation. It is worth spending extra time on these techniques, as the skills involved in preparing, sustaining, and releasing each one apply to a variety of conducting situations, including cues, rubato, and accompanimental conducting. For rehearsal strategies and the rehearsal toolkit our topics are phrasing and dynamics. As with many other topics in this class we can only touch the surface in terms of depth, but I hope there will be a few ideas to begin filling your rehearsal toolkit.

Accompanimental Conducting and Intonation
    -Module 6 (our final week!) begins with a brief discussion about planning rehearsals, moves to techniques for accompanimental conducting, and then dips into the Rehearsal Toolkit for intonation strategies. The intonation section includes an introduction to overtones, harmonics, and temperaments. These are acoustic concepts for which at least a basic understanding is useful for knowing how to achieve good pitch. It’s a fascinating topic, and a great example of how we can apply science to art. The final few videos cover a miscellanea of rehearsal topics, including protecting one’s ears, the use of a podium, and set-up issues.",Fundamentals of Rehearsing Music Ensembles
https://www.classcentral.com/course/teach-impacts-technology-global-society-11236,"In this course you’ll focus on how technology-enabled communication is changing geopolitics and, more broadly, how technology is connecting our world and changing lives. This will be done through a series of paired teaching sections, exploring a specific “Impact of Computing” in your typical day and the “Technologies and Computing Concepts” that enable that impact, all at a K12-appropriate level. 

This course is part of a larger Specialization through which you’ll learn impacts of computing concepts you need to know, organized into 5 distinct digital “worlds”, as well as learn pedagogical techniques and evaluate lesson plans and resources to utilize in your classroom. By the end, you’ll be prepared to teach pre-college learners to be both savvy and effective participants in their digital world.

In this particular digital world (global society), you’ll explore the following Impacts & Technology pairs --

Impacts (Freedom of Speech): Internet in third world countries, censorship, and social media
Technology and Computing Concepts: VPN, how Internet censorship works, metadata, tor

Impacts (Life Made Easy): Internet changing the way we live, travel, autonomous vehicles 
Technology and Computing Concepts: Internet of things, how self-driving cars work 

Impacts (Keeping Your Information Secure): two-factor authentication, PINs, Patterns, fingerprints, apple ID
Technology and Computing Concepts: DDoS attacks and Botnets, man-in-the-middle attacks, dangers of public Wifi, phishing, ransomware, bitcoin

In the pedagogy section for this course, in which best practices for teaching computing concepts are explored, you’ll learn about the principles of the computer science advanced placement exam, how it assesses students, and how to prepare your students for this critical exam. 

In terms of CSTA K-12 computer science standards, we’ll primarily cover learning objectives within the “impacts of computing” concept, while also including some within the “networks and the Internet” concepts and the “data and analysis” concept.  Practices we cover include “fostering and inclusive computing culture”, “recognizing and defining computational problems”, and “communicating about computing”.
      


            Read more
          



          Course Orientation
    -Welcome!  Are you interested in teaching about the impacts of the technology you use everyday?  To learn more about the computation and computing concepts that underlie those technologies?  We'll be using a problem-based approach to explore interesting ways to teach concepts of networks and the internet, data and analysis, and even algorithms and data representation.  Finally, we'll evaluate, critique and improve a TedED activity around the ethical choices facing designers of self-driving cars.

Freedom of Speech
    -Have you ever thoughts of technology as a support or amplification of free speech?  No need to get a news program or journalist to ""get your story out there"" when you can tweet!  But not everyone on the planet has equal access to the internet or apps that enable people to share their viewpoints.  We'll look at a range of technologies related (in some way!) to this including:  VPN, cell phone batteries, and internet connectivity at the global scale.

Life Made Easy
    -How has technology made your life easier?  One thing I love is that travel, including traveling outside of my home country has gotten a LOT easier -- just because I can use my smartphone to find information and directions when I am abroad!  But there's other ways global, ubiquitous access to the internet and cheap computational devices is changing our lives.  Super hot things right now are ""the Internet of Things"" -- and specifically self-driving cars.  Let's learn more about them!

Keeping your Information Secure
    -As our individual data generation and collection grows, so does the collective amount of data stored in the world.  Controlling access and maintaining the privacy of our data -- especially as we use our myriad of devices in places far outside our own homes over wireless connections -- is critical.  We'll also toss in here the concept of having a secure form of money -- bitcoin!

Impacts of Computing & Pedagogy",Teaching Impacts of Technology: Global Society
https://www.classcentral.com/course/golang-getting-started-12046,"Learn the basics of Go, an open source programming language originally developed by a team at Google and enhanced by many contributors from the open source community. This course is designed for individuals with previous programming experience using such languages as C, Python, or Java, and covers the fundamental elements of Go. Topics include data types, protocols, formats, and writing code that incorporates RFCs and JSON. Most importantly, you’ll have a chance to practice writing Go programs and receive feedback from your peers. Upon completing this course, you'll be able to implement simple Go programs, which will prepare you for subsequent study at a more advanced level.
      


          Introduction to the Specialization

Introduction to the Course
    -Learn the basics of Go, an open source programming language originally developed by a team at Google and enhanced by many contributors from the open source community. This is the first in a series of three courses comprising the Programming with Google Go specialization. It is designed for individuals with previous programming experience using such languages as C, Python, or Java, and covers the fundamental elements of Go. Topics include data types, protocols, formats, and writing code that incorporates RFCs and JSON. Most importantly, you’ll have a chance to practice writing Go programs and receive feedback from your peers. Upon completing this course, you’ll be able to implement simple Go programs, which will prepare you for the remaining two courses in this specialization: Functions, Methods, and Interfaces in Go and Concurrency in Go. 

Module 1: Getting Started with Go
    -This first module gets you started with Go. You'll learn about the advantages of using Go and begin exploring the language's features. Midway through the module, you’ll take a break from ""theory"" and install the Go programming environment on your computer. At the end of the module, you'll write a simple program that displays “Hello, World” on your screen.

Module 2: Basic Data Types
    -Now that you’ve set up your programming environment and written a test program, you’re ready to dive into data types. This module introduces data types in Go and gives you practice writing routines that manipulate different kinds of data objects, including floating-point numbers and strings.

Module 3: Composite Data Types
    -At this point, we’re ready to move into more complex data types, including arrays, slices, maps, and structs. As in the previous module, you’ll have a chance to practice writing code that makes use of these data types.

Module 4: Protocols and Formats
    -This final module of the course introduces the use of remote function calls (RFCs) and JavaScript Object Notation (JSON) in Go. You’ll learn how to access and manipulate data from external files, and have an opportunity to write several routines using Go that exercise this functionality.",Getting Started with Go
https://www.classcentral.com/course/teach-impacts-technology-fundamentals-11238,"In this course you’ll focus on the fundamentals of teaching the impacts of technology, starting by exploring how you interact with and benefit from technology in a typical 24 hour period, such as the desire for instant food and entertainment. This will be done through a series of paired teaching sections, exploring a specific “Impact of Computing” in your typical day and the “Technologies and Computing Concepts” that enable that impact, all at a K12-appropriate level. 

This course is part of a larger Specialization through which you’ll learn impacts of computing concepts you need to know, organized into 5 distinct digital ""worlds”, as well as learn pedagogical techniques and evaluate lesson plans and resources to utilize in your classroom. By the end, you’ll be prepared to teach pre-college learners to be both savvy and effective participants in their digital world.

In this particular digital world (daily life), you’ll explore the following Impacts & Technology pairs --

Impacts (Food Delivery): Apps that bring you food, drivers, and find and recommend businesses
Technologies and Computing Concepts: Geolocation, Push Notifications, Near Field Communications, HMTL5, GPS, Graph representations, Minimal Spanning Trees, Shortest Path Algorithms

Impacts (Entertainment): Streaming for entertainment and education, Environmental impact of Internet, YouTube culture
Technologies and Computing Concepts: Data Centers, Downloading vs Streaming, Digital vs. Analog image representation, basic compression algorithms, Internet metrics (latency, bandwidth)

In the pedagogy section for this course, in which best practices for teaching computing concepts are explored, you’ll learn to employ constructivist activities useful in teaching impacts of computing and to evaluate and contribute to an unplugged lesson plan. 

In terms of CSTA K-12 computer science standards, we’ll primarily cover learning objectives within the “impacts of computing” concept, while also including some within the “networks and the Internet” concepts and the “data and analysis” concept.  Practices we cover include “fostering and inclusive computing culture”, “recognizing and defining computational problems”, and “communicating about computing”.
      


            Read more
          



          Course Orientation
    -Welcome!  Are you interested in teaching about the impacts of the technology you use everyday?  To learn more about the computation and computing concepts that underlie those technologies?  We'll be using a problem-based approach to explore interesting ways to teach concepts of networks and the internet, data and analysis, and even algorithms and data representation.  Finally, we'll evaluate, critique and improve/personalize an ""unplugged activity"" where students learn how to create the minimal network needed to provide connectivity amongst a set of houses.  This activity can be scaled for use in grade levels from 4th grade to 12th grade.

Technology: Bring Me Some Food!
    -How do you interact with and benefit from technology in a 24 hour period?  We'll ask you to track your technology use and reflect on its costs and benefits to you.  We'll also start by looking at a problem many people might have in a given 24 hour period -- being hungry and wanting someone to bring them some food!  We'll explore several smartphone apps related to this including doordash, yelp, and lyft.

I want my entertainment... NOW!
    -Streaming media has had huge impacts not only on consumer choice, but on who is enabled to produce digital media -- be it entertainment or education. Then we'll look at some of the limitations and possible new advances in this area.

Impacts of Computing and Pedagogy
    -This week our work falls into 2 categories.  The impacts computing has had on our lives so far may not be the entire story.  The CSTA K-12 standards focus a lot on having students not only look at the past, but consider impacts of future advances.  Second, we reflect on core constructivist learning theory -- but with a specific focus on teaching computing concepts.

Lesson Plans
    -We'll evaluate a ""CS Unplugged"" lesson plan that supports students in learning how to represent real world map/travel representations in a graph.  This lesson plan extends upon the ""Paving a Muddy City"" online simulator you used earlier in the course.  We'll walk through a revised lesson plan and ask you to help improve it by added vocabulary and assessment items.  You'll be able to contribute to and access a crowdsources set of resources created by other learners in this class!",Teaching Impacts of Technology: Fundamentals
https://www.classcentral.com/course/bioinformatics-5661,"##
This free online course aims to raise awareness amongst healthcare professionals of the role of Clinical Bioinformatics  and Genomics in healthcare today. We will illustrate how the discipline of Clinical Bioinformatics provides an important bridge between the cutting edge science and the delivery of genomic medicine in clinical practice. By understanding the role of a Clinical Bioinformatician it will become clear how integral they are to ensuring the beneficial opportunities of genomic medicine are fully realised in patient care.
Discover the potential of Clinical Bioinformatics
This is an exciting time. We are now beginning to sequence whole genomes in the clinic, the most personal information we can have on a patient. We can start to see how genome variants might impact on health and we can direct really precise medicine to individual patients. This is not without its challenges. The genome is a huge amount of information. Identifying the causative variant (the part in the genome that can cause a change in health) is like looking for a needle in a haystack. But what does this phrase actually mean? This course will take you into the world of a Clinical Bioinformatician and show you what they do behind the scenes when finding that needle in the genomic data. It will also show you what happens next and the important contribution Clinical Bioinformatician’s make to the patient’s journey.
Explore the methods of Clinical Bioinformatics
Clinical Bioinformatics involves tools and technologies which require a certain set of skills and expertise. Using next generation sequencing techniques and data analysis allows the bioinformatician to filter and classify the information from the human genome. The course will bring these methods and processes to life using case studies, interviews with bioinformaticians and a host of activities to help you understand the basics of Clinical Bioinformatics.
Investigate the role of Clinical Bioinformatics in healthcare
The role of clinical bioinformatics can be seen as providing a link between computer science and biology and so involves tools and technologies which require specific skills and expertise. Using Next Generation Sequencing (NGS) techniques and data analysis bioinformaticians and clinical scientists can identify, filter and classify variants found in the human genome linked with genetic disease.  This course will bring these methods and processes to life using case studies, interviews with bioinformaticians and a host of activities to help you understand the role and its importance in genomic healthcare. You will also be able to see the benefits and the challenges to clinical bioinformatics in regards to wider ethical issues like those relating to data management - we’ll be asking questions about how patient data is stored and who has access to it.
Continuing Professional Development
On this course you there is an opportunity to purchase a Statement of Participation that will provide both a physical and digital record of your participation. You might find this useful for demonstrating evidence of informal Continuing Professional Development (CPD), commitment to your career, or of your awareness of the issues in a particular subject.
This course is aimed at current healthcare professionals, who are interested in learning more about the role of clinical bioinformatics and will also be applicable to people with an interest in the application of genomics in healthcare.
It is not essential to have previous experience or knowledge of bioinformatics or genomics although medical terminology is used and the course is designed to be applicable to practising healthcare professionals.



            Read more",Clinical Bioinformatics: Unlocking Genomics in Healthcare
https://www.classcentral.com/course/neurohacking-6420,"Neurohacking describes how to use the R programming language (https://cran.r-project.org/) and its associated package to perform manipulation, processing, and analysis of neuroimaging data. We focus on publicly-available structural magnetic resonance imaging (MRI). We discuss concepts such as inhomogeneity correction, image registration, and image visualization.

By the end of this course, you will be able to:

Read/write images of the brain in the NIfTI (Neuroimaging Informatics Technology Initiative) format
Visualize and explore these images
Perform inhomogeneity correction, brain extraction, and image registration (within a subject and to a template).
      


          Introduction

Neuroimaging: Formats and Visualization
    -In this section, we will discuss different formats that brain images come in, as well as some of the commonly done magnetic resonance imaging (MRI) scans.

Image Processing
    -In this section, we will discuss the steps done to process brain MRI data.  We will discuss inhomogeneity correction, brain extraction or skull stripping, and various image registration techniques.

Extended Image Processing
    -In this section, we will discuss the different types of registration and how one would go through processing a multi-sequence MRI scan, as well as wrapper functions that make the process much easier.  We also cover interactive exploration of brain image data and tissue-level (white/gray matter and cerebrospinal fluid (CSF)) segmentation from a T1-weighted image.",Introduction to Neurohacking In R
https://www.classcentral.com/course/logistic-regression-r-public-health-13075,"Welcome to Logistic Regression in R for Public Health! 

Why logistic regression for public health rather than just logistic regression? Well, there are some particular considerations for every data set, and public health data sets have particular features that need special attention. In a word, they're messy. Like the others in the series, this is a hands-on course, giving you plenty of practice with R on real-life, messy data, with predicting who has diabetes from a set of patient characteristics as the worked example for this course. Additionally, the interpretation of the outputs from the regression model can differ depending on the perspective that you take, and public health doesn’t just take the perspective of an individual patient but must also consider the population angle. That said, much of what is covered in this course is true for logistic regression when applied to any data set, so you will be able to apply the principles of this course to logistic regression more broadly too. 

By the end of this course, you will be able to: 
Explain when it is valid to use logistic regression 
Define odds and odds ratios 
Run simple and multiple logistic regression analysis in R and interpret the output 
Evaluate the model assumptions for multiple logistic regression in R 
Describe and compare some common ways to choose a multiple regression model 

This course builds on skills such as hypothesis testing, p values, and how to use R, which are covered in the first two courses of the Statistics for Public Health specialisation. If you are unfamiliar with these skills, we suggest you review Statistical Thinking for Public Health and Linear Regression for Public Health before beginning this course. If you are already familiar with these skills, we are confident that you will enjoy furthering your knowledge and skills in Statistics for Public Health: Logistic Regression for Public Health. 

We hope you enjoy the course!
      


            Read more
          



          Introduction to Logistic Regression
    -Welcome to Statistics for Public Health: Logistic Regression for Public Health! In this week, you will be introduced to logistic regression and its uses in public health. We will focus on why linear regression does not work with binary outcomes and on odds and odds ratios, and you will finish the week by practising your new skills. By the end of this week, you will be able to explain when it is valid to use logistic regression, and define odds and odds ratios. Good luck!

Logistic Regression in R
    -In this week, you will learn how to prepare data for logistic regression, how to describe data in R, how to run a simple logistic regression model in R, and how to interpret the output. You will also have the opportunity to practise your new skills. By the end of this week, you will be able to run simple logistic regression analysis in R and interpret the output. Good luck! 

Running Multiple Logistic Regression in R
    -Now that you're happy with including one predictor in the model, this week you'll learn how to run multiple logistic regression, including describing and preparing your data and running new logistic regression models. You will have the opportunity to practise your new skills. By the end of the week, you will be able to run multiple logistic regression analysis in R and interpret the output. Good luck!

Assessing Model Fit
    -Welcome to the final week of the course! In this week, you will learn how to assess model fit and model performance, how to avoid the problem of overfitting, and how to choose what variables from your data set should go into your multiple regression model. You will put all the skills you have learned throughout the course into practice. By the end of this week, you will be able to evaluate the model assumptions for multiple logistic regression in R, and describe and compare some common ways to choose a multiple regression model. Good luck!",Logistic Regression in R for Public Health
https://www.classcentral.com/course/an-introduction-to-cognitive-psychology-as-an-exp-14894,"Learn how to conduct, analyse and understand cognitive psychology experiments
Cognitive psychology is the scientific study of internal mental processes. On this course, you will be introduced to two key areas of cognitive psychology: reasoning and thinking and mental imagery.
You will explore cognitive psychology as an experimental science, as you consider the psychology of thinking and reasoning and the psychology of imagination and thinking visually. You will learn how to run an experiment, how to collect data, and understand the science behind memory and behaviour through experiments. You will also explore the effectiveness of experiments for the study of the mind.
This course is designed for anyone with an interest in the workings of the mind and how to study this through experiments.
This course will be of particular interest to those looking to study Psychology at university, and those thinking of applying to study degree level Psychology at the University of York.",Introduction to Cognitive Psychology: An Experimental Science
https://www.classcentral.com/course/managing-g-suite-14479,"Managing G Suite is the second course in the G Suite Administration Specialization.

This course focuses on the G Suite core services such as Gmail, Calendar, and Drive & Docs. You will become familiar with the various service settings, and learn how to enable them for all or just a subset of your users. You will gain an understanding of Google Vault, Google’s ediscovery service. You will understand the various admin console reports that are available and be able to search and filter the information in these reports. Finally you will see how multiple domains can be used with G Suite and learn how to add a new domain to your account.

Learning Objectives

By the end of this course participants will be able to:

- Enable and disable G Suite services for different parts of the organization.
- Configure common settings for G Suite core services such as Gmail, Calendar, and Drive and Docs.
- Understand the mobile device management options available in G Suite.
- Describe Google Vault and learn how to use it to retain, search and export your organization's data.
- Navigate and interpret G Suite admin reports and setup administrator alerts.
- Explain the basics of multi domain management within G Suite.

Prerequisites

You should have completed the first course in the series: Introduction to G Suite.
      


          Managing G Suite
    -This course focuses on the G Suite core services such as Gmail, Calendar, and Drive & Docs. You will become familiar with the various service settings, and learn how to enable them for all or just a subset of your users. You will gain an understanding of Google Vault, Google’s ediscovery service. You will understand the various admin console reports that are available and be able to search and filter the information in these reports. Finally you will see how multiple domains can be used with G Suite and learn how to add a new domain to your account.",Managing G Suite
https://www.classcentral.com/course/stepik-introduction-to-statistics-10543,"This course is designed to explain the fundamental of statistics. The course contains four weeks or four modules. The first module is devoted to the main concepts of statistics and data analysis. First of all we will introduce the concepts of sample, general population, descriptive statistics and normal distribution. At the end of the first module we will discuss the idea of statistical inference, one of the most important topics of our course. If you have just started to study statistics look more closely at the first week. All the lessons of the first module are extremely important to enable you to understand the rest of the course and more complicated concepts and methods of statistics. Each module contains lessons with short theoretical video lectures mixed with practical problems.
 



Introduction to Hypothesis Testing1.1 Introduction1.2 Sample and Population1.3 Types of Variables in Statistics1.4 Descriptive Statistics (Central Tendency Measures)1.5 Descriptive Statistics (Variance and Quantiles)1.6 Normal Distribution1.7 Central Limit Theorem1.8 Confidence Intervals1.9 Statistical Hypothesis Testing
Categorical Data Analysis2.1 Introduction. Categorical Data in Statistics2.2 Chi-Squared Distance2.3 Pearson Distribution, Degrees of Freedom and Chi-Squared Test2.4 Contingency Table Analysis2.5 P-value Calculation2.6 Fisher's Exact Test
T- test and Analysis of Variance3.1 Student's t-Distribution3.2 Student's t-Test3.3 One-Way ANOVA3.4 Post Hoc Analysis
Correlation and Linear Regression4.1 Definitions of Covariance and Correlation4.2 Simple Linear Regression. Least Squares. Residuals.4.3 Predictions from Linear Regression. Assumptions.4.4 Multiple Linear Regression",Introduction to Statistics
https://www.classcentral.com/course/essentials-global-health-7337,"Essentials of Global Health is a comprehensive introduction to global health. It is meant to introduce you to this topic in well-structured, clear and easy to understand ways. Much of the course will focus on five questions: What do people get sick, disabled and die from; Why do they suffer from these conditions? Which people are most affected? Why should we care about such concerns? What can be done to address key health issues, hopefully at least cost, as fast as possible, and in sustainable ways?  The course will be global in coverage but with a focus on low- and middle-income countries, the health of the poor, and health disparities. Particular attention will be paid throughout the course to health systems issues, the linkages between health and development, and health matters related to global interdependence. The course will cover key concepts and frameworks but be practical in orientation.

ESSENTIALS OF GLOBAL HEALTH WAS PRODUCED IN PART DUE TO THE GENEROUS FUNDING OF THE DAVID F. SWENSEN FUND FOR INNOVATION IN TEACHING.

-------------------------------------------------------------------------------------------------------------------------------------------------------

Course Learning Objectives

By the end of the course, learners should be able to:

•	Articulate key public health concepts related to global health;
•	Analyze the key issues in global health from a number of perspectives;	
•	Discuss with confidence the burden of disease in various regions of the world; how it varies by sex, age, and location; key risk factors for this burden; and how the disease burden can be addressed in cost-effective ways;
•	Assess key health disparities, especially as they relate to the health of low-income and marginalized people in low- and middle-income countries; 
•	Outline the key actors and organizations in global health and the manner in which they cooperate to address critical global health concerns;
•	Review key global health challenges that are likely to arise in the coming decades.


-------------------------------------------------------------------------------------------------------------------------------------------------------

Value Added of the Course

The course seeks to add special value by being comprehensive, by handling each  topic in a consistent framework, and by helping learners gain an understanding of well grounded approaches to assessing global health issues and what can be done to address them.


-------------------------------------------------------------------------------------------------------------------------------------------------------

The Readings and other materials for Essentials of Global Health

For almost every session of Essentials of Global Health, you will see: 

- Required readings
- Recommended readings
- Recommended videos

We have selected a small number of readings for each session that are central to understanding the content of the session. We have put these under “required readings”.

For each required reading, we have also indicated how carefully you should read the material and on what parts of the material you should focus your attention.

In addition, we have selected some additional readings that would be very helpful to your understanding the content of each session. 

The first is a textbook, Global Health 101, third edition. This is a comprehensive introductory textbook that closely follows the content of this Essentials of Global Health course. We have indicated for each session what part of the book you should read. Using this textbook can be very valuable to your mastering the content of the course.

The second set of “recommended readings” is some additional readings, mostly from journal articles and reports. For these, too, we have indicated how carefully you should read the material and on what parts of the material you should focus your attention.

Learners should note that to access articles from The Lancet they will have to register with the Lancet, if they do not have online access to a library that has The Lancet. Once they are registered, they will be able to sign into The Lancet and access all of its free articles.

We have also indicated for most sessions one or two videos that relate to the topic of the session. These are meant to help the learner get a better feel for the topic which is being covered. Most learners will find the videos brief, easy and enjoyable to watch, and very enlightening.
      


            Read more
          



          Module 1: Introduction
    -This module introduces you to the course, some of the basic concepts of global health, and a number of key perspectives for considering global health issues. This module will also introduce you to the key actors in global health and the different ways in which they are organized and function. 


Module 2: The Burden of Disease
    -Module 2 focuses on the “burden of disease”. It first examines the state of the world’s health. It then introduces you to key demographic factors and how they relate to global health. It concludes with several sessions that examine what people get sick, disabled and die from and to what risk factors and determinants these conditions can be attributed. 

Module 3: Health Systems and Value for Money in Health
    -Module 3 focuses on health systems. It first examines the notion of “value for money” in considering investments in health. It then reviews how health systems in different parts of the world are organized; some of the issues they face in effectively and efficiently providing appropriate services of acceptable quality; and what we are learning can be done to address those issues in cost-effective ways. 

Module 4: Cross-Cutting Themes in Global Health - Part I
    -Module 4 focuses on some of the most important cross-cutting themes in global health. These include the relationship between the environment and health, complex humanitarian emergencies and natural disasters and health, and nutrition and health. They also include an assessment of the health of women, children, and adolescents. A single session is devoted exclusively to childhood immunization.

Module 4: Cross-Cutting Themes in Global Health - Part II
    -Module 4 focuses on some of the most important cross-cutting themes in global health. These include the relationship between the environment and health, complex humanitarian emergencies and natural disasters and health, and nutrition and health. They also include an assessment of the health of women, children, and adolescents. A single session is devoted exclusively to childhood immunization.

Module 4: Cross-Cutting Themes in Global Health - Part III
    -Module 4 focuses on some of the most important cross-cutting themes in global health. These include the relationship between the environment and health, complex humanitarian emergencies and natural disasters and health, and nutrition and health. They also include an assessment of the health of women, children, and adolescents. A single session is devoted exclusively to childhood immunization.

Module 5: Critical Causes of Illness and Death - Part I
    -Module 5 focuses on critical causes of illness, disability, and death. It first examines  communicable diseases, such as emerging infectious diseases, HIV, TB, malaria, and the neglected tropical diseases. It then reviews key issues in noncommunicable diseases, such as heart disease, stroke, cancer, and diabetes. It concludes with a look at injuries. Each session examines the nature of the condition; its burden of disease; the determinants and risk factors for the condition; who is most affected by it; and what we have learned can be done to address the condition in cost-effective ways. 


Module 5: Critical Causes of Illness and Death - Part II
    -Module 5 focuses on critical causes of illness, disability, and death. It first examines  communicable diseases, such as emerging infectious diseases, HIV, TB, malaria, and the neglected tropical diseases. It then reviews key issues in noncommunicable diseases, such as heart disease, stroke, cancer, and diabetes. It concludes with a look at injuries. Each session examines the nature of the condition; its burden of disease; the determinants and risk factors for the condition; who is most affected by it; and what we have learned can be done to address the condition in cost-effective ways. 

Module 5: Critical Causes of Illness and Death - Part III
    -Module 5 focuses on critical causes of illness, disability, and death. It first examines  communicable diseases, such as emerging infectious diseases, HIV, TB, malaria, and the neglected tropical diseases. It then reviews key issues in noncommunicable diseases, such as heart disease, stroke, cancer, and diabetes. It concludes with a look at injuries. Each session examines the nature of the condition; its burden of disease; the determinants and risk factors for the condition; who is most affected by it; and what we have learned can be done to address the condition in cost-effective ways. 

Module 6: Looking Forward
    -Module 6 focuses on the likely global health challenges of the next few decades and how science and technology can be harnessed, though collective action, to address those challenges.",Essentials of Global Health
https://www.classcentral.com/course/averagedswitchmodelingandsimulation-19128,"This course can also be taken for academic credit as ECEA 5705, part of CU Boulder’s Master of Science in Electrical Engineering degree.

This is Course #1 in the Modeling and Control of Power Electronics course sequence. The course is focused on practical design-oriented modeling and control of pulse-width modulated switched mode power converters using analytical and simulation tools in time and frequency domains. A design-oriented analysis technique known as the Middlebrook's feedback theorem is introduced and applied to analysis and design of voltage regulators and other feedback circuits. Furthermore, it is shown how circuit averaging and averaged-switch modeling techniques lead to converter averaged models suitable for hand analysis, computer-aided analysis, and simulations of converters. After completion of this course, the student will be able to practice design of high-performance control loops around switched-mode power converters using analytical and simulation techniques. 

We strongly recommend students complete the CU Boulder Power Electronics specialization before enrolling in this course (course numbers provided for students in CU Boulder's MS-EE program):

● Introduction to Power Electronics (ECEA 5700)
● Converter Circuits (ECEA 5701)
● Converter Control (ECEA 5702)

After completing this course, you will be able to:

● Explain operation and modeling of switched-mode power converters
● Model open-loop transfer functions and frequency responses
● Design closed-loop regulated switched-mode power converters
● Verify operation of switched-mode power converters by simulations
● Understand the Feedback Theorem principles
● Apply the Feedback Theorem to practical design examples
● Derive averaged switch models of and averaged circuit models of power converters
● Apply averaged-switch modeling techniques to analysis and design and simulations of power converters
      


            Read more
          



          Modeling, Control and Simulation of Switched-Mode Power Converters
    -Review of modeling, control and simulation of switched-mode power converters

Techniques of Design Oriented Analysis: Feedback Theorem
    -Understand and apply Feedback Theorem in the analysis and design of power electronics

Averaged Switch Modeling and Averaged Circuit Simulations
    -Model and design switched-mode power converters using averaged switch modeling and averaged circuit simulations",Averaged-Switch Modeling and Simulation
https://www.classcentral.com/course/extreme-geological-events-13558,"Discover how extreme geological events have transformed our planet.
Retrace how Earth formed 4.5 billion years ago and has evolved to become the planet we know today.
On this course, you’ll get an introduction to the geological history of planet Earth, and explore the extreme events that shaped it and created conditions for life.
You’ll learn about the largest floods, tsunamis, earthquakes and volcanic eruptions, and explore the impact they have had and will continue to have on our dynamic planet.
Finally, you’ll discuss the likelihood of extreme events happening in the future and how we can deal with the risks and hazards.
This course is designed for anyone interested in the geological history of Earth, but may be of particular interest to students looking to study Earth Science.",Extreme Geological Events
https://www.classcentral.com/course/personalizedmed-2573,"Learn how advances in biomedicine hold the potential to revolutionize drug development, drug treatments, and disease prevention: where are we now, and what does the future hold? This course will present short primers in genetics and mechanisms underlying variability in drug responses. A series of case studies will be used to illustrate principles of how genetics are being brought to bear on refining diagnoses and on personalizing treatment in rare and common diseases. The ethical and operational issues around how to implement large scale genomic sequencing in clinical practice will be addressed. 

After completing this course, learners will understand
1. The ways in which genetic variants can contribute to human disease susceptibility
2. How to choose among drug therapies based on genetic factors  
3. That the functional consequences of the vast majority of genetic variants discovered by modern sequencing are unknown.

This course is targeted primarily at physicians 5+ years out of training. Other healthcare providers, medical/health sciences students, and members of the public may also be interested. 

Course launches January 15, 2016.

* The information presented in “Case Studies in Personalized Medicine” is offered for educational and informational purposes only, and should not be construed as personal medical advice. If you have questions or concerns about a medical matter, please consult your doctor or other professional healthcare provider.
      


            Read more
          



          UNIT 1: INTRODUCTION TO PERSONALIZED MEDICINE
    -The first module of this course will focus on introducing the concept of personalized medicine. We will very briefly review fundamentals of genetics as these apply to personalized medicine (DNA structure; RNA; protein structures; function of DNA; coding; DNA variations; types of genetic variants), as well as review statistical concepts and skills important to clinical data analysis (odds ratios, relative risk, P values, multiple testing, sensitivity, specificity, ROCs). In Module 2 we will explore drug actions and reactions as we look closely at the general mechanisms underlying variability in drug responses, drug metabolism and transport, and genetic variability in drug-handling molecules.

UNIT 2: STUDYING GENETIC VARIATION
    -Module 3 focuses on how we study genetic variation. We'll start by looking at families and populations. Topics that will be introduced include family history and inheritance patterns, ancestry, and linkage. Then in Module 4 we shift our focus to studying the contemporary techniques and technologies used to study genetic variation, including genome-wide association and sequencing.

UNIT 3: CASE STUDIES IN PERSONALIZED MEDICINE, PART 1
    -In Module 5 we will begin to discuss specific cases as these apply to personalized medicine. We will first look very closely at a case of familial hypercholesterolemia as we investigate how we use genomic medicine to move from a rare disease to a common medication, using genomics to find new drug targets, and a discussion of the side effects of statin therapy. In Module 6 we will look at a collection of ""high risk pharmacogenetics""cases that illustrate adverse reactions due to drug metabolism and variable drug responses.

UNIT 4: CASE STUDIES IN PERSONALIZED MEDICINE, PART 2
    -Module 7 continues our focus on case studies with a look at some cases that illustrate how personalized medicine informs treatment decisions related to specific diseases/conditions. These include cystic fibrosis, Marfan syndrome, heart failure, neuropsychiatric diseases, and diabetes. Three cases/lessons focus specifically on how genomic medicine informs testing for and treatment of cancer.  

UNIT 5: PERSONALIZED MEDICINE IN A SYSTEM OF CARE
    -Module 8 serves as a review and a continuing discussion of the cases presented in Modules 5-7, as we take a look at where we are now and what's on the horizon in personalized medicine. In Module 9 we will explore some critical considerations for implementing and operationalizing personalized medicine in a system of care, particularly in the area of informatics. We will discuss the role of the electronic medical record in a learning healthcare system, how electronic records support discovery, and using electronic records in the delivery of personalized medicine.     

FINAL REFLECTION ACTIVITY
    -We are on the verge of having patients come to their physicians with their entire genome sequenced. How can we best use this information to improve care? This course looks closely at many specific genetic variants that have been identified as playing a role in a person’s susceptibility to disease and/or potential for adverse reaction to certain substances/drugs. 

In the peer review activity below, please reflect on how your learning in this course has impacted your understanding of personalized medicine. There are two versions of this activity – one for healthcare professionals (doctors, nurses, pharmacists, medical students, etc.), and one for non-healthcare professionals (patients, consumers, general interest, etc.) 

Please be sure to choose the appropriate version of the activity.",Case Studies in Personalized Medicine
https://www.classcentral.com/course/c-bian-cheng-2337,"課程介紹 (About the course)

This course will introduce computer programming in C. We will cover basic operations about computer, then move on to how to write computer program in a language called C. Various C concepts will be introduced.


授課形式 (Course format)

We will have video lecture to introduce the concept of programming. The video will switch between the presentation slides and the actual coding process. After that we will have weekly programming homework to ensure that the students are able to practice what they learned from the video presentation. The students will practice on ideone.com, a web platform for compiling and running computer programs.


修課背景要求 (Recommended background)

No special prior computer knowledge is required. However, the students are expected to be able to use a web browser, has basic English vocabulary, and arithmetic skills of junior high school graduates.
      


          Week 1 - Introduction
    -We start with basic programming concepts that correspond to chapter 1, 2, 3 of the book. We will start with a basic program and gradually add computation statements so that our program will perform useful computation. Also we will use an online interface (ideone) to describe the process of editing, compiling and running a program. 

Week 2 - Control Structure
    -The second week will describe flow control and loops (book chapter 4, 5). After we learn how to write a program to perform basic computation in the first week, we start to learn the control structure of a program. We will learn how to control the execution of a program among several possible ""next steps"", and how to repeat the computation to finish repetitive tasks. We will also describe certain loop ending practice, which strongly relates to programming style. 

Week 3 - Array
    -The third week describes arrays and floating point numbers (book chapter 6, 7). We will introduce ways to organize related data into the most basic data structure, i.e., array. We will describe the circumstance of using an array, and the most useful idioms in using them. Various examples will be introduced to enforce the concepts in using array correctly. We will also describe the concept of floating point numbers, which is different from the integers we introduce at the beginning of this course.

Week 4 - Functions
    -The fourth will will describe the concept of functions (book chapter 8). We will motivate the use of function by system functions, including mathematic and input/output functions, so we the students can understand the key concept that if we can use existing code, then we do not need to reinvent the wheel. Then we will introduce the way to define our own functions. The key mechanism of function call, parameter passing, and return values wiill be discussed by a series of examples. 

Week 5 - Pointer
    -In the fifth week we will describe pointers (book chapter 9). We will focus on the semantic of pointers and then introduce the mechanism of using pointers. Here we would like to tie together the pointer concept with memory layout, i.e., the way the computer system places variables into memory. After the introduction of memory layout the students will have a very clear idea on how a computer system manages the memory, and how this layout affects the way we write program that handles variables of different types in C.

Week 6 - String
    -The sixth week will describe strings and characters (book chapter 10, 11). Up to this point in this course we deal with only numeric data. Now we are ready to introduce character and string that deal with mainly text data. We will introduce the concept of memory bits, and different types in C only means different ways to interpret the memory bits. We start with character, which is the basic unit of text information. Then we introduce string as an array of characters, and various useful functions to perform various operations on strings. 

Final Exam",計算機程式設計 (Computer Programming)
https://www.classcentral.com/course/edx-probability-and-statistics-in-data-science-using-python-8213,"The job of a data scientist is to glean knowledge from complex and noisy datasets.
Reasoning about uncertainty is inherent in the analysis of noisy data. Probability and Statistics provide the mathematical foundation for such reasoning.
In this course, part of the Data Science MicroMasters program, you will learn the foundations of probability and statistics. You will learn both the mathematical theory, and get a hands-on experience of applying this theory to actual data using Jupyter notebooks.
Concepts covered included: random variables, dependence, correlation, regression, PCA, entropy and MDL.",Probability and Statistics in Data Science using Python
https://www.classcentral.com/course/antimicrobial-resistance-6448,"The course will cover the topics related to antimicrobial resistance with basic definitions and overview on antimicrobials their use and the emergence and spread of resistance. The course will guide you through the concepts and the importance  of resistance spread and dissemination and how that happens. It will show you how bacteria become resistant and which mechanisms they might use for this. And as part of the course you will also receive some training in methods for antimicrobial susceptibility testing (AST) and detection of specific resistance in the microbiological laboratories with the basic methods available and with focus on the obtention of good quality results which can be interpreted and used for different purposes.
Additionally, it will show you how to use genomic analysis tools to analyze whole genome sequencing data to detect resistance genes (and or other genes of interest) in a simple and easy way using online tools freely available. 
In the new new version an additional module including detection of specific resistance mechanisms was added.

After this course you should be able to:

1.	Describe the most important families of antimicrobials and mode of action
2.	Understand the basic concepts of antimicrobial resistance from several perspectives (clinical, research and microbiological)
3.	Enumerate and describe how bacteria can become resistant and the mechanisms that may be involved in that process
4.	Describe how antimicrobial resistance emerges and spreads around the world including concepts of antimicrobial resistance transfer, selection and dissemination
5.	Enumerate the methods used for antimicrobial susceptibility testing (AST) 
6.	Compare dilution and diffusion methods and know the basic techniques of agar disk diffusion, broth dilution and agar dilution methods 
7.	Have detailed theoretical knowledge on how to perform the main methods in a laboratory
8.	Know the basic concepts about analysis and interpretation of results of AST, including different breakpoints, cut-off setting and their applications.
9.	Understand the importance and related concepts related to quality management and quality assurance method standardization, applied to AST 
10.	Relate the information obtained in this course with real cases of resistant bacteria spreading in patients, the community, animals or the environment
11.	Relate the phenotypical results with results from genotyping using molecular techniques for detection of resistance mechanisms
12.	Understand the concept and be able to apply genomic analysis tools used to detect resistance genes and other relevant genes from Whole Genome Sequencing (WGS) data (with demonstration of selected online tools)

Disclaimer: Please note that the guidelines and methods referred or links included in these materials are updated when the videos lectures are produced and before the course is released, however these might become outdated with time.
      


            Read more
          



          Welcome to the course
    -This module is basically a welcome to the course were you can find information on the Course structure, the contents you will be learning in the next modules, the grading, and introduction to the instructors and to the teaching material.

Module A- Antimicrobial and antimicrobial action
    -Antimicrobials and antimicrobial action ( includes two lectures and one quiz). Here you will learn a lot about antibiotics/ antimicrobials and you will know more about:what they are, where do they come from, what are the major groups and how can we classify them, how do they have an effect, how do they act on the bacterial cells

Module B - Antimicrobials and resistance
    -This module containd information about antimicrobials and the development of resistance in bacteria including causes for resistance and their mechanisms, as well as an insight in how resistance disseminates and how it can be selected.

Module C- Antimicrobial susceptibility testing
    -This module deals with antimicrobial susceptibility testing  in the laboratory: its importance and use, descriptions of the methods and their applications and detailed descriptions of the procedures applied for the main methods.

Module D- Interpretation
    -This module gives practical insight on how to interpret antimicrobial susceptibility results.

Module E- Quality assurance
    -This module is dedicated to Quality management and Quality assurance (QA/ Quality control (QC) procedures and use of QC strains  to assure the qulaity of results of antimicrobial susceptibility testing: importance, elements and principles.

Module F- Alternatives to AST- Genome analysis tools
    -As alternative to the phenotypical methods, the researcher might decide to use genotypically based methods to identify genes of interest. in the lectures of this module we present the Resfinder tool which may be used to find resistance mechanisms ( genes and in the future versions also specific point mutations)from Whole genome sequences of bacteria of interest.  The second Lecture is a demonstration of the My DB Finder which can be used to identify genes of interest defined by the user from Whole genome sequence data.

Module G- specific resistances",Antimicrobial resistance - theory and methods
https://www.classcentral.com/course/stanford-openedx-creating-effective-online-and-blended-courses-5145,"Creating Effective Online and Blended Courses was produced by the Open Learning Initiative This link opens in a new tab at Stanford University with contributions from the Vice Provost for Teaching and Learning This link opens in a new tab at Stanford University. These resources were partially funded by O.P.E.N., the Open Professionals Education Network This link opens in a new tab, which is sponsored by the Gates Foundation to support Department of Labor (DoL) Trade Adjustment Assistance Community College & Career Training (TAACCCT) grantees.These resources, designed for a general audience of instructors at 2-and 4-year higher education institutions, will help such instructors develop online courses or incorporate online learning approaches in their on-campus classes. A separate, Stanford-focused version will be released by winter of 2016. In our initial release, six of the eight modules will be available. The remaining two (in grey) will be released as they are built.



1. Introduction: How do I navigate these modules? What can I expect to get out of it? How are online courses different from on-campus courses?2. Course Organization: How can I structure my partially or fully online course?3. Learning Objectives: How do I formulate clear learning outcomes for my students?4. Assessment: How do I foster and measure student learning outcomes?5. Activities: What activities (such as guided discussions, reflection exercises, simulations, and games) can I use to support learning?6. Content Presentation: How can I most effectively use videos, HTML, and other media to present course content?7. Social Presence & Motivation: How do I build genuine community to keep students motivated?8. Iterative Design: How can I use platform data to improve my course over time?",Creating Effective Online and Blended Courses
https://www.classcentral.com/course/ecology-8638,"This course presents the principles of evolution and ecology for citizens and students interested in studying biology and environmental sciences. It discusses major ideas and results. Recent advances have energised these fields with evidence that has implications beyond their boundaries: ideas, mechanisms, and processes that should form part of the toolkit of all biologists and educated citizens.

Major topics covered by the course include fundamental principles of ecology, how organisms interact with each other and their environment, evolutionary processes, population dynamics, communities, energy flow and ecosystems, human influences on ecosystems, and the integration and scaling of ecological processes through systems ecology.

This course will also review major ecological concepts, identify the techniques used by ecologists, provide an overview of local and global environmental issues, and examine individual, group and governmental activities important for protecting natural ecosystems. The course has been designed to provide information, to direct the student toward pertinent literature, to identify problems and issues, to utilise research methodology for the study of ecology and evolution, and to consider appropriate solutions and analytical techniques. 

Needed Learner Background: general biology and a good understanding of English.

This course has the following expectations and results:
1) covers the theoretical and practical issues involved in ecology and evolution,
2) conducting surveys and inventories in ecology, 
3) analyzing the information gathered, 
4) and applying their analysis to ecological and conservation problems.
      


            Read more
          



          Welcome to the Course

Module 1. The Scope of Ecology  
    -In this module, after an introduction about the meaning and a brief history of Ecology, we will see how plant and animal adapt and interact with their environment and how these interactions changes life histories and populations. Then we will focus on interspecific competition and we will understand that the avoidance of competition is a more common pattern in ecology than pure competition.

Module 2. The Ecosystem 
    -In this module, we will talk about agonistic and foraging interactions between species (such as predation, herbivory and parasitism) and mutualistic interactions (such as symbiosis, commensalism, endosymbiosis, etc.). Then we will see how these interactions influence the evolutionary ecology of species and their diversity. In the last lesson of this module we will analyse the energy flux and biogeochemical cycles that keep alive Earth’s ecosystems and the whole biosphere (e.g. Gaia).

Module 3. Energy in Ecological Systems 
    -In this module, we will discuss some fundamental ecological processes, such as those must be present in any Gaian planet. We will consider the Gaian effects of parasites and predators, biodiversity and hypercycles and we will see how these processes regulates our planet. Finally, we will consider the global ecological role of biomass, photosynthesis and carbon sequestration.

Module 4. Population Ecology and Evolution 
    -In this final module, we will explore the possibility of a new ecology by exploring the concept of  sustainability, evaluating the human impacts on ecosystems and providing some solutions for nature conservation. Finally, we will see how to organise a citizen science event, called Bio-blitz, which can improve the scientific knowledge of our planet and, at the same time, rise the ecological awareness of citizens.

Final module
    -This module allows you to learn how to organise a Bio-blitz – an intensive biological investigation, which aims to record all the species living within a designated area, comprising groups of specialists supported by non-experts.",Ecology: from cells to Gaia
https://www.classcentral.com/course/how-to-read-a-mind-1574,"This free online course offers an introduction to the field known as cognitive poetics – applying cognitive science (the study of the mind and its processes) to how we read literature.
Understand cognitive poetics: what happens in our minds when we read
Taking our best current knowledge of how our minds and language work, we will ask some key questions about reading literature:

Why do we feel anything for fictional characters?
Why do we get angry, moved, irritated, annoyed or sentimental about imaginary people in imaginary worlds?
And why do the lives of fictional characters matter so much to readers?

The answers to these questions are surprising and empowering, and as we explore each, we will introduce you to some key concepts from  psychology, linguistics and philosophy.
In advance of the course starting you can join the conversation using #FLread or follow lead educator @PeterJStockwell on Twitter.
There are no previous requirements needed to take part in this course.",How to Read a Mind: an Introduction to Understanding Literary Characters
https://www.classcentral.com/course/data-analytics-accountancy-1-9051,"Welcome to Data Analytics Foundations for Accountancy I! You’re joining thousands of learners currently enrolled in the course. I'm excited to have you in the class and look forward to your contributions to the learning community.

To begin, I recommend taking a few minutes to explore the course site. Review the material we’ll cover each week, and preview the assignments you’ll need to complete to pass the course. Click Discussions to see forums where you can discuss the course material with fellow students taking the class.

If you have questions about course content, please post them in the forums to get help from others in the course community. For technical problems with the Coursera platform, visit the Learner Help Center.

Good luck as you get started, and I hope you enjoy the course!
      


          Course Orientation
    -You will become familiar with the course, your classmates, and our learning environment. The orientation will also help you obtain the technical skills required for the course.

Module 1: Foundations
    -This module serves as the introduction to the course content and the course Jupyter server, where you will run your analytics scripts. First, you will read about specific examples of how analytics is being employed by Accounting firms. Next, you will learn about the capabilities of the course Jupyter server, and how to create, edit, and run notebooks on the course server. After this, you will learn how to write Markdown formatted documents, which is an easy way to quickly write formatted text, including descriptive text inside a course notebook. Finally, you will begin learning about Python, the programming language used in this course for data analytics.

Module 2: Introduction to Python
    -This module focuses on the basic features in the Python programming language that underlie most data analytics scripts. First, you will read about why accounting students should learn to write computer programs. Second, you will learn about basic data structures commonly used in Python programs. Third, you will learn how to write functions, which can be repeatedly called, in Python, and how to use them effectively in your own programs. Finally, you will learn how to control the execution process of your Python program by using conditional statements and looping constructs. At the conclusion of this module, you will be able to write Python scripts to perform basic data analytic tasks.

Module 3: Introduction to Data Analysis
    -This module introduces fundamental concepts in data analysis. First, you will read a report from the Association of Accountants and Financial Professionals in Business that explores Big Data in Accountancy. Next, you will learn about the Unix file system, which is the operating system used for most big data processing (as well as Linux and Mac OSX desktops and many mobile phones). Second, you will learn how to read and write data to a file from within a Python program. Finally, you will learn about the Pandas Python module that can simplify many challenging data analysis tasks, and includes the DataFrame, which programmatically mimics many of the features of a traditional spreadsheet.

Module 4: Statistical Data Analysis
    -This module introduces fundamental concepts in data analysis. First, you will read about how to perform many basic tasks in Excel by using the Pandas module in Python. Second, you will learn about the Numpy module, which provides support for fast numerical operations within Python. This module will focus on using Numpy with one-dimensional data (i.e., vectors or 1-D arrays), but a later module will explore using Numpy for higher-dimensional data. Third, you will learn about descriptive statistics, which can be used to characterize a data set by using a few specific measurements. Finally, you will learn about advanced functionality within the Pandas module including masking, grouping, stacking, and pivot tables.

Module 5: Introduction to Visualization
    -This module introduces visualization as an important tool for exploring and understanding data. First, the basic components of visualizations are introduced with an emphasis on how they can be used to convey information. Also, you will learn how to identify and avoid ways that a visualization can mislead or confuse a viewer. Next, you will learn more about conveying information to a user visually, including the use of form, color, and location. Third, you will learn how to actually create a simple visualization (basic line plot) in Python, which will introduce creating and displaying a visualization within a notebook, how to annotate a plot, and how to improve the visual aesthetics of a plot by using the Seaborn module. Finally, you will learn how to explore a one-dimensional data set by using rug plots, box plots, and histograms.

Module 6: Introduction to Probability
    -In this Module, you will learn the basics of probability, and how it relates to statistical data analysis. First, you will learn about the basic concepts of probability, including random variables, the calculation of simple probabilities, and several theoretical distributions that commonly occur in discussions of probability. Next, you will learn about conditional probability and Bayes theorem. Third, you will learn to calculate probabilities and to apply Bayes theorem directly by using Python. Finally, you will learn to work with both empirical and theoretical distributions in Python, and how to model an empirical data set by using a theoretical distribution.

Module 7: Exploring Two-Dimensional Data
    -This modules extends what you have learned in previous modules to the visual and analytic exploration of two-dimensional data. First, you will learn how to make two-dimensional scatter plots in Python and how they can be used to graphically identify a correlation and outlier points. Second, you will learn how to work with two-dimensional data by using the Numpy module, including a discussion on analytically quantifying correlations in data. Third, you will read about statistical issues that can impact understanding multi-dimensional data, which will allow you to avoid them in the future. Finally, you will learn about ordinary linear regression and how this technique can be used to model the relationship between two variables.

Module 8: Introduction to Density Estimation
    -Often, as part of exploratory data analysis, a histogram is used to understand how data are distributed, and in fact this technique can be used to compute a probability mass function (or PMF) from a data set as was shown in an earlier module. However, the binning approach has issues, including a dependance on the number and width of the bins used to compute the histogram. One approach to overcome these issues is to fit a function to the binned data, which is known as parametric estimation. Alternatively, we can construct an approximation to the data by employing a non-parametric density estimation. The most commonly used non-parametric technique is kernel density estimation (or KDE). In this module, you will learn about density estimation and specifically how to employ KDE. One often overlooked aspect of density estimation is the model representation that is generated for the data, which can be used to emulate new data. This concept is demonstrated by applying density estimation to images of handwritten digits, and sampling from the resulting model.",Data Analytics Foundations for Accountancy I
https://www.classcentral.com/course/bioinfo-1390,"Курс «Введение в биоинформатику» адресован тем, кто хочет получить расширенное представление о том, что такое биоинформатика и как она помогает биологам и медикам в их работе.


The course is aimed at those who would like to have a better idea of what bioinformatics is and how it helps biologists and medical scientists in research and clinical work.
      


          Неделя 1 - Введение (Week 1 - Introducton)
    -Первая неделя нашего курса посвящена основным концепциям геномной биоинформатики. Вы узнаете об истории этой дисциплины, основных методах и алгоритмах. Также вас ждет знакомство с реальной лабораторной работой - мы расскажем, как выделяется ДНК и откуда берутся данные, с которыми нам предстоит работать в дальнейшем. The first week of our course covers the basic concepts of genome bioinformatics. You will learn about the history of this discipline, the main methods and algorithms. Also you will familiarize yourself with actual laboratory work - we will explain how DNA is extracted and where the sequencing data comes from.

Неделя 2 - Технологии секвенирования (Sequencing Technologies)
    -Добро пожаловать на вторую неделю нашего курса! Эта неделя будет посвящена обзору методов секвенирования ДНК. Вы узнаете об истории развития этих технологий и принципах, на которых они основаны. Welcome to the second week of the course! This week will be dedicated to Next Generation DNA Sequencing technologies.  You will learn about the new methods development and main approaches that gave base to NGS.

Неделя 3 - Контроль качества (Quality Control)
    -На этой неделе вы уже можете приступить к работе над геномным проектом. В лекциях мы поговорим о формате представления исходных данных и контроле качества. Также мы подготовили для вас небольшое введение в операционную систему Linux, так как большинство необходимых нам программ разработаны именно для нее. This week your can start working on the real genome project. This week lectures will cover raw data formats and aspects of quality control. Also we offer you a brief introduction to the Linux, because the majority of bioinformatics tools developed for this operation system.

Неделя 4 - Сборка ДНК de novo (De novo DNA assembly)
    -Добро пожаловать на четвертую неделю нашего курса. Она будет посвящена сборке геномов de novo. Вы узнаете о различных подходах к секвенированию малоизученных организмов, и о проблемах, которые при этом возникают. Также мы расскажем о работе алгоримов, используемых при сборке новых геномов. Оставайтесь с нами! Welcome to the fourth week of our course. It will be dedicated to de novo genome assembly. You will hear about different sequencing approaches of unknown organisms, and the problems associated with this task. We will also talk about algorithms used for the assembly of new genomes. Stay tuned!

Неделя 5 - Выравнивание коротких фрагментов (Short read alignment)
    -Пятая неделя нашего курса посвящена выравниванию коротких фрагментов на референс - подходу, который используется при работе с уже изученными геномами. В лекциях разбираются наиболее популярные программы для решения таких задач, а также основные алгоритмы для работы со строками. Fifth week of our course is devoted to short read alignment to the reference genome, which is used when we work with the already studied organisms. In lectures we will talk about the most popular software for solving such problems, as well as basic algorithms for working with strings.

Неделя 6 - Поиск и аннотация генов (Gene Finding and Annotation)
    -В завершающей неделе курса мы разберем методы поиска генов в собранных последовательностях и их аннотации.
In the final week of the course we will examine methods of gene finding and annotation in assembled sequences.

Геномный проект (Genome Project)
    -В этом практическом задании вам предстоит собрать и проаннотировать бактериальный геном, проинтерпретировать результаты и найти причину ужасной эпидемии, охватившей Европу в 2011 году. In this practice challenge you will have to assemble and annotate bacterial genome, interpret the results and find the cause of the terrible epidemic in Europe in 2011.",Введение в биоинформатику (Introduction to Bioinformatics)
https://www.classcentral.com/course/novoed-designing-for-deeper-learning-how-to-develop-performance-tasks-for-the-common-core-1557,"Given their emphasis on complex and sophisticated disciplinary skills and understandings, the Common Core State Standards and Next Generation Science Standards require ways of assessing that go beyond routine multiple-choice tests. Whether students are learning to select, use, and explain evidence to support a claim or to analyze data to evaluate a hypothesis, tests that require that students only bubble in a scantron are inadequate to measure (or support) students’ learning and growth. Performance assessments are more suited to this task. Performance-based tasks require that students create and produce rather than recall and regurgitate. While performance assessments vary along multiple dimensions, including duration and focus, they all demand that students use and apply critical skills and knowledge to demonstrate understanding.
This nine-week course will focus on building educators’ capacity to use, develop, and implement curriculum-embedded performance assessments that fit local contexts. Course activities include evaluating sample performance tasks and developing and implementing a performance task that is aligned with a specific curricular unit and performance outcomes. We will use a learning-centered approach where assessments are not only about measuring learning, but are also events for learning.
This MOOC is designed for grade 6-12 teachers working in the core disciplines of mathematics, language arts, history/social studies, and science. It is recommended that participants currently teach or have access to a classroom for which they can design a performance assessment and then implement that assessment. Participants will work collaboratively with other educators in their discipline to accomplish course learning goals and assignments.
The four main objectives of this course are for participants to:

Understand and identify features of high quality performance assessments;
Develop a grade-level, course-specific, practical, performance task that is aligned with (and embedded within) a curricular unit of study;
Begin to use data from performance tasks to tailor and improve instruction and curriculum;
Contribute to building an online community of educators focused on using performance-based assessments to identify and develop students’ abilities.




            Read more",Designing for Deeper Learning: How to Develop Performance Tasks for the Common Core
https://www.classcentral.com/course/chemhealth-2053,"This course covers chemicals in our environment and in our bodies and how they impact our health. It addresses policies and practices related to chemicals, particularly related to how they get into our bodies (exposures), what they do when they get there (toxicology), how we measure them (biomonitoring) and their impact on our health. Most examples are drawn from the US.
      


          Week 1: Welcome & Introduction
    -Start off this week with the peer assessment (we know, we know. . .how can we have an assessment before the course even starts, right?). We simply hope to gauge your initial understanding of the topics that we’ll cover (so grade easy). 

Then we get into a quick overview of the course, a discussion of chemicals & how we are exposed (in three parts) and an introduction to chemical production & regulation. The module ends with a fun homework assignment: watch an eight-minute video and discuss amongst yourselves (and with us too).

Week 2 - Toxicology: What do chemicals do in our bodies?
    -Now that you have a sense of what a chemical is, and how we are exposed to them, we dive into the science of how chemicals impact our health, starting with toxicology. But before you dive into the study of poisons, please review, evaluate, and grade at least four of your classmates' submissions from last week. After you listen to the lectures by Professor Trush, take the ten-question/multiple-choice quiz that covers weeks 1 & 2. Feel free to go back and use the lectures to help you answer the questions.

Week 3 - Biomonitoring: How do we measure these chemicals in our bodies and why?
    -Start by watching a two-minute video and a five-minute news report. Post your reactions not only to the video and audio files, but also to your peers’ thoughts! 

Next you’ll hear from a CDC scientist about the US’ National Biomonitoring Program, then you’ll hear how that program translates to the local level. Be sure to keep in mind the relationship of communities to their government! This week is pretty light – so enjoy!

Week 4 - Health effects of chemicals: How do we figure out how chemicals affect our health?
    -Finally we get to one of the main questions presented in this course - how do scientists assess the impact of chemicals on our health? You’ll hear from a physician who specializes in environmental & occupational medicine and epidemiology. Then you’ll hear how policymakers use the knowledge that we do have (about chemicals & health) to assess risk and drive policy. Once you’ve viewed the two lectures, another ten-question/multiple-choice quiz will assess how much information you absorbed from weeks 3 and 4. Feel free to go back and use the lectures to help you answer the questions.

Week 5 - Chemicals Policy: What do we do about chemicals & health?
    -So far we’ve covered: how chemicals get into our bodies and how we measure them,	what our bodies do with them and what they do to our bodies, and how that ultimately impacts our health. Now we turn to policy and how society addresses the impact of chemicals on health. 

We will hear from a non-profit group that works to change policies such as laws & regulations related to this area. Then we’ll hear how such changes have impacted our health and environment historically, looking specifically at air quality regulation in the US. 

After you view the lectures in Module 5, there is a second peer-reviewed writing assessment that aims to gauge your shift in understanding the complex relationship between chemicals and health (again grade each other generously).

Week 6: Case Studies 
    -At this point you may be wondering: so how do all these pieces fit together? From chemicals in our natural world to production on a large scale, through exposure to health effects and policy . . . this module provides real world examples of how the general public, scientists, industry, governments and non-profit groups come together to effect change. Specifically, we’ll hear about tobacco, contaminated food, drinking water, nanotechnology & worker health. At some point this week (either before, after or in-between listening to the case studies), you’ll need to review, evaluate, and grade at least four of your classmates' submissions from last week. The final lecture offers a summary & conclusion, hopefully providing ideas for next steps for those of you interested in learning or doing more related to chemicals & health. Please let us know how we did and how we can improve!",Chemicals and Health
https://www.classcentral.com/course/programdesign-845,"Phones, diesel engines, animated newspapers, medical devices, games, political
    campaigns, medical research, mining, transportation systems, ... and so
    on, and on, and on... every day more of the world around us is at least
    partly run by computer programs. This means that being able to design programs
    - or at least be able to work with people who design programs - is becoming
    a more and more valuable skill.
To build your own programs you need to know two things: how to use the
    specific programming language and libraries needed, and the more general
    skill of how to design a program.
This course presents a design method that will enable you to approach
    the design of complex programs systematically. The method will work for
    programs in this course as well as hard to design programs you develop
    in the future.
Using this method you will learn how to model the information in a problem
    domain, how to structure program data to mirror that information and how
    to further structure the data to lead to a well organized program. You
    will also learn to distinguish those parts of a program that are naturally
    data driven, from those that should use an alternative algorithmic approach.
    The method uses unit-tests to both produce a better developed design, and
    to test your program as you develop it.
In the first course -- Part 1 -- we use a simple
    teaching language to cover the core of the design method. In Part 1 we cover various forms of data; simple interactive programs like games and animations; storing information in and rendering trees; and finally exploring search programs: programs that solve puzzles like Sudoku boards. A second phase of the course, to be offered later,  will consist of parallel tracks, with each track using a different popular
    programming language and focusing on a different kind of problem. This
    will help you bring the design method to whatever language and problem
    domain interests you.



            Read more
          




Week One: Introduction and the structure of the course. The Beginning
Student Language; expressions and evaluation rules; primitive
operations on numbers, strings and images. The How to Design Functions
(HtDF) Recipe.


Week Two: Representing information as data. The How to Design Data
(HtDD) recipe. Atomic forms of data including intervals, enumerations,
and itemizations.


Week Three: The design of simple interactive programs. The big-bang
user interface framework. The How to Design Worlds (HtDW)
recipe. Representing information where two or more values naturally
form a whole using compound data.


Week Four: Representing arbitrary sized information using
lists. Decomposition of information into multiple types.


Week Five: Functions operating on natural numbers. A parlor
trick. Rules for decomposing functions.


Week Six: List abbreviations. Mutual reference allows more complex
arbitrary-sized data. Using binary trees to enable fast lookup of
information. Using arbitrary arity trees to represent inherently
hierarchical information.


Week Seven: Functions that consume two arguments that have 'one-of' in
their types. Using local definitions to improve the structure of
programs.


Week Eight: Using abstraction to control reduce repetition and
complexity in programs.


Week Nine: Generative recursion, fractals and search problems.",Introduction to Systematic Program Design - Part 1
https://www.classcentral.com/course/openhpi-introduction-to-internetworking-with-tcp-ip-590,"The Internet has become an integral part of our daily lives. This course will teach you about the technological foundation of this worldwide network. You will learn about its physical foundation of data transmission based on the functional principles and technologies of local area networks (LANs) and wide area networks (WANs). The TCP/IP reference model, that lies at the base of the Internet, its protocols and countless applications, will be presented in the units to follow. The participant will gain comprehensive insight into the complex world of Internet technologies.




Week 1 : Introduction - The Internet is great, but is it really so complex?
Week 2 : Network Technologies - How can messages be transferred from one computer, by way of electrical or optical signals, to the computer next door or to one that is halfway around the world?
Week 3 : Internetworking with IPv4 - How does a data packet find its way through an Internet that consists of different but interconnected single networks with completely different technologies?
Week 4 : The New Internet Protocol IPv6 -How will it be possible in the future for smartphones, household appliances, cars, etc. to also be able to communicate with each other via the Internet?
Extra knowledge: Hands-on Wireshark exercises
Week 5 : Transport Protocols TCP and UDP - Who can guarantee that my data will reach its goal intact after its long journey through the Internet across different networks?
Week 6 : Internet Applications - What else do we need to know in order to send an email or a video through the Internet?
Final Examination: Final Examination",Introduction to Internetworking with TCP/IP
https://www.classcentral.com/course/edx-embedded-systems-shape-the-world-multi-threaded-interfacing-8074,"Learn how electronic gadgets are designed, developed, and built as embedded systems that shape the world.
This is part two of a two part sequence. In this class, we will use interrupts to design a range of real-time systems including an audio player, a data acquisition system, a control system, and an interactive game. This is a hands-on, learn-by-doing course that shows you how to build solutions to real-world problems using embedded systems. These courses use a bottom-up approach to problem solving, building gradually from simple interfacing of switches and LEDs to complex concepts like display drivers, digital to analog conversion, generation of sound, analog to digital conversion, motor control, graphics, interrupts, and communication. We will present both general principles and practical tips for building circuits and programming the microcontroller in the C programming language. You will develop debugging skills using oscilloscopes, logic analyzers, and software instrumentation. Laboratory assignments are first performed in simulation, and then you will build and debug your system on the real microcontroller. At the conclusion of this course you will possess the knowledge to build your own arcade-style game from the ground up.
This is the fourth time we have offered this course. Since the reviews have been overwhelmingly positive we do not plan major changes over the previous offerings of the course. We did however break the large class into two smaller classes. There are eight labs in part 1 and six labs in this class. Students can pick and choose a subset of labs to achieve certification. The three labs that students found most rewarding were the hand-held video game, generating sound using a digital to analog convertor, and creating a smart object using Wifi communication.
To complete this course, you will be required to purchase a Texas Instruments TM4C123 microcontroller kit and a few electronic components. This microcontroller has a state-of-the-art ARM Cortex-M4 processor.
We will provide instructions about purchasing the kit and installing required software at: http://edx-org-utaustinx.s3.amazonaws.com/UT601x/index.html.



            Read more
          



The best way to understand what you will learn in this class is to list the labs you will complete and the example projects we will build. You will complete each lab first in simulation and then on the real board. For each module we will design a system and you will build and test a similar system.
Module 1: Welcome and introduction to course and staff
Module 11: UART - The Serial Interface, I/O Synchronization
Lab 11. Write C functions that output decimal and fixed-point numbers to serial port
Module 12: Interrupts
Lab 12. Design and test a guitar tuner, producing a 440 Hz tone
Module 13: DAC and Sound
Lab 13. Design and test a digital piano, with 4 inputs, digital to analog conversion, and sound
Module 14: ADC and Data Acquisition
Lab 14. Design and test a position measurement, with analog to digital conversion and calibrated output
Module 15: Systems Approach to Game Design
Lab 15. Design and test a hand-held video game, which integrates all components from previous labs. Lab 15 will be graded by having students watch videos of each other's’ games.
Module 16: Wireless Communication and the Internet of Things
Lab 16. Connect a CC3100 booster pack to the LaunchPad and communicate with an access point. Lab 16 will first fetch weather from the internet, and then you will send data to the class server.",Embedded Systems - Shape The World: Multi-Threaded Interfacing
https://www.classcentral.com/course/chem99-1351,"Please Note:  If you are signing up for the new run of Introduction to Chemistry that begins August 25th, the course has been split into two parts.To sign up for the new run of Introduction to Chemistry, please go to this urlhttps://class.coursera.org/chem991-001 and enroll in this new version of the course.This is an introductory course for students with limited or no background in chemistry; chemical problem solving will be emphasized. The goal of the course is to prepare students for further study in the chemistry needed
for many science, health, and policy professions. Topics include introductions to atoms, molecules, ions, the periodic table, stoichiometry, chemical reactions, bonding, thermochemistry, and gas laws.

Each week the course will contain short video lectures with interactive questions embedded in the lectures. Students will have opportunities to practice each week via exercises at two levels of depth: one set of foundational
problems directly related to lecture videos and another set of problems requiring more synthesis of ideas and application of pre-existing algebra skills. Students who complete the course while earning an average of 70% of more on the foundational problem
sets, writing assignment, and exams will receive a signed statement of accomplishment. Students who complete the course and achieve an average of 85% or more on the foundational problem sets, advanced problem sets, writing assignment, and exams will receive
a signed statement of accomplishment with distinction.Course icon from Wikimedia commons.



            Read more
          



          Week One: Introductions with an overview of scientific methods, scientific notation, measurements, units and unit conversions, using proper significant figures to indicate precision, general concepts in matter and energy including definitions of
atoms, elements, molecules, and compounds, chemical formula stoichiometry, basic layout of the periodic table, endothermic and exothermic reactions, Coulomb’s law, and heat capacity.


Week Two: More study of atomic and molecular structure, information on the periodic table including some periodic trends, the subatomic particles most critical to chemical reaction and calculations, ions, isotopes, atomic and molecular mass, moles,
introduction to ionic and covalent bonding concepts, and nomenclature including some polyatomic ions.


Week Three: Introduction to chemical composition calculations (compound stoichiometry); introduction to chemical reaction equations, including identifying and balancing simple acid-base, redox, dissolution, and precipitation reactions; more practice
with gram/mole calculations.


Week Four: Reaction calculations, including limiting reagent, yield, and enthalpy changes; practice writing and balancing chemical reaction equations; stoichiometry practice and review. Work on writing assignment.


Week Five: No new topics this week. Complete mid-term exam and peer review process on writing assignment.
Week Six:  Introduction to light, Bohr model of the hydrogen atom, atomic orbitals, electron configurations, valence versus core electrons, more information about periodicity.

Week Seven:   Introduction to chemical bonding concepts including sigma and pi bonds, Lewis dot structures, resonance, formal charge, hybridization of the main group elements, introduction to molecular shapes.

Week Eight:  Introduction to intermolecular forces, states of matter, phase changes and phase diagrams, ideal gas laws, kinetic molecular theory of gases, properties of solids and liquids.

Week Nine:  Review solutions, review polarity, electrolytes, concentration units including molarity and mass percent, solubility, solubility product constant, and dilutions.  Complete final exam.",Introduction to Chemistry
https://www.classcentral.com/course/edx---data-structures-and-algorithm-design-part-ii-5720,"Data structures play a central role in computer science and are the cornerstones of efficient algorithms. Knowledge in this area has been at the kernel of related curriculums. This course aims at exploring the principles and methods in the design and implementation of various data structures and providing students with main tools and skills for algorithm design and performance analysis. Topics covered by this course range from fundamental data structures to recent research results. ""Data Structures and Algorithm Design Part II"" is an advanced course extending the materials in ""Part I"". We will cover more powerful and sophisticated data structures & algorithms, including: splay trees, B-trees, red-black trees, hash tables, priority queues, strings and sorting.
数据结构是计算机科学的关键内容，也是构建高效算法的必要基础。其中涉及的知识，在相关专业的课程系统中始终处于核心位置。本课程旨在围绕各类数据结构的设计与实现，揭示其中的规律原理与方法技巧；同时针对算法设计及其性能分析，使学生了解并掌握主要的套路与手段。讲授的主题从基础的数据结构，一直延伸至新近的研究成果。",数据结构与算法设计(下) | Data Structures and Algorithm Design Part II
https://www.classcentral.com/course/independent-machine-learning-crash-course-with-tensorflow-apis-10503,"A self-study guide for aspiring machine learning practitioners. Machine Learning Crash Course features a series of lessons with video lectures, real-world case studies, and hands-on practice exercises.
Some of the questions answered in this course:

Learn best practices from Google experts on key machine learning concepts.
How does machine learning differ from traditional programming?
What is loss, and how do I measure it?
How does gradient descent work?
How do I determine whether my model is effective?
How do I represent my data so that a program can learn from it?
How do I build a deep neural network?




ML Concepts

Introduction
Framing
Descending into ML
Reducing Loss
First Steps with TF
Generalization
Training and Test Sets
Validation
Representation
Feature Crosses
Regularization: Simplicity
Logistic Regression
Classification
Regularization: Sparsity
Introduction to Neural Nets
Training Neural Nets
Multi-Class Neural Nets
Embeddings

ML Engineering

Production ML Systems
Static vs Dynamic Training
Static vs Dynamic Inference
Data Dependencies

ML Real World Examples

Cancer Prediction
18th Century Literature
Real-World Guidelines

Conclusion

Next Steps",Machine Learning Crash Course with TensorFlow APIs
https://www.classcentral.com/course/fam-inflammation-9149,"Learn how to answer questions related to inflammation and disease, and food
On this course, designed specially for healthcare professionals, get an introduction to current evidence surrounding the impact of nutrition and foods on development and treatment of chronic low-grade inflammation, and potential subsequent disease development
Designed by experts in food, nutrition and genetics from Monash University, and featuring input from General Practitioners and nurses this course will give you up to date information on inflammation and health, and help you to help your patients incorporate foods with potential anti-inflammatory properties into their diet.
Places in this course are limited to 100, so please register early to avoid disappointment.
This course has been designed for healthcare professionals, specifically medical specialists, general practitioners and nurses.
However, the course may be of benefit to healthcare professionals such as dietitians and nutritionists with a background in nutrition, who may like a ‘refresher’ in this area of study.
You should have a good knowledge of science, medicine and healthcare practice.
Who has recognised this course?
This course is recognised by:


British Dietetic Association (BDA): endorsement applies only to the educational content of the learning activity.


Association for Nutrition (AfN): endorsed for CPD. Registered Nutritionists can work with acutely-ill patients only under the close supervision of a Dietitian or other regulated health professional.


If you have any questions on the course, its accreditation/endorsement or how it may relate to your professional healthcare practice we encourage you to email your questions to base.nutrition@monash.edu



            Read more",Food as Medicine: Food and Inflammation
https://www.classcentral.com/course/edx-algorithms-design-and-analysis-part-1-8984,"Welcome to the self paced course, Algorithms: Design and Analysis! Algorithms are the heart of computer science, and the subject has countless practical applications as well as intellectual depth.
This specialization is an introduction to algorithms for learners with at least a little programming experience. The specialization is rigorous but emphasizes the big picture and conceptual understanding over low-level implementation and mathematical details. After completing this specialization, you will be well-positioned to ace your technical interviews and speak fluently about algorithms with other programmers and computer scientists.
Specific topics in the course include: ""Big-oh"" notation, sorting and searching, divide and conquer (master method, integer and matrix multiplication, closest pair), randomized algorithms (QuickSort, contraction algorithm for min cuts), data structures (heaps, balanced search trees, hash tables, bloom filters), graph primitives (applications of BFS and DFS, connectivity, shortest paths).
Learners will practice and master the fundamentals of algorithms through several types of assessments. There are 6 multiple choice quizzes to test your understanding of the most important concepts. There are also 6 programming assignments, where you implement one of the algorithms covered in lecture in a programming language of your choosing. The course concludes with a multiple-choice final. There are no assignment due dates and you can work through the course materials and assignments at your own pace.



            Read more","Algorithms: Design and Analysis, Part 1"
https://www.classcentral.com/course/robotics-mobility-5032,"How can robots use their motors and sensors to move around in an unstructured environment?  You will understand how to design robot bodies and behaviors that recruit limbs and more general appendages to apply physical forces that confer reliable mobility in a complex and dynamic world.  We develop an approach to composing simple dynamical abstractions that partially automate the generation of complicated sensorimotor programs.  Specific topics that will be covered include: mobility in animals and robots, kinematics and dynamics of legged machines, and design of dynamical behavior via energy landscapes.
      


          Introduction: Motivation and Background
    -We start with a general consideration of animals, the exemplar of mobility in nature.  This leads us to adopt the stance of bioinspiration rather than biomimicry, i.e., extracting principles rather than appearances and applying them systematically to our machines. A little more thinking about typical animal mobility leads us to focus on appendages – limbs and tails – as sources of motion. The second portion of the week offers a bit of background on the physical and mathematical foundations of limbed robotic mobility. We start with a linear spring-mass-damper system and consider the second order ordinary differential equation that describes it as a first order dynamical system. We then treat the simple pendulum – the simplest revolute kinematic limb – in the same manner just to give a taste for the nature of nonlinear dynamics that inevitably arise in robotics. We’ll finish with a treatment of stability and energy basins.

 Link to bibliography: https://www.coursera.org/learn/robotics-mobility/resources/pqYOc 

Behavioral (Templates) & Physical (Bodies)
    -We’ll start with behavioral components that take the form of what we call “templates:” very simple mechanisms whose motions are fundamental to the more complex limbed strategies employed by animal and robot locomotors. We’ll focus on the “compass gait” (the motion of a two spoked rimless wheel) and the spring loaded inverted pendulum – the abbreviated versions of legged walkers and legged runners, respectively.We’ll then shift over to look at the physical components of mobility.  We’ll start with the notion of physical scaling laws and then review useful materials properties and their associated figures of merit. We’ll end with a brief but crucial look at the science and technology of actuators – the all important sources of the driving forces and torques in our robots. 

Link to bibliography: https://www.coursera.org/learn/robotics-mobility/resources/pqYOc 

Anchors: Embodied Behaviors
    -Now we’ll put physical links and joints together and consider the geometry and the physics required to understand their coordinated motion. We’ll learn about the geometry of degrees of freedom. We’ll then go back to Newton and learn a compact way to write down the physical dynamics that describes the positions, velocities and accelerations of those degrees of freedom when forced by our actuators.Of course there are many different ways to put limbs and bodies together: again, the animals can teach us a lot as we consider the best morphology for our limbed robots. Sprawled posture runners like cockroaches have six legs which typically move in a stereotyped pattern which we will consider as a model for a hexapedal machine.  Nature’s quadrupeds have their own varied gait patterns which we will match up to various four-legged robot designs as well. Finally, we’ll consider bipedal machines, and we’ll take the opportunity to distinguish human-like robot bipeds that are almost foredoomed to be slow quasi-static machines from a number of less animal-like bipedal robots whose embrace of bioinspired principles allows them to be fast runners and jumpers. 

Link to bibliography: https://www.coursera.org/learn/robotics-mobility/resources/pqYOc 

Composition (Programming Work)
    -We now introduce the concept of dynamical composition, reviewing two types: a composition in time that we term “sequential”;  and composition in space that we call “parallel.” We’ll put a bit more focus into that last concept, parallel composition and review what has been done historically, and what can be guaranteed mathematically when the simple templates of week 2 are tasked to worked together “in parallel” on variously more complicated morphologies. The final section of this week’s lesson brings you to the horizons of research into legged mobility. We give examples of how the same composition can be anchored in different bodies, and, conversely, how the same body can be made to run using different compositions. We will conclude with a quick look at the ragged edge of what is known about transitional behaviors such as leaping.

 Link to bibliography: https://www.coursera.org/learn/robotics-mobility/resources/pqYOc",Robotics: Mobility
https://www.classcentral.com/course/datasci2-4341,"Statistical experiment design and analytics are at the heart of data science.  In this course you will design statistical experiments and analyze the results using modern methods.  You will also explore the common pitfalls in interpreting statistical arguments, especially those associated with big data.  Collectively, this course will help you internalize a core set of practical and effective machine learning methods and concepts, and apply them to solve some real world problems.


Learning Goals: After completing this course, you will be able to:
1. Design effective experiments and analyze the results
2. Use resampling methods to make clear and bulletproof statistical arguments without invoking esoteric notation
3. Explain and apply a core set of classification methods of increasing complexity (rules, trees, random forests), and associated optimization methods (gradient descent and variants)
4. Explain and apply a set of unsupervised learning concepts and methods
5. Describe the common idioms of large-scale graph analytics, including structural query, traversals and recursive queries, PageRank, and community detection
      


          Practical Statistical Inference
    -Learn the basics of statistical inference, comparing classical methods with resampling methods that allow you to use a simple program to make a rigorous statistical argument.  Motivate your study with current topics at the foundations of science: publication bias and reproducibility.

Supervised Learning
    -Follow a tour through the important methods, algorithms, and techniques in machine learning.  You will learn how these methods build upon each other and can be combined into practical algorithms that perform well on a variety of tasks.  Learn how to evaluate machine learning methods and the pitfalls to avoid.

Optimization
    -You will learn how to optimize a cost function using gradient descent, including popular variants that use randomization and parallelization to improve performance.  You will gain an intuition for popular methods used in practice and see how similar they are fundamentally. 

Unsupervised Learning
    -A brief tour of selected unsupervised learning methods and an opportunity to apply techniques in practice on a real world problem.",Practical Predictive Analytics: Models and Methods
https://www.classcentral.com/course/edx-knowledge-management-and-big-data-in-business-3642,"The business landscape is changing so rapidly that traditional management, business and computing courses do not meet the needs for the next generation of workers in the business world. Most traditional methods are of a repetitive, rule-based nature and will be gradually replaced by Artificial Intelligence. In the knowledge era, the most value added job will be to manage knowledge, which includes how knowledge is created, mined, processed, shared and reused in different trades and industry. At the same time, the amount of data and information (prerequisites of knowledge) is exploding exponentially. By 2020, IDC projects that the size of the digital universe will reach 40 zetabytes from all sources including, websites, weblog, sensors, and social media. Digitalisation, Cloud Computing, Big data will transform how we live, work and even think in a Networked Economy. These trends and more will have a profound effect on how we see the world and create policies. In this course, the following topics and more are covered:

What is knowledge management?
How is knowledge captured, elicited, organized and created in business?
Managing knowledge at the enterprise, SMBs and personal levels
Digitalisation and its impact on the workplace, collaborations and new value creation
What is big data and how can we use data analytics from a laymen perspective?
What is Open Linked Data and how can it support machine reasoning?
How can new knowledge be mined from big data?
What are the technical and social problems with big data?

The Cloud as a canvas for service design and business model re-inventionWhat are examples of applications and case studies?The course is offered by the Knowledge Management and Innovation Research Center (KMIRC) of the Hong Kong Polytechnic University. Most of our research is company and industry based. Capabilities and competencies of the KMIRC are further strengthened by the international alliances it has formed with leading practitioners, many of which are regarded as members of the ""Hall of Fame"" in knowledge management, and renowned worldwide. The course is suitable for participants with a background in humanities, management, social science, physical science or engineering. No prior technical background is needed.
      


            Read more",Knowledge Management and Big Data in Business
https://www.classcentral.com/course/image-understanding-tensorflow-gcp-12121,"This is the third course of the Advanced Machine Learning on GCP specialization. In this course,
We will take a look at different strategies for building an image classifier using convolutional neural networks. We'll improve the model's accuracy with augmentation, feature extraction, and fine-tuning hyperparameters while trying to avoid overfitting our data. We will also look at practical issues that arise, for example, when you don’t have enough data and how to incorporate the latest research findings into our models.

You will get hands-on practice building and optimizing your own image classification models on a variety of public datasets in the labs we’ll work on together.  

Prerequisites: Basic SQL, familiarity with Python and TensorFlow
      


          Welcome to Image Understanding with TensorFlow on GCP
    -In this introductory module you will learn about the rapid growth in high-resolution image data available and the types of applications that it can be applied to. We’ll also cover image data as inputs to your model. 




Linear and DNN Models
    -We’ll start with a brief introduction where we’ll cover the image dataset you will be using for part of this course. Then we’ll tackle an image classification problem with a linear model in TensorFlow. After that we’ll move onto tackling the same problem using a Deep Neural Network. Lastly, we’ll close with a discussion and application of dropout which is a regularization technique for neural networks to help prevent them from memorizing our training dataset. 


Convolutional Neural Networks (CNNs)
    -This module will introduce Convolutional Neural Networks or CNNs for short, and get you started with implementing CNNs using TensorFlow. Since 2012, CNN based systems achieved unparalleled performance on tasks like image recognition and even at playing the ancient board game of Go against the top human champions.

Dealing with Data Scarcity
    -In this module, we’ll focus on data scarcity, what it is, why it’s important, and, before moving onto building ML models, what you need to do about it.

Going Deeper Faster
    -In this module, you will learn how to train deeper, more accurate networks and do such training faster.You will learn about common problems that arise when training deeper networks, and how researchers have been able to address these issues.

Pre-built ML Models for Image Classification
    -Welcome to the last module of the Image Classification course. Now that you have build your own image classifiers using linear, DNN, and CNN models with TensorFlow, it’s time to experiment with pre-built image models. In most cases, you will want to try these before investing your time in developing  custom TensorFlow code for a model.

Summary
    -In this final module, we will review the core concepts covered in this image classification course. You will recall creating classifiers with linear models, DNNs, DNNs with Dropout,  Convolutional Neural Networks (CNNs), and lastly with pre-built models like the Cloud Vision API and AutoML Vision.",Image Understanding with TensorFlow on GCP
https://www.classcentral.com/course/futurelearn-getting-a-grip-on-mathematical-symbolism-1758,"##
This course is aimed at those who aspire to study science or engineering foundation courses at university level. It draws upon the experience of staff from the Mathematics Education Centre at Loughborough University - a centre that has specialised for many years in mathematics teaching and mathematics support for science and engineering students who find the transition to university mathematics particularly challenging.
Through an accessible introduction to graphical and algebraic techniques students will start to think mathematically and develop an informal understanding of vital properties of points, lines and curves before formalising mathematically some of these essential notions. We adopt a user-friendly approach and describe mathematical processes in everyday language. New ideas are developed by example and discovery rather than by formal proof.  Further development will introduce the equation of a line and the significance of its slope and vertical intercept.
The course will close by reinforcing the importance of mathematics to science and engineering. It will pave the way into the study of calculus by explaining that engineers and scientists need to build upon the ideas introduced in order to describe, analyse and predict the behaviour of physical, biological and technological systems.
What will you do ?

watch video explanations of key mathematical ideas
hear from leading scientists and engineers about the importance of mathematics to their work
watch fully worked mathematical examples
try to solve mathematics problems yourself
learn how to plot points and straight line graphs and  use these lines to solve problems
test your progress with quizzes
try to apply what you have learned
share ideas with other learners on the course
prepare yourself well for embarking upon a science or engineering course

Professor Tony Croft has written two blogs posts which talk about the role this free online course might play in helping to prepare young people for the mathematical demands of university courses in STEM subjects:
Trying to make it all add up: preparing young people for the mathematical demands of university
Breaking into science and engineering: strengthening mathematical foundations
The course is designed for students who have some engineering or science knowledge gained through vocational qualifications or through workplace experience but who perhaps have not studied mathematics formally since leaving school. It will be appropriate for those who lack confidence but who need to establish a bedrock of knowledge in order to further their education.  To gain the most from the course it will be necessary to  plot some graphs (graph paper will be provided).  Please note that this is a foundation, entry-level course and is not intended for those who already possess recent post-GCSE mathematics qualifications.



            Read more",Getting a Grip on Mathematical Symbolism
https://www.classcentral.com/course/hetero-427,"All computing
systems, from mobile to supercomputers, are becoming heterogeneous, massively
parallel computers for higher power efficiency and computation
throughput. While the computing community is racing to build tools and
libraries to ease the use of these systems, effective and confident
use of these systems will always require knowledge about low-level
programming in these systems. This course is designed for students to
learn the essence of low-level programming interfaces and how to use these
interfaces to achieve application goals. CUDA C, with its good balance between
user control and verboseness, will serve as the teaching vehicle for the first
half of the course. Students will then extend their learning into closely
related programming interfaces such as OpenCL, OpenACC, and C++AMP.

The course is unique in that it is application oriented and only introduces the
necessary underlying computer science and computer engineering knowledge for
understanding. It covers the concept of data parallel execution models,
memory models for managing locality, tiling techniques for reducing bandwidth
consumption, parallel algorithm patterns, overlapping computation with
communication, and a variety of
heterogeneous parallel programming interfaces. The concepts learned in this
course form a strong foundation for learning other types of parallel
programming systems.




Week One: Introduction to Heterogeneous
Computing, Overview of CUDA C, and Kernel-Based Parallel Programming, with lab tour
and programming assignment of vector addition in CUDA C. Week Two: Memory Model for Locality, Tiling
for Conserving Memory Bandwidth, Handling Boundary Conditions, and Performance
Considerations, with programming assignment of simple matrix-matrix multiplication
in CUDA C.Week Three: Parallel Convolution Pattern, with
programming assignment of tiled matrix-matrix multiplication in CUDA C.Week Four: Parallel Scan Pattern, with
programming assignment of parallel convolution in CUDA C.Week Five: Parallel Histogram Pattern and
Atomic Operations, with programming assignment of parallel scan in CUDA C.Week Six: Data Transfer and Task
Parallelism, with programming assignment of parallel histogram in CUDA C.Week Seven: Introduction to OpenCL,
Introduction to C++AMP, Introduction to OpenACC, with programming assignment of
vector addition using streams in CUDA C.Week Eight: Course Summary,
Other Related Programming Models –Thrust, Bolt, and CUDA FORTRAN, with
programming assignment of simple matrix-matrix multiplication in choice of
OpenCL, C++AMP, or OpenACC.Week Nine: complete any
remaining lab assignments, with optional, bonus programming assignments in choice
of OpenCL, C++AMP, or OpenACC.",Heterogeneous Parallel Programming
https://www.classcentral.com/course/swayam-design-and-analysis-of-algorithms-3984,"This course will cover basic concepts in the design and analysis of algorithms.Asymptotic complexity, O() notationSorting and searchAlgorithms on graphs: exploration, connectivity, shortest paths, directed acyclic graphs, spanning treesDesign techniques: divide and conquer, greedy, dynamic programmingData structures: heaps, union of disjoint sets, search treesIntractabilityINTENDED AUDIENCE: Students in BE/BTech Computer Science, 2nd/3rd year.PRE-REQUISITES: Exposure to introductory courses on programming and data structures.INDUSTRY SUPPORT: This course should be of value to any company working in the area of software services and products. 
      


COURSE LAYOUT Week 1Module 1: IntroductionModule 2: Examples and motivationModule 3: Examples and motivationModule 4: Asymptotic complexity: informal conceptsModule 5: Asymptotic complexity: formal notationModule 6: Asymptotic complexity: examplesAssignments MCQ/Fill in blanks (unique answer)Week 2Module 1: Searching in list: binary searchModule 2: Sorting: insertion sortModule 3: Sorting: selection sortModule 4: Sorting: merge sortModule 5: Sorting: quicksortModule 6: Sorting: stability and other issuesAssignments MCQ/Fill in blanks, programming assignmentWeek 3Module 1: Graphs: MotivationModule 2: Graph exploration: BFSModule 3: Graph exploration: DFSModule 4: DFS numbering and applicationsModule 5: Directed acyclic graphsModule 6: Directed acyclic graphsAssignments MCQ/Fill in blanks, programming assignmentWeek 4Module 1: Shortest paths: unweighted and weightedModule 2: Single source shortest paths: DijkstraModule 3: Single source shortest paths: DijkstraModule 4: Minimum cost spanning trees: Prim’s algorithmModule 5: Minimum cost spanning trees: Kruskal’s AlgorithmModule 6: Union-Find data structureAssignments MCQ/Fill in blanks, programming assignmentWeek 5Module 1: Divide and conquer: counting inversionsModule 2: Divide and conquer: nearest pair of pointsModule 3: Priority queues, heapsModule 4: Priority queues, heapsModule 5: Dijstra/Prims revisited using heapsModule 6: Search Trees: IntroductionAssignments MCQ/Fill in blanks, programming assignmentWeek 6Module 1: Search Trees: Traversals, insertions, deletionsModule 2: Search Trees: BalancingModule 3: Greedy : Interval schedulingModule 4: Greedy : Proof strategiesModule 5: Greedy : Huffman codingModule 6: Dynamic Programming: weighted interval schedulingAssignments MCQ/Fill in blanks, programming assignmentWeek 7Module 1: Dynamic Programming: memoizationModule 2: Dynamic Programming: edit distanceModule 3: Dynamic Programming: longest ascending subsequenceModule 4: Dynamic Programming: matrix multiplicationModule 5: Dynamic Programming: shortest paths: Bellman FordModule 6: Dynamic Programming: shortest paths: Floyd WarshallAssignments MCQ/Fill in blanks, programming assignmentWeek 8Module 1: Intractability: NP completenessModule 2: Intractability: reductionsModule 3: Intractability: examplesModule 4: Intractability: more examplesModule 5: Misc topicsModule 6: Misc topicsAssignments MCQ/Fill in blanks",Design and Analysis of Algorithms
https://www.classcentral.com/course/journalism-6009,"Welcome to English for Journalism, a course created by the University of Pennsylvania, and funded by the U.S. Department of State Bureau of Educational and Cultural Affairs, Office of English Language Programs. 

To enroll in this course for free, click on “Enroll now” and then select ""Full Course.  No certificate.""

This course is designed for non-native English speakers who are interested in developing the skills needed for a career in modern journalism. In this course, you will explore print and digital media through authentic readings and video lectures, while expanding your vocabulary and increasing your ability to read, research, and develop local and global news stories. Unit 1 will provide an introduction to the history and principles of journalism. In unit 2, you will learn how to research, pitch, and interview. The next unit in the course will focus on the language needed to write newspaper and magazine articles, while unit 4 will cover the basics of broadcasting the news. In the final unit of the course, you will analyze the growth, impact, and challenges of digital news, while completing a reflection assignment that allows you to think about and discuss the recent changes to the field of journalism.

Unless otherwise noted, all course materials are available for re-use, repurposing and free distribution under a Creative Commons 4.0 Attribution license. 

Supplemental reading materials were provided by Newsela, which publishes daily news articles at a level that's just right for each English language learner.
      


            Read more
          



          Unit 1: Introduction and Principles of Journalism
    -In this unit, you will first learn about how the course works. Then we will explore the history of journalism, as well as important principles, or ideas, that make good journalism possible. 

Unit 2: How to Research, Pitch, and Interview
    -This unit will show you how journalists choose their topics and stories. You will also learn how journalists research their stories and interview their sources. 

Unit 2: How to Research, Pitch, and Interview: Lesson Choices
    -Choice 1: This is the recommended option. | Choice 2: Complete this option if you cannot record a video.

Unit 3: Words in Print
    -This unit will help you to write briefly and with emphasis, create a lead that makes the audience want to read more, and effectively edit and proofread article drafts. At the end of the unit, you will create a lead and write an article based on that lead. 

Unit 4: Broadcasting the News
    -In this unit, we will focus on speaking skills for delivering the news. At the end of the unit, you will write a script and read a news report for other students to listen to. 

Unit 4: Broadcasting the News: Lesson Choices
    -Choice 1: This is the recommended option. | Choice 2: Complete this option if you are unable to complete the video recording.

Unit 5: Journalism in the Digital Age
    -The final unit of this course discusses how journalism is changing fast because of digital technologies. At the end of the unit, you will describe data about the news and complete a reflection assignment that allows you to think about and discuss the recent changes to the field of journalism.",English for Journalism
https://www.classcentral.com/course/business-statistics-5243,"This course provides an analytical framework to help you evaluate key problems in a structured fashion and will equip you with tools to better manage the uncertainties that pervade and complicate business processes. The course aim to cover statistical ideas that apply to managers. We will consider two basic themes: first, is recognizing and describing variations present in everything around us, and then modeling and making decisions in the presence of these variations. The fundamental concepts studied in this course will reappear in many other classes and business settings. Our focus will be on  interpreting the meaning of the results in a business and managerial setting.

While you will be introduced to some of the science of what is being taught, the focus will be on applying the methodologies.  This will be accomplished through use of Excel and using data sets from many different disciplines, allowing you to see the use of statistics in very diverse settings. The course will focus not only on explaining these concepts but also understanding the meaning of the results obtained.

Upon successful completion of this course, you will be able to:
•	Test for beliefs about a population..
•	Compare differences between populations.
•	Use linear regression model for prediction. 
•	Learn how to use Excel for statistical analysis.

This course is part of the iMBA offered by the University of Illinois, a flexible, fully-accredited online MBA at an incredibly competitive price. For more information, please see the Resource page in this course and onlinemba.illinois.edu.
      


            Read more
          



          Course Orientation
    -In the course orientation, you will become familiar with the course, your classmates, and our learning environment. The orientation will also help you obtain the technical skills required for the course.

Module 1: Hypothesis Testing
    -Watch any infomercial and you hear many outrageous promises.  Use this cream and your skin will look 80% firmer!  Use this supplement and you will lose 10 pounds in the first 10 days!  Are they telling you the truth?  Are they all lying? The only way to know the answer to any of these questions is to scientifically test the claim being made – that is what we call hypothesis testing and what we will learn in this module.

Module 2: Statistical Inference Based on Two Samples
    -Does the medicine a person is taking to treat his condition really work better than a sugar pill?  Is the new chip-enabled credit card more secure than the magnetic card? How do you know whether the claims being made about anything being “better than” or “faster than” a competitor are true?  In this module we will learn to make this comparison.

Module 3: Simple Linear Regression
    -Does your job involve a lot of sitting?  If so, you are at higher risk of coronary heart disease.  How do I know this?  We got to know the relationship between coronary heart disease and sitting when researchers studied a cohort of London bus drivers and bus conductors from 1947 to 1972.  If you want to know more, then read on!

Module 4: Multiple Linear Regression
    -You are trying to predict next month’s sales numbers.  You know that dozens, maybe even hundreds, of things like the weather, competitor’s promotions, rumors, etc. can impact the number. You talk to five people and each one has an idea about what makes the biggest impact, and the only thing they offer is “trust me.”  Do you wish there was a better way of doing this rather than relying on blind faith?  Well, there is.  We can use Multiple Regression to sort through this mess and bring the focus to factors that really do matter.",Inferential and Predictive Statistics for Business
https://www.classcentral.com/course/python-basics-12555,"This course introduces the basics of Python 3, including conditional execution and iteration as control structures, and strings and lists as data structures. You'll program an on-screen Turtle to draw pretty pictures. You'll also learn to draw reference diagrams as a way to reason about program executions, which will help to build up your debugging skills. The course has no prerequisites. It will cover Chapters 1-9 of the textbook ""Fundamentals of Python Programming,"" which is the accompanying text (optional and free) for this course.

The course is for you if you're a newcomer to Python programming, if you need a refresher on Python basics, or if you may have had some exposure to Python programming but want a more in-depth exposition and vocabulary for describing and reasoning about programs.

This is the first of five courses in the Python 3 Programming Specialization.
      


          General Introduction
    -In week one you will be introduced to programming in python through lectures and the Runestone textbook - an interactive online textbook built for this course. By the end of the module, you will have run your first python program, and learned how to draw images by writing a program.

Sequences and Iteration
    -In week two you will use the lectures and the Runestone textbook to understand the basics of a few python data types - lists, strings, tuples - as well as a control structure - for loops. By the end of this week, you will be able to write more complex programs that create drawings by incorporating for loops. Finally, we will present the basics of an accumulation pattern to you, which will be expanded on in each week for the rest of the course.

Booleans and Conditionals
    -In week three you will learn a new python data type - the boolean - as well as another control structure - conditional execution. Through the use of video lectures and the Runestone textbook, you will learn what Binary, Unary, Nested, and Chained Conditionals are, as well as how to incorporate conditionals within an accumulation pattern.

Sequence Mutation  and Accumulation Patterns
    -In week four we will present deeper knowledge on using lists, strings, and python objects in general. We will also cover how to use the accumulation pattern with lists and with strings. The final assignment will test your knowledge and skills through application, much like previous assessments and assignments did, though with a more difficult set of tasks now that you have learned the basics.",Python Basics
https://www.classcentral.com/course/swayam-functional-foods-and-nutraceuticals-14069,"The online course on Functional Foods and Nutraceuticals is a 4 credit course of 15 weeks duration. This online course deals with health promoting nutritional factors and bioactive constituents, their potential health implications and mechanisms of action. This course is a part of the approved curriculum and is being taught in Indian Universities for one semester in Masters in Food Science and Nutrition, Clinical Nutrition and Dietetics and Applied Nutrition. After studying this online course, the student shall be able to describe what are functional foods and nutraceuticals, classify the functional foods, discuss the potential health implications and mechanism of functional foods and discuss the applications of functional foods in the industry. The pre-requisites of this course is, the student must be enrolled for Masters degree in Food Science and Nutrition or Clinical Nutrition and Dietetics or Applied Nutrition from Indian Universities. The course shall cover five units viz., ‘Introduction to Functional Foods and Nutraceuticals ,Probiotics, Prebiotics, Other Food Components with Potential Health Benefits and Non Nutrient Effect of Specific Nutrients’. These five units shall be covered in 40 modules and every week two to three modules shall be taught. The final evaluation and credit award of the student shall be based on formative assessments and assignments of 30 marks and summative assessment through online exams of 70 marks. 
      


COURSE LAYOUT Week 1Introduction to Functional Foods and Nutraceuticals :Definition, History and ClassificationPerceived Effects of Functional FoodsWeek 2Introduction to Probiotics,Prebiotics and SynbioticsProbiotics: Taxonomy and Important Features of Probiotic MicroorganismsHealth Effects of Probiotic MicroorganismsWeek 3Probiotics in Various FoodsQuality Assurance of Probiotics and SafetyWeek 4Prebiotics: Non Digestible Carbohydrates/ Oligosaccharides,Prebiotics: Dietary FiberWeek 5Prebiotics: Resistant StarchPrebiotics: GumsWeek 6Polyphenols: Flavonoids, Catechins, Isoflavones, TanninsWeek 7Phytoestrogens, Phytosterols, GlucosinolatesWeek 8Pigments: Carotenoids, Lycopene, CurcuminWeek 9Organosulphur CompoundsIntroduction to Anti-nutritional Factors, PhytatesWeek 10Enzymes, Protease inhibitors, Amylase inhibitorsWeek 11Saponins, Haemagglutinins,An introduction to Active Biodynamic Principles in Spices, Condiments and Plant extractsWeek 12Active Biodynamic Principles in Spices, Condiments and Plant extracts: Resveratrol, Kaempferol, Quercetin, Cinnamaldehyde, Crocin, LutolineWeek 13Active Bio-dynamic Principles in Spices, Condiments and Plant extracts: Capsaicin, Piperine, Gingerol, Eugenol, Rosmarinic acid, Apigenine, ThymoquinoneWeek 14Active Biodynamic Principles in Spices, Condiments and Plant extracts: Fenugreek and DiosgeninNon Nutrient Effect of Specific Nutrients: Conjugated Linoleic Acid, Omega 3 Fatty acids",Functional Foods and Nutraceuticals
https://www.classcentral.com/course/political-economy-8960,"This course is part of the SDG initiative  addressing the UN Sustainable Development Goals, specifically for the following SDGs [1, 8, 10 and 16]. We hope you will join in our efforts to reach the SDG’s in small but measurable and actionable ways, cooperating with Development Done Differently. Expand your impact. You can create a better world.

In today’s world, politics and economics are interconnected, but what is the nature of this connectivity? What are the power relationships that shape the world economy today and create new challenges for international institutions facing globalization? What makes some countries wealthier than others? Do we face cultural diversity or fragmentation? Does the type of governance effect economic development and social change or is it the other way around? How do we measure it and how trustworthy is the data?  These issues and many more will be examined in this course along with a wide library of sources and a biting criticism.
      


          Introduction into this course
    -Welcome to this course! Here we present the instructor and his team, what we will do in the upcoming modules, and what is exactly Political Economy. You play an important role in this module. 
We would also like to hear who you are and what are your expectations from this course. Don't forget to read before that our academic standards and tips and tricks that will help you succeed in this course. Good luck!

Data used in Political Economy
    -Basic Data. Reviews the basic data of population, output and development used to make international comparisons between countries.

Trust
    -Trust. Argues for the centrality of trust in explanations of differences in wealth and poverty between nations but highlights difficulties in measuring it and in explaining the direct of causality.

Society and Fragmentation
    -Inequality and Fragmentation. Examines how society can be fragmented along lines of religion, language, ethnicity and income

Governance
    -Governance. Argues that good governance provides a transparent and stable environment for risk assessment and decision-making and contributes to welfare and growth. The question is how to get it. 

Economic Development
    -Development Assistance. Assesses the motivations for development assistance but raises doubts about the extent to which it can overcome local issues.

Globalisation
    -Let us now focus on the international context of the elements we've seen so far. Globalisation - what is it really? What are the benefits it is supposed to confer and what is the role, if any, left for national governments in today's world?

International organizations
    -International organization. What role do they play in the world economy? 

Non Governmental actors
    -Even though they do not belong to any establishment or an institution, certain non- governmental institutions can have a lot of power and influence. Who are those actors? How much power do they really have? We will dive into these question in this module!

Final
    -The final exam! Good luck!

Extra Material 
    -Not for the test - but very good for your general knowledge!",Political Economy of Institutions and Development
https://www.classcentral.com/course/surveillance-2463,"It’s easy to be
cynical about government surveillance. In recent years, a parade of Orwellian
disclosures have been making headlines. The FBI, for example, is hacking into
computers that run anonymizing software. The NSA is vacuuming up domestic phone
records. Even local police departments are getting in on the act, tracking cellphone location history and intercepting signals in realtime.
Perhaps 2014 is
not quite 1984, though. This course explores how American law facilitates electronic
surveillance—but also substantially constrains it. You will learn the legal
procedures that police and intelligence agencies have at their disposal, as well as the security
and privacy safeguards built into those procedures. The material also provides
brief, not-too-geeky technical explanations of some common surveillance
methods.



I. Introduction
We will begin with a brief overview of how surveillance fits into the American legal system. We will also discuss how surveillance issues can be litigated.


II. The Basics of Surveillance Law
Next, we will review established police surveillance procedures. Using telephone technology as a simple starting point, we will work through various sorts of data that investigators might seek to access—and the constitutional and statutory safeguards on that data.

III. Applying Surveillance Law to Information Technology
Having learned the basics, we will turn to more modern technologies. We will discuss snooping on email, web browsing, and mobile phone location, as well as hacking into devices.

IV. Compelled Assistance to Law Enforcement
What happens when data is technically protected? In this section, we will talk about the government’s (limited) ability to mandate backdoors and to require decryption.

V. The Structure of Foreign Intelligence Surveillance Law
The law that applies to foreign intelligence activities runs parallel to the law that applies to police activities. We will compare the two systems of law and review key distinctions. The section places particular emphasis on Section 215 of the USA PATRIOT Act, Section 702 of the FISA Amendments Act, and Executive Order 12333.

VI. Controversial NSA Programs
In the final section, we will review the conduct and legality of controversial National Security Agency programs. We will discuss in detail the domestic phone metadata program, PRISM, and “upstream” Internet monitoring.",Surveillance Law
https://www.classcentral.com/course/molevol-651,"This course is about molecular evolution - the evolution of DNA, RNA, and protein molecules. The focus is on computational methods for inferring phylogenetic trees from sequence data, and the course will give an introduction to the fundamental theory and algorithms, while also giving the student hands-on experience with some widely used software tools. Since evolutionary theory is the conceptual foundation of biology (in the words of Theodosius Dobzhansky: ""Nothing in biology makes sense except in the light of evolution""), what you learn on this course will be relevant for any project you will ever do inside the life sciences. A phylogenetic tree will almost always help you think more clearly about your biological problem. A special emphasis is put on methods that employ explicit models of the evolutionary process (maximum likelihood and Bayesian approaches), and we will explore the role of statistical modeling in molecular evolution, and in science more generally. A mathematical (statistical) model of a biological system can be considered to be a stringently phrased hypothesis about that system, and this way of thinking about models will often be helpful. In addition to model-based methods, you will also learn about other approaches, such as those based on parsimony and genetic distance (e.g., neighbor joining). Often, the evolutionary tree is the result we are interested in - knowing how a set of sequences (or organisms) are related can provide us with important information about the biological problem we are  investigating. For instance, knowing which organisms are most closely related to a newly identified, uncharacterized, pathogenic bacterium will allow you to infer many aspects of its lifestyle, thereby giving you important clues about how to fight it. In other cases, however, inferring the structure of the tree is not the goal: for instance, our main focus may instead be the detection of positions in a protein undergoing positive selection (indicating adaptation) or negative selection (indicating conserved functional importance). However, even in these cases, the underlying phylogenetic tree will be an important part of our hypothesis about (model of) how the proteins have been evolving, and will help in getting the correct answer. Although the study of molecular evolution does require a certain level of mathematical understanding, this course has been designed to be accessible also for students with limited computational background (e.g., students of biology).Topics covered:Brief introduction to evolutionary theory and population genetics.Mechanisms of molecular evolution.Models of substitution.Reconstruction of phylogenetic trees using parsimony, distance based methods, maximum likelihood, and Bayesian techniques.Advanced models of nucleotide substitution (gamma-distributed mutation rates, codon models and analysis of selective pressure).Statistical analysis of biological hypotheses (likelihood ratio tests, Akaike Information Criterion, Bayesian statistics).



            Read more
          



Module 1:   Introduction to evolutionary theory and population genetics: models of growth, selection and mutationModule 2:   Neutral mutations and genetic drift. Tree reconstruction by parsimonyModule 3:   Consensus trees. Distance matrix methodsModule 4:   Models of sequence evolution. Likelihood methodsModule 5:   Bayesian inference of phylogenyModule 6:   Testing hypotheses in a phylogenetic context",Computational Molecular Evolution
https://www.classcentral.com/course/climateliteracy-844,"This course explores the basic concepts and terms needed to understand
    the science of climate change, and the available mitigation, adaptation
    and policy options. By the end of the course, students will be able to:
·  Tell the story of our climate, describing how interactions among
    atmosphere, ocean, land, and life lead to climatic changes at all timescales
·  Evaluate the likely effect of historical human fossil emissions
    and land use changes on Earth’s energy balance and climate.
·  Describe the direct observations of climate change in recent decades, and articulate the evidence attributing global
    warming in this time period to human causes.
·  Assess the utility - and limits - of climate models to predict
    global and regional climate change.
·  Articulate the demographic, economic, technological and political
    factors that influence both humans’ impact on the climate and humans’ vulnerability
    to climate change.
·  Express an informed opinion on the scope and urgency of the efforts
    needed to both mitigate and adapt to climate change.
 We provide the scientific basics of climate change paired with the
    response options (mitigation and adaptation) and policy landscape. Focusing
    exclusively on the science of climate change may not allow a nuanced understanding
    of the social implications of this science.  Similarly, political
    or economic analyses of climate change frequently neglect the underlying
    mechanics behind climate change thresholds, feedbacks, and the potential
    for abrupt change. This course explores linkages between climate change
    and other pressing priorities such as human health, poverty, community
    livability, economic resilience, and other environmental problems (such
    as biodiversity and water quality).  We acknowledge the urgent need
    to design innovative strategies that realize multiple objectives (or co-benefits)
    simultaneously, and explore the particular capacity for sustainability
    and climate change to provide an avenue for achieving these objectives. 



            Read more
          



Climate Literacy is delivered in ten Modules.  The first half of
    the course deals mainly with climate change science and models, while the
    second half of the course speaks to climate change impacts, response options,
    and polices.  The Modules are as follows: 
1.
 Climate in the public sphere

Climate change is a pervasive and challenging phenomenon that can be viewed
    through a multitude of lenses. A scientific lens, for instance, reveals
    altered ecosystems and climatic tipping points while the lens of ethics
    raises the question of the right to develop and influence the well-being
    of others while doing so. This module will introduce you to a few of the
    core concepts that you will need to delve deeper into the science and policy
    of climate change. We will explore the broad findings offered by the scientific
    community with regard to our influence on the climate system, the policy
    tools that we have developed to respond to this challenge, and the core
    of the climate change debate in scientific, political, and lay communities.
2.
 Introduction to the climate system

In this first module of the science section of
the course, we’ll look at the big picture of Earth’s climate system.  What are the parts?  What are some of the major interactions among
the parts?  We’ll spend some time
learning about the energy-related units we’ll use in this course, some basics
of systems dynamics, which is one of the overarching frameworks in this course,
and then we’ll have a look at data showing how Earth’s climate has changed over
time.  




3. 
Earth's
energy budget

This module covers the basics of climatology at the planetary scale. We will trace the path of energy coming in from the
    Sun and leaving the planet as thermal radiation (or infrared), and explore
    the various factors affecting these flows: greenhouse gases, aerosols, surface albedo, and clouds. We will investigate how humans influence    these climate controls, and compare
    anthropogenic factors to natural factors such as variation in solar energy
    and volcanic eruptions.
4.
The carbon cycle

Our planet breathes; its biosphere on land and in the oceans inhales and
    exhales oxygen and carbon dioxide every second. Even water and rocks exchange
    carbon dioxide with the atmosphere. Humans, particularly through deforestation
    and fossil fuel use, have a significant impact on the planetary carbon cycle. This module explores the natural
    carbon cycle, the perturbations in carbon stocks and flows from human activities, and the climate system's response to human perturbations. 
5.
 Climate models

Climate models are crucial tools to help people understand the complexities and dynamic interactions within Earth's climate system.  Models are built on our understanding of basic physics and Earth processes, and are grounded in observations and measurements of the world around us.  In this module, we'll explore different types of climate models, consider some of the choices you'd need to make as a climate modeler, and have a look at some climate model output compared to observations.  Since we only have one planet, and can only run one global climate experiment in the real world, models are our only tools to help us peer into the future and ask ""what if..."" questions.  The range of probable outcomes from possible future scenarios helps us make decisions about mitigation and adaptation.  6. 
Future climate

Now that we have a clearer sense of the principles, components
    and assumptions of climate models, we’ll look more closely at their results.
    Given hypothetical future pathways, including possibilities for our own future actions, like carbon emissions, what range of temperature
    increases can we expect? How will future changes affect the climatic factors that
    are most relevant to humans and ecosystems: precipitation, circulation
    patterns, extreme events, melting of snow and ice, etc? These global projections
    give us estimates of what we can expect if we embark on various emission
    and development paths, and offer a broad view for decision-making. The least well-known aspect of these projections is what choices we, the human community, will make in the future. 
7.
 Climate change impacts

As we have seen, the emission of vast quantities of greenhouse gases by
    humans fundamentally influences the global climatic system. The chain reaction
    does not end here, however. Rising temperatures and sea levels, changing
    precipitation patterns, and ocean acidification, for instance, trigger
    dramatic shifts in the way that human and natural systems function.
This module forms the transition between the science of climate change,
    which we have explored in Modules 2-6, and the more human-oriented Modules
    7-10.
8.
 Climate change mitigation: dealing with the
causes


Now that we understand the central causes of anthropogenic climate change,
    and the impacts that we can expect to (and already) experience, the next
    step is to explore the response options that are available to us. The most
    commonly-discussed response to climate change is mitigation: tackling the
    causes of climate change by reducing the concentration of greenhouse gases
    in the atmosphere. The aim of mitigation is to reduce the severity and
    frequency of climate change impacts, thereby protecting ecosystems and
    human societies.
This module will explore the basic concept of mitigation, the core mitigation
    strategies that we currently have available to us, the innovative action
    that is being taken around the world, and leading-edge ideas with regard
    to tackling the roots of climate change. By the end of this module, you
    will be able to critique the likelihood of implementation of many of these
    strategies, and will have a framework through which you can learn more
    about greenhouse gas management, both at home and around the world.
9.
 Climate change adaptation: dealing with the
effects

In contrast to the previous module, this module introduces the idea of
    addressing the impacts of climate change rather than its causes. In particular,
    we will explore the various adaptation strategies that are available to
    be utilized around the world, the heated debate surrounding the equity
    implications of adaptation, and the linkages between adaptation and mitigation.
    By the end of this module we will have explored the difference between
    proactive and reactive adaptation, and our track record with both. We will
    outline the most common and effective adaptation strategies, including
    those related to human settlements, ecosystems, and the broader issue of
    development. Finally, we will explore the inevitable trade-offs between
    adaptation and mitigation, setting us up to finish this course with a survey
    of climate change response policies.
10.
 Policy
tools for mitigation and adaptation

This Module forms a bridge between this first course in the Decision-making
    for Climate Change series, and the three courses that will follow. Given
    what we know now about the science behind climate change, and the strategies
    that we have at our disposal for responding to it, we can now be introduced
    to policies that bear this in mind. After being introduced to the fundamentals
    of mitigation and adaptation policy, we will use the British Columbia carbon
    tax and the proposed cap-and-trade system in the United States as relevant
    examples. Finally, we will finish with a glimpse forward to the future
    of climate change policy, and the most promising opportunities for both
    managing impacts and ensuring a rapid transition to a fundamentally low-carbon
    development path.",Climate Literacy: Navigating Climate Change Conversations
https://www.classcentral.com/course/opensap-next-steps-in-software-development-on-sap-hana-2489,"SAP HANA is an in-memory data platform that is deployable either as an appliance or in the cloud. At its core, it is an innovative, in-memory, relational database management system that exploits all the capabilities of current hardware to increase application performance, reduce total cost of ownership, and enable new scenarios and applications that were not possible before.
SAP HANA enables you to build applications that integrate the business logic, the control logic, and the database layer with unprecedented performance. As a developer, one of the key issues is how to minimize data movements. The more you can do directly on the data in memory next to the CPUs, the better the application will perform.
This course will build upon last year’s Introduction to Software Development on SAP HANA course and go deeper into each of the major topics around SAP HANA native development. We will explore the many advances in the programming model and tooling that came with SAP HANA SPS6, SPS7, and SPS8.During the course, we will use SAP HANA studio as well as several new Web-based tools (for example, the Web-based Development Workbench, SAP HANA Lifecycle Management, and SAP HANA XS Administration Tool).We will also go well beyond the basics of each of the programming models, allowing discussion of deeper, real-world patterns and anti-patterns. We will look at the architecture of applications that are not just read-only or analytic but also transactional or provide an interface with transactional systems. We will also look at the extended capabilities of SAP HANA, from beyond a database to a complete application platform.
Registration, learning content, final exam, and Record of Achievement are free of charge. However, to fully benefit from the course, you can access a fee-based system environment to develop your own code.
Course Requirements

A basic knowledge of database technology, especially relational databases, SQL query language, and JavaScript
A general understanding of how columnar, in-memory databases work
Completion of the Introduction to Software Development on SAP HANA course or similar basic experience with SAP HANA native development




            Read more
          




Week 1: Introduction
Week 2: Database and Modeling
Week 3: SQLScript Advanced
Week 4: OData Services (XSODATA)
Week 5: Server-Side JavaScript (XSJS)
Week 6: Miscellaneous Topics / Wrap-Up
I Like, I Wish: We Love Your Feedback … And Want More
Final Exam: Good Luck!",Next Steps in Software Development on SAP HANA
https://www.classcentral.com/course/edx-optimization-methods-in-business-analytics-6735,"Optimization is the search for the best and most effective solution. In this mathematics course, we will examine optimization through a Business Analytics lens. You will be introduced to the to the theory, algorithms, and applications of optimization. Linear and integer programming will be taught both algebraically and geometrically, and then applied to problems involving data. Students will develop an understanding of algebraic formulations, and use Julia/JuMP for computation. Theoretical components of the course are made approachable, and require no formal background in linear algebra or calculus.
The recommended audience for this course is undergraduates, as well as professionals interested in using optimization software. The content in this course has applications in logistics, marketing, project management, finance, statistics and machine learning.
Most of the course material will be covered in lecture and recitation videos, and only an optional textbook, available at no cost, will be used.
Students interested in the material prior to deciding on course enrollment can visit the MIT Open Courseware version of 15.053 Spring 2013. The topics of the 2013 subject were optimization modeling, algorithms, and theory. As a six week subject, 15.053x covers about half of the material of the 2013 subject. The primary focus of 15.053x is optimization modeling.",Optimization Methods in Business Analytics
https://www.classcentral.com/course/accessibility-13860,"This course introduces some of the fundamental principles of accessibility and prepares learners for further study in accessibility and inclusive design. Learners will have an opportunity to explore the major types of disabilities and related assistive technology and adaptive strategies, the most salient contours of the legal landscape, and the major principles that guide universal design and accessible content creation. Spotlight guest videos will highlight firsthand perspectives on disability, as well as topics like disability etiquette, universal design and universal design for learning, accommodation in higher education, campus accessibility policy, and accessibility in a corporate setting.
      


          Course Orientation
    -You will become familiar with the course, your classmates, and our learning environment. The orientation will also help you obtain the technical skills required for the course.

Module 1: Understanding Disability and Assistive Technology
    -This module will give you a basic understanding of some of the major disability types (visual, hearing, motor, and cognitive), their main functional challenges, and some of the related assistive technologies. You’ll also get valuable firsthand perspectives on disabilities and assistive technology from people with different disabilities, including a spirited panel discussion on disability etiquette from a team of disability experts.

Module 2: The Legal Landscape and the Workplace
    -In this module, you’ll develop a basic understanding of some of the key legislation that impacts accessibility. From the workplace perspective, you’ll have an opportunity to explore some insightful firsthand occupation-specific perspectives from a web developer, a media specialist, an instructional designer, and a computer science instructor. Finally, you’ll get an insider’s view on accommodation from a team of accommodation specialists who handle document conversion, captioning, audio description, accessible document design, and testing accommodations.

Module 3: Universal Design
    -This module will give you a basic understanding of the seven principles of universal design and the roots of universal design in architecture. You’ll learn how universal design can be applied in a learning context through Universal Design for Learning (UDL) and its inclusive design practices. Video interviews with recognized experts in the field will highlight insightful IT perspectives on universal design along with higher ed perspectives on Universal Design for Learning.

Module 4: Accessible Digital Materials
    -This module will give you an introduction to some of the major accessibility considerations that apply to common digital formats like HTML, MS Word, PDF, and PowerPoint. You’ll also learn some of the key accessibility considerations for multimedia, including areas like captioning and complex images. Helpful demos and hands-on activities will give you a clearer idea of how you can make your digital content more accessible.",An Introduction to Accessibility and Inclusive Design
https://www.classcentral.com/course/bigdataschool-2482,"This is not a class as it is commonly understood; it is the set of materials from a summer school offered by Caltech and JPL, in the sense used by most scientists: an intensive period of learning of some advanced topics, not on an introductory level. The school will cover a variety of topics, with a focus on practical 
computing applications in research: the skills needed for a 
computational (""big data"") science, not computer science.  The specific 
focus will be on applications in astrophysics, earth science (e.g., 
climate science) and other areas of space science, but with an emphasis 
on the general tools, methods, and skills that would apply across other 
domains as well.  It is aimed at an audience of practicing researchers who already have a strong background in computation and data analysis.  The lecturers include computational science and 
technology experts from Caltech and JPL.Students can evaluate their own progress, but there will be no tests, exams, and no formal credit or certificates will be offered.



The anticipated schedule of lectures (subject to changes):Each bullet bellow corresponds to a set of materials that includes approximately 2 hours of video lectures, various links and supplementary materials, plus some on-line, hands-on exercises.1. Introduction to the school.  Software architectures.  Introduction to Machine Learning.2. Best programming practices.  Information retrieval.3. Introduction to R.  Markov Chain Monte Carlo.4. Statistical resampling and inference.5. Databases.6. Data visualization.7. Clustering and classification.8. Decision trees and random forests.9. Dimensionality reduction.  Closing remarks.",The Caltech-JPL Summer School on Big Data Analytics
https://www.classcentral.com/course/swayam-industrial-automation-and-control-5222,"This course provides an overall exposure to the technology of Industrial Automation and Control as widely seen in factories of all types both for discrete and continuous manufacturing. The course, in 52 lectures, discusses a wide range of related topics from the advantage and architecture of automation systems, measurement systems including sensors and signal conditioning, discrete and continuous variable control systems, hydraulic, pneumatic and electric actuators, industrial communication and embedded computing and CNC Machines. A student of IIT Kharagpur once commented - “ because of the course I can identify and relate to much of the equipment that I see in a factory”.INTENDED AUDIENCE : Any interested studentPREREQUISITES : Electrical Networks, Control SystemsINDUSTRY SUPPORT : All Process Control (Oil and Gas, Chemical), Manufacturing (Machine tools, Textile) etc.



COURSE LAYOUT Module I1 Introduction2 Introduction(Cont.)3 Architecture of Industrial Automation Systems4 Architecture of Industrial Automation Systems(Cont.)Module II5 Measurement Systems Characteristics6 Measurement Systems Characteristics(Cont.)7 Data Acquisition Systems8 Data Acquisition Systems(Cont.)Module III9 Introduction to Automatic Control10 Introduction to Automatic Control(Cont.)11 P-I-D Control12 P-I-D Control(Cont.)13 PID Control Tuning14 PID Control Tuning(Cont.)15 Feedforward Control Ratio Control16 Feedforward Control Ratio Control(Cont.)17 Time Delay Systems and Inverse Response Systems18 Time Delay Systems and Inverse Response Systems(Cont.)19 Special Control Structures20 Special Control Structures(Cont.)21 Concluding Lesson on Process Control (Self-study)22 Introduction to Sequence Control, PLC , RLL23 Introduction to Sequence Control, PLC , RLL(Cont.)24 Sequence Control. Scan Cycle, Simple RLL Programs25 Sequence Control. Scan Cycle, Simple RLL Programs(Cont.)26 Sequence Control. More RLL Elements, RLL Syntax27 Sequence Control. More RLL Elements, RLL Syntax(Cont.)28 A Structured Design Approach to Sequence Control29 A Structured Design Approach to Sequence Control(Cont.)30 PLC Hardware Environment31 PLC Hardware Environment(Cont.)Module IV32 Flow Control Valves33 Flow Control Valves(Cont.)34 Hydraulic Control Systems - I35 Hydraulic Control Systems - I(Cont.)36 Hydraulic Control Systems - II37 Hydraulic Control Systems - II(Cont.)38 Industrial Hydraulic Circuit39 Industrial Hydraulic Circuit(Cont.)40 Pneumatic Control Systems - I41 Pneumatic Control Systems - I(Cont.)42 Pneumatic Systems - II43 Pneumatic Systems - II(Cont.)44 Energy Savings with Variable Speed Drives45 Energy Savings with Variable Speed Drives(Cont.)46 Introduction To CNC Machines47 Introduction To CNC Machines(Cont.)Module V48 The Fieldbus Network - I49 The Fieldbus Network - I(Cont.)50 Higher Level Automation Systems51 Higher Level Automation Systems(Cont.)52 Course Review and Conclusion (Self-study)",Industrial Automation and Control
https://www.classcentral.com/course/demandmanagement-4274,"The biggest challenge facing the hospitality industry over the next 5 years is the lack of integration between the key commercial disciplines of sales, revenue, distribution and finance and the negative impact this will continue to have on delivering asset value and maximum profitability.

This course, spread over 4 key modules:

Asset Management
Demand Generation
Digital Marketing
Demand Optimisation

aims to break down these commercial silos and reveal the journey from long-term asset development through to short-term profit tactics and how commercial teams can align themselves throughout the organisation.

Created by SnapShot, this course is hosted by a group of experienced Industry guest lecturers in their fields of expertise and includes an ideal mix of accessible theory and practical exercises and simulations.

SnapShot is a Hotel Demand Management company that specializes in helping hotels aggregate and use their data. We provide useful tools as well as innovative education and coaching services to empower hotels to take informed decisions in managing their demand to increase profits.
      


          Asset Management
    -After a short introduction and definition of asset management, this module will explore the relationship between what we call the ""Asset management triangle"" actors. We will then walk through the different milestones of a hotel project, from start to finish, from initial plan to exit.

Demand Generation
    -In this module, you will understand what demand generation means, and explore the key factors that ensure that you can achieve your goals in terms of the hotel's positioning in the market place, the profitability of the operation and its long term valuation.

Online Marketing
    -Marketing is about making something known, desired and bought by the right public.  While this hasn't changed, the means to achieve it has changed exponentially over the last two decades. As the customer searches for and finds your hotel, you will have to deal with the costs of distribution and how to sell through the most profitable channels to keep a healthy bottom line, while ensuring adequate visibility and top line. 

Revenue Management
    -In this module, we will look at what problems Revenue Management was invented to help hotels and other similar business overcome. Then we will go through each of the critical six steps of the Revenue Management Cycle answering such questions along the way as: Where do I get the data I need from? What do I do with the data once I have it? How can I predict what is going to happen in the future? What kind of forecasting method can I use? What decisions do I need to make to get the most revenue and profit?",Demand management: Breaking down today’s commercial silos
https://www.classcentral.com/course/information-visualization-programming-d3-11817,"In this course you will learn how to use D3.js to create powerful visualizations for web. Learning D3.js will enable you to create many different types of visualization and to visualize many different data types. It will give you the freedom to create something as simple as a bar chart as well your own new revolutionary technique. 

In this course we will cover the basics of creating visualizations with D3 as well as how to deal with tabular data, geography and networks. By the end of this course you will be able to:

- Create bar and line charts
- Create choropleth and symbol maps
- Create node-link diagrams and tree maps
- Implement zooming and brushing
- Link two or more views through interaction

The course mixes theoretical and practical lectures. We will show you step by step how to use the library to build actual visualizations and what theoretical concepts lie behind them. Throughout the course you will learn skills that will lead you to building a whole application by the end of the lectures (a fully working visualization system to visualize airlines routes).

This course is the third one of the “Specialization in Information Visualization"". The course expects you to have some basic knowledge of programming as well as some basic visualization skills.
      


          Introduction to web and d3
    -In this module we will focus on the basics of web development and d3.js

Dealing  & drawing with data
    -In this week we will learn how can we load and manipulate data using d3.js

Lines, Arcs, and maps

Layouts and interaction",Information Visualization: Programming with D3.js
https://www.classcentral.com/course/edx-big-data-and-social-physics-1989,"Social physics is a big data science that models how networks of people behave and uses these network models to create actionable intelligence. It is a quantitative science that can accurately predict patterns of human behavior and guide how to influence those patterns to (for instance) increase decision making accuracy or productivity within an organization. Included in this course is a survey of methods for increasing communication quality within an organization, approaches to providing greater protection for personal privacy, and general strategies for increasing resistance to cyber attack.",Big Data and Social Physics
https://www.classcentral.com/course/algorithms-on-graphs-5479,"If you have ever used a navigation service to find optimal route and estimate time to destination, you've used algorithms on graphs. Graphs arise in various real-world situations as there are road networks, computer networks and, most recently, social networks! If you're looking for the fastest time to get to work, cheapest way to connect set of computers into a network or efficient algorithm to automatically find communities and opinion leaders in Facebook, you're going to work with graphs and algorithms on graphs.

In this course, you will first learn what a graph is and what are some of the most important properties. Then you'll learn several ways to traverse graphs and how you can do useful things while traversing the graph in some order. We will then talk about shortest paths algorithms — from the basic ones to those which open door for 1000000 times faster algorithms used in Google Maps and other navigational services. You will use these algorithms if you choose to work on our Fast Shortest Routes industrial capstone project. We will finish with minimum spanning trees which are used to plan road, telephone and computer networks and also find applications in clustering and approximate algorithms.
      


          Decomposition of Graphs 1
    -Graphs arise in various real-world situations as there are road networks, computer networks and, most recently, social networks! If you're looking for the fastest time to get to work, cheapest way to connect set of computers into a network or efficient algorithm to automatically find communities and opinion leaders hot in Facebook, you're going to work with graphs and algorithms on graphs. In this module, you will learn ways to represent a graph as well as basic algorithms for decomposing graphs into parts. In the programming assignment of this module, you will apply the algorithms that you’ve learned to implement efficient programs for exploring mazes, analyzing Computer Science curriculum, and analyzing road networks. In the first week of the module, we focus on undirected graphs.

Decomposition of Graphs 2
    -This week we continue to study graph decomposition algorithms, but now for directed graphs.

Paths in Graphs 1
    -In this module you will study algorithms for finding Shortest Paths in Graphs. These algorithms have lots of applications. When you launch a navigation app on your smartphone like Google Maps or Yandex.Navi, it uses these algorithms to find you the fastest route from work to home, from home to school, etc. When you search for airplane tickets, these algorithms are used to find a route with the minimum number of plane changes. Unexpectedly, these algorithms can also be used to determine the optimal way to do currency exchange, sometimes allowing to earh huge profit! We will cover all these applications, and you will learn Breadth-First Search, Dijkstra's Algorithm and Bellman-Ford Algorithm. These algorithms are efficient and lay the foundation for even more efficient algorithms which you will learn and implement in the Shortest Paths Capstone Project to find best routes on real maps of cities and countries, find distances between people in Social Networks. In the end you will be able to find Shortest Paths efficiently in any Graph. This week we will study Breadth-First Search algorithm.

Paths in Graphs 2
    -This week we continue to study Shortest Paths in Graphs. You will learn Dijkstra's Algorithm which can be applied to find the shortest route home from work. You will also learn Bellman-Ford's algorithm which can unexpectedly be applied to choose the optimal way of exchanging currencies. By the end you will be able to find shortest paths efficiently in any Graph.

Minimum Spanning Trees
    -In this module, we study the minimum spanning tree problem. We will cover two elegant greedy algorithms for this problem: the first one is due to Kruskal and uses the disjoint sets data structure, the second one is due to Prim and uses the priority queue data structure. In the programming assignment for this module you will be computing an optimal way of building roads between cities and an optimal way of partitioning a given set of objects into clusters (a fundamental problem in data mining).

Advanced Shortest Paths Project (Optional)
    -In this module, you will learn Advanced Shortest Paths algorithms that work in practice 1000s (up to 25000) of times faster than the classical Dijkstra's algorithm on real-world road networks and social networks graphs. You will work on a Programming Project based on these algorithms. You will find the shortest paths on the real maps of parts of US and the shortest paths connecting people in the social networks. We encourage you not only to use the ideas from this module's lectures in your implementations, but also to come up with your own ideas for speeding up the algorithm! We encourage you to compete on the forums to see whose implementation is the fastest one :)",Algorithms on Graphs
https://www.classcentral.com/course/python-for-data-visualization-11199,"""A picture is worth a thousand words"". We are all familiar with this expression. It especially applies when trying to explain the insight obtained from the analysis of increasingly large datasets. Data visualization plays an essential role in the representation of both small and large-scale data.

One of the key skills of a data scientist is the ability to tell a compelling story, visualizing data and findings in an approachable and stimulating way. Learning how to leverage a software tool to visualize data will also enable you to extract information, better understand the data, and make more effective decisions.

The main goal of this Data Visualization with Python course is to teach you how to take data that at first glance has little meaning and present that data in a form that makes sense to people. Various techniques have been developed for presenting data visually but in this course, we will be using several data visualization libraries in Python, namely Matplotlib, Seaborn, and Folium.

LIMITED TIME OFFER: Subscription is only $39 USD per month for access to graded materials and a certificate.
      


          Introduction to Data Visualization Tools
    -In this module, you will learn about data visualization and some of the best practices to keep in mind when creating plots and visuals. You will also learn about the history and the architecture of Matplotlib and learn about basic plotting with Matplotlib. In addition, you will learn about the dataset on immigration to Canada, which will be used extensively throughout the course. Finally, you will briefly learn how to read csv files into a pandas dataframe and process and manipulate the data in the dataframe, and how to generate line plots using Matplotlib.

Basic and Specialized Visualization Tools
    -In this module, you learn about area plots and how to create them with Matplotlib, histograms and how to create them with Matplotlib, bar charts, and how to create them with Matplotlib, pie charts, and how to create them with Matplotlib, box plots and how to create them with Matplotlib, and scatter plots and bubble plots and how to create them with Matplotlib.


Advanced Visualizations and Geospatial Data
    -In this module, you will learn about advanced visualization tools such as waffle charts and word clouds and how to create them. You will also learn about seaborn, which is another visualization library, and how to use it to generate attractive regression plots. In addition, you will learn about Folium, which is another visualization library, designed especially for visualizing geospatial data. Finally, you will learn how to use Folium to create maps of different regions of the world and how to superimpose markers on top of a map, and how to create choropleth maps.",Data Visualization with Python
https://www.classcentral.com/course/machinelearningwithbigdata-4238,"Want to make sense of the volumes of data you have collected?  Need to incorporate data-driven decisions into your process?  This course provides an overview of machine learning techniques to explore, analyze, and leverage data.  You will be introduced to tools and algorithms you can use to create machine learning models that learn from data, and to scale those models up to big data problems.

At the end of the course, you will be able to:
•	Design an approach to leverage data using the steps in the machine learning process.
•	Apply machine learning techniques to explore and prepare data for modeling.
•	Identify the type of machine learning problem in order to apply the appropriate set of techniques.
•	Construct models that learn from data using widely available open source tools.
•	Analyze big data problems using scalable machine learning algorithms on Spark.

Software Requirements: 
Cloudera VM, KNIME, Spark
      


          Welcome

Introduction to Machine Learning with Big Data

Data Exploration

Data Preparation

Classification

Evaluation of Machine Learning Models

Regression, Cluster Analysis, and Association Analysis",Machine Learning With Big Data
https://www.classcentral.com/course/coursera-internet-emerging-technologies-3933,"This is a notice to inform you that the “Internet Emerging Technologies” course will close for new learner enrollment on September 17, 2018. Since you have already enrolled, you will continue to see it on your Coursera Dashboard as long as you remain enrolled in the course. If you are interested in earning a Course Certificate for this course, please upgrade or apply for Financial Aid by September 16, 2018, if you have not already done so. In order to earn a Course Certificate, you will need to complete all graded assignments, including peer reviews, by March 17, 2019. After that point, no new assignment submissions will be accepted for Certificate credit. The reason to close this course is because a new course “Introduction to TCP/IP” has already been released and a new upgraded ""Emerging Technologies: From Smartphones to IoT to Big Data"" Specialization has been prepared and will be launched in a few weeks. I recommended you to check the “Introduction to TCP/IP” course for more details on the Internet and security as well as a location and network traffic analysis projects using Wireshark. While we hope that you will be able to complete the course, you can find more information about requesting a refund (https://learner.coursera.help/hc/en-us/articles/209819043-Request-a-refund) or unenrolling from a course (https://learner.coursera.help/hc/en-us/articles/208279756-Unenroll-from-a-course) in our Learner Help Center. We sincerely thank you for your interest and contributions to this course. In addition, we sincerely hope you will be interested in the new courses as well.
      


            Read more",Internet Emerging Technologies
https://www.classcentral.com/course/global-systems-science-5190,"##
Policy seeks desired outcomes given differing priorities and constraints. But which policy options will work?  Working together for better outcomes, the elements of Global Systems Science are:


Policy at all levels: from individuals to the world


Complex Systems Science: a new, interdisciplinary approach to modelling social and physical systems


Policy informatics: data science and computational modelling for policy


Citizen engagement: societal behaviour emerges bottom-up in the context of top-down policy and individual citizens must be involved


We discuss and critically evaluate GSS.
No prior knowledge is required for this course. It is aimed at:

policy makers;
officials in the European Commission;
UNESCO officials and field workers;
members of local, national and international charities and NGOs;
national and local government civil servants and politicians;
social scientists;
information and communications systems developers;
students with the UNESCO UniTwin Complex Systems Digital Campus;
or anyone interested in how new scientific approaches can support policy.",Global Systems Science and Policy: an Introduction
https://www.classcentral.com/course/fpga-training-nios-ii-13678,"The complexity of digital logic designs requires understanding of large scale devices such as Field Programmable Gate Arrays (FPGAs) to realize solutions.  Implementation in discrete components is nearly impossible to realize and debug due to the growing complexity of solutions.  Integration of processor capability into one platform enables reduction in size and conservation of power with improved microelectronic hardware.  The focus of this specialization is the practical use of Soft Processors with emphasis on testing and debugging in applications of video.  

Hands on bring up of DE10-Lite board with expansion into the use of the VGA output interface is provided.  Focus on the use of the NIOS II processor to control Video IP for generation of test pattern output after reviewing the sample test pattern demonstration in Verilog.  Review of the manual for the implementation of Video IP for display of signals using the Avalon-ST streaming protocol is covered.  Tools for the design of systems are provided which include the System Console and TCL scripts for evaluation of board and processor interfaces with custom project, and an embedded Logic Analyzer for probing of signal values to characterize performance and state transition.  A traffic light controller and thunderbird tail lights are used to provide hands-on examples.
      


          Hardware setup and verification for DE10-Lite with VGA monitor output 
    -Focus on the use of hardware platform with detailed support for key steps necessary to launch solutions from demonstration folders provided by manufacturer of FPGA systems.  Examples provided with an emphasis on video.  Additional resources are pointed out for access.  Peer review assignment evaluates understanding of key concepts in FPGA design software and interaction with TPG and CVO Video IP blocks. 

Methods and approaches for testing FPGA designs
    -Overview of tools for design verification for functionality and performance.  Discussion of system console capabilities using TCL scripts with emphasis on board bring up and processor evaluation.  Description of embedded logic analyzer capabilities with triggering for state transition verification and logic operation along with capabilities to store results for data analysis.  Brief introduction to external memory evaluation capabilities to be discussed in future modules.

NIOS II IP for Video and Performance Monitoring
    -This module covers the use of additional Video IP suite modules with emphasis on the bus interfaces used for streaming along with more test modules that are available in System Console for verification.  Introduction to custom IP blocks is provided using TCL and the Custom IP capabilities in the Soft Processor environment of Qsys provided by the Intel development tools for FPGA design.",Expanded FPGA Training with NIOS II
https://www.classcentral.com/course/trading-strategies-reinforcement-learning-17913,"This course is for finance professionals, investment management professionals, and traders. Alternatively, this Specialization can be for machine learning professionals who seek to apply their craft to trading strategies. 

At the end of the course you will be able to do the following: 

- Understand what reinforcement learning is and how trading is an RL problem
- Build Trading Strategies Using Reinforcement Learning (RL)
- Understand the benefits of using RL vs. other learning methods
- Differentiate between actor-based policies and value-based policies 
- Incorporate RL into a momentum trading strategy

To be successful in this course, you should have a basic competency in Python programming and familiarity with the Scikit Learn, Statsmodels and Pandas library.You should have a background in statistics (expected values and standard deviation, Gaussian distributions, higher moments, probability, linear regressions) and foundational knowledge of financial markets (equities, bonds, derivatives, market structure, hedging).
      


          Introduction to Course and Reinforcement Learning
    -In this module, reinforcement learning is introduced at a high level. The history and evolution of reinforcement learning is presented, including key concepts like value and policy iteration. Also, the benefits and examples of using reinforcement learning in trading strategies is described.  We also introduce LSTM and AutoML as additional tools in your toolkit to use in implementing trading strategies.

Neural Network Based Reinforcement Learning
    -In the previous module, reinforcement learning was discussed before neural networks were introduced. In this module, we look at how reinforcement learning has been integrated with neural networks. We also look at LSTMs and how they can be applied to time series data. 

Portfolio Optimization
    -In this module we discuss the practical steps required to create a reinforcement learning trading system. Also, we introduce AutoML, a powerful service on Google Cloud Platform for training machine learning models with minimal coding.",Reinforcement Learning for Trading Strategies
https://www.classcentral.com/course/compfinance-460,"Learn mathematical, programming and statistical tools used in the real world analysis and modeling of financial data. Apply these tools to model asset returns, measure risk, and construct optimized portfolios using the open source R programming language
    and Microsoft Excel.  Learn how to build probability models for asset returns, to apply statistical techniques to evaluate if asset returns are normally distributed, to use Monte Carlo simulation and bootstrapping techniques to evaluate statistical
    models, and to use optimization methods to construct efficient portfolios.
You'll do the R assignments for this course on DataCamp.com, an online interactive learning platform that offers free R tutorials through learning-by-doing.
    The platform provides you with hints and instant feedback on how to perform even better. Every week, new labs will be posted.  



          Topics covered include:

Computing asset returns
Univariate random variables and distributions

Characteristics of distributions, the normal distribution, linear function of random variables, quantiles of a distribution, Value-at-Risk

Bivariate distributions

Covariance, correlation, autocorrelation, linear combinations of random variables

Time Series concepts

Covariance stationarity, autocorrelations, MA(1) and AR(1) models

Matrix algebra
Descriptive statistics

histograms, sample means, variances, covariances and autocorrelations

The constant expected return model

Monte Carlo simulation, standard errors of estimates, confidence intervals, bootstrapping standard errors and confidence intervals, hypothesis testing , Maximum likelihood estimation, review of unconstrained optimization methods

Introduction to portfolio theory
Portfolio theory with matrix algebra

Review of constrained optimization methods, Markowitz algorithm, Markowitz Algorithm using the solver and matrix algebra

Statistical Analysis of Efficient Portfolios
Risk budgeting

Euler’s theorem, asset contributions to volatility, beta as a measure of portfolio risk

The Single Index Model

Estimation  using simple linear regression",Introduction to Computational Finance and Financial Econometrics
https://www.classcentral.com/course/sensation-perception-11042,"Explore the role of touch, sight, hearing, taste and smell in our behaviour
How do our sensory systems work together to help us understand the world and somebody else’s behaviour?
On this course, you’ll find out - investigating perception and how our senses help our mind create the world we live in. You’ll also explore the differences between perception and sensation and how they work together with attention to determine what we perceive in the environment. Before you finish, you’ll investigate why psychologists study sensation to better understand perception, which is a key component of our behaviour and mental processes.
This introductory course is for anyone interested in psychology - you don’t need any past experience.
It might be of particular use to learners who have already completed a Bachelor degree in other disciplines who are interested in expanding their science and research skills.
Complete this course, then the program
This course is part of the Introduction to Psychology Program, based on the first unit of Monash University’s fully online Graduate Diploma of Psychology (GDP).
Learners who successfully complete the seven courses in the Program and who are accepted into the Graduate Diploma of Psychology will receive one unit of academic credit.",Introduction to Psychology: Sensation and Perception
https://www.classcentral.com/course/mobilecloudprogram-3079,"This MOOC describes by example how to connect Android mobile devices to clouds via the use of object-oriented design techniques, Java programming language features, Jetty middleware, Java Servlets, the Java Spring Framework, and cloud computing platforms, such as Google App Engine. Although there will be 10 weeks of lecture material, the required core of the course is six weeks long and can be completed flexibly within the ten week schedule to provide flexibility for students during the summer.An extended case study project will be used throughout the required core of the MOOC to showcase architectures for communicating with the cloud using HTTP, server-side processing of mobile data using servlets and the Java Spring Framework, and scalable storage of data using no-SQL databases and other platforms. Due to the importance of building secure and scalable mobile/cloud platforms, this MOOC will not only show you how to program handheld systems that talk to the cloud, but how to do so securely, scalably, and efficiently. Security and scalability topics will be woven into discussions of cloud service creation so that students learn, from the start, how to create robust cloud services for mobile devices.Four weeks of optional lecture material will also be provided for students who would like to gain a deeper understanding of the patterns and frameworks for building cloud infrastructure building. This material will be presented in the context of the open-source JAWS web server, which is implemented in C++ as part of the ACE open-source object-oriented concurrent and networked programming toolkit.Although the cloud service topics in this course will be taught in the context of connecting mobile devices to the cloud, the concepts are broader and will give students the ability to create the cloud services to support large-scale web applications, such as social networking applications; cloud services for embedded systems, such as the Internet of Things and Industrial Internet; and wearable computing devices, such as Google Glass.The Mobile Cloud Computing with Android (MoCCA) SpecializationThis is the 5th course of the six-course Mobile Cloud Computing with Android (MoCCA) Specialization. It has been designed as part of a Coursera Specialization designed to help learners create complex, cloud-based Android Applications, and includes a final “capstone” project for those who earn Verified Certificates across all six courses.Note: We are proud to announce that the MoCCA specialization has already reached hundreds of thousands of learners around the globe. In its last iteration, we worked with Google to provide Nexus tablets, feedback from the Google App team, and the potential to be featured in the Google Play store to top course completers.This time around, we are providing more flexibility for all of you busy learners. We are running the Programming Mobile Applications courses in more digestible one-month-long sections, each with a meaningful mini-project at the end. Additionally, we will be re-offering the courses more frequently. For example, new sessions of my two introductory courses will be launched on a monthly basis, so that you can find a convenient time to join us or pick up where you left off if you didn’t quite finish before.For previous MoCCA students: If you have already earned a Verified Certificate in the previous version of this course, ""Pattern-Oriented Software Architectures: Programming Mobile Services for Android Handheld Systems” offered in May 2014, you do not need to retake this course to continue towards the Specialization certificate and final project in 2015. Please consult the Specializations Help Center or contact the Coursera support team if you are not sure whether you qualify.This MOOC and five others, taught by Dr. Adam Porter from the University of Maryland and Dr. Jules White from Vanderbilt University, have been designed to complement each other as part of the first trans-institution sequence of MOOCs taught on the Coursera platform, structured as follows:The first two courses by Dr. Adam Porter, of the University of Maryland, are Programming Mobile Applications for Android Handheld Systems Part 1 and Part 2. They focus on the design and programming of user-facing applications.  The third and fourth courses by Dr. Douglas Schmidt, of Vanderbilt University, are Programming Mobile Services for Android Handheld Systems: Concurrency and Communication. They focus on middleware systems programming topics, such as synchronous and asynchronous concurrency models, background service processing, structured data management, local inter-process communication and networking, and integration with cloud-based services.  The fifth and sixth courses by Dr. Jules White, of Vanderbilt University, are Programming Cloud Services for Android Handheld Systems: Spring and Security.  They focus on how to connect Android mobile devices to cloud computing and data storage resources, essentially turning a device into an extension of powerful cloud-based services on popular cloud computing platforms, such as Google App Engine and Amazon EC2.The final “capstone” project will require students to develop a complex mobile cloud computing application from the ground up.Some of the programming assignments and the iRemember integrative project for these MOOCs will be coordinated.  If you just want to take some of the MOOCs in this sequence or take them all in different order you’re certainly welcome to do so, and you’ll still learn a lot. However, if you take all the MOOCs in this sequence in the order presented you’ll gain a deeper, end-to-end understanding of handheld systems, their applications and services, as well as their integration into the cloud.
      


            Read more
          



This MOOC describes by example how to connect Android mobile devices to clouds via the use of object-oriented design techniques; Java programming language features; Android Content Providers, Content Resolvers, and SQLite databases; Jetty middleware; Java Servlets, the Java Spring Framework; and cloud computing platforms, such as Google App Engine. An extended case study project will be used throughout the required core of the MOOC to showcase architectures for communicating with the cloud using HTTP, server-side processing of mobile data using servlets and the Java Spring Framework, and scalable storage of data using no-SQL databases and other platforms. Due to the importance of building secure and scalable mobile/cloud platforms, this MOOC will not only show you how to program handheld systems that talk to the cloud, but how to do so securely, scalably, and efficiently. Security and scalability topics will be woven into discussions of cloud service creation so that students learn, from the start, how to create robust cloud services for mobile devices.Optional lecture material will also be provided for students who would like to gain a deeper understanding of the patterns and frameworks for building cloud infrastructure building. This material will be presented in the context of the open-source JAWS web server, which is implemented in C++ as part of the ACE open-source object-oriented concurrent and networked programming toolkit.Although the cloud service topics in this course will be taught in the context of connecting mobile devices to the cloud, the concepts are broader and will give students the ability to create the cloud services to support large-scale web applications, such as social networking applications; cloud services for embedded systems, such as the Internet of Things and Industrial Internet; and wearable computing devices, such as Google Glass. The course is organized into the sections outlined below.Section 0: Overview of HTTP [Optional for students who took the POSA Communication MOOC]Module 1: Overview of Hyper-Text Transfer Protocol (HTTP)What are Communication Protocols?Intro to HTTPWhy HTTP?What is a Cloud ServiceHTTP Request MethodsHTTP Request AnatomyURLs Query ParametersCompleted HTTP Response AnatomyCompleted HTTP Response CodesCompleted HTTP CookiesModule 2: Designing Mobile Applications with HTTP CommunicationBuilding Cloud Services on HTTP Overview of RESTPush MessagingIntro to Java AnnotationsCompleted HTTP to Object MarshallingCompleted Intro to JSONModule 3: Better Client-side Communication Abstractions for HTTPIntroduction to RetrofitRetrofit Client Code WalkthroughSection 1: Structured Data Storage on AndroidPart 1:  Overview of Android Content Providers and Content ResolversPart 2: Programming with Android Content ResolversPart 3: Programming Android Content ProvidersPart 4: Overview of SQLite Part 5: Asynchronous Access to Content Providers Section 2: Building Java Cloud ServicesModule 1: Java ServletsWhat are Servlets?A First Cloud Service with a ServletWeb.xmlVideo Servlet Code WalkthroughVideo Servlet Test Walkthrough with HttpClientSecurely Handling Client Data Avoiding Injection AttacksModule 2: Better Abstractions for Building Java Cloud ServicesIntro to Java AnnotationsHTTP to Object MarshallingIntro to JSONThe Spring Dispatcher Servlet and the Controller AbstractionIntro to Spring ControllersAccepting Client Data with RequestParam AnnotationsAccepting Client Data with PathVar AnnotationsAccepting Client Data with RequestBody Annotations and JSONHandling Multipart DataGenerating Responses with the ResponseBody AnnotationCustom Marshalling with Jackson Annotations Serializers/DeserializersSpring Boot Application StructureSpring Controller Code WalkthroughSpring Controller Test Code WalkthroughModule 3: Better Client-side Communication AbstractionsIntroduction to RetrofitRetrofit Client Code WalkthroughAndroid Retrofit Client Code WalkthroughModule 4: Building Loosely Coupled and Extensible Java ServicesSpring Dependency Injection Auto-wiringSpring Configuration AnnotationsSpring Dependency Injection Controller Code WalkthroughSpring Dependency Injection Controller Test Code WalkthroughSection 3: Building Database-driven Java Cloud ServicesModule 1: Persistent ObjectsObject to DB MappingJPAEntitiesRepositoriesUnderstanding SQL Injection AttacksSpring Data Code WalkthroughModule 2: RESTful Services for Persistent ObjectsSpring Data RESTSpring Data REST Code WalkthroughSection 4: Deploying to the Cloud ScalingModule 1: General Scaling StrategiesStateless vs. Stateful ApplicationsHorizontal ScalingAuto-scaling HorizontallyCachingOffloading to Cloud Provider ServicesAsynchronous IO in ControllersModule 2: Scaling Up Data StorageNoSQL DatabasesOptimizing for Key-based LookupsOptimizing for Reads vs. WritesContention ShardingMongo DBSpring Data Mongo DBDatabase as a ServiceAmazon DynamoSpring Data Dynamo DBApp Engine Big TableModule 3: Automating Packaging DeploymentDeploying to Infrastructure as a ServiceDeploying to Amazon EC2Packaging Web Applications into WAR filesAdapting Spring Boot Applications for Google App EngineDeploying to App EngineModule 4: Performance TestingIntro to Cloud Service Performance TestingApache JMeterBuilding Realistic TestsSection 5: Patterns and Frameworks for Concurrent and Networked Server Software [Optional Material]Module 1: Introduction to the Web Server Case StudyApplying Patterns and Frameworks to Concurrent and Networked SoftwareOverview of JAWS Web Server Case Study: Part 1Overview of JAWS Web Server Case Study: Part 2Overview of JAWS Web Server Case Study: Part 3Module 2: Patterns and Frameworks for Service Access and CommunicationAccidental Complexities with the Sockets APIThe Wrapper Facade PatternACE C++ Socket Wrapper FacadesApplying the ACE Wrapper Facades to a Web Client and ServerModule 3: Patterns and Frameworks for Synchronous Event Handling, Connections, and Service InitializationThe Reactor and Acceptor-Connector PatternsThe ACE Reactor FrameworkApplying the ACE Reactor to JAWSThe ACE Acceptor-Connector Framework and Applying it to JAWSModule 4: Patterns and Frameworks for Service Configuration and ActiviationThe Component Configurator PatternThe ACE Service Configurator FrameworkApplying the ACE Service Configurator to JAWSApplying the Activator Pattern to JAWSModule 5: Patterns and Frameworks for Concurrency and SynchronizationThe Active Object PatternThe ACE Task FrameworkApplying ACE Task and Acceptor-Connector to JAWSThe Half-Sync/Half-Async PatternImplementing Half-Sync/Half-Async Using ACEThe Monitor Object PatternApplying the Monitor Object and Synchronization Patterns to JAWSThe Leader/Followers PatternApplying the Leader/Followers Pattern and ACE_TP_Reactor to JAWSModule 6: Patterns and Frameworks for Asynchronous Event HandlingThe Proactor patternThe ACE Proactor FrameworkApplying the ACE Proactor Framework to JAWSThe Asynchronous Completion Token Pattern and Applying it to JAWSModule 7: SummaryEvaluating Patterns and Frameworks for Concurrent and Networked Software",Programming Cloud Services for Android Handheld Systems: Spring
https://www.classcentral.com/course/novoed-finance-468,"We live in an uncertain world. Every day, we need to make decisions about alternatives whose consequences cannot be predicted with certainty. Here are a few examples:

You have saved 2000 dollars from your summer internship. Should you put it under your mattress, buy a Certificate of Deposit, Apple stock or an S&P 500 index fund?
You manage a mutual fund specializing in technology stocks. Which proportion of the fund's total assets should you invest in each of the stocks recommended by your analysts?
You work for a venture capital firm that wants to exit an investment. How can you compute the fair value the firm's share in the venture?

In each of these situations, you need to commit resources (time, money, effort, etc.) in the face of uncertainty about the future. This course develops concepts and tools to address these types of situations. The focus is on basic principles and how they are applied in practice. No prior knowledge of finance required. A basic preparation in mathematics (probability, statistics, and optimization) is desirable; however many technical concepts and tools will be developed or reviewed in the course. The course is appropriate for engineering or science students wishing to apply their quantitative skills to develop a basic understanding of financial modeling and markets. This is a 10 week course. There will be several short (5-30 minutes) lectures each week. Challenges covering the lecture material will be given each week. There will also be two projects that involve real financial data. Solutions will be posted online. Submissions will be evaluated by fellow participants. The following topics will be covered:

Time is money: understand basic interest rates
Evaluating investments: present value and internal rate of return
Fixed-income markets: bonds, yield, duration, portfolio immunization
Term structure of interest rates 5. Measuring risk: volatility and value at risk
Designing optimal security portfolios




            Read more",Finance
https://www.classcentral.com/course/psychology-of-learning-11039,"Understand the different ways we learn
How do people learn different behaviours? How does biology affect our ability to learn new things?
On this course you will answer these questions and others, exploring the psychology of learning. You will consider the difference between learned and instinctive behaviours and approaches to how we learn - for instance, you’ve probably heard of Pavlov and his dog, an example of classical conditioning. But you’ll also learn about operant conditioning (learning behaviours based on positive or negative consequences), and observational learning (watching other people and imitating their behaviour).
This course is designed for anyone interested in learning psychology.
It will be of particular use to learners who have already completed a Bachelor degree in other disciplines who are interested in expanding their science and research skills.
Complete this course, then the program
This course is part of the Introduction to Psychology Program, based on the first unit of Monash University’s fully online Graduate Diploma of Psychology (GDP).
Learners who successfully complete the seven courses in the Program and who are accepted into the Graduate Diploma of Psychology will receive one unit of academic credit.",Introduction to Psychology: The Psychology of Learning
https://www.classcentral.com/course/udacity-intro-to-relational-databases-3253,"This course is a quick, fun introduction to using a relational database from your code, using examples in Python. You'll learn the basics of SQL (the Structured Query Language) and database design, as well as the Python API for connecting Python code to a database. You'll also learn a bit about protecting your database-backed web apps from common security problems.After taking this course, you'll be able to write code using a database as a backend to store application data reliably and safely.Why Take This Course?If you look under the hood of a lot of major web sites — from Wikipedia to Reddit — you'll find a relational database somewhere.Database systems such as PostgreSQL and MySQL have been part of the web developer's toolkit for many years, and remain some of the most powerful tools available for storing and manipulating structured data.If you're planning to continue on in full-stack development, knowing about databases is essential background. Even though many toolkits hide the details of the database from your application code, being able to interact with the database will serve you well in designing, debugging, and maintaining your applications.



Lesson 1: Data and TablesIn this lesson, you'll learn about how relational databases let you structure data into tables. You'll learn about the importance of unique keys and relationships between tables.Lesson 2: Elephants Elements of SQLIn this lesson, you'll begin learning SQL, the Structured Query Language used by most relational databases. You'll learn about the select and insert statements, the basic operations for getting data out of a database and putting data into a database. You'll learn about the operators and syntax available to get the database to scan and join tables for you.Lesson 3: Python DB-APIIn this lesson, you'll learn how to access a relational database from Python code. You'll use a virtual machine (VM) running on your own computer to run a Python web application, and adapt that application to use a database backend. Then you'll learn about some of the most common security pitfalls of database-backed applications, including the famous Bobby Tables. This lesson also covers the SQL update and delete statements.Lesson 4: Deeper Into SQLIn this lesson, you'll learn how to design and create new databases. You'll learn about normalized design, which makes it easier to write effective code using a database. You'll also learn how to use the SQL join operators to rapidly connect data from different tables.Lesson 5: Final ProjectIn this project, you'll use your Python and SQL knowledge to build a database-backed Python module to run a game tournament. You'll design the database schema and write code to implement an API for the project.",Intro to Relational Databases
https://www.classcentral.com/course/edx-cyber-security-economics-2680,"This economics course provides an introduction to the field of cybersecurity through the lens of economic principles. Delivered by four leading research teams, it will provide you with the economic concepts, measurement approaches and data analytics to make better security and IT decisions, as well as understand the forces that shape the security decisions of other actors in the ecosystem of information goods and services.
Systems often fail because the organizations that defend them do not bear the full costs of failure. In order to solve the problems of growing vulnerability to computer hackers and increasing crime, solutions must coherently allocate responsibilities and liabilities so that the parties in a position to fix problems have an incentive to do so. This requires a technical comprehension of security threats combined with an economic perspective to uncover the strategies employed by cyber hackers, attackers and defenders.
The course covers five main areas:

Introduction to key concepts in security economics. Here, we provide an overview of how information security is shaped by economic mechanisms, such as misaligned incentives, information asymmetry, and externalities.
Measuring cybersecurity. We introduce state of the art security and IT metrics and conceptualize the characteristics of a security metric, its challenges and advantages.
Economics of information security investment. We discuss and apply different economic models that help determine the costs and benefits of security investments in network security.
Security market failures. We discuss market failures that may lead to cybersecurity investment levels that are insufficient from society’s perspective and other forms of unsafe behaviour in cyber space.
Behavioural economics for information security, policy and regulation. We discuss available economic tools to better align the incentives for cybersecurity, including better security metrics, cyber insurance/risk transfer, information sharing, and liability assignment.

After finishing this course, you will be able to apply economic analysis and data analytics to cybersecurity. You will understand the role played by incentives on the adoption and effectiveness of security mechanisms, and on the design of technical, market-based, and regulatory solutions to different security threats.
 



            Read more",Cyber Security Economics
https://www.classcentral.com/course/edx-business-and-data-analysis-skills-4947,"In the modern workplace, it’s crucial to know how to analyze, synthesize, and tell stories with data. This self-paced career development course will help you learn how to use a spreadsheet application (like Microsoft Excel) as a powerful analytical and communication tool. You will perform real-world market and financial analyses and practice presenting your findings visually for maximum impact. By the end of the course, you will be able to make data-driven decisions that help your organization grow and prosper.
This is the fourth course in Fullbridge’s four-part Career Development XSeries, designed to prepare you to succeed in the modern workplace.



This is a self-paced course and can be completed according to your own schedule. Our recommendation is to complete the course over four weeks, with one to two hours of time spent working through the course per week. After the Course Introduction, each section should take approximately one to two hours to complete.   
Section 0: Course Introduction
Review course logistics, including the course overview, schedule, components, grading, and support.   
Section 1: Spreadsheet Basics with Excel
Learn strategies and techniques that will enable you to effectively use spreadsheet applications like Excel to perform basic analyses.   
Section 2: Market Analysis
Familiarize yourself with market analysis and learn how to visualize data in a persuasive, honest way.   
Section 3: Financial Analysis
Master how to plan and execute effective financial analyses, including how to evaluate investments.   
Section 4: Final Assessment and Course Recap
Demonstrate your mastery of the course content in the final assessment.",Business and Data Analysis Skills
https://www.classcentral.com/course/edx-the-beauty-and-joy-of-computing-ap-cs-principles-part-1-2525,"Discover the big ideas and thinking practices in computer science plus learn how to code using one of the friendliest programming languages, Snap! (based on Scratch).
Computing has profoundly changed the world, opening up wonderful new ways for people to connect, design, research, play, create, and express themselves. However, just using a computer is only a small part of the picture. The real transformative and empowering experience comes when one learns how to program the computer, to translate ideas into code.
This course teaches students how to do exactly that, using Snap! (based on Scratch), one of the friendliest programming languages ever invented. It's purely graphical, which means programming involves simply dragging blocks around, and building bigger blocks out of smaller blocks. But this course is far more than just learning to program. We focus on seven big ideas (creativity, abstraction, data and information, algorithms, programming, the Internet, and global impact), and six computational thinking practices (connecting computing, creating computational artifacts, abstracting, analyzing problems and artifacts, communicating, and collaborating). Throughout the course, relevance is emphasized: relevance to the student and to society.
Topics include:

Abstraction
Programming Paradigms Algorithms
Global Implications of Computing
Lab-Based Topics: Snap! Programming, Conditionals and Abstraction, Lists and the Internet

This fun, introductory course is not just for computer science majors, it’s for everyone… join us!



            Read more",The Beauty and Joy of Computing - AP® CS Principles Part 1
https://www.classcentral.com/course/complexity-explorer-introduction-to-renormalization-11490,"What does a JPEG have to do with economics and quantum gravity? All of them are about what happens when you simplify world-descriptions. A JPEG compresses an image by throwing out fine structure in ways a casual glance won't detect. Economists produce theories of human behavior that gloss over the details of individual psychology. Meanwhile, even our most sophisticated physics experiments can't show us the most fundamental building-blocks of matter, and so our theories have to make do with descriptions that blur out the smallest scales. The study of how theories change as we move to more or less detailed descriptions is known as renormalization. 
This tutorial provides a modern introduction to renormalization from a complex systems point of view. Simon DeDeo will take students from basic concepts in information theory and image processing to some of the most important concepts in complexity, including emergence, coarse-graining, and effective theories. Only basic comfort with the use of probabilities is required for the majority of the material; some more advanced modules rely on more sophisticated algebra and basic calculus, but can be skipped. Solution sets include Python and Mathematica code to give more advanced learners hands-on experience with both mathematics and applications to data.
We'll introduce, in an elementary fashion, explicit examples of model-building including Markov Chains and Cellular Automata. We'll cover some new ideas for the description of complex systems including the Krohn-Rhodes theorem and State-Space Compression. And we'll show the connections between classic problems in physics, including the Ising model and plasma physics, and cutting-edge questions in machine learning and artificial intelligence.
 



            Read more
          




Introduction to Renormalization
Markov Chains
Cellular Automata
Ising Model
Krohn-Rhodes Theorem
A Classical Analogy for Renormalization in Quantum Electrodynamics
Conclusion: The Future of Renormalization & Rate Distortion Theory
Homework",Introduction to Renormalization
https://www.classcentral.com/course/linearopt-526,"This
 course serves as an introduction to linear and discrete 
optimization from the viewpoint of a mathematician or computer 
scientist.  Besides learning how linear and discrete optimization can be applied, we focus on 
understanding methods that solve linear programs and discrete optimization problems in a mathematically 
rigorous way. We will answer  questions like:Does a particular method work correctly?Does it terminate and, if yes, in what time?Can we prove that a solution is optimal?The
 course starts by discussing what a linear program is and how linear programming can be 
applied. Then, we will treat the simplex method and the theory of 
duality. We will then discuss some combinatorial optimization problems like maximum weight bipartite matching and maximum flows. The
 course constitutes about half of the material on linear and discrete optimization 
that is taught for mathematics and computer science undergraduates at 
EPFL and will feature video lectures, quizzes, programming assignments, 
and a final exam. 



Linear programming, modeling, equivalence of standard forms Basic solutions, primal and dual feasible basic solutions, pivoting and the simplex methodTermination and complexity of the simplex method Integer programming, bipartite matching and flowsModels of computation, bit-complexity",Linear and Discrete Optimization
https://www.classcentral.com/course/futurelearn-monitoring-climate-from-space-3468,"Satellite Earth Observation technology provides a powerful and compelling insight into climate change which can help to underpin climate policy, scientific research and public engagement. But how does this technology work, and how can it achieve the essential detail and comprehensive worldwide view that we need?
Join Lead Educator Professor Martin Wooster and leading climate experts such as Professor Konrad Steffen, Professor Anny Cazenave, Dr Stephen Briggs and Dr Emily Shuckburgh as they reveal the perspective provided by satellite Earth observation. The course is free and fully flexible - you can progress in step with other learners week by week, or take the course entirely at your own pace, with all materials available indefinitely once you have registered.
The ‘live run’ of the course, allowing you to interact with experts and other learners, will continue until 28th August 2016, and you can register any time up to that date. You can also view and share some ‘highlights’ from the course without registering, using the links at the bottom of this page. This film, the course trailer above and a small selection of other videos are also available with Spanish and Chinese subtitles. Just click on the small pink square in the video controls to select your preferred language.
Introducing Earth observation
Seeing the Earth from space allows us to gain this global perspective. By using Earth observation techniques, we can now monitor global environmental change on a scale that has never before been possible.
Earth observation has not only revolutionised the way we perceive our home, but changed the way we understand our profound impact on the environment. This technology has brought on a transformation in the way we observe, monitor and study our planet.
Learn with  experts from ESA and leading European research centres
In this free online course, you will join leading experts and scientists from ESA and key European research centres, to explore the science that underpins Earth observation.
We will look at recent and current satellite missions that are providing an archive of essential data; and find out how this data is used in local and international policy and planning.
The course consists of five themed weeks:
Week 1 - Observing Climate Change from Space
What is Earth observation? How do we observe the Earth with satellites? And what role does Earth observation play in climate policy and planning?
Weeks 2 & 3 - Earth Observation Techniques and Technology
How do we use different types of mission, instrumentation and data to study changes to our atmosphere, land, oceans and ice?
Week 4 - Earth Observation in Action
How does Earth observation help us set policy; plan for climate risk, resilience and adaptation; and manage resources and biodiversity?
Week 5 - Managing Earth Observation Data
How do we make sense of the large amount of data produced by Earth observation? Can crowdsourcing and citizen science play a role in developing climate change models?
The lead presenters on this course are: Professor Martin Wooster, King’s College London; Dr Mathias Disney, University College London; Dr Emily Shuckburgh, British Antarctic Survey; Professor Andy Shepherd, University of Leeds. Further expert insight is provided by Professor Alan O’Neill, University of Reading.
Other contributors for the course include: Professor Konrad Steffen, WSL; Professor Anny Cazenave, LEGOS & ISSI; Dr Pierre-Philippe Mathieu, ESA; Dr Stephen Briggs, ESA; Dr Angela Benedetti, ECMWF; Dr Nathalie Pettorelli, ZSL; Professor Chris Merchant, University of Reading; Dr Melanie Ades, University of Reading; Dr Helen Snaith, BODC (NOC); Dr Stephanie Henson, NOC; Dr Simon Boxall, University of Southampton; Dr Paolo Cipollini, NOC; Professor Chris Lintott, University of Oxford; Dr Kirsten Barrett, University of Leicester.
This course is designed for people who want to learn more about Earth observation, climate change and monitoring climate from space. The course can also help decision makers, policy makers, educators and communicators, to gain a better insight into how satellite data can help them assess the state of our climate and its changes, in order to support climate science, and adaptation and mitigation decisions.



            Read more",Monitoring Climate from Space
https://www.classcentral.com/course/developmental-psychology-11040,"Learn about the psychological changes that all humans go through
As humans, we experience three phases of development over our lifespan: physical, cognitive and social development.
On this course, you’ll investigate the key transitions associated with these phases of development, examining the psychological changes and exploring how and why these changes happen.
You’ll also consider whether development is continuous or discontinuous and to what extent development is influenced by nature or the environment, all before you explore designs and considerations for carrying out research in the discipline of psychology.
This introductory course is for anyone interested in psychology - you don’t need any past experience.
It might be of particular use to learners who have already completed a Bachelor degree in other disciplines who are interested in expanding their science and research skills.
Complete this course, then the program
This course is part of the Introduction to Psychology Program, based on the first unit of Monash University’s fully online Graduate Diploma of Psychology (GDP).
Learners who successfully complete the seven courses in the Program and who are accepted into the Graduate Diploma of Psychology will receive one unit of academic credit.",Introduction to Psychology: Developmental Psychology
https://www.classcentral.com/course/uol-machine-learning-for-all-17124,"Machine Learning, often called Artificial Intelligence or AI, is one of the most exciting areas of technology at the moment. We see daily news stories that herald new breakthroughs in facial recognition technology, self driving cars or computers that can have a conversation just like a real person. Machine Learning technology is set to revolutionise almost any area of human life and work, and so will affect all our lives, and so you are likely to want to find out more about it. Machine Learning has a reputation for being one of the most complex areas of computer science, requiring advanced mathematics and engineering skills to understand it. While it is true that working as a Machine Learning engineer does involve a lot of mathematics and programming, we believe that anyone can understand the basic concepts of Machine Learning, and given the importance of this technology, everyone should. The big AI breakthroughs sound like science fiction, but they come down to a simple idea: the use of data to train statistical algorithms. In this course you will learn to understand the basic idea of machine learning, even if you don't have any background in math or programming. Not only that, you will get hands on and use user friendly tools developed at Goldsmiths, University of London to actually do a machine learning project: training a computer to recognise images. This course is for a lot of different people. It could be a good first step into a technical career in Machine Learning, after all it is always better to start with the high level concepts before the technical details, but it is also great if your role is non-technical. You might be a manager or other non-technical role in a company that is considering using Machine Learning. You really need to understand this technology, and this course is a great place to get that understanding. Or you might just be following the news reports about AI and interested in finding out more about the hottest new technology of the moment. Whoever you are, we are looking forward to guiding you through you first machine learning project.

NB this course is designed to introduce you to Machine Learning without needing any programming. That means that we don't cover the programming based machine learning tools like python and TensorFlow.
      


            Read more
          



          Machine learning
    -In this week you will learn about artificial intelligence and machine learning techniques. You will learn about the problems that these techniques address and will have practical experience of training a learning model.

Data Features
    -This week you will learn about how data representation affects machine learning and how these representations, called features, can make learning easier.  

Machine Learning in Practice
    -In this topic you will get ready to do your own machine learning project. You will learn how to test a machine learning project to make sure it works as you want it to. You will also think about some of the opportunities and dangers of machine learning technology. 

Your Machine Learning Project
    -In this final topic you will do your own machine learning project: collecting a dataset, training a model and testing it.",Machine Learning for All
https://www.classcentral.com/course/oral-communication-7425,"Taught by Rice University communication faculty from the Rice Center for Engineering Leadership (RCEL). This course covers core topics in oral communication: Communication strategy, content, data visualization, and delivery. You’ll learn key principles in
•	Creating a communication strategy
•	Developing a clear message and organizing persuasive content
•	Creating strong visual support
•	Presenting data effectively
•	Presenting professionally and confidently
•	Handling formal presentations, giving pitches, speaking extemporaneously, managing online presentations, and lowering 
        public speaking anxiety

Selected materials courtesy of Communication Faculty at Rice University - all rights reserved.
      


          Specialization Introduction - Communication for Engineers

Course Introduction - Oral Communication for Engineering Leaders

Week 1: Introduction and Communication Strategy: It Is All About Audience and Purpose
    -In this module, you’ll learn how to lay the foundation for a variety of communication modes with a discussion on developing a communication strategy and the importance of knowing your audience, your purpose, and your key message before you start communicating. 

Week 2: Presentations: What to Say so that Your Audience Listens
    -In today’s workplace, formal and informal presentations are a major communication tool, and leaders give them frequently for different purposes. In this module, you’ll learn how to create different types of oral presentations. You will also practice building strong, cohesive, visually interesting, and convincing persuasive presentations that will get your audience on board with your ideas. 

Week 3: Creating Visual Support: A Picture Is Worth a Lot of Words
    -Develop good visual support for your content. Learn how to create attractive slides and other types of visuals.  Especially important for engineers, you’ll find out how to show and explain complex data so your audience understands it. 

Week 4: How to Speak so that Your Audience Listens
    -Once you have your content developed and your visual support finished, you need to deliver the presentation. That means you have to stand in front of an audience, small or large, and keep them interested in what you have to say. Many things contribute to an engaging presentation, from professional body language to how fast you talk. In this module, you’ll learn and practice the many aspects of delivering a professional presentation with confidence. 

Week 5: Elevator Pitch, Impromptu, Online Presentations, and  Managing Public Speaking Anxiety
    -Have you ever had someone ask you about your job when you aren’t expecting it? How good are you at thinking on your feet? In this module, you’ll learn about other types of presentations that require different preparation and approaches. These different types are valuable additions to your communication toolkit and learning them can help set you apart as a leader.",Oral Communication for Engineering Leaders
https://www.classcentral.com/course/futurelearn-learn-to-code-for-data-analysis-3997,"Learn to code in Python and analyse real, open data
This hands-on course will teach you how to write your own computer programs, one line of code at a time. You’ll learn how to access open data, clean it and analyse it, and produce visualisations. You will also learn how to write up and share your analyses, privately or publicly.
You will install free software to learn to code in Python, a widely used programming language. You will write up analyses and do coding exercises using the popular Jupyter Notebook platform. And you will look at real data from the World Health Organisation, the World Bank and other organisations.
The course does not assume prior experience in programming or data analysis. Basic familiarity with a spreadsheet application will be an advantage.
The course does not require any knowledge of statistics, but you need to have basic numeracy skills, like writing arithmetic expressions, using percentages and understanding scientific notation. If you wish to brush up on your numeracy skills, we recommend the FutureLearn course Basic Science: Understanding Numbers from The Open University.
To study this course you will use specialist software. You can use the software online, via a free account on a website, or offline, by downloading and installing a free software package. You will receive instructions about both options via email before the course starts. The online solution requires a good internet connection and has some limitations.
The offline software has no limitations and is the recommended option. However, you will need access to a desktop or laptop computer on which you can install software. The software is free and there are versions available for Windows, Mac and Linux platforms. You will need about 3 GB of free disk space to download and install the software, and to store datasets that will be provided in the course.
Whether you choose the online or offline software option, you will need to be proficient in basic computer tasks, like creating folders, downloading files and copying them to specific folders, etc. In terms of accessibility, you will be asked to use your web browser and to type code.



            Read more",Learn to Code for Data Analysis
https://www.classcentral.com/course/udacity-computer-networking-2336,"This class is offered as CS6250 at Georgia Tech where it is a part of the Online Masters Degree (OMS). Taking this course here will not earn credit towards the OMS degree.This course covers advanced topics in Computer Networking such as Software-Defined Networking (SDN), Data Center Networking and Content Distribution. The course is divided into three parts:Part 1 is about the implementation, design principles and goals of a Computer Network and touches upon the various routing algorithms used in CN (such as link-state and distance vector). Part 2 talks about resource control and content distribution in Networking Applications. It covers Congestion Control and Traffic Shaping.Part 3 deals with the operations and management of computer networks encompassing SDN's (Software Defined Networks), Traffic Engineering and Network Security.Why Take This Course?Want to build on your Computer Networking knowledge or move into Network Engineering positions such as Systems Admin, Network Admin or Technical Operations (WebOps)? If so, this is the class for you.Computer Networking takes a hands-on approach to teaching very technical material, using Mininet (a network emulator) to show you how a computer network functions, what factors contribute to its efficiency and how to overcome inherent limitations.



Lesson 1: IntroductionComputer Networking OverviewWhat This Class is Not AboutLesson 2: Architecture & Principles  A Brief History of the Internet  Architectural Design Principles  Packet Switching  File Transfer  End to End Argument ViolationsLesson 3: Switching  Switching and Bridging  Bootstrapping: Networking Two Hosts  ARP: Address Resolution Protocol  Interconnecting LANs with Hubs  Switches: Traffic Isolation  Spanning Tree  Switches vs. Routers  Buffer Sizing for a TCP SenderLesson 4: Routing  Internet Routing  Intra-AS Topology  Distance-Vector Routing  Link State Routing  Interdomain Routing  IGP vs. iBGP  BGP Route Selection  Multiple Exit Discriminator (MEI)  Interdomain Routing Business ModelsLesson 5: Naming, Addressing & Forwarding  IP Addressing  Pre-1994: ""Classful"" Addressing  IP Address Allocation  Classless Interdomain Routing (CIDR)  Multihoming Frustrates Aggregation  Address Lookup Using Tries  Memory Efficiency and Fast Lookup  Alternatives to LPM with Tries  NAT and IPv6  Network Address Translation (NAT)Lesson 5.1: Router Design Basics  Router Design  Basic Router Architecture  Decision: Crossbar Switching  Switching Algorithm: Maximal Matching  Head of Line Blocking  Scheduling and Fairness  Max-Min FairnessLesson 5.2: Domain Name System (DNS)  Record Types  Examples (using ""dig"")  Lookup IP AddressLesson 6: Congestion Control & Streaming  Congestion Control  AIMD (TCP Congestion Control)  Data Centers & TCP ""Incast""  Barrier Synchronization & Idle Time  Multimedia & Streaming  Digitizing Audio & Video  Streaming Video  SkypeLesson 7: Rate Limiting and Traffic Shaping  Traffic Classification & Shaping  Source Classification   Leaky Bucket Traffic Shaping  (r, t) Traffic Shaping  Shaping Bursty Traffic Patterns  Power Boost  Effects on Latency  Buffer Bloat  Packet MonitoringLesson 8: Content Distribution  The Web and Caching  HTTP Requests  Persistent Connections  Content Distribution Networks (CDNs)  Server Selection  Content Routing  Bit Torrent  Solution to Freeriding: ""Choking""  Distributed Hash Tables  Consistent HashingLesson 9: Software Defined Networking  Network Management Overview  Software Defined Networking (SDN)  Control and Data Planes  Different SDN Controllers  NOX: Overview  Ryu, Floodlight, Nox and Pox  Customizing ControlLesson 10: Traffic Engineering  Traffic Engineering Overview  Interdomain Traffic Engineering  Measuring, Modeling and Controlling Traffic  Link Utilization Function  BGP in Interdomain Traffic Engineering  Multipath Routing  Data Center Networking  Valiant Load Balance  Jellyfish Data Center TopologyLesson 11: Network Security  Internet is Insecure  Resource Exhaustion   Routing Security  Origin and Path Authentication  DNS Security  DNS Cache PoisoningLesson 11.1: Internet Worms  Viruses and Internet Worms  Internet Worm Lifecyle  First Worm: ""Morris"" Worm  Worm Outbreaks in Detail   Modeling Fast-Spreading WormsLesson 11.2: Spam  Spam  IP BlacklistingLesson 11.3: Denial of Service (DoS) Attacks  TCP 3-Way Handshake  Inferring Denial of Service Activity using Backscatter  Automated DoS Attack Mitigation  MTPCP",Computer Networking
https://www.classcentral.com/course/make-infographics-5717,"In this project-centered course*, you will create a content-rich infographic on a topic of your choice. You might choose to create a visual representation of data from the world of sports, entertainment, politics, or science, to explain a business trend or environmental issue, or even to present a theme or development from your personal life. Your finished infographic will engage your target audience and convey information clearly through effective use of design elements such as typography, color, and structure.  Whether you’re a graphic designer, a writer or the intern in the department, you’ll learn:  • what an infographic is and what makes a good one • how to work within your limits • how to work with a team (if you have one)  • why infographics are effective  • techniques for spotting data in stories • six valuable steps for planning an effective infographic  • how to use and make some of the building blocks of infographics: maps, charts and flow charts  • ways data can be visualized to clarify it and give it meaning  • how to effectively design a good infographic by effectively using elements like type, color and an underlying grid structure • some free or cheap, online tools for making various kinds of infographics  As you work on your project, you’ll learn more about why infographics are effective, what makes a good infographic, and how to plan and design an infographic for maximum impact. You’ll explore various approaches to data visualization, and you’ll practice creating visualizations like maps, charts, flow charts, and simple drawings in a free version of Adobe Illustrator.   What you’ll need to get started: This project-based course is aimed at anyone interested in understanding, designing, and using infographics - from students and hobbyists to professional graphic designers.   We’ll use Adobe Illustrator for some components of the project. If you don’t have access to the full version of Illustrator,you can download a free version at www.Adobe.com/Illustrator.   *About Project-Centered Courses: Project centered courses are designed specifically to help you complete a personally meaningful real-world project, with your instructor and a community of like-minded learners providing guidance and suggestions along the way. By actively applying new concepts as you learn, you’ll master the course content more efficiently; you’ll also get a head start on using the skills you gain to make positive changes in your life and career. When you complete the course, you’ll have a finished project that you’ll be proud to use and share.



            Read more",Design and Make Infographics (Project-Centered Course)
https://www.classcentral.com/course/openhpi-semantic-web-technologies-615,"The Web has become an object of our daily life and the amount of information in the web is ever growing. Besides plain texts, especially multimedia information such as graphics, audio or video have become a predominant part of the web's information traffic. But, how can we find useful information within this huge information space? Traditional search engines will reach the limits of their power, when it comes to understanding information content. The Semantic Web is an extension of the traditional web in the sense that information in the form of natural language text in the web will be complemented by its explicit semantics based on a formal knowledge representation. Thus, the meaning of information expressed in natural language can be accessed in an automated way and interpreted correctly, i.e. it can be understood by machines.
Semantic Web technologies enable the explicit representation of knowledge and its further processing to deduce new knowledge from implicitly hidden knowledge. Thus, information access and information search will be more precise and more complete compared to today's traditional information retrieval technology. Previously heterogeneous data can be mapped and combined based on common knowledge representation and schemata easily extended in a dynamic way.
In this course, you will learn the fundamentals of Semantic Web technologies. You will learn how to represent knowledge and how to access and benefit from semantic data on the Web.



            Read more
          




Week 1: Introduction to the Semantic Web
Week 2: Identifying Things with URI and RDF
Week 3: Querying RDF(S) with SPARQL
Excursus: Semantic (Meta) Data and the Web
Week 4: Knowledge Representation I
Week 5: Knowledge Representation II
Week 6: Applications in the Web of Data
Final Exams: Final Exams",Semantic Web Technologies
https://www.classcentral.com/course/edx-macroeconometric-forecasting-4105,"In this macroeconomics course, you will learn to predict macroeconomic variables such as inflation, growth or consumption, and to create statistical models in economics and use them to predict responses to economic policy.
You will learn from hands-on demonstrations of model-building, forecasting and policy analysis, using data sets from a wide variety of countries. Demonstrations and applications will be conducted using EViews—a popular software for estimating and simulating forecasting models on Windows. Free, temporary licenses for EViews will be made available for the duration of the course.
Macroeconometric Forecasting is offered by the IMF with financial support from the Government of Japan.



          Module 1: EViews Basics (Optional)
Review of the main EViews commands to manage data.
 
Module 2: Introduction to Forecasting with EViews
Introduction to the EViews model simulator to estimate and forecast multiple equation models.
 
Module 3: Statistical Properties of Times Series Data
The concept of stationarity is defined as well as how to test for it. Box-Jenkins (ARMA) methodology to study time series is introduced.
 
Module 4: Forecast Uncertainty and Model Evaluation
How best to choose between forecasts from competing models or sources. Participants will learn the main forecast evaluation statistics and how to calculate them in EViews.
 
Module 5: Vector Auto-Regressions (VARs)
Understand VARs, how they used for forecasting and structural analysis, and how to estimate a well-specified VAR and generate forecasts.
 
Module 6: Cointegration and Vector Error Correction Models (VECMs)
Define and understand the concept of cointegration among unit-root variables and its implications for forecasting. Learn how to test for cointegration using the Johansen method and how to estimate and forecast using a VECM.
 
Module 7: Evaluating Regressions Models
What does it mean to have a “good model” (model evaluation and key model assumptions) and the consequences for forecasting. Introduction to model testing and dealing with error irregularities and structural breaks.
 
Module 8: Final Assignment: Bringing It All Together
An overview of the techniques studied is provided using a case study focused on private saving-consumption behavior in the U.S. before and after the global financial crisis.",Macroeconometric Forecasting
https://www.classcentral.com/course/canvas-network-introduction-to-geographical-information-systems-gis-3493,"GIS (Geographical Information Systems) is everywhere. From your smartphone to your tablet, location enabled devices are present in almost every household. With over 80% of all data having some type of spatial (or geographical) component, GIS and the principles of geographic data have relevancy everywhere. This course will introduce students to GIS and the principles of spatial data in their personal life as well as applications of GIS across various industries. Major components of the course include computer representation of geographic information, the basics of GIS databases, spatial analysis with GIS, and application areas of GIS. At the end of the course, students will have an understanding of elementary GIS theory and examples of GIS-based solutions in the world around them.



Week 1: Introduction to Geographical Information Systems (GIS)
Week 2: Layers, Scales of Measurement, Map Design
Week 3: Inside A GIS
Week 4: Earth Measurements, Coordinate Systems and Projections
Week 5: GIS Editing, Geoprocessing, and Programming
Week 6: GIS Data and Analysis in GIS",Introduction to Geographical Information Systems (GIS)
https://www.classcentral.com/course/molecularevolution-3555,"In the previous course in the Specialization, we learned how to compare genes, proteins, and genomes.  One way we can use these methods is in order to construct a ""Tree of Life"" showing how a large collection of related organisms have evolved over time.

In the first half of the course, we will discuss approaches for evolutionary tree construction that have been the subject of some of the most cited scientific papers of all time, and show how they can resolve quandaries from finding the origin of a deadly virus to locating the birthplace of modern humans.

In the second half of the course, we will shift gears and examine the old claim that birds evolved from dinosaurs.  How can we prove this?  In particular, we will examine a result that claimed that peptides harvested from a T. rex fossil closely matched peptides found in chickens. In particular, we will use methods from computational proteomics to ask how we could assess whether this result is valid or due to some form of contamination.

Finally, you will learn how to apply popular bioinformatics software tools to reconstruct an evolutionary tree of ebolaviruses and identify the source of the recent Ebola epidemic that caused global headlines.
      


          Week 1: Introduction to Evolutionary Tree Construction
    -Welcome to our class!In this class, we will consider the following two central biological questions (the computational approaches needed to solve them are shown in parentheses):Weeks 1-3: Which Animal Gave Us SARS? (Evolutionary tree construction)Weeks 4-5: Was T. rex Just a Big Chicken? (Combinatorial Algorithms)In Week 6, you will complete a Bioinformatics Application Challenge to apply evolutionary tree construction algorithms in order to determine the origin of the recent ebola outbreak in Africa.As in previous courses, each of these two chapters is accompanied by a Bioinformatics Cartoon created by talented artist Randall Christopher and serving as a chapter header in the Specialization's bestselling print companion. You can find the first chapter's cartoon at the bottom of this message. What do stick bugs and bats have to do with deadly viruses? And how can bioinformatics be used to stop these viruses in their tracks? Start learning today and find out!

Week 2: More Algorithms for Constructing Trees from Distance Matrices
    -Welcome to Week 2 of class!

Last week, we started to see how evolutionary trees can be constructed from distance matrices.  This week, we will encounter additional algorithms for this purpose, including the neighbor-joining algorithm, which has become one of the top-ten most cited papers in all of science since its introduction three decades ago.

Week 3: Constructing Evolutionary Trees from Characters
    -Welcome to week 3 of class!

Over the last two weeks, we have seen several different algorithms for constructing evolutionary trees from distance matrices.

This week, we will conclude the current chapter by considering what happens if we use properties called ""characters"" instead of distances. We will also see how to infer the ancestral states of organisms in an evolutionary tree, and consider whether it is possible to define an efficient algorithm for this task.

Week 4
    -Welcome to week 4 of the class!

Did birds evolve from dinosaurs? Over the next two weeks, we will see how we could analyze molecular evidence in support of this theory. You can find this week's Bioinformatics Cartoon from Randall Christopher at the bottom of this E-mail. Why does the T. rex look so much like a chicken? And why is the monkey typing frantically? Keep learning to find out!



Week 5: Resolving the T. rex Peptides Mystery? 
    -Welcome to week 5 of class!

Last week, we asked whether it is possible for dinosaur peptides to survive locked inside of a fossil for 65 million years. This week, we will see what this question has to do with statistics; in the process, we will see how a monkey typing out symbols on a typewriter can be used to address it.

Week 6: Bioinformatics Application Challenge
    -Welcome to the sixth and final week of the course!

In this week's Bioinformatics Application Challenge, we will use reconstruct an evolutionary tree of ebolaviruses and use it to determine the origin of the pathogen that caused the recent outbreak in Africa.",Molecular Evolution (Bioinformatics IV)
https://www.classcentral.com/course/psychology-personality-11041,"Learn about about the complexities of personality, and what makes us - us
On this course, you’ll examine the factors that influence something as complex as your personality. You will explore the work of Freud on the psychodynamic perspective of personality, and consider theories of behaviourism, humanism and personality traits, considering how personality is influenced by the culture of the society in which you were raised.
You will also investigate models, theories and approaches of pioneers who contributed to our understanding of personality before examining personality tests to determine how they can be used to better understand our decision making process.
This introductory course is for anyone interested in psychology - you don’t need any past experience.
It might be of particular use to learners who have already completed a Bachelor degree in other disciplines who are interested in expanding their science and research skills.
Complete this course, then the program
This course is part of the Introduction to Psychology Program, based on the first unit of Monash University’s fully online Graduate Diploma of Psychology (GDP).
Learners who successfully complete the seven courses in the Program and who are accepted into the Graduate Diploma of Psychology will receive one unit of academic credit.



            Read more",Introduction to Psychology: The Psychology of Personality
https://www.classcentral.com/course/edx-introduction-to-biostatistics-for-big-data-applications-6843,"This course provides a broad foundation of statistical terms and concepts as well as an introduction to the R statistical software package. The topics covered are fundamental components of biostatistical methods used in both omics and population health research.
Working with biomedical big data presents many challenges; familiarity with common statistical terms and definitions, and understanding basic statistical theory will help you overcome those challenges.
Topic-specific information and examples will be followed by self-assessment opportunities for you to gauge your understanding. In addition, practice datasets and exercises will be provided for you to improve your R programming skills.",Introduction to Biostatistics for Big Data Applications
https://www.classcentral.com/course/python-capstone-5102,"In the capstone, students will build a series of applications to retrieve, process and visualize data using Python. The projects will involve all the elements of the specialization. In the first part of the capstone, students will do some visualizations to become familiar with the technologies in use and then will pursue their own project to visualize some other data that they have or can find. Chapter 15 from the book “Python for Informatics” will serve as the backbone for the capstone. This course covers Python 2.



Welcome to the CapstoneCongratulations to everyone for making it this far. Before you begin, please view the Introduction video and read the Capstone Overview. The Course Resources section contains additional course-wide material that you may want to refer to in future weeks.Building a Search EngineThis week we will download and run a simple version of the Google PageRank Algorithm and practice spidering some content. The assignment is peer-graded, and the first of three required assignments in the course. This a continuation of the material covered in Course 4 of the specialization, and is based on Chapter 15 of the textbook. Exploring Data Sources (Project)The optional Capstone project is your opportunity to select, process, and visualize the data of your choice, and receive feedback from your peers. The project is not graded, and can be as simple or complex as you like. This week's assignment is to identify a data source and make a short discussion forum post describing the data source and outlining some possible analysis that could be done with it. You will not be required to use the data source presented here for your actual analysis.Spidering and Modeling Email DataIn our second required assignment, we will retrieve and process email data from the Sakai open source project. Video lectures will walk you through the process of retrieving, cleaning up, and modeling the data.Accessing New Data Sources (Project)The task for this week is to make a discussion thread post that reflects the progress you have made to date in retrieving and cleaning up your data source so can perform your analysis. Feedback from other students is encouraged to help you refine the process.Visualizing Email DataIn the final required assignment, we will do two visualizations of the email data you have retrieved and processed: a word cloud to visualize the frequency distribution and a timeline to show how the data is changing over time.Visualizing new Data Sources (Project)This week you will discuss the analysis of your data to the class. While many of the projects will result in a visualization of the data, any other results of analyzing the data are equally valued, so use whatever form of analysis and display is most appropriate to the data set you have selected.","Capstone: Retrieving, Processing, and Visualizing Data with Python"
https://www.classcentral.com/course/finance-healthcare-managers-10797,"In this course, you’ll explore how financial statement data and non-financial metrics can be linked to financial performance. Professors Rick Lambert and Chris Ittner of the Wharton School have designed this course to help you gain a practical understanding of how data is used to assess what drives financial performance and forecast future financial scenarios. You’ll learn more about the frameworks of financial reporting, income statements, and cash reporting, and apply different approaches to analyzing financial performance using real-life examples to see the concepts in action. By the end of this course, you’ll have honed your skills in understanding how financial data and non-financial data interact to forecast events and be able to determine the best financial strategy for your organization.
      


          Module 1: Introduction, Balance Sheet and Income Statement
    -This module was designed to give you a foundational overview of financial reporting and income statements. You’ll identify and analyze balance sheet equations and its key components such as assets, liabilities, and shareholders’ equity. Through examining a sample real-world financial statement, you’ll learn how to calculate income, revenue, and expenses transactions, and see how the income statement is linked to changes in the balance sheet. By the end of this module, you’ll have a better understanding of the key components in financial reporting and learn how to craft an accurate income statement for your organization.

Module 2: Cash Flow Statement
    -In this module, you’ll examine cash flow statements further, and take a closer look at methods of creating cash flow statements. Using your understanding of financial reporting, you’ll be able to classify different business activities into separate categories such as operating, investing, and financing activities. Through analyzing the real-world financial statement from the previous module, you’ll learn about both direct and indirect methods of creating cash flow statements. By the end of this module, you’ll be able to differentiate between various business activities and effectively utilize both direct and indirect methods of creating cash flow statements for your organization.

Module 3: Financial Statement Analysis
    -In this module, you’ll examine a systematic approach to ratio analysis and other common tools of financial statement analysis. You’ll develop an understanding of ratios and liquidity measures so you can accurately assess risk within your organization’s financial activities. You’ll discover different approaches to profitability measures such as Earnings Per Share (EPS), Return on Equity (ROE), and the Dupont Analysis. You will be able to match Return on Assets (ROA) to various types of companies and gain a better understanding of the drivers of ROA. Then, you’ll explore the concepts of sales revenue and different qualities of earnings. By the end of this module, you’ll understand the theoretical basis behind ratio analysis, and be able to employ different ratio analyses and accurately calculate profitability measures for your organization.

Module 4: Linking Non-Financial Metrics to Financial Performance
    -In this module, you’ll discover how to determine which non-financial performance measures predict financial results through asking these fundamental questions: Of the hundreds of non-financial measures, which are the key drivers of financial success? How do you rank or weight non-financial measures which don’t share a common denominator? And what performance targets are desirable? You’ll examine comprehensive examples of how companies have used accounting data to show how investments in non-financial dimensions pay off in the future and important organizational issues that commonly arise using these models. By the end of this module, you’ll know how predictive analytics can be used to determine what you should be measuring, how to weight different performance measures when trying to analyze potential financial results, how to make trade-offs between short-term and long-term objectives, and how to set performance targets for optimal financial performance.",Financial Acumen for Non-Financial Managers
https://www.classcentral.com/course/opensap-transformation-to-hybrid-landscapes-3669,"SAP’s clients are increasingly interested in adopting cloud solutions. The prediction from IDC is that more than 65% of enterprise IT organizations will commit to hybrid cloud technologies before 2016. Companies that use SAP solutions can now choose between on-premise, cloud, and hybrid deployments – a combination of both on-premise and cloud. This freedom of choice allows companies to transform at their own pace, following their business priorities and markets, which can change at any time.
If you’re asking yourself questions like “how do I get there?”, “what does the hybrid deployment model mean for my security and operations teams?” and “how can I ensure sufficient integration between the different environments?” then this openSAP course is for you. The questions are highly company-specific, so there is no one correct answer to them all. However, the aim of this openSAP course is to give you an understanding for what running a hybrid landscape means for integration, security, and operations, and how you can start your own hybrid transformation journey.
Week 1 will provide you with an introduction to cloud and hybrid deployments.
Week 2 offers a deep dive into the topic of integration, where we will give you an overview of the different integration technologies before going on to compare them.
In week 3, we will talk about the security aspects you should consider in order to ensure that the data in your hybrid landscape is secure.
In week 4, the focus will be on operating the new environment. How do operative tasks change when you move from an on-premise environment to a hybrid landscape?
The course concludes with week 5 – the transformation. Here, the topics of adoption, organizational impact, strategy, and roadmap will be discussed.



            Read more",Transformation to Hybrid Landscapes
https://www.classcentral.com/course/edx-strategic-social-media-marketing-8212,"Social media technologies are continuously transforming the ways consumers interact with each other and firms. These changes constitute a fundamental shift in the marketplace--consumers have greater opportunities to voice their opinions and connect with their peers as well as increased influence over marketers and brands. 
In this course, part of the Digital Product Management MicroMasters program, we examine how organizations capitalize on social media and consumer-to-consumer interactions to support their marketing efforts. We view these issues from a strategic and a practical perspective, rather than a technical or platform perspective. We will give you the knowledge you need to create engaging content for platforms such as Facebook, Instagram, Twitter, and Snapchat and how to identify influencers, deliver content to a targeted audience, and measure the success of your efforts. 
Understanding social media is crucial for product managers who will be operating in a digital environment. Product managers will learn how to use social media conversations to inform their decision-making and how to leverage social media to promote their products, services and the brand. Additionally, learners will gain an understanding of how social media can be used to achieve specific organizational objectives and to measure the effectiveness of those efforts.



Week 1: A Strategic Perspective on Social Media Marketing
Introduction to social media and how it has altered the consumer decision-making process and communications paradigm. Describe the role of social media in marketing strategy and assess the tradeoffs in using social media relative to traditional communication methods. Learn how to set social media marketing objectives that are linked to business objectives. 
Week 2: Leveraging Networks
Understand the role of networks in the distribution of content, including network structure and how it affects the flow of information. Learn how to leverage online networks and communities to engage consumers in brand-related conversations. Discuss how to identify influencers and their role in distributing content. 
Week 3: Creating Engaging Content
Learn how to create social media content that attracts and retains consumers' attention and motivates engagement and sharing. Describe the role of storytelling in a digital landscape. Understand how to evaluate and select platforms for distributing content. 
Week 4: Social Media Listening and Co-Creation
Examine how social media listening is integrated into marketing decision making. Introduction to approaches to social media listening and how to draw inferences from listening data. Learn how social media is used to facilitate open innovation and co-creation. 
Week 5: Assessing Social Media ROI
Introduction to a framework for assessing the return on investment of social media activities. Describe metrics for measuring the success of social media efforts and explore the role of analytics in linking these metrics to the bottom line. Understand the role of paid media in social media marketing. 
Week 6: The Role of Social Media in the Organization
Describe organizational approaches to managing social media and developing social media policy. Discuss how to manage specific issues in social media, including negative feedback, online reviews, and crisis management. Identify ethical conflicts and issues associate with social media marketing decisions.",Strategic Social Media Marketing
https://www.classcentral.com/course/mobilecloud-1704,"This MOOC describes by example how to connect Android mobile devices to clouds via the use of object-oriented design techniques, Java programming language features, Jetty middleware, Java Servlets, the Java Spring Framework, and cloud computing platforms, such as Google App Engine. Although there will be 10 weeks of lecture material, the required core of the course is six weeks long and can be completed flexibly within the ten week schedule to provide flexibility for students during the summer.
An extended case study project will be used throughout the required core of the MOOC to showcase architectures for communicating with the cloud using HTTP, server-side processing of mobile data using servlets and the Java Spring Framework, and scalable storage of data using no-SQL databases and other platforms. Due to the importance of building secure and scalable mobile/cloud platforms, this MOOC will not only show you how to program handheld systems that talk to the cloud, but how to do so securely, scalably, and efficiently. Security and scalability topics will be woven into discussions of cloud service creation so that students learn, from the start, how to create robust cloud services for mobile devices.
Four weeks of optional lecture material will also be provided for students who would like to gain a deeper understanding of the patterns and frameworks for building cloud infrastructure building. This material will be presented in the context of the open-source JAWS web server, which is implemented in C++ as part of the ACE open-source object-oriented concurrent and networked programming toolkit.
Although the cloud service topics in this course will be taught in the context of connecting mobile devices to the cloud, the concepts are broader and will give students the ability to create the cloud services to support large-scale web applications, such as social networking applications; cloud services for embedded systems, such as the Internet of Things and Industrial Internet; and wearable computing devices, such as Google Glass. 
 Note: This course is part of a trans-institution sequence of MOOCs entitled Mobile Cloud Computing with Android
This MOOC and two others, taught by Dr. Adam Porter from the University of Maryland and Dr. Douglas C. Schmidt from Vanderbilt University, have been designed to complement one another as part of the first trans-institution Specialization taught on the Coursera platform. Some of the programming assignments and the course project for these MOOCs will be coordinated. Dr. Porter's MOOC, Programming Mobile Applications for Android Handheld Systems, will be taught first; it focuses on the design and programming of user-facing application components. Dr. Schmidt's MOOC, Programming Mobile Services for Android Handheld Systems, will be taught next; it focuses on middleware systems programming topics, such as synchronous and asynchronous concurrency models, background service processing, structured data management, local inter-process communication and networking. This MOOC introduces the concepts and knowledge needed to connect the user-facing and service-based components, built in the first two courses, to the cloud.  
If you just want to take some of the MOOCs in this sequence or take them all in different order you’re certainly welcome to do so, and you’ll still learn a lot. If you take all the MOOCs in this sequence in the order presented, however, you’ll gain a deeper, end-to-end understanding of handheld systems, their applications and services, as well as their integration into the cloud.



            Read more
          



The course is organized into the sections outlined below.
Section 1: Talking to the Cloud with HTTP

Module 1: The HTTP Protocol

Introduction
What are Communication Protocols?
Intro to HTTP
Why HTTP?
What is a cloud service?
HTTP Request Methods
HTTP Request Anatomy
URLs Query Parameters
Mime Types Content Type Header
Request Body Encoding
HTTP Response Anatomy
HTTP Response Codes
Cookies


Module 2: Designing Applications with HTTP Communication

Building Cloud Services on HTTP
Protocol Layering / HTTP Design Methodologies
REST
HTTP Polling
Push Messaging



Section 2: Building Java Cloud Services

Module 1: Java Servlets

What are Servlets?
A First Cloud Service with a Servlet
Web.xml
Video Servlet Code Walkthrough
Video Servlet Test Walkthrough with HttpClient
Securely Handling Client Data Avoiding Injection Attacks




Module 2: Better Abstractions for Building Java Cloud Services

Intro to Java Annotations
HTTP to Object Marshalling
Intro to JSON
The Spring Dispatcher Servlet and the Controller Abstraction
Intro to Spring Controllers
Accepting Client Data with RequestParam Annotations
Accepting Client Data with PathVar Annotations
Accepting Client Data with RequestBody Annotations and JSON
Handling Multipart Data
Generating Responses with the ResponseBody Annotation
Custom Marshalling with Jackson Annotations Serializers/Deserializers
Spring Boot Application Structure
Spring Controller Code Walkthrough
Spring Controller Test Code Walkthrough


Module 3: Better Client-side Communication Abstractions

Introduction to Retrofit
Retrofit Client Code Walkthrough
Android Retrofit Client Code Walkthrough


Module 4: Building Loosely Coupled and Extensible Java Services

Spring Dependency Injection Auto-wiring
Spring Configuration Annotations
Spring Dependency Injection Controller Code Walkthrough
Spring Dependency Injection Controller Test Code Walkthrough



Section 3: Building Database-driven Java Cloud Services

Module 1: Persistent Objects

Object to DB Mapping
JPA
Entities
Repositories
Understanding SQL Injection Attacks
Spring Data Code Walkthrough


Module 2: RESTful Services for Persistent Objects

Spring Data REST
Spring Data REST Code Walkthrough



Section 4: Restricting Service Access with User Accounts

Module 1: Secure HTTP Communication

Man in the Middle Attacks Public Key Infrastructure
HTTPS

Module 2: What was I Saying: Keeping Track of Sessions

Sessions
Spring Security Overview
Spring Security Configuration in Java
Building a Custom UserDetailsService
Setting up a custom UserDetailsService
The Principal
Spring Security Role Annotations
More Complex Expression-based Pre Post Authorize Annotations
Spring Security Controller Code Walkthrough
Spring Security Controller Test Code Walkthrough


Module 3: Authenticating Mobile Clients

Stateful Sessions with Cookies Why They Aren't Ideal for Mobile
Stateless Sessions with Tokens
OAuth 2.0
Spring Security OAuth 2.0
A Spring OAuth 2.0 Secured Service
A Retrofit Oauth 2.0 Client for Password Grants



Section 5: Deploying to the Cloud Scaling

Module 1: General Scaling Strategies

Stateless vs. Stateful Applications
Horizontal Scaling
Auto-scaling Horizontally
Caching
Offloading to Cloud Provider Services
Asynchronous IO in Controllers


Module 2: Scaling Up Data Storage

NoSQL Databases
Optimizing for Key-based Lookups
Optimizing for Reads vs. Writes
Contention Sharding
Mongo DB
Spring Data Mongo DB
Database as a Service
Amazon Dynamo
Spring Data Dynamo DB
App Engine Big Table


Module 3: Automating Packaging Deployment

Deploying to Infrastructure as a Service
Deploying to Amazon EC2
Packaging Web Applications into WAR files
Adapting Spring Boot Applications for Google App Engine
Deploying to App Engine


Module 4: Performance Testing

Intro to Cloud Service Performance Testing
Apache JMeter
Building Realistic Tests



Section 6: Patterns and Frameworks for Concurrent and Networked Server Software [Optional Material]

Module 1: Introduction to the Web Server Case Study

Applying Patterns and Frameworks to Concurrent and Networked Software
Overview of JAWS Web Server Case Study: Part 1
Overview of JAWS Web Server Case Study: Part 2
Overview of JAWS Web Server Case Study: Part 3


Module 2: Patterns and Frameworks for Service Access and Communication

Accidental Complexities with the Sockets API
The Wrapper Facade Pattern
ACE C++ Socket Wrapper Facades
Applying the ACE Wrapper Facades to a Web Client and Server


Module 3: Patterns and Frameworks for Synchronous Event Handling, Connections, and Service Initialization

The Reactor and Acceptor-Connector Patterns
The ACE Reactor Framework
Applying the ACE Reactor to JAWS
The ACE Acceptor-Connector Framework and Applying it to JAWS


Patterns and Frameworks for Service Configuration and Activiation

The Component Configurator Pattern
The ACE Service Configurator Framework
Applying the ACE Service Configurator to JAWS
Applying the Activator Pattern to JAWS


Patterns and Frameworks for Concurrency and Synchronization

The Active Object Pattern
The ACE Task Framework
Applying ACE Task and Acceptor-Connector to JAWS
The Half-Sync/Half-Async Pattern
Implementing Half-Sync/Half-Async Using ACE
The Monitor Object Pattern
Applying the Monitor Object and Synchronization Patterns to JAWS
The Leader/Followers Pattern
Applying the Leader/Followers Pattern and ACE_TP_Reactor to JAWS


Patterns and Frameworks for Asynchronous Event Handling

The Proactor pattern
The ACE Proactor Framework
Applying the ACE Proactor Framework to JAWS
The Asynchronous Completion Token Pattern and Applying it to JAWS


Summary

Evaluating Patterns and Frameworks for Concurrent and Networked Software",Programming Cloud Services for Android Handheld Systems
https://www.classcentral.com/course/iot-connectivity-security-7415,"Welcome to Web Connectivity and Security in Cyber Physical Systems!

In this course, we will explore several technologies that bring modern devices together, facilitating a network of connected things and making devices internet enabled. We will discuss rules, protocols, and standards for these devices to communicate with each other in the network. We will also go through security and privacy issues and challenges in cyber physical systems (CPS). We will explore measures and techniques for securing systems from different perspectives. Possible attack models are introduced and solutions to tackle such attacks are discussed. Moreover, some basic concepts related to privacy in cyber physical systems are presented.

The course comprises altogether five modules and is split up into two main sections. The first section contains three modules and centers on the problem of web connectivity in cyber physical systems. The second section consist of two modules focusing on security measures in such systems. Each module ends with a graded quiz, and there is a final peer reviewed exam at the end of the course covering the two main sections of the course. 

After completing this course, you will have the basic knowledge and capacity for designing the network architecture of your cyber physical system. This includes putting together different components, selecting suitable communication protocols, and utilizing these protocols in your system. You will also be able to define security requirements for your system and choose and implement a proper security and privacy technique to protect it.
      


            Read more
          



          Introduction to Web Connectivity & Security
    -In this module you will learn about the layered architecture of communication protocols in cyber physical systems. More specifically the learning objectives include: 

M2M Connectivity Protocols
    -In this module you will learn about communication protocols . More specifically the learning objectives incluede:

Web Connectivity
    -In this module you will learn about Data Transfer over Web. More specifically the learning objectives incluede:

CPS Security and Privacy
    -In this module you will learn the basic concepts about security and privacy in cyber physical systems. More specifically the learning objectives include: 

Cryptography
    -In this module you will learn about cryptographic solutions for securing the cyber physical systems. More specifically the learning objectives include: 


Final peer-reviewed exam",Web Connectivity and Security in Embedded Systems
https://www.classcentral.com/course/edx-quantum-information-science-i-part-1-10087,"This course is part of a three-course series that provides an introduction to the theory and practice of quantum computation. We cover:

the physics of information processing
quantum logic
quantum algorithms including Shor's factoring algorithm and Grover's search algorithm
quantum error correction
quantum communication and key distribution  

This course will help you establish a foundation of knowledge for understanding what quantum computers can do, how they work, and how you can contribute to discovering new things and solving problems in quantum information science and engineering.The three-course series comprises:

8.370.1x: Foundations of quantum and classical computing – quantum mechanics, reversible computation, and quantum measurement
8.370.2x: Simple quantum protocols and algorithms – teleportation and superdense coding, the Deutsch-Jozsa and Simon’s algorithm, Grover’s quantum search algorithm, and Shor’s quantum factoring algorithm
8.370.3x: Foundations of quantum communication – noise and quantum channels, and quantum key distribution

Prior knowledge of quantum mechanics is helpful but not required. It is best if you know some linear algebra.
This course has been authored by one or more members of the Faculty of the Massachusetts Institute of Technology. Its educational objectives, methods, assessments, and the selection and presentation of its content are solely the responsibility of MIT. MIT gratefully acknowledges major support for this course, provided by IBM Research. This course on quantum information science is a collective effort to further advance knowledge and understanding in quantum information and quantum computing.
For more information about MIT’s Quantum Curriculum, visit quantumcurriculum.mit.edu.



            Read more
          



          Week 1: quantum mechanicsWeek 2: reversible computationWeek 3: quantum measurement","Quantum Information Science I, Part 1"
https://www.classcentral.com/course/introduction-tensorflow-13287,"If you are a software developer who wants to build scalable AI-powered algorithms, you need to understand how to use the tools to build them. This course is part of the upcoming Machine Learning in Tensorflow Specialization and will teach you best practices for using TensorFlow, a popular open-source framework for machine learning. 

The Machine Learning course and Deep Learning Specialization from Andrew Ng teach the most important and foundational principles of Machine Learning and Deep Learning. This new deeplearning.ai TensorFlow Specialization teaches you how to use TensorFlow to implement those principles so that you can start building and applying scalable models to real-world problems. To develop a deeper understanding of how neural networks work, we recommend that you take the Deep Learning Specialization.
      


          A New Programming Paradigm
    -Welcome to this course on going from Basics to Mastery of TensorFlow. We're excited you're here! In week 1 you'll get a soft introduction to what Machine Learning and Deep Learning are, and how they offer you a new programming paradigm, giving you a new set of tools to open previously unexplored scenarios. All you need to know is some very basic programming skills, and you'll pick the rest up as you go along.

You'll be working with code that works well across both TensorFlow 1.x and the TensorFlow 2.0 alpha. 

To get started, check out the first video, a conversation between Andrew and Laurence that sets the theme for what you'll study...

Introduction to Computer Vision
    -Welcome to week 2 of the course! In week 1 you learned all about how Machine Learning and Deep Learning is a new programming paradigm. This week you’re going to take that to the next level by beginning to solve problems of computer vision with just a few lines of code! 

Check out this conversation between Laurence and Andrew where they discuss it and introduce you to Computer Vision!


Enhancing Vision with Convolutional Neural Networks
    -Welcome to week 3! In week 2 you saw a basic Neural Network for Computer Vision. It did the job nicely, but it was a little naive in its approach. This week we’ll see how to make it better, as discussed by Laurence and Andrew here. 

Using Real-world Images
    -Last week you saw how to improve the results from your deep neural network using convolutions. It was a good start, but the data you used was very basic. What happens when your images are larger, or if the features aren’t always in the same place? Andrew and Laurence discuss this to prepare you for what you’ll learn this week: handling complex images!","Introduction to TensorFlow for Artificial Intelligence, Machine Learning, and Deep Learning"
https://www.classcentral.com/course/social-impact-growth-7036,"In Course 3 of this Specialization you will first of all learn about  Social Impact Assessment. Hence you will be able to develop a method to evaluate the social mission that you achieve while implementing your business plan. Next you will outline an appropriate communication strategy for your social enterprise and will demonstrate how to market your products and services to beneficiaries and other customers. Here you will employ an adaptable communication strategy as you move from early adopters to a broader market share. 

Furthermore you will determine growth strategies and how you can scale or replicate your business plan internationally in order to reach a larger number of beneficiaries. In particular you will discuss organic growth, social franchising, and an open source approach. Finally, you will evaluate exit strategies. Thus you will review options social enterprises have when they need to finance their growth but the original funders can not or do not want to finance the expansion. 

Course 3 will be completed by your Capstone project, which will ask you to submit the final business plan of your social venture.

Note: It is highly recommended to have completed Course 1 & 2 of the Social Entrepreneurship Specialization before starting this Course!
      


          Introduction to Social Impact Assessment
    -Welcome to the final Course of this Social Entrepreneurship Specialization. In this session you will be introduced to the topic of measuring the social impact of a venture. You are asked to apply your knowledge to the case of Specialisterne and frame your business plan by writing the executive summary. 

Measuring Social Impact
    -Welcome to Module 2. In this week we will delve deeper into social impact assessment. We encourage you to explore your possibilities as you grow and try to find indicators for your activities. It is crucial to understand and document how societal value is created. Most startups do not yet have any actual impact that can be measured, therefore, it is important to spell out your “theory of change” as clearly as possible and to back it up with data if possible. Relevant data would substantially strengthen your position in terms of investors, stakeholders as well as your communication and marketing strategy.

How Social Enterprises Communicate
    -Welcome to Module 3! In this week we will talk about how social enterprises communicate about their products and their impact. The case about CaféDirect will be presented and you will be encouraged to think about your own communication strategy. Finally we will kick-off the topic about growth and replication. 

Growth and Replication of Social Enterprises
    -Welcome! In week 4 we will talk about how social enterprises can replicate their social innovations. We will focus on the  case of Specialisterne, which demonstrates that also mixed approaches can be valuable and we will also listen to best-practice examples of India and the U.S. Finally you will be asked to give advice about the the Mobility CarSharing case. 

Finalize your Business plan
    -Welcome change-makers to the final week of this Social Entrepreneurship Specialization! We will use this session to further discuss exit strategies by looking at two cases: Mobility and Café Direct. Finally we will approach the sensitive topic of failing and what role it plays in the field of social entrepreneurship. We also want to use this option to thank all learners for participation, contribution and support! We hope that this specialization helped to kick-start your own social entrepreneurship journey. Keep up your good work! Congratulations and good luck!",Unleashing the Impact of your Social Enterprise
https://www.classcentral.com/course/intro-tensorflow-11075,"We introduce low-level TensorFlow and work our way through the necessary concepts and APIs so as to be able to write distributed machine learning models. Given a TensorFlow model, we explain how to scale out the training of that model and offer high-performance predictions using Cloud Machine Learning Engine.

Course Objectives:
Create machine learning models in TensorFlow
Use the TensorFlow libraries to solve numerical problems
Troubleshoot and debug common TensorFlow code pitfalls
Use tf.estimator to create, train, and evaluate an ML model
Train, deploy, and productionalize ML models at scale with Cloud ML Engine
      


          Introduction
    -The tool we will use to write machine learning programs is TensorFlow and so in this course, we will introduce you to TensorFlow. In the first course, you learned how to formulate business problems as machine learning problems and in the second course, you learned how machine works in practice and how to create datasets that you can use for machine learning. Now that you have the data in place, you are ready to get started writing machine learning programs.

Core TensorFlow
    -We will introduce you to the core components of TensorFlow and you will get hands-on practice building machine learning programs. You will compare and write lazy evaluation and imperative programs, work with graphs, sessions, variables, as finally debug TensorFlow programs.

Estimator API
    -In this module we will walk you through the Estimator API.

Scaling TensorFlow models
    -I’m here to talk about how you would go about taking your TensorFlow model and training it on GCP’s managed infrastructure for machine learning model training and deployed.

Summary
    -Here we summarize the TensorFlow topics we covered so far in this course. We'll revisit core TensorFlow code, the Estimator API, and end with scaling your machine learning models with Cloud Machine Learning Engine.",Intro to TensorFlow
https://www.classcentral.com/course/audio-2488,"In this course you will learn about audio signal processing methodologies that are specific for music and of use in real applications. We focus on the spectral processing techniques of relevance for the description and transformation of sounds, developing the basic theoretical and practical knowledge with which to analyze, synthesize, transform and describe audio signals in the context of music applications.

The course is based on open software and content. The demonstrations and programming exercises are done using Python under Ubuntu, and the references and materials for the course come from open online repositories. We are also distributing with open licenses the software and materials developed for the course.
      


          Concluding topics: Lesson Choices

Introduction 
    -Introduction to the course, to the field of Audio Signal Processing, and to the basic mathematics needed to start the course. Introductory demonstrations to some of the software applications and tools to be used. Introduction to Python and to the sms-tools package, the main programming tool for the course.

Discrete Fourier transform
    -The Discrete Fourier Transform equation; complex exponentials; scalar product in the DFT; DFT of complex sinusoids; DFT of real sinusoids; and inverse-DFT. Demonstrations on how to analyze a sound using the DFT; introduction to Freesound.org. Generating sinusoids and implementing the DFT in Python.

Fourier theorems
    - Linearity, shift, symmetry, convolution; energy conservation and decibels; phase unwrapping; zero padding; Fast Fourier Transform and zero-phase windowing; and analysis/synthesis. Demonstration of the analysis of simple periodic signals and of complex sounds; demonstration of spectrum analysis tools. Implementing the computation of the spectrum of a sound fragment using Python and presentation of the dftModel functions implemented in the sms-tools package.

Short-time Fourier transform
    -STFT equation; analysis window; FFT size and hop size; time-frequency compromise; inverse STFT. Demonstration of tools to compute the spectrogram of a sound and on how to analyze a sound using them. Implementation of the windowing of sounds using Python and presentation of the STFT functions from the sms-tools package, explaining how to use them. 

Sinusoidal model
    -Sinusoidal model equation; sinewaves in a spectrum; sinewaves as spectral peaks; time-varying sinewaves in spectrogram; sinusoidal synthesis. Demonstration of the sinusoidal model interface of the sms-tools package and its use in the analysis and synthesis of sounds. Implementation of the detection of spectral peaks and of the sinusoidal synthesis using Python and presentation of the sineModel functions from the sms-tools package, explaining how to use them. 

Harmonic model
    -Harmonic model equation; sinusoids-partials-harmonics; polyphonic-monophonic signals; harmonic detection; f0-detection in time and frequency domains. Demonstrations of pitch detection algorithm, of the harmonic model interface of the sms-tools package and of its use in the analysis and synthesis of sounds. Implementation of the detection of the fundamental frequency in the frequency domain using the TWM algorithm in Python and presentation of the harmonicModel functions from the sms-tools package, explaining how to use them. 

Sinusoidal plus residual model
    -Stochastic signals; stochastic model; stochastic approximation of sounds; sinusoidal/harmonic plus residual model; residual subtraction; sinusoidal/harmonic plus stochastic model; stochastic model of residual. Demonstrations of the stochastic model, harmonic plus residual, and harmonic plus stochastic interfaces of the sms-tools package and of its use in the analysis and synthesis of sounds. Presentation of the stochasticModel, hprModel and hpsModel functions implemented in the sms-tools package, explaining how to use them. 

Sound transformations
    -Filtering and morphing using the short-time Fourier transform; frequency and time scaling using the sinusoidal model; frequency transformations using the harmonic plus residual model; time scaling and morphing using the harmonic plus stochastic model. Demonstrations of the various transformation interfaces of the sms-tools package and of Audacity. Presentation of the stftTransformations, sineTransformations and hpsTransformations functions implemented in the sms-tools package, explaining how to use them. 

Sound and music description
    -Extraction of audio features using spectral analysis methods; describing sounds, sound collections, music recordings and music collections. Clustering and classification of sounds. Demonstration of various plugins from SonicVisualiser to describe sound and music signals and demonstration of some advance features of freesound.org. Presentation of Essentia, a C++ library for sound and music description, explaining how to use it from Python. Programming with the Freesound API in Python to download sound collections and to study them. 

Concluding topics
    -Audio signal processing beyond this course. Beyond audio signal processing. Review of the course topics. Where to learn more about the topics of this course. Presentation of MTG-UPF. Demonstration of Dunya, a web browser to explore several audio music collections, and of AcousticBrainz, a collaborative initiative to collect and share music data.",Audio Signal Processing for Music Applications
https://www.classcentral.com/course/teaching-data-science-19139,"Learn practical ways to teach data science
Understanding how to use and interpret data will be essential for the next generation, but many schools and teachers aren’t equipped to teach basic data science to students. This course will help you introduce data science in the classroom so that your students are prepared for the future.
You will get an introduction to useful tools for exploring data, learn the basics of statistics and explore how you can embed data activities into your teaching plans. You will get hands on experience interpreting real data so that you feel comfortable helping students get started with data science.
This course is primarily for school teachers, but it might also be of interest to parents looking to teach their children about data science.",Getting Started with Teaching Data Science in Schools
https://www.classcentral.com/course/edx-preparing-for-the-ap-computer-science-a-exam-part-1-2516,"CSAP.1x  covers the material of AP Computer Science A which is equivalent to a first-semester, college-level course in computer science. This highly interactive course will introduce students to the fundamental concepts of computer science. The course will be structured to encourage students to think computationally and enjoy problem solving. New York City’s companies, museums, art and architecture will be used as examples to emphasize the ubiquitous role of computing and programming concepts in the world around us.
The course will delve into object- oriented problem solving and design using the Java  programming language. Students will have access to practice problems that will help them learn to program without spending hours on finding and fixing syntax errors. These will include online multiple-choice questions in the style of those on the AP exam, mixed-up code that the user drags into the correct order, fill in the blank code and audio tours of the code.
Topics include problem solving, programming design strategies and  data structures, algorithms, role of computation in real-world applications like smart phones, google glass and robots. This material may be used for self-study and as a preview by students and teachers considering the September 2015 offering of the course.
Learn more about our High School and AP* Exam Preparation Courses
*Advanced Placement and AP are registered trademarks of the College Board, which was not involved in the production of, and does not endorse, these offerings.



            Read more",Preparing for the AP* Computer Science A Exam - Part 1
https://www.classcentral.com/course/statistics101-3334,"Statistics is the lingua franca of modern science, including the social sciences. It is also of ever greater importance in daily life, as data of all sorts are now ubiquitous. Statistical literacy is hence of great value, both for academic purposes and for our daily routines. This course offers a solid foundation in statistical reasoning and its uses in the quantitative social sciences.Learning statistics can be a daunting experience. There is a plethora of statistical concepts to master and many of them come with a hefty dose of mathematical notation. The goal of the present course is to develop a clear path through the conceptual forest and to explain each concept both in its narrow meaning and as a part of the larger enterprise of statistical reasoning. Mathematical skills are not taken for granted; instead, we shall review the necessary mathematical tools so that you will not get stuck on this aspect.The field of statistics is sometimes divided into descriptive and inferential statistics, with probability theory forming a bridge between the two. In this course, we start out descriptively, by considering different ways in which we can learn from data. We then delve into the subject of probability theory, to end with a discussion of statistical inference. The emphasis in this part is on learning how to draw conclusions about populations with the help of data from a sample.By the end of this course, you should have a good feeling for descriptive statistics, statistical inference, and probability theory. You should also understand the interplay of these elements in the broader enterprise of statistical reasoning. And you should feel more comfortable reading about statistics and using them in your own work.
      


            Read more
          



          MODULE I: DESCRIPTIVE STATISTICSWeek 1: Understanding the properties of a single variable through visualizationWeek 2: Understanding the properties of a single variable through summary statisticsWeek 3: Understanding associations between variablesMODULE II: PROBABILITY THEORYWeek 4: Understanding and computing with probabilitiesWeek 5: Random variables and distributionsWeek 6: Commonly used statistical distributionsMODULE III: INFERENTIAL STATISTICSWeek 7: Understanding samplingWeek 8: A primer of estimation theoryWeek 9: The theory of hypothesis testingWeek 10: Commonly used statistical tests",Introduction to Statistics for the Social Sciences
https://www.classcentral.com/course/edx-oriental-beliefs-between-reason-and-traditions-6540,"This course takes a journey through the world of beliefs as they have developed in a great variety of cultures, ranging from Ancient Egypt, the Near East to Central Asia, India, China, and the Far East. We will discuss where these beliefs, theories and practices originated from, how they were passed on over the ages and why some are still so central to large communities of believers across the world today, whether it be amongst Jews, Christians, Muslims, Buddhists or Shintoists.
We'll be dealing with everything from gods and spirits, to angels and demons, to afterlife and the netherworld, as well as the great cycles of the universe and the tremendous power of lunar and solar eclipses. The interpretation of dreams and all sorts of magic and miraculous deeds will also be covered during this course.
Students will have the opportunity to travel extensively in time and space. The comparative, critical and contextualized approach of this course will allow for a valuable and thought-provoking experience.
We are a course team of about twenty-five specialists working at, or in close interaction with, the Department of Greek, Latin and Oriental Studies (GLOR) at the University of Louvain. We are all historians or philologists, all passionate about our respective fields of expertise, and all fully determined to help you as much as we can as we progress through this course. Most of all, we're looking forward to ""meeting"" you and to having lively discussions with you on the forums.
If you're curious about the cultures of this world, past and present, this course is definitely for you. Put your wings on and get ready to ride on our “GLOR-ious” dragon and to enjoy the whole adventure with us!



            Read more
          



Week 1: Overall presentation

Modalities of course
Team
Geographical introduction 
Historical introduction

Week 2: Gods and Spirits

Nature in Japanese Daily Life
The Power of Chinese Hybrids
The Gods in Buddhism
Egyptian Gods, Cult Centres and the Cosmogony of Heliopolis

Week 3: Angels and Demons

Angels in the Hebrew Bible
Angels in Islam
Demons in Ancient Mesopotamia
Fighting the Demons in Egypt: from Texts to Religious Practices

Week 4: Netherworld and Afterlife

Concepts of Afterlife in Ancient Egypt
The Netherworld in Ancient Mesopotamia
The Netherworld in Ancient Anatolia and Iran
Underworld and Afterlife in Ancient Greek Epics 1: Tartarus/Erebus
Underworld and Afterlife in Ancient Greek Epics 2: Hades
Buddha, the Man Who Refuses to Talk About the Afterlife • Ancestor Worship in China

Week 5: Astrology and Heavenly Cycles

Eclipses: Beliefs and Theories in the Ancient World 1 - Superstitions
Eclipses: Beliefs and Theories in the Ancient World 2 - Theories
On World Cycles 1: The Great Year Doctrine in Antiquity
On World Cycles 2: The Great Year Doctrine in the Middle Ages
Arab Astrology in the Medieval Latin West
Astrology and Love in Romance Literatures

Week 6: Magic, Dreams and Miracles

The Miraculous Portrait of Jesus
The Science of the Letters
Alchemy throughout the Ages
The Varieties of Magic in Islam
Dreams and Meditation in Tibet
Forbidden Directions in Japan

Week 7: A Case Study

The Miracle of the Moving Muqattam Image

Week 8: Summing up",Oriental Beliefs: Between Reason and Traditions
https://www.classcentral.com/course/applied-data-science-capstone-11207,"This capstone project course will give you a taste of what data scientists go through in real life when working with data. 

You will learn about location data and different location data providers, such as Foursquare. You will learn how to make RESTful API calls to the Foursquare API to retrieve data about venues in different neighborhoods around the world. You will also learn how to be creative in situations where data are not readily available by scraping web data and parsing HTML code. You will utilize Python and its pandas library to manipulate data, which will help you refine your skills for exploring and analyzing data. 

Finally, you will be required to use the Folium library to great maps of geospatial data and to communicate your results and findings.

If you choose to take this course and earn the Coursera course certificate, you will also earn an IBM digital badge upon successful completion of the course.  

LIMITED TIME OFFER: Subscription is only $39 USD per month for access to graded materials and a certificate.
      


          Introduction
    -In this module, you will learn about the scope of this capstone course and the context of the project that you will be working on. You will learn about different location data providers and what location data is normally composed of. Finally, you will be required to submit a link to a new repository on your Github account dedicated to this course.

Foursquare API
    -In this module, you will learn in details about Foursquare, which is the location data provider we will be using in this course, and its API. Essentially, you will learn how to create a Foursquare developer account, and use your credentials to search for nearby venues of a specific type, explore a particular venue, and search for trending venues around a location.

Neighborhood Segmentation and Clustering
    -In this module, you will learn about k-means clustering, which is a form of unsupervised learning. Then you will use clustering and the Foursquare API to segment and cluster the neighborhoods in the city of New York. Furthermore, you will learn how to scrape website and parse HTML code using the Python package Beautifulsoup, and convert data into a pandas dataframe.

The Battle of Neighborhoods
    -In this module, you will start working on the capstone project. You will clearly define a problem and discuss the data that you will be using to solve the problem.

The Battle of Neighborhoods (Cont'd)
    -In this module, you will carry out all the remaining work to complete your capstone project. You will submit a report of your project for peer evaluation.",Applied Data Science Capstone
https://www.classcentral.com/course/edx-creative-coding-13438,"In Creative Coding, students are introduced to object-oriented programming concepts, moving past the sequential problem solving found in typical beginner programming classes to use the computer as a creative medium for art, games, and graphic design. This introductory course will introduce you to a variety of concepts in programming, and how they can be applied creatively to work in a variety of media, such as 2D graphics, animation, image and video processing. A strong focus will be on creating interactive experiences for the web. By the end of this course, students will be empowered to read and write javascript for creative applications. This is reinforced through weekly assignments and a midterm and final project that leverage the skills learned in the course




Week 1: Introduction to the class. Basics of 2D Drawing
Week 2: Variables and Conditionals
Week 3: Looping and Repetition
Week 4: Color
Week 5: Functions and Interaction with the Keyboard and Mouse
Week 6: Transformation and Translation
Week 7: Harmonic Motion and Animation
Week 8: Object-Oriented Programming
Week 9: The Document Object Model (DOM)
Week 10: Generative Text and Typography: An Introduction to the RiTa Addon for p5.js
Week 11: Data Visualization and APIs
Week 12: Image
Week 13: Video
Week 14: Final Project Submission",Creative Coding
https://www.classcentral.com/course/nativescript-8684,"This course focuses on developing truly cross-platform, native iOS and Android apps using NativeScript (Ver 3.x). The framework uses Angular, TypeScript or modern JavaScript to get truly native UI and performance while sharing skills and code with the web. You will learn about UI development with NativeScript UI and layout support and access the native mobile platform's capabilities from Javascript. You should have already completed the Bootstrap 4 and the Angular courses in this specialization before proceeding with this course.

At the end of this course you will be able to (a) Build mobile applications targeting multiple platforms with a single codebase, (b) Leverage your Angular, TypeScript and Javascript skills, and (c) Use various features of the NativeScript framework to build truly cross-platform mobile applications
      


          Hybrid Mobile App Development Frameworks: NativeScript: An Introduction
    -This module introduces you to hybrid mobile application development. You will learn about the NativeScript framework and explore some of the features of the NativeScript framework to implement a mobile app based on the Angular application that was implemented in the previous course on Angular.

NativeScript UI Elements
    -This module introduces you to various NativeScript UI elements. We will look at how we can make use of these elements in designing the various views of our application.

NativeScript Animations, Gestures, Storage and Image Resources
    -In this module we look at enhancing the user experience through the use of animations and support for gesture-based interaction. We also look at leveraging the storage for persisting data, and the customization of splash screens, icons and the use of other image resource in the app

Accessing Native Capabilities of Devices: NativeScript Plugins
    -In this module you will explore NativeScript Plugins that enable you to access the native capabilities of the mobile devices. You will use a few plugins in order to understand the general concepts and the patterns for using these plugins within your NativeScript application",Multiplatform Mobile App Development with NativeScript
https://www.classcentral.com/course/futurelearn-electrify-an-introduction-to-electrical-and-electronic-engineering-2128,"Engineering is all about using science to make the world a better place and touches our everyday lives; the device you’re reading this on wouldn’t exist if it wasn’t for electrical and electronic engineers!
In Electrify we’ll cover six different areas of electrical and electronic engineering over the six weeks:

Electromechanics
DC Circuits
AC Circuits
Digital Electronics
Analogue Electronics
Introduction to C Programming

Each week is a topic in it’s own right, so if you find one week difficult the next week will give you something rather different to think about.
You won’t find a hard hat or a spanner anywhere in this course, we’ll be focussing on how engineers use their brains to solve problems and to give a taste of some of the topics a degree level course in Electrical and Electronic Engineering may include.
If you’d like to meet up and chat with your fellow participants before the course starts, get extra updates and have access to special offers and competitions, you can join our Facebook group.
Electrify is open to anyone who is interested in learning more about Electrical and Electronic Engineering, particularly at anyone aged 16+ thinking about their career choices.
The maths in this course is kept to a minimum, however a knowledge of GCSE maths will be helpful.",Electrify: An Introduction to Electrical and Electronic Engineering
https://www.classcentral.com/course/coursera-general-chemistry-concept-development-and-application-3885,"This course will cover the topics of a full year, two semester General Chemistry course.  We will use a free on-line textbook, Concept Development Studies in Chemistry, available via Rice’s Connexions project. 

The fundamental concepts in the course will be introduced via the Concept Development Approach developed at Rice University.  In this approach, we will develop the concepts you need to know from experimental observations and scientific reasoning rather than simply telling you the concepts and then asking you to simply memorize or apply them.

So why use this approach? 

One reason is that most of us are inductive learners, meaning that we like to make specific observations and then generalize from there.  Many of the most significant concepts in Chemistry are counter-intuitive.  When we see where those concepts come from, we can more readily accept them, explain them, and apply them. 

A second reason is that scientific reasoning in general and Chemistry reasoning in particular are inductive processes.  This Concept Development approach illustrates those reasoning processes.  

A third reason is that this is simply more interesting! The structure and reactions of matter are fascinating puzzles to be solved by observation and reasoning.  It is more fun intellectually when we can solve those puzzles together, rather than simply have the answers to the riddles revealed at the outset.

Recommended Background: 
The class can be taken by someone with no prior experience in chemistry.  However, some prior familiarity with the basics of chemistry is desirable as we will cover some elements only briefly.  For example, a prior high school chemistry class would be helpful.

Suggested Readings:
Readings will be assigned from the on-line textbook “Concept Development Studies in Chemistry”, available via Rice’s Connexions project. In addition, we will suggest readings from any of the standard textbooks in General Chemistry.  A particularly good free on-line resource is Dickerson, Gray, and Haight, ""Chemical Principles, 3rd Edition"".  Links to these two texts will be available in the Introduction module.
      


            Read more
          



          Introduction
    -This lecture will cover the unique approach used in this course to the introduction of the fundamental concepts of Chemistry. The Concept Development Study approach was created, implemented, developed and refined at Rice over the course of more than twenty years.  In this pedagogy, each new concept is developed from experimental observations and scientific reasoning.  By contrast, most introductory Chemistry courses simply present each concept as an accepted fact, without foundation.  This is why most Chemical concepts seem abstract and unapproachable. The CDS approach has been shown to more effective for most beginning students. I hope that this opening lecture will pique your curiosity about how you might learn Chemistry in a way which is more effective and more fun.

Atomic Molecular Theory and Atomic Masses
    -Chemistry can be understood fundamentally as the study of atoms and molecules.  In this module, we will examine the experiments which reveal that all matter is composed of atoms which combine to form molecules.  The clever analysis of these experiments illustrates scientific reasoning at its finest, allowing us to understand the existence and properties of particles which could not be directly observed.  In addition, by measuring the relative masses of the different types of atoms, we can begin to predict the ratios of masses of reactants and products during a chemical reaction.

Structure of an Atom and the Electron Shell Model
    -Proving the existence of atoms and knowing that they combine to form molecules does not provide a means to predict how or why these atoms might combine.  This requires greater detail about the structure and properties of individual atoms.   In this module, we extend our understanding of atoms by making observations which reveal the internal structure of the atom including a model for the arrangement of the electrons around the atomic nucleus.  

Electron Energies and Orbitals
    -The electron shell model does not account for all of the observable properties of atoms, including the energies and motions of electrons.  In this module, we observe that these energies are quantized.  We also observe behaviors which reveal the surprising fact that electron motion is described by waves or “orbitals” which provide the probability for the movement of the electrons about the nucleus.  This module takes us into the strange world of quantum mechanics.

Bonding and Structures in Covalent Molecules
    -To understand the types of compounds which can be formed and the properties of those compounds, we have to understand how atoms bond together to form molecules.  In this module, we develop a model for the bonding of non-metal atoms to non-metal atoms, called a covalent bond.   The model can be used to predict which combinations of atoms are stable and which are unstable.  Observations of the structures of the molecules lead to a model to understand molecular geometries and properties related to those geometries.  From this, we build a foundation for understanding and predicting how molecular structure is related to molecular reactivity and function.

Types of Bonding: Non-Metals, Metals, and Salts 
    -In this module, we extend our model of bonding by observing properties of compounds formed between metals and non-metals.  These properties reveal the existence of ionic bonds, which contrast to covalent bonds.  We also consider the properties of pure metals and of metal compounds, leading to a model which explains the bonding between metals atoms.  We develop a means to differentiate and predict the three types of bonding: covalent, ionic, and metallic.

Energy Changes and Reaction Energies
    -Chemical reactions involve energy changes, most commonly with the transfer of heat into or out of the reaction.  Many chemical reactions are performed specifically because of the release of heat or other forms of energy.  In this module, we develop a means to measure these energy transfers and we use these measurements to develop laws which govern energy transfers.  These laws permit us to calculate and predict energy changes during reactions and to understand the energy of a reaction in terms of the energies of the bonds between atoms breaking and forming during a reaction.

Ideal Gas Law and the Kinetic Molecular Theory 
    -One of the powers of chemistry is the ability to relate the properties of individual molecules to the physical and chemical properties of the compounds of these molecules. In other words, we want to relate the atomic molecular world to the macroscopic world of materials.  We begin this study by observing the physical properties of gases and deriving an equation which relates these properties.  From this law, we can devise a model which describes how these physical properties result from the properties and motions of individual molecules.  Understanding the significance of temperature is a critical part of this study.

Phase Transitions and Phase Equilibrium
    -Substances can exist in different physical states, which we call “phases.”  These include solid, liquid and gas.  In this module, we study the transitions between these phases, which are observed to occur only at specific combinations of temperature and pressure.  In addition, we observe that phases exist in equilibrium with one another at this specific temperatures and pressures.  We develop from our observations a model to describe phase equilibrium using the concepts of the kinetic molecular theory deduced in the previous module.

Chemical Kinetics
    -Chemical reactions occur at very different rates, some occurring so slowly that we only notice them with great passing of time and some occurring explosively rapidly.  In this module, we develop measurements of the rates of reaction, determining the factors which can make a reaction proceed more rapidly or more slowly.  These observations are summarized in equations called Rate Laws, where each reaction has its own empirical rate law.  By using kinetic molecular theory, we develop a model to understand how and why each factor in the rate law is important in determining the rate of a chemical reaction.

Chemical Equilibrium
    -Many chemical reactions are observed to “go to completion,” meaning that essentially all of the reactants are consumed in creating products within the constraints of the stoichiometry of the reaction.  However, other chemical reactions do not go to completion.  Rather, we observe that reactants and products can coexist simultaneously at specific observable concentrations or pressures.  This equilibrium between reactants and products is observed to follow an equation called the equilibrium constant.  In this module, we observe many examples of reactions at equilibrium, we measure their equilibrium constants, and we use these to make predictions about how to maximize the yield of chemical reactions.  Included in these important reactions are those involving acids and bases. 

Chemical Thermodynamics
    -One of the most subtle aspects of chemistry is in understanding the factors which make a chemical reaction favorable or unfavorable.  In this module, we pursue this understanding by observing what makes a process “spontaneous,” and we develop the concept of entropy as a predictive tool for spontaneity.  We observe the second law of thermodynamics, and from this, we develop a model for predicting chemical equilibrium based on a new quantity called the “free energy.”  We conclude by relating the free energy to the equilibrium constant observed in a previous module, culminating in one of the most beautiful theories in all of science.",General Chemistry: Concept Development and Application
https://www.classcentral.com/course/edx-lean-research-skills-for-conducting-interviews-11441,"Interviews are one of the most common and powerful field research methods, used across a wide variety of disciplines and topics. Whether conducting a research study, an evaluation of an existing product or service, or gathering insights for a business plan, or a design process, interviews are often the method of choice for gaining insights directly from people.  The quality of that information, however, depends to a large degree on the skill of the interviewer.This course introduces effective techniques for conducting interviews and is designed to help you develop and strengthen your skills as an interviewer. It does not assume any existing experience conducting interviews, but will quickly take you past the basics and into best practices that incorporate the Lean Research principles of rigor, relevance, respect, and right-size. The course focuses specifically on conducting interviews in “the field” - contexts in which we may be in an unfamiliar setting or culture, such as when traveling abroad or conducting research in a place we haven’t been before.Photo by Megha Hegde, MIT D-Lab



          Week 1: The Lean Research Approach to Interviewing 

Lesson 1: Introduction to Lean Research
Lesson 2: The Lean Research principles in practice

Week 2: Becoming a Skilled Interviewer 

Lesson 3: Introduction to interviewing skills: the basics
Lesson 4: Qualities and skills of effective interviewers

Week 3: Lean Research Interviewing Skills 

Lesson 5: Lean Research interview skills
Lesson 6: Analyzing and using interview data

Week 4: Handling Challenges in Interviewing 

Lesson 7: Dealing with challenges in interviewing
Lesson 8: Connecting across differences

Week 5: Practicing our Interviewing Skills 

Lesson 9: Preparing to conduct your own interviews

Week 6: Conduct an interview! 

Lesson 10: Conduct your practice interview (final project)

Week 7: Helping each other improve 

Lesson 11: Peer review of interviews
Lesson 12: Course wrap-up",Lean Research Skills for Conducting Interviews
https://www.classcentral.com/course/forecasting-skills-17041,"For many people, the future comes as a surprise – or even a shock. But with strong forecasting skills, YOU can avoid future shock. You can adapt faster, and become better prepared to benefit from change.

In this course, you’ll build your future forecasting skills. You'll learn how to turn groups of ""signals"" (clues about the future) and ""drivers"" (global forces that influence the direction of change) into compelling future forecasts. Forecasts help you discover new possibilities and opportunities for yourself, your company, or any community you want to inspire to make a better future. 

You'll also learn how to write future scenarios. Scenarios take forecasts one step further. They spark imagination and tell a story about what might happen if a forecast comes true. Scenarios help you evaluate: Is this a future I'm ready for? Is this a future I want?

Leading futurists from the Institute for the Future will show you exactly how it's done. They'll share with you the forecasts and scenarios they’re most excited about right now, and walk you through the key steps they took to create them. Then, it's your turn! You'll create a forecast and a scenario on any future topic you choose.

How will you benefit from taking this course? With strong forecasting skills, you'll get better at seeing the future before it happens. You'll be ready to consider possibilities that others never see coming or refuse to accept. You'll be able to help others prepare for and adapt to the future. You can decide which futures you want to make more likely, and which futures you want to prevent.

Many thanks to the Enlight Foundation and the Enlight Collaborative, which provided a grant to support the creation of this course.
      


            Read more
          



          Introduction to Future Forecasting
    -Welcome to our journey to the future! This week, you'll learn the basics: What's a future forecast? What makes a forecast good? What kind of data should I use to make my forecasts? By the end of the week, you'll be ready to analyze ""drivers of change"", and make your own first, tiny future forecast.

How to Create a Future Forecast
    -You've got the forecasting basics down. Now it's time to play and experiment with bigger ideas! This week, you'll take a look at some of the Institute for the Future's most interesting recent forecasts. Then, you'll practice combining signals and drivers of change to reveal your own surprising possibilities.

How to Write a Future Scenario
    -You've forecast the future! Now what? This week, you'll learn how to write scenarios. A scenario takes your forecast one step further. It tells a story about what might happen IF your forecast comes true. A scenario will help YOU evaluate: Am I ready for this future? Is this a future I want? Scenarios are fun. Let's go explore some!

How to Update Your Forecasts 
    -What happens if your forecast is wrong? What happens when a scenario you wrote actually comes true? This week, you'll learn how to update your forecasts and rethink your scenarios. With these techniques, you can make sure you're never ""stuck"" with old ways of thinking about possible futures.",Forecasting Skills: See the Future Before it Happens
https://www.classcentral.com/course/act-on-climate-8737,"Are you concerned about climate change? Would you like to learn how to address and respond to this challenge? If so, this course is for you.  

Act on Climate: Steps to Individual, Community, and Political Action is intended to help learners understand, address and respond to climate change as individuals and in partnership with their communities and political leaders. The course focuses on how to translate learning into action on climate change in the areas of food, energy, transportation and the built environment (cities). This course was co-developed and taught by Michaela Zint, Professor of Environmental Education and Communication, and University of Michigan Students. A range of academic climate change experts and professional leaders are featured.

As a result of completing this course, you will be able to:

1) Identify individual, community, and political actions you can engage in to effectively address and respond to climate change.

2) Describe how insights from the social sciences can be employed to create change at the individual, community, and political levels.

3) Feel empowered to continue to influence how you, your community, and political leaders address and respond to climate change.

Use #UMichActonClimate on social media to share what you're doing and connect with other learners.
      


          Introduction
    -As part of this introductory lesson, we will help you explore your motivations for taking this course, briefly introduce you to the current state of climate science and policy, and prepare you for taking actions on climate change throughout the course. 

Food
    -Food is part of our everyday lives. From breakfast to dinner, we make choices that affect the planet. This week, you will hear from Chris about his journey toward vegetarianism, and you will learn from Dr. Sara Soderstrom about social movement theory and food businesses in Detroit, as well as actions that you can take to make food choices that can mitigate climate change.

Energy
    -We use energy in almost everything we do, but there are also many ways we can reduce emissions from our energy consumption. This week, you will hear from Benjamin about saving energy in cold winters and from Dr. Kaitlin Raimi about the theory of environmental peer persuasion. You will also learn several actions you can take to reduce energy consumption in your home, on your campus, and in your community. 

Transportation
    -Transportation is part of everyday life. This week, you will hear from Stephanie about the collective impact of personal transportation decisions and from Brandon Schoettle about how driving decisions impact greenhouse gas emissions. You will also examine popular ride-hailing services, as well as actions that you can take to make transportation choices that can mitigate climate change, and ultimately you will learn to support a more resilient transportation system.

Built Environment
    -There is a complex relationship between our lives and the built infrastructure with which we interact on a daily basis. This week, you will learn about one theory of urban design - “New Urbanism” - and use it as a way to explore these relationships and how you can reimagine the built environment as a means to act on climate change. You will also learn about how one city used deliberative democracy to transform their built environment and move toward carbon neutrality. Together, the content will assist you in identifying how the built environment can be transformed to address the effects of climate change. 

Climate Action Plan
    -This week, you will apply ideas you learned in this course, learn about another relevant social change theory, and develop your own Personal Climate Action Plan. As part of this plan you will identify individual and community-related actions that you can take to mitigate the impact of increased greenhouse gas emissions and adapt to climate change after completing this course.

Conclusion
    -You have now learned about a variety of theories of social change and tried a range of mitigation and adaptation actions. We hope that this will not be the end! During this concluding week, we will provide you with resources to continue to engage in climate actions, including: making new practices “stick,” how to work with your community, and why you might even consider making a bigger commitment, like running for political office.","Act on Climate: Steps to Individual, Community, and Political Action"
https://www.classcentral.com/course/gameprogramming-1031,"The Beginning Game Programming with C# course is all about learning how to develop video games using the C# programming language. Why use C# instead of C++, Java, ActionScript, or some other programming language you may have heard of? First, using C# lets us use the open-source MonoGame framework, which help us quickly develop games for Windows, Android, iOS, Mac OS X, and others. Second, the Unity game engine is very popular with indie game developers, and C# is one of the programming languages you can use in the Unity environment. And finally, C# is a really good language for learning how to program.

That learning how to program comment is important because this course doesn't assume you have any previous programming experience. Don't worry if you've never written code before; we'll start at the very beginning and work our way up to building a small, complete game by the end of the course. Throughout the course you'll learn core programming concepts that apply to lots of programming languages, including C#, and you'll also learn how to apply those concepts when you develop games: drawing all the entities in the game world, updating the game world based on user input and simple physics, playing music and sound effects in your games, and so on.

Computer programming is really fun in general, and programming games is even better!

Caution: Beginning (assuming no prior programming knowledge) is not the same as easy (not hard to do). Learning to program IS hard to do, especially since this course is essentially a freshman-level college course. Meeting the course challenges while you master the material will be rewarding to you, but doing that will require hard work and maybe even a few expletives along the way.
      


            Read more
          



Course Introduction, First C# Program, and Storing DataLearn about the course structure, the course programming environment, and Dr. T; Learn how to write a C# program; Learn how we use data types, variables, and constants to store data in our programs; Complete and submit Programming Assignment 1Classes and Objects, MonoGame/XNA BasicsLearn some foundational Object-Oriented concepts; Learn the basics of MonoGame/XNA; Complete and submit Programming Assignment 2; Complete and submit Peer Review of Programming Assignment 1Strings and SelectionLearn about using C# strings; Learn how we make decisions in our code; Complete and submit Programming Assignment 3; Complete and submit Peer Review of Programming Assignment 2Recovery weekReflect on previous course material with no new material this week; Complete and submit Project Increment 1; Complete and submit Peer Review of Programming Assignment 3MonoGame/XNA Mice and Controllers, Arrays and Collection ClassesLearn how to use mice and controllers for input; Learn how to store larger amounts of data; Complete and submit Programming Assignment 4; Complete and submit Peer Review of Project Increment 1Recovery weekReflect on previous course material with no new material this week; Complete and submit Project Increment 2; Complete and submit Peer Review of Programming Assignment 4IterationLearn how to do things multiple times; Complete and submit Programming Assignment 5; Complete and submit Peer Review of Project Increment 2Recovery weekReflect on previous course material with no new material this week; Complete and submit Project Increment 3; Complete and submit Peer Review of Programming Assignment 5Class Design and ImplementationLearn how to design and implement classes; Complete and submit Programming Assignment 6; Complete and submit Peer Review of Project Increment 3Recovery WeekReflect on previous course material with no new material this week; Complete and submit Project Increment 4; Complete and submit Peer Review of Programming Assignment 6MonoGame/XNA Audio, MonoGame/XNA Text IOLearn how to play music and sound effects in MonoGame/XNA; Learn how to process keyboard input and display text in MonoGame/XNA; Complete and submit Project Increment 5; Complete and submit Peer Review of Project Increment 4The Final WeekThe description goes here",Beginning Game Programming with C#
https://www.classcentral.com/course/evidence-based-toxicology-12316,"Welcome to the Evidence-based Toxicology (EBT) course. In medicine and healthcare, evidence-based medicine has revolutionized the way that information is evaluated transparently and objectively. Over the past ten years, a movement in North America and Europe has attempted to translate this revolution to the field of toxicology.
The Center for Alternatives to Animal Testing (CAAT) within the department of Environmental Health and Engineering at the Johns Hopkins Bloomberg School of Public Health hosts the first chair for EBT and the secretariat for the EBT Collaboration on both sides of the Atlantic. Based on the Cochrane Collaboration in Evidence-based Medicine, the EBT Collaboration was established at the CAAT to foster the development of a process for quality assurance of new toxicity tests for the assessment of safety in humans and the environment.
Regulatory safety sciences have undergone remarkably little change in the past fifty years. At the same time, our knowledge in the life sciences is doubling about every seven years. Systematic review and related evidence-based approaches are beginning to be adapted by regulatory agencies like the Environment Protection Agency (EPA), the European Food Safety Authority (EFSA), and the US National Toxicology Program. They provide transparent, objective, and consistent tools to identify, select, appraise, and extract evidence across studies. 
This course will showcase these emerging efforts and address opportunities and challenges to the expanded use of these tools within toxicology.
      


            Read more
          



          Introduction & Shortcomings of Current Approaches
    - This module introduces you to the course, outlines the shortcomings of current toxicity testing approaches, and shows how EBT can help to overcome these shortcomings.

History and Causation
    -This module explains how evidence-based toxicology originated and describes the driving forces for the initiative. In the second lesson, you will learn how to distinguish between correlation and causation as well as the main problems with drawing conclusions on the basis of correlations. The  Bradford Hill criteria are introduced, along with  examples for each criterion. You will also learn about mechanistic toxicology and mechanistic validation.

Systematic Review and Meta-Analysis
    -This module shows how to perform systematic reviews and meta-analyses. You will learn the history of both methods and will receive step-by-step instructions on how to perform systematic reviews and meta-analyses using examples from the research activities of the instructors. 

Risk of Bias & Application to Test Methods Comparison
    -This module teaches you about possible biases that can be introduced at different stages of research. Each bias is explained with examples, including solutions for overcoming those biases. The second lesson covers systematic review of the zebrafish embryotoxicity test as a case study conducted by the Evidence-based Toxicology Collaboration (EBTC). You will go through all of the steps of the systematic review again to imprint the knowledge from  module 3, but this systematic review will be related to a toxicological method.

Quality Assurance, Good Practices, and Validation
    -Quality control is a very important aspect of not only modern toxicology but the entirety of life sciences. The first lesson in this module demonstrates the importance of performing quality control on your experiments. The second lesson is connected with the first one because validation of an alternative method requires highly standardized protocols and quality control at each step. This lesson teaches you different aspects of alternatives methods validation, how to perform classical validation, its pitfalls, and strategies to overcome them.

Biometrical Tools & Future Perspectives
    -Evidence-based toxicology requires some knowledge of bioinformatics. The first lesson in the module teaches you some biostatistical tools you can apply when analyzing predectivity, specificity, and sensitivity of a method. You will also learn how to identify biases in a study with the help of bioinformatics. Evidence-based principles can be applied to every question you might have, even to which pizza to order tonight. You will learn the difference between eminence-based vs. evidence-based approaches. You will learn what is driving the lack of reproducibility and how evidence-based approaches should help to overcome the reproducibility crisis in science, which is explained with examples of experimental design, wrong models, poor quality of the cell cultures, etc.

Summative Assessment - Systematic Review Assignment
    -The final week of the course is devoted to completing the Systematic Review Assignment. You will use SysRev to review at least 20 abstracts, apply inclusion and exclusion criteria, render decisions, and resolve conflicts with other reviewers.",Evidence-based Toxicology
https://www.classcentral.com/course/edx-reliable-distributed-algorithms-part-1-6604,"This course is the first course in a series of two. Both courses provide a solid foundation in the area of reliable distributed computing, including the main concepts, results, models and algorithms in the field.
Today's global IT infrastructures are distributed systems; from the Internet to the data-centers of cloud computing that fuel the current revolution of global IT services. At the core of these services you find distributed algorithms.
These algorithms run on multiple computers and communicate only by sending and receiving messages. It is crucial for the implemented services to continue to work 24/7 even if some of the computers fail or some of the messages are lost in transit. This is the subject of reliable distributed algorithms in computer science.
ID2203.1x covers models of distributed algorithms based on input/output automata; specifications of fault tolerant abstractions and failure detectors; specific distributed abstractions and fault-tolerant algorithms, including reliable broadcast and causal broadcast; key-value stores and consistency models; single-value consensus and the Paxos algorithm.
To complete the course with a full grade (100%) students are required to answer the graded quizzes provided every week, as well as the programming assignments.",Reliable Distributed Algorithms - Part 1
https://www.classcentral.com/course/pressure-force-motion-humidity-sensors-12361,"""Pressure, Force, Motion, and Humidity Sensors"" can also be taken for academic credit as ECEA 5342, part of CU Boulder’s Master of Science in Electrical Engineering degree.

This is our third course in our specialization on Embedding Sensor and Motors. To get the most out of this course, you should first take our first course entitled Sensors and Sensor Circuits. Our first course gives you a tutorial on how to use the hardware and software development kit we have chosen for the lab exercises. This third course assumes that you already know how to use the kit.

After taking this course, you will be able to:
●	Understand how to specify the proper AC or DC motor for a machine design.
●	Integrate the motor to a machine, based on analysis of motor equations for voltage, current, torque and speed.
●	Implement the motor and accompanying rotary sensor into a motor control circuit in both hardware and software.
●	Add a motor and motor control circuit into a microprocessor based development kit.
●	Create hardware and firmware to process motor feedback data to a microprocessor for further evaluation.


After taking this course, you will be able to:
●	Understand how to specify the proper pressure, force, strain, position, motion, acceleration, occupancy, and humidity sensors for taking real-time process data. 
●	Implement these sensors into an embedded system in both hardware and software.
●	Add the sensor and sensor interface into a microprocessor based development kit.
●	Create hardware and firmware to process sensor signals and feed data to a microprocessor for further evaluation.


In this course you will build the circuit from Video 7 (Lab Exercise on strain gauges), Module 2 (Force and Strain Sensors and Touch Screens), and use it to make screen shots of the timing of the switch. If you haven't already wired up the system and written all the software per the instructions of Video 7, please do so now. 

You will need to buy the following components to complete this assignment. Note that if you have already purchased the PSOC 5LP PROTOTYPING KIT, you do not need to buy it again. 

These parts may be purchased off the Digikey web site, www. Digikey.com. One part needs to be purchased off the Sparkfun website www.sparkfun.com. Or, you may obtain the specs from the site, and purchase them elsewhere.

Digikey Part numbers are typed out here: 
428-3390-ND 
CF14JT22K0CT-ND 
CF14JT100KCT-ND 

Table shown here:

Index	Quantity	                      Part Number	Description
1	           1	                           428-3390-ND	PSOC 5LP PROTOTYPING KIT
2	           2	                  CF14JT22K0CT-ND 	RES 22K OHM 1/4W 5% AXIAL 
3	           1	                 CF14JT100KCT-ND	RES 100K OHM 1/4W 5% AXIAL 


Sparkfun part numbers are typed out here: 
TAL221

Table shown here:

Index	Quantity	        Part Number	    Description
1	           1	                      TAL221	    Mini-load cell - 100g, straight bar
      


            Read more
          



          Pressure Sensors
    -In module 1 you will learn how to specify and use various types of pressure sensors for an embedded circuit. First, you will learn about piezoresistive, capacitive, and vacuum sensors. This includes a deep dive into the piezoresistive effect and how a Wheatstone bridge is used in these systems. This is followed by a discussion on pressure transmitters and how to  calculate an error budget. Finally, we will give you examples of commercial pressure sensors and explain what you need to know to purchase them on a web site. 

Force and Strain Sensors and Touch Screens
    -In module 2 you will learn how to specify and use various types of force and strain sensors for an embedded circuit. First, you will learn about how strain gauges use the piezoresistive effect and Wheatstone bridges to output a strain signal. Then you will learn how load cells use strain gauges to output a force signal. We have a video on a teardown of a weight scale for you to watch, where we teach you how the strain gauges are arranged in an unusual bridge circuit.  Finally, we teach you about how touch screens used in kiosks, PC's and smart phones work. We have a lab exercise for you to perform on strain gauges, where you will get hands-on experience wiring the gauges into the PSoC system, and writing code to read the gauges.

Position, Acceleration and Velocity Sensors
    -In module 3 you will first learn how magnetic detection sensors such as Hall sensors and LVDT's work, as well as how capacitive detection sensors. Then you will learn how to specify and use accelerometers in an embedded circuit. We will discuss how the first accelerometers used the piezoelectric effect to output a sinusoidal signal. We will review the key principles and equations involved in vibrational measurement. Then you will learn later accelerometers used the piezoresistive effect and internal strain gauges to output a sinusoidal signal representative of force, as opposed to acceleration. Then we will explain how accelerometers are now using MEMS technology and changes in capacitive to output the signal. We teach you about gyroscopes, both traditional mechanical ones, still used in aircraft for angular position sensing, and modern MEMS ones used to determine angular velocity. 

Motion, Distance and Humidity Sensors
    -In module 4 you will learn how to specify and use position and motion detectors in an embedded circuit. First, you will learn about the pyroelectric effect. Then you will learn how Passive Infrared  motion detectors use the pyroelectric effect in commercial burglar alarms. Then you will learn how ultrasonic distance detection is accomplished, the same principles that whales, dolphins and bats use to navigate their worlds. We tackle microwave  detection sensors last, as these are the most complex sensors that we cover in the course. They are used in long range position detection sensors and commercial security sensors for outdoors use. 

Course Projects
    -This module contains the materials you need to complete the Strain Gauge lab assignment.","Pressure, Force, Motion, and Humidity Sensors"
https://www.classcentral.com/course/edx-introduction-to-java-programming-fundamental-data-structures-and-algorithms-7454,"In this introductory course, you will learn programming with Java in an easy and interactive way.You will learn about fundamental data structures, such as lists, stacks, queues and trees, and presents algorithms for inserting, deleting, searching and sorting information on these data structures in an efficient way.Emphasis is put on immediate feedback and on having a fun experience. Programming knowledge is not only useful to be able to program today’s devices such as computers and smartphones. It also opens the door to computational thinking, i.e. the application of computing techniques to every-day processes.This course is designed taking into account the subset and recommendations of the College Board in order to prepare learners for the Advanced Placement (AP) Computer Science A exam.



1. Lists The first week starts with the most fundamental data structure: Lists. Several implementations for storing information in Lists are presented in this week, including the use of Arrays of primitive data types, the use of Arrays of objects of the same class, and the use of links (Linked Lists).  2. Stacks The second week addresses Stacks, which are one well-known linear data structure. Stacks are also called LIFO data structures (last-in, first-out). Algorithms for inserting and extracting information from Stacks will be discussed this week, as well as implementations of Stacks with Linked Lists.  3. Queues The third week addresses another well-known linear data structure: Queues. Queues are also called FIFO data structures (first-in, first-out). Algorithms for inserting and extracting information from Queues will be discussed this week, as well as implementations of Queues with Linked Lists.  4. Trees The fourth week introduces non-linear data structures, and particularly Trees. Binary Search Trees and Heaps are presented as two well-known examples of Trees. Algorithms for inserting and extracting information from Binary Search Trees and Heaps will be discussed this week. Implementations based on Linked Lists for Trees and Heaps will be analyzed.  5. Searching and Sorting The last week presents some basic algorithms for searching and sorting information in linear and non-linear data structures. The efficiency of these algorithms is discussed, proposing alternatives for their improvement.",Introduction to Java Programming: Fundamental Data Structures and Algorithms
https://www.classcentral.com/course/opensap-get-to-know-sap-s-innovative-enterprise-solutions-2459,"To be competitive and remain relevant in today’s business world, a good IT solution has to:

Enable business anywhere at any time, on any device
Crunch big data easily and quickly
Be tailored to the specific needs of the customer

Join our lectures and learn how SAP responds to these challenges.
This six week course provides you with a broad overview of SAP’s latest technologies, covering many engaging topics like SAP HANA, SAP Mobile Platform, and SAP Cloud. It begins with an overview of SAP enterprise solutions and an introduction to SAP Business Suite powered by SAP HANA. You will then learn about SAP solutions in key areas such as analytics and mobile security; you will be introduced to SAP’s cloud-based solutions like SuccessFactors and Ariba, and you will also have the chance to discover the new SAP Fiori user experience. In addition to this, you will see how SAP offers tailored solutions to meet customers’ business needs, for example with best practices provided through simplified solution deployment.




Week 1: SAP History and Applications
Week 2: SAP Analytics
Week 3: Mobility and User Interfaces
Week 4: SAP HANA
Week 5: SAP Cloud
Week 6: Simplified Solution Deployment
Week 7: Final Exam",Get to Know SAP’s Innovative Enterprise Solutions
https://www.classcentral.com/course/edx-ielts-academic-test-preparation-3760,"IELTS is the world's most popular English language test for those wanting to study in higher education in an English-speaking country.
This IELTS course will prepare you to take the IELTS Academic tests with confidence. You will have immediate access to over 80 hours of interactive practice materials covering each of the four skills: listening, speaking, reading and writing.
This innovative preparation course has been designed and written by experienced English teaching professionals from The University of Queensland, an IELTS testing centre and one of the world's leading centres of learning. All of the course writers have extensive experience enabling students to reach their academic IELTS goal of entering a university where English is the primary language.
Each section of this course includes engaging multi-media presentations reviewing key test-taking skills, strategies and techniques. These are accompanied by a wide variety of authentic IELTS-style exercises and interactive activities that provide focused practice of the skills, strategies and techniques that you need to perform at your best.
In the new release of this IELTS preparation course, you will find a number of enhancements to an already-successful formula. The course appears with new videos and improvements to the explanation of answers as well as a number of new and engaging practice activities. Significantly, we have responded to requests from existing users to offer more comprehensive feedback on your writing using several new features.
As the course is self-paced, you can complete all of the course units in sequence, or only select the areas you want to focus on to prepare for the IELTS Academic tests. In completing this course, you will feel fully prepared to complete the IELTS Academic tests.
Students who select Verified enrolment in this course will have access to additional materials provided by the IELTSx course team.



            Read more
          



MODULE 1: LISTENING
The module begins with an overview of the IELTS Listening Test and what it includes. This will give you important facts about this module and what it is designed to assess. Following this, we'll show you the differences between each section of the IELTS Listening Test and the types of questions you will need to answer. You will also have opportunities to practise these types of questions and gain the skills that you need. 

MODULE 2: SPEAKING
This module outlines the different features of the Speaking Test. In preparation for Part 1 of the Speaking Test, we focus on some of the grammar that you can use to talk about your likes and dislikes. We'll also give you some examples of how to extend your answers, or make them longer. For Part 2 of the test, we'll then focus on the ""Individual Long Turn"". We'll look at how to analyse the task effectively and how to organise your ideas so that you have a good start, and end, to your talk. For Part 3 of the test, we will focus on ""The Discussion"". You'll learn to develop vocabulary related to common Part 3 topics and also some of the common grammar features you need for success in the discussion. This includes focussing on tenses and making comparisons. Later in the unit, we'll introduce some strategies to make your pronunciation clearer. In this module, you can watch and learn from videos of students taking different parts of the test. 
MODULE 3: READING
This module begins with an overview of the IELTS Reading Test and what it includes. This will give you important information about what the test is designed to assess and the different question types used in the test. There will be opportunities to practise the skills you have learned. 

MODULE 4: WRITING
The module begins with an overview of the IELTS Writing Test and what it includes. We'll then look at the two tasks involved in the test. In preparation for Task 1, you'll learn how to identify different types of visuals, identify and describe the topic and the main features of these visuals, and also how to write an overview paragraph to summarise the key information. We'll then look at describing data for Task 1 of the test. You'll learn about what language to use to describe data, as well as how to select and group information. We'll also look at the language used for ordering ideas in paragraphs. In addition, this module offers the chance to practise writing the opening and data description paragraphs, which you can grade with our new assessment criteria. Additionally, you can get feedback on your writing from your peers and give them feedback using the IELTSx criteria. In preparation for Task 2, we're going to take a closer look at the essay question to help you answer all its parts and we will examine ways of planning and organising your essay. We'll also analyse the different parts of an IELTS essay, look in more detail at some possible task types in Task 2, and explain how they are assessed. We'll then look at how to write a good essay with good structure and appropriate language. Along the way, you'll have a chance to practise writing an introduction, body paragraphs and conclusion and submit these for assessment from other IELTSx students. There will also be practice of proofreading and editing.",IELTS Academic Test Preparation
https://www.classcentral.com/course/developer-iot-6040,>>> By enrolling in this course you agree to the End User License Agreement as set out in the FAQ.  Once enrolled you can access the license in the Resources area,A developer's guide to the Internet of Things (IoT)
https://www.classcentral.com/course/opioid-epidemic-17143,"While prescription opioids serve an invaluable role for the treatment of cancer pain and pain at the end of life, their overuse for acute and chronic non-cancer pain as well as the increasing availability of heroin and illicit fentanyl, have contributed to the highest rates of overdose and opioid addiction in U.S. history. Evidence-informed solutions are urgently needed to address these issues and to promote high-quality care for those with pain. This course and the report it is based on are a response to that need. They offer timely information and a path forward for all who are committed to addressing injuries and deaths associated with opioids in the United States.
      


          Introduction and Data
    -This module reviews the data available about opioid use disorders in the United States. Information about general trends in opioid overdose, and some limitations of current data systems are discussed. This module draws from section 6 of the ""The Opioid Epidemic"" report (2017). 

Prescription Drug Monitoring Programs (PDMPs)
    -This module provides an overview of Prescription Drug Monitoring Programs (PDMPs). Explanations of how PDMPs are used to reduce the supply of prescription opioids likely to be misused are discussed. A review of the research about PDMPs is also included.  This module draws from section one of the ""The Opioid Epidemic"" report (2017). 

Clinical Guidelines
    -This module reviews prescribing guidelines as an intervention for reducing high risk opioid prescribing. A conversation between the course instructors and representatives from CDC’s National Center for Injury Prevention and Control about  CDC’s Guideline for Prescribing Opioids for Chronic Pain provides insight into the process of developing and disseminating one guideline. This module aligns with section two of of the ""The Opioid Epidemic"" report (2017). 

Pharmacy Benefit Managers
    -This module provides an overview of the role of pharmacy benefit managers and pharmacies in the supply of prescription opioids. Opportunities to monitor high risk prescribing through PBMs and pharmacies are also discussed. This module draws from section three of the ""The Opioid Epidemic"" report (2017). 

Engineering Strategies
    -This module introduces the idea that redesigning opioid medications and the pill vials they are prescribed in is one strategy to reduce unintentional opioid poisonings and diversion. The module features a discussion of a prototype design for a pill vial engineered to dispense a specified amount of medication at programmed intervals to authorized users. This module aligns with section four of the ""The Opioid Epidemic"" report (2017). 

Engaging Patients and the General Public
    -This module reviews strategies for communicating with patients and the public about opioid use disorders. Safe storage and disposal strategies are also discussed. This module draws from section five of the ""The Opioid Epidemic"" report (2017). 

Treating Opioid Use Disorders
    -This module discusses addiction as a disease and medication as treatment. Consideration of known risk factors for disease are also reviewed. This module aligns with section seven of the ""The Opioid Epidemic"" report (2017). 

Naloxone
    -This module describes naloxone, a medication that effectively reverses an opioid overdose, and how access to naloxone has increased. The role of government agencies in disseminating naloxone prescriptions is also highlighted. This module draws from section eight of the ""The Opioid Epidemic"" report (2017). 

Harm Reduction
    -This module provides an overview of harm reduction in the context of opioid use disorders. Examples of harm reduction strategies are provided, and the available evidence discussed. This module aligns with section nine of the ""The Opioid Epidemic"" report (2017). 

Stigma
    -This module discusses the stigma surrounding drug use and treatment. Strategies for combatting stigma by providing alternatives to stigmatizing language are discussed. This module draws from section 10 of the ""The Opioid Epidemic"" report (2017).",Opioid Epidemic: From Evidence to Impact
https://www.classcentral.com/course/geohealth-6530,"##
The environment in which we live and work can have a profound effect on our health – an effect that is explored by the emerging field of geohealth.
This free online course will introduce you to new developments in geohealth, looking at the latest thinking and methods for using spatial data and geographic information systems (GIS) in health settings.
Understand geohealth techniques and best practice
The course consists of ten different topics, ranging from data collection techniques to spatial simulation, and aims to bridge the gap between scientific research and health professionals.
By the end of the course, you will understand how spatial data and geo-information techniques can contribute to solving public health problems, and be aware of best practice when using GIS in the health field.
Learn with health and geo-informatics specialists
The Geohealth course has been developed by three well-known institutions with experience in both the health domain and the field of geo-informatics:

Public Health Foundation of India helps to build institutional and systems capacity in India for strengthening education, training, research and policy development in the area of public health.
Royal Tropical Institute in Amsterdam aims to improve health and ensure equitable socio-economic development as much as intercultural cooperation with partners worldwide.
Faculty of ITC at the University of Twente is recognised worldwide for achievements in teaching, research and capacity development in the field of geo-information science and earth observation.

This course is designed for professionals working in both human and animal health, and GIS specialists and geo-scientists who are interested in the health domain.



            Read more",Geohealth: Improving Public Health through Geographic Information
https://www.classcentral.com/course/edx-deep-learning-essentials-18145,"Gain a good understanding of what Deep Learning is, what types of problems it resolves, and what are the fundamental concepts and methods it entails. The course developed by IVADO, Mila and Université de Montréal offers diversified learning tools for you to fully grasp the extent of this ground-breaking cross-cutting technology, a critical need in the field.

IVADO, a scientific and economic data science hub bridging industrial, academic and government partners with expertise in digital intelligence designed the course, and the world-renowned Mila, rallying researchers specialized in Deep Learning, created the content. Mila’s founder and IVADO’s scientific director, Yoshua Bengio, also a professor at Université de Montréal, is a world-leading expert in artificial intelligence and a pioneer in deep learning as well as the scientific director of this course. He is also a joint recipient of the 2018 A.M. Turing Award, “the Nobel Prize of Computing”, for conceptual and engineering breakthroughs that have made deep neural networks a critical component of computing.
Deep Learning is an extension of Machine Learning where machines can learn by experience without human intervention. It is largely influenced by the human brain in the fact that algorithms, or artificial neural networks, are able to learn from massive amounts of data and acquire skills that a human brain would. Thus, Deep learning is now able to tackle a large variety of tasks that were considered out of reach a few years ago in computer vision, signal processing, natural language processing, robotics, and sequential decision-making. Because of these recent advances, various industries are now deploying deep learning models that impact various economic sectors such as transport, health, finance, energy, as well as our daily life in general.
If you are a professional, a scientist or an academic with basic knowledge in mathematics and programming, this MOOC is designed for you! Atop the rich Deep Learning content, discover issues of bias and discrimination in machine learning and benefit from this sociotechnical topic that has proven to be a great eye-opener for many.



            Read more
          



MODULE 1 Machine Learning (ML) and experimental protocol

Introduction to ML
ML Tools

MODULE 2 Introduction to Deep Learning

Modular approaches
Backpropagation
Optimization

MODULE 3 Intro to Convolutional Neural Networks (CNN)

Introduction to CNN
CNN architectures

MODULE 4 Introduction to Recurrent Neural Networks

Sequence to sequence models
Concepts in natural language processing

MODULE 5 Bias and discrimination in ML

Differences of fairness
Fairness in pre- in- and post-processing",Deep Learning Essentials
https://www.classcentral.com/course/edx-cyber-security-protecting-yourself-and-your-data-8054,"Our daily lives, economic vitality, and national security all revolve around technology. Our dependence on technology means we need a stable, safe, and resilient cyberspace. However, computers and networks are being misused at a growing rate both by cybercriminals and by our own employees. In this computer science course, you will learn the fundamentals of cybersecurity and basic threats. You will also learn to build a comprehensive security plan that integrates people, processes, and technology, and how to begin protecting yourself and your information.
You will be exposed to areas of personal and physical security, best practices for using our computers and mobile devices, and how we protect our privacy and secure our devices and networks against attacks.
We will examine cybersecurity standards, laws, and ethical issues, the impact of cyber terrorism, how governments use technology and computer systems to defend and attack adversaries, and the effect this has on privacy and individual liberties. We will also explore why IT administrators and cybersecurity professionals need to demonstrate adherence to ethical principles.
Finally, we will look at the important areas of data breach planning and business continuity, both of which are critical to the long-term viability of an organization.
This course will also focus on the types of careers within the cyber security field and how you can enhance your career through professional certifications.
No prior knowledge or skills are required except for basic computer literacy.



            Read more
          



Module 1: Introduction to Cybersecurity
 
Module 2: The Big Picture of Cybersecurity
 
Module 3: Personal and Physical Security
 
Module 4: Computer and Application Security
 
Module 5: Web Security
 
Module 6: Network Security
 
Module 7: Mobile and Wireless Security
 
Module 8: Cybersecurity Standards and Law
 
Module 9: Data Breach Planning and Business Continuity",Cyber Security: Protecting Yourself and Your Data
https://www.classcentral.com/course/history-medical-cannabis-cbd-thc-13822,"This History of Medical Cannabis course is designed to have you think critically about past, present, and future research on the health effects of cannabis by developing a more nuanced understanding of the barriers to research as well as different approaches to research. You will learn about the history of cannabis cultivation, the legal history of cannabis or ""marijuana"",  and the obstacles that led to the lack of science on its medicinal use. You will also learn how to critically evaluate research on the effects of cannabis cannabis, and discuss the associated risks of using cannabis in the context of public health and epidemiological research. Finally, you will learn about how to administer cannabis products in ways that minimize risk adn maximize any potential benefits.  Obtaining this knowledge will be helpful in terms of informing public policy, public health, and personal decisions regarding the use of cannabis products.
      


          Introduction to Course and to Cannabis
    -In this module, we will discuss the biological characteristics of cannabis and the effect cannabinoids have on the body. Will will cover the basic pharmacology of THC and CBD and the action these cannabinoids have in the brain. Lastly, we will evaluate the evidence for what is called the entourage effect.

History of Cannabis
    -In this module, we will discuss the history of cannabis as an alternative medicine and the legal history of cannabis in both the US and abroad. We will discuss the variety of different product types post-legalization, how products are made, and implications for safety.  We will also discuss the cannabis industry and how it compares to other mature industries like the pharmaceutical and alcohol industries. 

Barriers to Research and How to Evaluate Research
    -In this module, we will discuss the legal barriers to institutional research in the US and how this has impacted conducting much-needed cannabis research. You will learn the difference between high quality, rigorous research design compared to biased sources of information. Lastly, you will learn how the placebo effect works and evaluate how much of a role it plays with regards to the medical benefits of cannabis. 

Risks Associated with Cannabis Use
    -In this module, we will review the animal and human literature with regards to the effects of cannabis in the brain. We will discuss the epidemiology of cannabis use and review public health data.  Lastly, we will discuss the best practices for using it medically, such as to minimize the risks and harms while maximizing the benefits.",History of Medical Cannabis
https://www.classcentral.com/course/edx-fintech-ethics-and-risks-11392,"FinTech has started a global revolution in the financial services industry, and the transformation will only increase in coming years. There are many ways in which FinTech can improve the lives of people around the world; however, those same technologies can also be used to enslave, coerce, track, and control people. Accordingly, it is appropriate and necessary to consider the implications of the introduction of these technologies so that they are utilized properly, regulated sufficiently, and their adoption does not come at the expense of societal growth. 
This 6-week online coursecovers 6 modules, representing the full spectrum of finance, technology, and the introduction of FinTech solutions globally. We will ask questions that are not often asked or addressed when new technologies are adopted. Why should we adopt FinTech solutions, and what are the best ways to introduce disruptive technologies? How does blockchain technology change the way we provide financial services, and how should blockchain technology be governed? Is FinTech creating risks in cybersecurity and how can technology help us prevent financial crimes? As Artificial Intelligence (AI) is developed and adopted, will human biases and prejudices be built into such mechanisms? And at a larger scope, should FinTech lead to a decentralized, democratized system of finance, or will existing institutions adopt FinTech strategies to cement their existing hold on the financial markets? 
Through discussing and attempting to answer these questions, you will understand better how the introduction of these technologies can benefit or harm society. And through considering the proper application or introduction of such technologies, you will learn to make better decisions as an individual and organization when facing the question: is FinTech our savior or a villain?



            Read more
          



Introduction: Ethics of Finance and Emerging Technologies 
This module will provide a historical and broad perspective of ethical issues relating to finance and the introduction or adoption of emerging technologies. 
Blockchain and its Governance
This module will expand off the Introduction to FinTech course (https://www.edx.org/course/introduction-to-fintech), to consider the most relevant and ethical ways such technology should be implemented, in a number of different industries or product segmentation. In particular, data collection, customer privacy, and transactional issues will be covered in this module. 
Cybersecurity & Crimes 
FinTech can make it easier and cheaper for banks to monitor and control financial transactions, thus reducing fraud and reducing bank costs. But at the same time, these tools can be used to steal money and other corporate secrets, hide illegality (including purchases of weapons, drugs, etc.), and finance terrorists and other criminal organizations. Accordingly, this module will consider the implications of such important issues. 
AI & FinTech 
In this module we will consider the implications of building our own concepts of “human” morality into amoral machines, as well as a consideration of whether human biases and prejudices can or will be built into such mechanisms, whether purposefully or unintentionally. 
Institutionalization vs. Decentralization 
One of the key reasons people are calling for FinTech is for its decentralized nature, thus democratizing finance, and allowing regular people to participate more fully and affordably in financial transactions through technologies like cryptocurrencies, non-government issued IDs, and P2P lending. In this module we will address some large questions, considering whether FinTech should lead to a decentralized, democratized system of finance. Or whether existing institutions will adopt FinTech strategies to cement their existing hold on the financial markets. 
Big Questions Relating to the Introduction of FinTech 
In this final module, we will consider some of the many outstanding questions and purposes of introducing FinTech to the world, exploring the many ways that FinTech can both help and hurt society. We will discuss financial inclusion, sustainable development, and many other positive aspects of FinTech development. Conversely, we will also consider how these same technologies and solutions could potentially be used to inhibit access to financial markets, or worse.",FinTech Ethics and Risks
https://www.classcentral.com/course/udacity-high-performance-computer-architecture-1018,"This class is offered as CS6290 at Georgia Tech where it is a part of the Online Masters Degree (OMS). Taking this course here will not earn credit towards the OMS degree.The course begins with a lesson on performance measurement, which leads to a discussion on the necessity of performance improvement.Pipelining, the first level of performance refinement, is reviewed. The weaknesses of pipelining will be exposed and explored, and various solutions to these issues will be studied. The student will learn hardware, software, and compiler based solutions to these issues.Why Take This Course?You will explore the fascinating field of computer architecture, studying the many methods developed to enhance computer performance.  The trade-offs and compromises associated with each design and their effects on processor development is a captivating story that will make you a better computer scientist, regardless of your field of study.



Lesson 1: Introduction and TrendsComputer Architecture & Tech TrendsMoore's LawProcessor Speed, Cost, PowerPower ConsumptionFabrication YieldLesson 2: Performance Metrics and EvaluationMeasuring PerformanceBenchmarks StandardsIron Law of PerformanceAmdahl's LawLhadma's LawLesson 3: Pipelining ReviewPipeline CPIProcessor Pipeline StallsData DependenciesPipelining OutroLesson 4: BranchesBranch PredictionDirection PredictorHierarchical Predictors PShareLesson 5: PredicationIf ConversionConditional MoveMOVc SummaryLesson 6: Instruction Level Parallelism (ILP)ILP IntroRAW Dependencies WAW Dependencies Duplicating Register Values Instruction Level Parallelism (ILP) Lesson 7: Instruction SchedulingImproving IPCTomasulo's Algorithm Load and Store Instructions Lesson 8: ReOrder BufferExceptions in Out Of Order Execution Branch Misprediction Hardware Organization with ROB Lesson 9: Memory OrderingMemory Access OrderingWhen Does Memory Write Happen Out of Order Load Store Execution Store to Load Forwarding LSQ, ROB, and RS Lesson 9: MemoryHow Memory WorksOne Memory Bit SRAM One Memory Bit DRAM Fast Page Mode Connecting DRAM To The ProcessorLesson 10: Multi-ProcessingFlynn's Taxonomy of Parallel Machines Multiprocessor Needs Parallel Programs! Centralized Shared Memory Distributed Shared Memory Message Passing Vs Shared Memory Shared Memory Hardware SMT Hardware Changes SMT and Cache Performance",High Performance Computer Architecture
https://www.classcentral.com/course/udacity-high-performance-computer-architecture-1018,"This class is offered as CS6290 at Georgia Tech where it is a part of the Online Masters Degree (OMS). Taking this course here will not earn credit towards the OMS degree.The course begins with a lesson on performance measurement, which leads to a discussion on the necessity of performance improvement.Pipelining, the first level of performance refinement, is reviewed. The weaknesses of pipelining will be exposed and explored, and various solutions to these issues will be studied. The student will learn hardware, software, and compiler based solutions to these issues.Why Take This Course?You will explore the fascinating field of computer architecture, studying the many methods developed to enhance computer performance.  The trade-offs and compromises associated with each design and their effects on processor development is a captivating story that will make you a better computer scientist, regardless of your field of study.



Lesson 1: Introduction and TrendsComputer Architecture & Tech TrendsMoore's LawProcessor Speed, Cost, PowerPower ConsumptionFabrication YieldLesson 2: Performance Metrics and EvaluationMeasuring PerformanceBenchmarks StandardsIron Law of PerformanceAmdahl's LawLhadma's LawLesson 3: Pipelining ReviewPipeline CPIProcessor Pipeline StallsData DependenciesPipelining OutroLesson 4: BranchesBranch PredictionDirection PredictorHierarchical Predictors PShareLesson 5: PredicationIf ConversionConditional MoveMOVc SummaryLesson 6: Instruction Level Parallelism (ILP)ILP IntroRAW Dependencies WAW Dependencies Duplicating Register Values Instruction Level Parallelism (ILP) Lesson 7: Instruction SchedulingImproving IPCTomasulo's Algorithm Load and Store Instructions Lesson 8: ReOrder BufferExceptions in Out Of Order Execution Branch Misprediction Hardware Organization with ROB Lesson 9: Memory OrderingMemory Access OrderingWhen Does Memory Write Happen Out of Order Load Store Execution Store to Load Forwarding LSQ, ROB, and RS Lesson 9: MemoryHow Memory WorksOne Memory Bit SRAM One Memory Bit DRAM Fast Page Mode Connecting DRAM To The ProcessorLesson 10: Multi-ProcessingFlynn's Taxonomy of Parallel Machines Multiprocessor Needs Parallel Programs! Centralized Shared Memory Distributed Shared Memory Message Passing Vs Shared Memory Shared Memory Hardware SMT Hardware Changes SMT and Cache Performance",High Performance Computer Architecture
https://www.classcentral.com/course/edx-fintech-ethics-and-risks-11392,"FinTech has started a global revolution in the financial services industry, and the transformation will only increase in coming years. There are many ways in which FinTech can improve the lives of people around the world; however, those same technologies can also be used to enslave, coerce, track, and control people. Accordingly, it is appropriate and necessary to consider the implications of the introduction of these technologies so that they are utilized properly, regulated sufficiently, and their adoption does not come at the expense of societal growth. 
This 6-week online coursecovers 6 modules, representing the full spectrum of finance, technology, and the introduction of FinTech solutions globally. We will ask questions that are not often asked or addressed when new technologies are adopted. Why should we adopt FinTech solutions, and what are the best ways to introduce disruptive technologies? How does blockchain technology change the way we provide financial services, and how should blockchain technology be governed? Is FinTech creating risks in cybersecurity and how can technology help us prevent financial crimes? As Artificial Intelligence (AI) is developed and adopted, will human biases and prejudices be built into such mechanisms? And at a larger scope, should FinTech lead to a decentralized, democratized system of finance, or will existing institutions adopt FinTech strategies to cement their existing hold on the financial markets? 
Through discussing and attempting to answer these questions, you will understand better how the introduction of these technologies can benefit or harm society. And through considering the proper application or introduction of such technologies, you will learn to make better decisions as an individual and organization when facing the question: is FinTech our savior or a villain?



            Read more
          



Introduction: Ethics of Finance and Emerging Technologies 
This module will provide a historical and broad perspective of ethical issues relating to finance and the introduction or adoption of emerging technologies. 
Blockchain and its Governance
This module will expand off the Introduction to FinTech course (https://www.edx.org/course/introduction-to-fintech), to consider the most relevant and ethical ways such technology should be implemented, in a number of different industries or product segmentation. In particular, data collection, customer privacy, and transactional issues will be covered in this module. 
Cybersecurity & Crimes 
FinTech can make it easier and cheaper for banks to monitor and control financial transactions, thus reducing fraud and reducing bank costs. But at the same time, these tools can be used to steal money and other corporate secrets, hide illegality (including purchases of weapons, drugs, etc.), and finance terrorists and other criminal organizations. Accordingly, this module will consider the implications of such important issues. 
AI & FinTech 
In this module we will consider the implications of building our own concepts of “human” morality into amoral machines, as well as a consideration of whether human biases and prejudices can or will be built into such mechanisms, whether purposefully or unintentionally. 
Institutionalization vs. Decentralization 
One of the key reasons people are calling for FinTech is for its decentralized nature, thus democratizing finance, and allowing regular people to participate more fully and affordably in financial transactions through technologies like cryptocurrencies, non-government issued IDs, and P2P lending. In this module we will address some large questions, considering whether FinTech should lead to a decentralized, democratized system of finance. Or whether existing institutions will adopt FinTech strategies to cement their existing hold on the financial markets. 
Big Questions Relating to the Introduction of FinTech 
In this final module, we will consider some of the many outstanding questions and purposes of introducing FinTech to the world, exploring the many ways that FinTech can both help and hurt society. We will discuss financial inclusion, sustainable development, and many other positive aspects of FinTech development. Conversely, we will also consider how these same technologies and solutions could potentially be used to inhibit access to financial markets, or worse.",FinTech Ethics and Risks
https://www.classcentral.com/course/independent-web-applications-for-everybody-7362,"Learn to build database-backed web sites using PHP, MySQL, JQuery, and Handlebars.
      


1: Installing PHP and SQL
The first task is to work through the installation steps including installing a text editor, install ...
2: Introduction to Structured Query Language (SQL)
We learn about single table queries and the basic syntax of the SQL language.
3: Database Design
Covering database design with multiple tables, foreign keys, and the JOIN operation..
4: Introduction to Dynamic Web Content
We look at the basic structure of a web application and how a web browser interacts with a web serve ...
5: Introduction to PHP
We begin learning PHP.
6: Overview of PHP Language
We begin the syntax of the PHP language, control structures, and expressions.
7: PHP Arrays
We look at arrays and superglobals like $_GET in PHP language.
8: PHP Functions
We look at functions in PHP language.
9: PHP Forms
We look at how HTML forms are created and processed in the PHP language.
10: PHP Objects
We look at the object oriented pattern in the PHP language.
11: PHP and MySQL
We look at how we connect to a MySQL using the Portable Data Objects (PDO) library and issue SQL com ...
12: PHP Sessions
We look at how PHP uses cookies and manages session data. We also look at how we properly handle PO ...
13: Building a CRUD Application
Now we buid our first 'complete' application that has multiple screens to Create, Read, Update and D ...
14: Basic JavaScript
We talk a quick look at the JavaScript language. We assume that you already know PHP - so it is a p ...
15: JavaScript Objects
We do a quick look at how the JavaScript language supports the Object-Oriented pattern.
16: JQuery
This is a brief introduction to the JQuery library which is widely used to do in-browser manipulatio ...
17: JSON - JavaScipt Object Notation
In this section we look at JavaScript Object Notation (JSON). JSON is commonly used as a syntax to ...
18: Handlebars UI Templates
In this section we look at moving the templates to build HTML fragments from the server (PHP) in to ...
19: Advanced SQL
This section covers some advanced SQL topics.
20: SQL Transactions
This section covers SQL transactions.",Web Applications for Everybody
https://www.classcentral.com/course/demand-analytics-13827,"Welcome to Demand Analytics - one of the most sought-after skills in supply chain management and marketing!

Through the real-life story and data of a leading cookware manufacturer in North America, you will learn the data analytics skills for demand planning and forecasting. Upon the completion of this course, you will be able to  

1. Improve the forecasting accuracy by building and validating demand prediction models. 
2. Better stimulate and influence demand by identifying the drivers (e.g., time, seasonality, price, and other environmental factors) for demand and quantifying their impact.

AK is a leading cookware manufacturer in North America. Its newly launched top-line product was gaining momentum in the marketplace. However, a price adjustment at the peak season stimulated a significant demand surge which took AK completely by surprise and resulted in huge backorders. AK faced the risk of losing the market momentum due to the upset customers and the high cost associated with over-time production and expedited shipping. Accurate demand forecast is essential for increasing revenue and reducing cost. Identifying the drivers for demand and assessing their impact on demand can help companies better influence and stimulate demand.

I hope you enjoy the course!
      


          Welcome!
    -Welcome to the exciting world of Demand Analytics! In Week 1, you will learn the crisis that AK MetalCrafters, a leading cookware manufacturer in North America, faced in launching new products, and how AK successfully resolved the crisis using Demand Analytics. You will also learn the general principles of demand planning and forecasting, and how it fits into a firm's integrated business planning.

Predicting Trend
    -Welcome to Week 2 of Demand Analytics! In Week 1, you learned the general principles, now in Week 2, you will put them to action by building and interpreting a linear model for predicting the trend (as in new product introduction). You will also learn data collection, pre-processing and visualization techniques, which are critical to model building.

Predicting the Impact of Price and Other Environmental Factors
    -Welcome to Week 3 of Demand Analytics! In Week 2, you built a linear model to predict the trend. In this week, you will validate and improve the model by first analyzing its errors to identify missing variables and then building a multiple regression model to capture not only the trend but also the impact of price and other environmental factors. 

Predicting Seasonality
    -In this last week of Demand Analytics, you will further improve your demand forecasting model built in Week 3 by including seasonality to capture the periodic patterns in the errors; you will learn how to model and format categorical variables, and how to create and test your forecast.",Demand Analytics
https://www.classcentral.com/course/linear-regression-business-statistics-7041,"Regression Analysis is perhaps the single most important Business Statistics tool used in the industry. Regression is the engine behind a multitude of data analytics applications used for many forms of forecasting and prediction.  
This is the fourth course in the specialization, ""Business Statistics and Analysis"". The course  introduces you to the very important tool known as Linear Regression. You will learn to apply various procedures such as dummy variable regressions, transforming variables, and interaction effects. All these are introduced and explained using easy to understand examples in Microsoft Excel.
The focus of the course is on understanding and application, rather than detailed mathematical derivations.
Note: This course uses the ‘Data Analysis’ tool box which is standard with the Windows version of Microsoft Excel. It is also standard with the 2016 or later Mac version of Excel. However, it is not standard with earlier versions of Excel for Mac. 


WEEK 1
Module 1: Regression Analysis: An Introduction
In this module you will get introduced to the Linear Regression Model. We will build a regression model and estimate it using Excel. We will use the estimated model to infer relationships between various variables and use the model to make predictions. The module also introduces the notion of errors, residuals and R-square in a regression model.

Topics covered include:
•	Introducing the Linear Regression
•	Building a Regression Model and estimating it using Excel
•	Making inferences using the estimated model
•	Using the Regression model to make predictions
•	Errors, Residuals and R-square


WEEK 2
Module 2: Regression Analysis: Hypothesis Testing and Goodness of Fit
This module presents different hypothesis tests you could do using the Regression output. These tests are an important part of inference and the module introduces them using Excel based examples. The p-values are introduced along with goodness of fit measures R-square and the adjusted R-square. Towards the end of module we introduce the ‘Dummy variable regression’ which is used to incorporate categorical variables in a regression. 

Topics covered include:
•	Hypothesis testing in a Linear Regression
•	‘Goodness of Fit’ measures (R-square, adjusted R-square)
•	Dummy variable Regression (using Categorical variables in a Regression)


WEEK 3
Module 3: Regression Analysis: Dummy Variables, Multicollinearity
This module continues with the application of Dummy variable Regression. You get to understand the interpretation of Regression output in the presence of categorical variables. Examples are worked out to re-inforce various concepts introduced. The module also explains what is Multicollinearity and how to deal with it. 

Topics covered include:
•	Dummy variable Regression (using Categorical variables in a Regression)
•	Interpretation of coefficients and p-values in the presence of Dummy variables
•	Multicollinearity in Regression Models


WEEK 4
Module 4: Regression Analysis: Various Extensions
The module extends your understanding of the Linear Regression, introducing techniques such as mean-centering of variables and building confidence bounds for predictions using the Regression model. A powerful regression extension known as ‘Interaction variables’ is introduced and explained using examples. We also study the transformation of variables in a regression and in that context introduce the log-log and the semi-log regression models. 

Topics covered include:
•	Mean centering of variables in a Regression model
•	Building confidence bounds for predictions using a Regression model
•	Interaction effects in a Regression
•	Transformation of variables
•	The log-log and semi-log regression models
      


            Read more
          



          Regression Analysis: An Introduction

Regression Analysis: Hypothesis Testing and Goodness of Fit

Regression Analysis: Dummy Variables, Multicollinearity

Regression Analysis: Various Extensions",Linear Regression for Business Statistics
https://www.classcentral.com/course/hypothesis-testing-confidence-intervals-7035,"Confidence intervals and Hypothesis tests are very important tools in the Business Statistics toolbox. A mastery over these topics will help enhance your business decision making and allow you to understand and measure the extent of ‘risk’ or ‘uncertainty’ in various business processes. 
This is the third course in the specialization ""Business Statistics and Analysis"" and the course  advances your knowledge about Business Statistics by introducing you to Confidence Intervals and Hypothesis Testing. We first conceptually understand these tools and their business application. We then introduce various calculations to constructing confidence intervals and to conduct different kinds of Hypothesis Tests. These are done by easy to understand applications.

To successfully complete course assignments, students must have access to a Windows version of Microsoft Excel 2010 or later. Please note that earlier versions of Microsoft Excel (2007 and earlier) will not be compatible to some Excel functions covered in this course. 


WEEK 1
Module 1: Confidence Interval - Introduction
In this module you will get to conceptually understand what a confidence interval is and how is its constructed. We will introduce the various building blocks for the confidence interval such as the t-distribution, the t-statistic, the z-statistic and their various excel formulas. We will then use these building blocks to construct confidence intervals.

Topics covered include:
•	Introducing the t-distribution, the T.DIST and T.INV excel functions
•	Conceptual understanding of a Confidence Interval
•	The z-statistic and the t-statistic
•	Constructing a Confidence Interval using z-statistic and t-statistic 


WEEK 2
Module 2: Confidence Interval - Applications
This module presents various business applications of the confidence interval including an application where we use the confidence interval to calculate an appropriate sample size. We also introduce with an application, the confidence interval for a population proportion. Towards the close of module we start introducing the concept of Hypothesis Testing.

Topics covered include:
•	Applications of Confidence Interval
•	Confidence Interval for a Population Proportion
•	Sample Size Calculation
•	Hypothesis Testing, An Introduction


WEEK 3
Module 3: Hypothesis Testing
This module introduces Hypothesis Testing. You get to understand the logic behind hypothesis tests. The four steps for conducting a hypothesis test are introduced and you get to apply them for hypothesis tests for a population mean as well as population proportion. You will understand the difference between single tail hypothesis tests and two tail hypothesis tests and also the Type I and Type II errors associated with hypothesis tests and ways to reduce such errors. 

Topics covered include:
•	The Logic of Hypothesis Testing
•	The Four Steps for conducting a Hypothesis Test
•	Single Tail and Two Tail Hypothesis Tests
•	Guidelines, Formulas and an Application of Hypothesis Test
•	Hypothesis Test for a Population Proportion
•	Type I and Type II Errors in a Hypothesis 


WEEK 4
Module 4: Hypothesis Test - Differences in Mean
In this module, you'll apply Hypothesis Tests to test the difference between two different data, such hypothesis tests are called difference in means tests. We will introduce the three kinds of difference in means test and apply them to various business applications. We will also introduce the Excel dialog box to conduct such hypothesis tests.

Topics covered include:
•	Introducing the Difference-In-Means Hypothesis Test
•	Applications of the Difference-In-Means Hypothesis Test
•	The Equal & Unequal Variance Assumption and the Paired t-test for difference in means.
•	Some more applications
      


            Read more
          



          Confidence Interval - Introduction

Confidence Interval - Applications

Hypothesis Testing

Hypothesis Test - Differences in Mean",Business Applications of Hypothesis Testing and Confidence Interval Estimation
https://www.classcentral.com/course/fog-2731,"Pushing computation, control and storage into the “cloud” has been a key trend in
networking in the past decade. The cloud is now “descending” to the network
edge and often diffused among the client devices in both mobile and wireline
networks. The cloud is becoming the “fog.” Empowered by the latest chips,
radios, and sensors, each client device today is powerful in computation, in
storage, in sensing and in communication. Yet client devices are still limited
in battery power, global view of the network, and mobility support. Most
interestingly, the collection of many clients in a crowd presents a highly
distributed, under-organized, and possibly dense network. 
Fog Networking is an architecture that will also support the Internet of Things, IoT, such as the “connected wearables.” Bold, new user interfaces are getting close to affordable price points for the mass, begging questions on the “architectural choices for the glasses and watches,” from naming to billing, and from session management to resource optimization. Fog Networking leverages past experience in sensor networks, P2P and MANET research, and incorporates the latest advances in devices, network systems, and data science to reshape the “balance of power” in the ecosystem of computing and networking. 



Overview: From Cloud to FogOverview: From IT to loTPrinciples of Edge/P2P networkingSmart data pricing for new network servicesClient side control and configurationClient-side measurement & Control SignalingEdge resource pooling and cachingSecurity and privacy in FogConsumer and wearable IoTConnected cars IoTSmart grids IoTHealthcare IoT",Fog Networks and the Internet of Things
https://www.classcentral.com/course/inclusive-design-11169,"This course provides instruction and strategies to support you in developing a course that is inclusive to students with a wide range of abilities, including students with disabilities. We cover effective practices to increase inclusion and avoid some of the common accessibility issues that can arise in an online course.

In particular, Basics of Inclusive Design Online covers course organization, the accessibility of Microsoft Office and PDF documents, making course instruction pages accessible, captioning of videos, making images accessible, and designing for learning differences. We also discuss how inclusive course materials can help all students, including students without disabilities.

This course will appeal to those who want both a broad overview of the range of accessibility considerations and also a step-by-step guide of how to check documents for accessibility, caption a video, or prepare course content for non-visual users.

Course logo credit: ""web accessibility word cloud"" by Jill Wright (https://goo.gl/xyUoeU). 
Copyright - some rights remain. See https://creativecommons.org/licenses/by/2.0/
      


          Week 1: Introduction to Course, Demographics, Universal Design
    -Welcome to the first week of Basics of Inclusive Design! This module will review the structure and logistics of the course and then introduce the issues that affect course accessibility. The topic of course accessibility will include an interview with two students who use Assistive Technology to access digital material. The assignment will allow you to learn more about the issues that students with different backgrounds and abilities face when taking a course and for you to offer your own solutions for addressing the needs of students who may need special adaptations for accessing course material.

Week 2: Accessible Documents
    -Following a review of online accessibility issues, in this week we will explain the steps to create and  remediate course documents in MS Word, PowerPoint, and Adobe PDF documents. The assignment will provide you with an opportunity to apply these skills to actual documents.

Week 3: Complex Images, Tables, Graphs
    -Week 3 will focus on creating appropriate text alternatives for complex images and other more complex material, such as data tables and graphs. The assignment will provide you the opportunity to add alternate text to images.

Week 4: Captioning
    -This week, we will introduce the topic of captioning, discuss its accessibility and Universal Design benefits and then provide step-by-step instruction for captioning videos using a variety of tools. The assignment will provide the opportunity to caption a video.

Week 5: Uncovered Topics, Resources & Review
    -This final week of the course will cover topics not covered in earlier lessons: keyboard accessibility, color contrast and the accessibility of Learning Management Systems (LMS). The assignment will ask you to use a resource we have covered and one discovered by you to address one of a number of accessibility scenarios.",Basics of Inclusive Design for Online Education
https://www.classcentral.com/course/fpga-sdaccel-theory-13559,"This course is for anyone passionate in learning how to develop FPGA-accelerated applications with SDAccel!

We are entering in an era in which technology progress induces paradigm shifts in computing!
As a tradeoff between the two extreme characteristics of GPP and ASIC, we can find a new concept, a new idea of computing... the reconfigurable computing, which has combined the advantages of both the previous worlds. Within this context, we can say that reconfigurable computing will widely, pervasively, and gradually impact human lives. Hence, it is time that we focus on how reconfigurable computing and reconfigurable system design techniques are to be utilised for building applications.

One one hand reconfigurable computing can have better performance with respect to a software implementation but paying this in terms of time to implement. On the other hand a reconfigurable device can be used to design a system without requiring the same design time and complexity compared to a full custom solution but being beaten in terms of performance.
Within this context, the Xilinx SDx tools, including the SDAccel environment, the SDSoC environment, and Vivado HLS, provide an out-of-the-box experience for system programmers looking to partition elements of a software application to run in an FPGA-based hardware element, and having that hardware work seamlessly with the rest of the application running in a processor or embedded processor. 

The out-of-the-box experience will provide interesting and, let us say, “good enough” results for many applications. 
However, this may not be true for you, you may be looking for better performance, data throughput, reduced latency, or to reduce the resources usage... This course is focusing exactly on this. After introducing you to the FPGAs we are going to dig more into the details on how to use Xilinx SDAccel providing you also with working examples on how to optimize the hardware logic to obtain the best of of your hardware implementations. In this case, certain attributes, directives, or pragmas, can be used to direct the compilation and synthesis of the hardware kernel, or to optimise the function of the data mover operating between the processor and the hardware logic.
Furthermore, In this course we are going to focus on distributed, heterogeneous infrastructures, presenting how to bring your solutions to life by using the Amazon EC2 F1 instances.
      


            Read more
          



          Familizarize youself with FPGA technologies
    -From the mid-1980s, reconfigurable computing has become a popular field due to the FPGA technology progress. An FPGA is a semiconductor device containing programmable logic components and programmable interconnects but no instruction fetch at run time, that is, FPGAs do not have a program counter. In most FPGAs, the logic components can be programmed to duplicate the functionality of basic logic gates or functional Intellectual Properties (IPs). FPGAs also include memory elements composed of simple flip-flops or more complex blocks of memories. Hence, FPGA has made possible the dynamic execution and configuration of both hardware and software on a single chip. This module provides a detailed description of FPGA technologies starting from a general description down to the discussion on the low-level configuration details of these devices, to the bitstream composition and the description of the configuration registers.

A bird's eye view on SDAccel 
    -The Xilinx SDAccel Development Environment let the user express kernels in OpenCL C, C++ and RTL (as an example we can think of, SystemVerilog, Verilog or VHDL) to run on Xilinx programmable platforms. The programmable platform is composed of (1) the SDAccel Xilinx Open Code Compiler (XOCC), (2) a Device Support Archive (DSA) which describes the hardware platform, (3) a software platform, (4) an accelerator board, and5. last but not least, the SDAccel OpenCL runtime. Within this module, after an introduction to OpenCL, we are going to see how this language has been sued in SDAccel and the main ""components"" of this toolchain.

On how to optmize your system
    -Within this module, Before getting into the optimisation, we will first understand how an FPGA is working, also from a computational point of view. Although the traditional FPGA design flow is more similar to a regular IC than a processor, an FPGA provides significant cost advantages in comparison to an IC development effort and offers the same level of performance in most cases. Another advantage of the FPGA when compared to the IC is its ability to be dynamically reconfigured. This process, which is the same as loading a program in a processor, can affect part or all of the resources available in the FPGA fabric. When compared with processor architectures, the structures that comprise the FPGA fabric enable a high degree of parallelism in application execution. The custom processing architecture generated by SDAccel for an OpenCL kernel presents a different execution paradigm. This must be taken into account when deciding to port an application from a processor to an FPGA. To better understand such a scenario we will briefly compare a processor sequential execution with the intrinsic parallel nature of an FPGA implementation.
Furthermore, within this module we are going to familiarise ourselves with the application optimisation flow.The Xilinx SDAccel Environment is a complete Software Development Environment, for creating, compiling, and optimising OpenCL applications with the objective of being accelerated on Xilinx FPGAs. From a designer perspective we can organise the flow for optimising an application in the SDAccel Environment as a three phases flow. Those three phases are: (1) baselining functionalities and performance, (2) optimising data movement and (3) optimising kernel computation

Optimize your system via SDAccel
    -In this module  we will provide a bird's eye view on the available SDAccel optimisations.
The  presented optimisations are not the only available ones, but they are more a list of recommendations to optimise the performance of an OpenCL application that have to be used as a starting point for ideas to consider or investigate further. Within this context we will organise these “recommendations” in three sets of optimisations: (1) arithmetic optimisations, (2) data-related optimisations, and finally (3) memory-related optimisations.

Other optimizations
    -After an overall description of possibile optimisations, within this module we will focus on four specific optimisations (1) loop unrolling, (2) loop pipelining, (3) array partitioning and (4) the host optimisations. First, we will describe loop unrolling which means to unroll the loop iterations so that, the number of iterations of the loop reduces, and the loop body performs extra computation. This technique allows to expose additional instruction level parallelism that Vivado HLS can exploit to implement the final hardware design. After that we will present the loop pipelining optimisation, where we will move from a sequential execution of the loop iterations to a pipelined execution in which the loop iterations are overlapped in time. After that we will present the array partitioning optimisation which allows to optimise the usage of BRAM resources in order to improve the performance of the kernel. Finally, at the end of this module we are going to discuss optimisations related to the host system that is responsible for transferring the data to and from the FPGA board, as well as to send the command to start the execution of a kernel.

An introduction to FPGA-augmented cloud infrastructures",Developing FPGA-accelerated cloud applications with SDAccel: Theory
https://www.classcentral.com/course/futurelearn-cyber-security-safety-at-home-online-in-life-6265,"##
In the modern world, information security has an influence on all of us: at home, at work, online and in life in general. Like many inventions that have gone before, the internet and the web, the cloud and the Internet of Things (IoT) bring with them many advantages, but also open up new possibilities for criminal activity.
So should you avoid all contact with this brave new world? This free online course presents an alternative, providing you with the knowledge to make informed decisions.
Understand key topics in cyber security
The course will introduce you to some of the current key topics in cyber security research and show how they relate to everyday life. We’ll look at how the move to online storage of personal data affects privacy, how online payments can be made safely, and how the proliferation of “smart” devices affect security.
Over the three weeks of the course we will look at these topics from different perspectives: the user’s, a potential attacker’s and a business’s.  We’ll also discuss how research underway at Newcastle University addresses these topics.


Privacy online:  What is privacy? We begin by looking into our own beliefs and practices when it comes to giving out our data online. What is the value of our personal data to businesses? And how can you find out what information about you is readily available online?


Payment safety: We make payments everyday, we purchase items at the store and we purchase items online, but how secure are these payments?  How safe is our money?   All of the different methods of payment cash, credit/debit card, cheque and bitcoin are a trade-off between security and convenience.   We will look at constantly evolving race between the payment fraud and the security measures employed to prevent fraud.


Security at home: With increasing numbers of autonomous, internet-enabled devices in our homes and cars, on our wrists and in our clothes, how could they be misused? And what can we do about understanding and responding to the risks and threats?


Learn from cyber security researchers and practitioners
The course is presented by researchers and practitioners from Newcastle University’s School of Computing Science, an acknowledged Academic Centre of Excellence in Cyber Security Research (ACE-CSR).
The team conduct research in areas such as cryptography and information assurance with a focus on understanding the human element of cyber security - victims, investigators and attackers. Each topic is led by a research expert in that field. The North East Regional Cyber Crime Unit (UK) said:
I was impressed. The content is really relevant and dynamic and not just your basic security tips - there’s a bit more to it than that. It’s very user interactive.
The course is suitable for people who have some knowledge of cyber security, some IT background and an interest in finding out the state of practice in cyber security as well as future research directions.



            Read more","Cyber Security: Safety at Home, Online, in Life"
https://www.classcentral.com/course/descriptivestats-2756,"Understanding statistics is essential to understand research in the social and behavioral sciences. In almost all research studies, statistics are necessary to decide whether the results support the research hypothesis. In this course you will learn the basics of descriptive statistics; not just how to calculate them, but also how to evaluate them. An important part of the material treated in this course will prepare you for the next course in the specialization, namely the course Inferential Statistics. We will start with the concepts variable and data, the difference between population and sample and types of data. Then we will consider the most important measures for centrality (mean, median and mode) and spread (standard deviation and variance). These will be followed by the concepts contingency, correlation and regression. All these statistics make it possible to represent large amounts of data in a clear way, enabling us to spot interesting patterns. The second part of the course is concerned with the basics of probability: calculating probabilities, probability distributions and sampling distributions. You need to know about these things in order to understand how inferential statistics work. We will end the course with a short preview of inferential statistics - statistics that help us decide whether the differences between groups or correlations between variables that we see in our data are strong enough to conclude that our predictions were confirmed and our hypothesis is supported.You will not only learn about all these concepts, you will also be trained to calculate and generate these statistics yourself using freely available statistical software.
      


            Read more
          



Descriptive statistics allow us to represent essential information about a large amount of data by summarizing characteristics of the data visually and numerically. They also form the basis for inferential statistics, that help us decide whether our data provide support for the research hypothesis. You will learn about the basic concepts and learn to calculate and generate these statistics yourself using freely available statistical software.In the first part of the course we will consider the basic concepts, graphs and the most important descriptive statistics that help us to spot interesting patterns. The second part of the course is concerned with the basics of probability, necessary to understand inferential statistics. We will end the course with a short preview of inferential statistics. Week 1: Exploring data 

introduction to statistics 
sample and population
center and variability statistics
graphical representation
quiz and warm-up assignments (not graded)
Week 2: Association

contingency tables
correlation
regression
quiz and small assignment (graded)
Week 3: Probability

definition of probability
calculating probabilities
quiz and paper on week 1 & 2 (graded)
Week 4: Probability distributions

basic concepts
types of distributions
normal distribution
binomial distribution
quiz and small assignment (graded) 
Week 5: Sampling distributions

variation in sample values 
sampling distribution for proportions 
sampling distribution for means 
quiz and paper on week 3 & 4 (graded)
Week 6: Confidence intervals & significance
testing

statistical inference
confidence interval for proportions and means
significance tests for one proportion and one mean
quiz and small assignment (graded)
Week 7: Study week

time to ask your final questions
time to work on last paper
Week 8: Exam week

paper on week 5 & 6 (graded), final exam (graded) and course evaluation",Descriptive Statistics
https://www.classcentral.com/course/edx-blockchain-technology-11428,"Developed by Blockchain at Berkeley and faculty from UC Berkeley's premier Computer Science department, this course provides a wide overview of many of the topics relating to and building upon the foundation of Bitcoin and blockchain technology.The course covers many key topics in the blockchain space. First, we take a look at distributed systems and alternative consensus mechanisms, as well as cryptoeconomic and proof-of-stake. We then move on to the fundamental applications of bitcoin and blockchain technology, including exploring enterprise blockchain implementations (JP Morgan’s Quorum, Ripple, Tendermint, and HyperLedger), the challenges and solutions around scaling blockchain adoption, and the measures that the government is taking to regulate and control blockchain technology. We wrap up the course by also taking a look at the various blockchain ventures today and conclude with a blockchain-based future thought experiment. This course is open to anyone with any background. Whether you are planning your next career move as a blockchain developer, crypto trader, data analyst, researcher, or consultant, or are just looking for an introduction to Blockchain. This course will help you begin to develop the critical skills needed to future-proof your career. This is the second course in the Blockchain Fundamentals Professional Certificate program.
      


Distributed Systems and Alternative ConsensusBlockchain architecture is built on the foundation of decades of computer science and distributed systems literature. We start out by providing a formal definition of distributed consensus and presenting foundational theoretical computer science topics such as the CAP Theorem and the Byzantine Generals Problem. We then explore alternative consensus mechanisms to Bitcoin’s Proof-of-work, including Proof-of-Stake, voting-based consensus algorithms, and federated consensus.Cryptoeconomics and Proof-of-StakeWe examine the meaning and properties of cryptoeconomics as it relates to its two compositional fields: cryptography and economics. We then look at the goals of cryptoeconomics with respect to distributed systems fundamentals (liveness, safety, data availability) and the griefing factors and faults in the way of these goals.Enterprise Blockchain: Real-World ApplicationsWe look at various existing enterprise-level blockchain implementations, such as JP Morgan’s Quorum, Ripple, Tendermint, and HyperLedger. We also explore business and industry use cases for blockchain, ICOs, and the increasing regulations surrounding blockchain.Scaling Blockchain: Cryptocurrencies for the MassesOne major obstacle to widespread blockchain adoption is the problem of scalability. We define scaling first as it relates to Bitcoin as a payment method, and compare it to more traditional forms of payment such as credit cards. We then consider the general blockchain scalability debate and look into some of the solutions that have been proposed for vertical scaling (e.g. blocksize increases, Segregated Witness, and the Lightning Network), as well as horizontal scaling (e.g. sidechains, sharding). Regulation and AnonymityWe look into the measures that governments have taken to regulate and control blockchain technology.  We examine Anti-Money Laundering (AML) and Know Your Customer (KYC) regulations, anonymity goals, and government techniques for deanonymization of entities on blockchain. Then from the user’s perspective, we also dive into privacy oriented altcoins and mixing techniques.A Blockchain-Powered FutureA summary of the course and an exploratory look into blockchain ventures today, such as venture capitalism, ICOs, and crowdfunding. We conclude with a blockchain-based future thought experiment.",Blockchain Technology
https://www.classcentral.com/course/edx-introduction-to-nosql-data-solutions-8125,"As a data pro, you know that some scenarios—particularly those involving real-time analytics, site personalization, IoT, and mobile apps—are better addressed with NoSQL storage and compute solutions than they are with relational databases. Microsoft Azure has several NoSQL (or “Not Only SQL”) non-relational data storage options to choose from. NoSQL databases are generally built to be distributed and partitioned across many servers. And they’re built to scale out for high availability and to be flexible enough to handle semi-structured and unstructured data. If you have a data model that is constantly evolving and you want to move fast, that’s what these databases are about.
In this practical course, complete with labs, assessments, and a final exam, join the experts to learn how NoSQL has evolved over time. Explore non-relational data storage options in Azure, and see how to use them in your applications. Find out how to create, store, manage, and access data in these different storage options. Get an in-depth look at Azure Table Storage, DocumentDB, MongoDB, and more. Learn about the “three Vs”—variety (schemas or scenarios that evolve quickly), volume (scale in terms of data storage), and velocity (throughput needs to support a large user base). Take this opportunity to get hands-on with NoSQL options in Azure.",Introduction to NoSQL Data Solutions
https://www.classcentral.com/course/gcp-infrastructure-scaling-automation-8761,"This accelerated on-demand course introduces participants to the comprehensive and flexible infrastructure and platform services provided by Google Cloud Platform. Through a combination of video lectures, demos, and hands-on labs, participants explore and deploy solution elements, including securely interconnecting networks, load balancing, autoscaling, infrastructure automation and managed services.

Prerequisites: 
To get the most out of this course, participants should have:
• Completed Google Cloud Platform Fundamentals: Core Infrastructure or have equivalent experience
• Completed Essential Cloud Infrastructure: Foundation or have equivalent experience
• Completed Essential Cloud Infrastructure: Core Services or have equivalent experience
• Basic proficiency with command-line tools and Linux operating system environments
• Systems Operations experience including deploying and managing applications, either on-premises or in a public cloud environment

>>> By enrolling in this course you agree to the Qwiklabs Terms of Service as set out in the FAQ and located at: https://qwiklabs.com/terms_of_service 
      


          Introduction
    -In this module we introduce the Architecting with Google Compute Engine course series. This course series is defined for cloud solution architects, DevOps engineers, and anyone who's interested in using GCP, to create new solutions or to integrate existing systems, application environments, and infrastructure with a focus on Compute Engine.

Module 1: Interconnecting Networks
    -In this module, we’ll focus on GCP’s hybrid connectivity products, which are Cloud VPN, Cloud Interconnect, and Peering. We’ll also look at options for sharing VPC networks within GCP.

Module 2: Load Balancing and Autoscaling
    -In this module, we will cover the different types of load balancers that are available in GCP. We will also go over managed instance groups and their autoscaling configurations, which can be used by these load balancing configurations.

Module 3: Infrastructure Automation
    -In this module, we cover how to use Deployment Manager to automate the deployment of infrastructure and how to use GCP Marketplace to launch infrastructure solutions. You will use Deployment Manager or Terraform to deploy a VPC network, a firewall rule, and VM instances in the lab of this module.

Module 4: Managed Services
    -In this module, we give you an overview of BigQuery, Cloud Dataflow, Cloud Dataprep by Trifacta, and Cloud Dataproc. Now all of these services are for data analytics purposes, and since that’s not the focus of this course series, there won’t be any labs in this module. Instead, we’ll have a quick demo to illustrate how easy it is to use a managed service.",Elastic Google Cloud Infrastructure: Scaling and Automation
https://www.classcentral.com/course/continuous-learning-culture-7120,"There is mounting concern that organizational groups and teams often fail to learn from their past experiences. It’s pertinent to address this issue as groups and teams are often the main ways that work gets done in organizations.  

In this course, we examine the main reasons that groups and teams are often ineffective, which include:
•	The lack of organizational structures and support for teams and groups 
•	The lack of understanding and emphasis on learning
•	Misaligned reward structures

So, what can be done to create an enabling learning culture in teams? 

This course emphasizes practical and impactful ways to begin to address this state of affairs. Through the use of stories, scenarios with actors simulating different team issues, examples and dialogue, you learn how to: 
•	Understand teams in their larger organizational context
•	Diagnose the learning strengths and barriers to learning on teams
•	Identify ways to develop a team and group that continually learns and impacts the larger organization positively
•	Create an organizational environment that encourages learning and innovation
      


          Week 1: Introduction to Framing & Systems Thinking
    -Thank you for joining us.  In this module you will learn to step back and re-frame your point of view, and apply systems thinking in everyday situations in order to help your team to be creative and innovative. Our goal is to enable you to learn through real-life stories, practical scenarios illustrated by actors,  on-going conversations, suggested readings and links rather than lectures and instructions. So, come join us at the table, bring your own experiences with you, and be part of the conversation! 
Check out this NY Times story before you begin: (https://www.nytimes.com/video/business/100000004807604/the-power-of-outsiders.html?smid=fb-share)
This story illustrates many of the important points of this course:  the importance of thinking about the whole system, the value of including different, outside perspectives (not just experts), and - even when you and your team come up with a breakthrough idea - accepting that it is a difficult challenge to spread the idea and make change happen. 


Week 2 : Diagnosing Strengths & Barriers to Learning on Teams
    -Thank you for joining us in this module! You will learn to recognize the strengths and barriers - visible and invisible - that exist in teams. Quite like the George Washington Bridge story in Week 1, where you learned about Framing and Systems Thinking, here you will learn to define, frame and diagnose the problems and conflicts that can arise in teams; and you will learn to think about data gathering and creating solutions that work! Join us at the table.

Week 3 : Developing Groups & Teams for Positive Organizational Impact
    -Thank you for joining us In Modules 1 & 2.  In the previous modules you have learned about Framing, Reframing, Systems Thinking, and Taking a Diagnostic Focus on Groups and Teams.  In this module you will learn about disabling and enabling group and team structures.  You will also learn about diffusing innovations, and how to have productive conversations using the Ladder of Inference as a guide.    

Week 4 : Fostering Innovation in Groups & Teams
    -Thank you for staying with and being a part of our emergent conversations. If you have accompanied us through weeks 1,2 and 3, we are now at the closing end of our on-going discussion around learning in teams - in this section, we'll focus on Complex Adaptive Systems and structures that foster and accelerate engagement, learning and team conversations. Come join us.",Creating a Team Culture of Continuous Learning
https://www.classcentral.com/course/computer-architecture-fundamentals-7501,"This course introduces several topics for the learners about the fundamentals of computer architecture. After completing this course, the students will have the basic knowledge of:
•	Computer Performance and Benchmarks
•	Summarizing Performance
•	Amdahl’s law
•	Introduction to Embedded Systems

Learning Outcome:
•	After completing this course, the learners will have the tools to evaluated different computer architectures as well as the software executing on them.
•	The learners of this course will have knowledge about modern microprocessors and the design techniques used to increase their performance.

Skills Gained:
•	Basic skills to evacuate the performance of computer systems
      


Introduction This week we first present a definition of computer architecture and the overall objectives of this specialization. Then we will learn how to measure and summarize performance, and about Amdahl's famous law. Finally we will give an introduction to embedded systems.ISA Design and MIPS64The set of instructions supported by a processor is called its Instruction Set Architecture (ISA). This week we will learn the MIPS64 ISA, which will be used for code examples throughout this specialization. We will also learn some basic code optimizations that reduce the number of instructions.Review of PipeliningThis week we will learn about pipelining, which is a technique that overlaps the execution of several instructions. Pipelining is a key implementation technique to make CPUs fast. Using the canonical 5-stage pipeline for illustration, we will learn about pipelining hurdles called hazards and how they can be solved.Multicycle Operations and Pipeline SchedulingThis week we extend the canonical 5-stage pipeline with multicycle operations; operations that require multiple cycles to execute. Thereafter we learn how instructions can be scheduled in order to reduce the number of pipeline stalls.Cache BasicsTo bridge the gap between processor speed and memory speed, modern processors employ caches. Caches are high-speed memories that contain recently used code and data. This week we will learn the basics of caches (how they are organized, how data is found in the cache, etc.). In addition, we will learn the average memory access time (AMAT) equation as well as 5 basic cache optimizations that aim at reducing the AMAT.",Fundamentals of Computer Architecture
https://www.classcentral.com/course/machlearning-373,"Machine learning algorithms can figure out how to perform important tasks by generalizing from examples. This is often feasible and cost-effective when manual programming is not. Machine learning (also known as data mining, pattern recognition and predictive analytics) is used widely in business, industry, science and government, and  there is a great shortage of experts in it. If you pick up a machine learning textbook you may find it forbiddingly mathematical, but in this class you will learn that the key ideas and algorithms are in fact quite intuitive. And powerful!Most of the class will be devoted to supervised learning (in other words, learning in which a teacher provides the learner with the correct answers at training time). This is the most mature and widely used type of machine learning. We will cover the main supervised learning techniques, including decision trees, rules, instances, Bayesian techniques, neural networks, model ensembles, and support vector machines. We will also touch on learning theory with an emphasis on its practical uses. Finally, we will cover the two main classes of unsupervised learning methods: clustering and dimensionality reduction. Throughout the class there will be an emphasis not just on individual algorithms but on ideas that cut across them and tips for making them work.In the class projects you will build your own implementations of machine learning algorithms and apply them to problems like spam filtering, clickstream mining, recommender systems, and computational biology. This will get you as close to becoming a machine learning expert as you can in ten weeks!



            Read more
          



          Week One: Basic concepts in machine learning.Week Two: Decision tree induction.Week Three: Learning sets of rules and logic programs.Week Four: Instance-based learning.Week Five: Statistical learning.Week Six: Neural networks.Week Seven: Model ensembles.Week Eight: Learning theory.Week Nine: Support vector machines.Week Ten: Clustering and dimensionality reduction.",Machine Learning
https://www.classcentral.com/course/ethicalsocialgenomic-2193,"Please note: This course was developed in 2014. This course is not actively moderated by course instructors, please use the course forums to collaborate with other learners.

Knowledge linking genomics to health and disease is rapidly expanding. Translation of this knowledge into clinical and public health practice offers promising opportunities but also raises a host of ethical, legal, social, and policy questions.  Using case examples, this inter-disciplinary course will explore the challenges of genomic and precision medicine.

This seven week, inter-disciplinary course provides an introduction to ethical, legal, social, and policy issues that arise in the translation of genomic knowledge into medical and public health practice. It considers challenges in health related and reproductive testing/screening focusing on six specific areas:
•	Pre‐conception genetic diagnosis, and prenatal testing/screening 
•	Newborn screening 
•	Use of genomic sequencing technologies to diagnose and predict disease 
•	Targeting genomic testing/screening by race/ethnicity 
•	Direct‐to‐consumer genomic testing/screening 
•	Use of “big data” for genomic research and genomic translation 

Course Objectives 

1.	Critique the promise of genomics and precision medicine for improving health outcomes for individuals and populations. 
2.	Through analysis of key cases, demonstrate an understanding of the ethical, legal, social, and policy (ELSI) challenges that accompany the translation of new genomic knowledge into clinical medicine and public health practice. 
3.	Apply a critical analysis of ELSI concerns to your professional practice (if relevant), your interest as a potential user of genomic knowledge, and as a citizen with a responsibility to shape health policy.
      


            Read more
          



Week 1Introduction to Genetics in Medicine and Public Health, Genetics as a Tool in Cancer Prevention, and Genetic Screening.Week 2Reproductive GeneticsWeek 3ScreeningWeek 4Genetic Technology in the Prediction and Diagnosis of DiseaseWeek 5Race and GeneticsWeek 6Direct to Consumer TestingWeek 7Where Do We Go From Here?",Ethical and Social Challenges of Genomic and Precision Medicine
https://www.classcentral.com/course/thermodynamics-656,"This introductory physical chemistry course examines the connections between molecular properties and the behavior of macroscopic chemical systems.
      


          Module 1
    -This module includes philosophical observations on why it's valuable to have a broadly disseminated appreciation of thermodynamics, as well as some drive-by examples of thermodynamics in action, with the intent being to illustrate up front the practical utility of the science, and to provide students with an idea of precisely what they will indeed be able to do themselves upon completion of the course materials (e.g., predictions of pressure changes, temperature changes, and directions of spontaneous reactions). The other primary goal for this week is to summarize the quantized levels available to atoms and molecules in which energy can be stored. For those who have previously taken a course in elementary quantum mechanics, this will be a review. For others, there will be no requirement to follow precisely how the energy levels are derived--simply learning the final results that derive from quantum mechanics will inform our progress moving forward. Homework problems will provide you the opportunity to demonstrate mastery in the application of the above concepts. 

Module 2
    -This module begins our acquaintance with gases, and especially the concept of an ""equation of state,"" which expresses a mathematical relationship between the pressure, volume, temperature, and number of particles for a given gas. We will consider the ideal, van der Waals, and virial equations of state, as well as others. The use of equations of state to predict liquid-vapor diagrams for real gases will be discussed, as will the commonality of real gas behaviors when subject to corresponding state conditions. We will finish by examining how interparticle interactions in real gases, which are by definition not present in ideal gases, lead to variations in gas properties and behavior. Homework problems will provide you the opportunity to demonstrate mastery in the application of the above concepts. 

Module 3
    -This module delves into the concepts of ensembles and the statistical probabilities associated with the occupation of energy levels. The partition function, which is to thermodynamics what the wave function is to quantum mechanics, is introduced and the manner in which the ensemble partition function can be assembled from atomic or molecular partition functions for ideal gases is described. The components that contribute to molecular ideal-gas partition functions are also described. Given specific partition functions, derivation of ensemble thermodynamic properties, like internal energy and constant volume heat capacity, are presented. Homework problems will provide you the opportunity to demonstrate mastery in the application of the above concepts. 

Module 4
    -This module connects specific molecular properties to associated molecular partition functions. In particular, we will derive partition functions for atomic, diatomic, and polyatomic ideal gases, exploring how their quantized energy levels, which depend on their masses, moments of inertia, vibrational frequencies, and electronic states, affect the partition function's value for given choices of temperature, volume, and number of gas particles. We will examine specific examples in order to see how individual molecular properties influence associated partition functions and, through that influence, thermodynamic properties. Homework problems will provide you the opportunity to demonstrate mastery in the application of the above concepts. 

Module 5
    -This module is the most extensive in the course, so you may want to set aside a little extra time this week to address all of the material. We will encounter the First Law of Thermodynamics and discuss the nature of internal energy, heat, and work. Especially, we will focus on internal energy as a state function and heat and work as path functions. We will examine how gases can do (or have done on them) pressure-volume (PV) work and how the nature of gas expansion (or compression) affects that work as well as possible heat transfer between the gas and its surroundings. We will examine the molecular level details of pressure that permit its derivation from the partition function. Finally, we will consider another state function, enthalpy, its associated constant pressure heat capacity, and their utilities in the context of making predictions of standard thermochemistries of reaction or phase change. Homework problems will provide you the opportunity to demonstrate mastery in the application of the above concepts. 

Module 6
    -This module introduces a new state function, entropy, that is in many respects more conceptually challenging than energy. The relationship of entropy to extent of disorder is established, and its governance by the Second Law of Thermodynamics is described. The role of entropy in dictating spontaneity in isolated systems is explored. The statistical underpinnings of entropy are established, including equations relating it to disorder, degeneracy, and probability. We derive the relationship between entropy and the partition function and establish the nature of the constant β in Boltzmann's famous equation for entropy. Finally, we consider the role of entropy in dictating the maximum efficiency that can be achieved by a heat engine based on consideration of the Carnot cycle. Homework problems will provide you the opportunity to demonstrate mastery in the application of the above concepts. 

Module 7
    -This module is relatively light, so if you've fallen a bit behind, you will possibly have the opportunity to catch up again. We examine the concept of the standard entropy made possible by the Third Law of Thermodynamics. The measurement of Third Law entropies from constant pressure heat capacities is explained and is compared for gases to values computed directly from molecular partition functions. The additivity of standard entropies is exploited to compute entropic changes for general chemical changes. Homework problems will provide you the opportunity to demonstrate mastery in the application of the above concepts. 

Module 8
    -This last module rounds out the course with the introduction of new state functions, namely, the Helmholtz and Gibbs free energies. The relevance of these state functions for predicting the direction of chemical processes in isothermal-isochoric and isothermal-isobaric ensembles, respectively, is derived. With the various state functions in hand, and with their respective definitions and knowledge of their so-called natural independent variables, Maxwell relations between different thermochemical properties are determined and employed to determine thermochemical quantities not readily subject to direct measurement (such as internal energy). Armed with a full thermochemical toolbox, we will explain the behavior of an elastomer (a rubber band, in this instance) as a function of temperature. Homework problems will provide you the opportunity to demonstrate mastery in the application of the above concepts. The final exam will offer you a chance to demonstrate your mastery of the entirety of the course material. 

Final Exam
    -This is the final graded exercise (20 questions) for the course. There is no time limit to take the exam.",Statistical Molecular Thermodynamics
https://www.classcentral.com/course/futurelearn-the-lottery-of-birth-3691,"Explore the inequalities between rich and poor, female and male
This online course will look at the big picture of the lottery of birth and the smaller, human stories. You will examine key inequalities, such as being born rich or poor, female or male.
You will consider how individual countries and global organisations are responding to demographic changes and predictions, and how this plays out in the lives of individual women and men in different parts of the world.
The course draws on demography, health studies, sociology, comparative social policy, history, political science and economics, to bring new perspectives and fresh insights.
The course does not assume any prior knowledge of the issues surrounding birth or inequalities. It is post-graduate level and encourages personal research and data interpretation.
Please note that this course includes some content of a sensitive nature, including discussions around abortion and female genital mutilation (FGM).",The Lottery of Birth
https://www.classcentral.com/course/nanosensors-977,"Nanotechnology and nanosensors are broad, interdisciplinary areas
that encompass (bio)chemistry, physics, biology, materials science, electrical
engineering and more. The present course will provide a survey on some of the
fundamental principles behind nanotechnology and nanomaterials and their vital
role in novel sensing properties and applications. The course will discuss interesting interdisciplinary
scientific and engineering knowledge at the nanoscale to understand fundamental
physical differences at the nanosensors. By the end of the course, students
will understand the fabrication, characterization, and manipulation of
nanomaterials, nanosensors, and how they can be exploited for new applications.
Also, students will apply their knowledge of nanotechnology and nanosensors to
a topic of personal interest in this course.



Week 1: Introduction to Nanotechnology:
Definition of nanotechnology; main features of nanomaterials; types of
nanostructures (0D, 1D, and 2D structures); nanocomposites; and main
chemical/physical/electrical/optical properties of nanomaterials.
Week 2: Introduction to Nanotechnology - continue:
Methods for characterizing the nanomaterials: Atomic Force Microscopy (AFM),
Scanning Electron Microscopy (SEM), Transmission Electron Microscopy (TEM), and
spectroscopy- and spectrometry-based surface analysis techniques. Fabrication
of sensors by bottom-up and top-down approaches; self-assembly of
nanostructures; and examples for nanotechnology application
Week 3: Introduction to Sensors' Science and Technology:
Definition of sensors; main elements of sensors; similarities between living
organisms and artificial sensors; working mechanism of physical sensation
(seeing, hearing, and feeling) and chemical sensation (smelling and tasting); the
parameters used for characterizing the performance of sensors: accuracy,
precision, sensitivity, detection limit, dynamic range, selectivity, linearity,
resolution, response time, hysteresis, and life cycle.
Week 4: Metal nanoparticle-based Sensors:
Definition of nanoparticle; features of nanoparticles; and production of
nanoparticles by physical approach (laser ablation) and chemical approaches
(Brust method, seed-mediated growth, etc.).
Week 5: Quantum Dot Sensors: Definition of
quantum dot; fabrication techniques of quantum dots; Macroscopic and
microscopic photoluminescence measurements; applications of quantum dots as
multimodal contrast agents in bioimaging; and application of quantum dots as
biosensors.
Week 6: Nanowire-based Sensors: Definition of nanowires; features
of nanowires; fabrication of individual nanowire by top-down approaches and
bottom-up approaches; and fabrication of nanowire arrays (fluidic channel,
blown bubble film, contact printing, spray coating, etc.).
Week 7: Carbon Nanotubes-based Sensors: Definition of carbon
nanotube; features of carbon nanotubes; synthesis of carbon nanotubes;
fabrication and working principles of sensors based on individual carbon
nanotube; fabrication and working principles of sensors based on random array
of carbon nanotubes.
Week 8: Sensors Based on Nanostructures of Metal Oxide: Synthesis
of metal oxide structures by dry and wet methods; types of metal oxide gas
sensors (0D, 1D, and 2D); defect chemistry of the metal oxide sensors; sensing
mechanism of metal-oxide gas sensors; and porous metal-oxide structures for
improved sensing applications. 
Week 9: Mass-Sensitive Nanosensors: Working
principle of sensors based on polymeric nanostructures; sensing mechanism and
applications of nanomaterial-based of chemiresistors and field effect
transistors of (semi-)conductive polymers, w/o inorganic materials.
Week 10: Arrays of Nanomaterial-based Sensors: A
representative example for the imitation of human senses by means of nanotechnology
and nanosensors: electronic skin based on nanotechnology.",Nanotechnology and Nanosensors
https://www.classcentral.com/course/waterwestus-2985,"This course combines an overview of the science behind water and climate in the Western United States with a survey of the major legal, political, and cultural issues focused on this precious resource.
      


          Course Introduction
    -Are you ready? In this module, we introduce you to how the course works, describe the unique nature of water issues in the American West, and provide important background that will orient you to the region we are studying and the science of hydrology. Let's get started!

History, Politics, and Culture of Water Development in the Western US
    -How did the American West end up with many of the world's largest dams? How does the West's unique legal system for allocating water work? Who gets the right to use water how, and why? We'll cover these topics and more in our module on history, politics, and culture!

Hydrology, Water Demand, and Climate in the Western US
    -Is the West drying up? What happens to a watershed when many of the trees in it die? Let's explore the major scientific issues related to water in the American West. Along the way, we'll hear from a number of experts working on some of the latest cutting-edge research in hydrology, ecology, climate, and more!

Case Study: The Colorado River Basin
    -The Colorado River is a vital source of drinking water for nearly 40 million people and supplies countless farms across a parched landscape. Cutting through nearly 1,500 miles of mountains and deserts, the Colorado's small size belies the fact that it is one of the most intensively managed and litigated rivers in the world. That makes this river perfect for exploring many of the concepts we've covered already in our course.

Controversial Issues and the Future of Water in the Western US
    -In this course, we've emphasized the importance of how the scarcity of water in the American West has shaped so many of the issues around it. In this final module, we'll present some specific cases of complex and often controversial issues that come up because of the unique nature of water in the Western US.",Water in the Western United States
https://www.classcentral.com/course/internet-of-things-dragonboard-4260,"Do you want to develop skills to prototype mobile-enabled products using state-of-the-art technologies? In this course you will build a hardware and software development environment to guide your journey through the Internet of Things specialization courses. We will use the DragonBoard™ 410c single board computer (SBC). 

This is the first in a series of courses where you will learn both the theory and get the hands-on development practice needed to prototype Internet of Things products.  This course is suitable for a broad range of learners. 

This course is for you if:
•  You want to develop hands-on experience with mobile technologies and the Internet
•  You want to pivot your career towards the design and development of Internet of Things enabled products
•  You are an entrepreneur, innovator or member of a DIY community 

Learning Goals: 
After completing this course, you will be able to:
1.  Configure at least one integrated development environment (IDE) for developing software.
2.  Make use of git, adb and fastboot to flash multiple OS and repair bricked boards.
3.  Install Android 5.1 (Lollipop) and Linux based on Ubuntu.
4.  Create, compile and run a Hello World program.
5.  Describe the DragonBoard™ 410c peripherals, I/O expansion capabilities, Compute (CPU and Graphics) capabilities, and Connectivity capabilities.
      


          Introduction
    -Welcome to the Internet of Things! Before diving into this course give us a chance to let you know what it is all about! We will walk you through a module by module outline that will give you highlights on the interesting aspects of the course.

Terminology/Cheat Sheet (Beginner)
    -In this course, you will see a lot of new words and acronyms you might not be familiar with. If you feel comfortable with your knowledge of tech terminology, feel free to skip these lessons since they will not affect the overall integrity of the course. If you see something that you want to know a little more about, feel free to watch the video to gain insight on some basic concepts. We do expect you to know the majority of this material before going into the next module, we would recommend going through the lessons as a quick brush up.

Board Bring up
    -The new and exciting DragonBoard™ 410c is now available! In this module you will get introduced to the new all-in-one board, get an overview of all its amazing features and find out how you can get one yourself. We will then walk you through the registration process, and how to get your board started up for the first time! By the end of this module you will know enough about the DragonBoard™ 410c to begin using it for the fun projects that are to come later in this course and in the rest of the courses in the Internet of Things specialization.

Setting up your Developing Environment
    -In order to easily communicate with your DragonBoard™ 410c it is essential to set up a developing environment. In this lesson we will talk about Android Studio as our preferred IDE (Integrated Development Environment), we will show you how and where to download it as well as walk you through the installation process on both Mac/Linux and Windows. As an Android developer you will need a variety of tools, these tools come bundled with the Android Studio download and are referred to as the SDK (Software Developer Kit). This lesson will cover accessing the SDK and utilizing the various tools it has to offer. ADB (Android Debug Bridge) and Fastboot are among the tools we will be using most throughout this course. It is with these tools that you will be able to access your board at all levels and make crucial changes needed for development.

Changing your Operating System
    -The DragonBoard™ 410c is capable of running a variety of different operating systems, that being said you are free to chose the operating system that you find is best fit for you. Now, we understand that there is a diverse user base for this board and would like to cover as much as possible in this lesson so everyone can enjoy it! Whether you are a Windows user or a Mac user, or prefer Android over Ubuntu, there is a video or two here for you! In this lesson we will help you choose an operating system to best fit for your needs, we will then cover the download, flashing and installation process for all currently available operating systems. Because of the diverse nature of this board we will teach you multiple ways to flash your new operating system and provide a pro's and con's list for the different methods. By the end of this lesson switching between operating system will be easy and exciting for users of all skill levels.

Rescuing your Bricked Board
    -No one expects to damage their new DragonBoard™ 410c, but sometimes accidents happen. This module is dedicated to helping you not only prevent these accidents from happening, but also to fixing any problems should your board become damaged in any way. Here we will go over the difference between a soft brick and a hard brick and why they are two things you want to avoid.

Creating your First Application
    -Welcome to Module 6! In this module we will be creating your first Android App to port to the DragonBoard™ 410c. This “Network Test” App will give you a teaser for the programmatic feats you will be able to accomplish with the DragonBoard™! You will learn about the different GPS and Location Services available on Android and how to access Bluetooth and Wi-fi Data. This module will briefly go over the importance of the Android Manifest and asking the Users for the proper permissions. Lastly, we’ll spice up our application by playing around with Intents and enabling the application to facilitate the above connectivity and network tests. This may sound like a lot, but don’t worry! We will help you get on your feet and by the end of this module, you’ll have coded a neat little application.

Native Development Kit (NDK)
    -In Module 7, will give you a general introduction and brief overview of Android Studio’s Native Development Kit (NDK). The NDK allows us users to program Android applications using C/C++. The NDK utilizes the Java Native Interface (JNI) to facilitate code and interaction between Java and C/C++. This tool was created for users who either have existing C/C++ libraries or plan to use libraries only available in C/C++. Android Studio has a specific build and compilation process catered specifically for NDK Applications that we will explain and cover in this Module. Once we have a better understanding of the NDK, we will create a straightforward “Hello World!” application.

CALIT2 Bird Application
    -Who doesn’t love a good game to pass time? In this Module, we will create a more advanced and interactive Android Application / Game! We will be creating our version of FlappyBird--CalliBird or Calit2Bird, as we like to call it. We will cover the basics of the game by defining certain parameters. First, we have what we call our “Actors”. You can think of “Actors” as any part of the game that appears on the screen (the obstacles and the bird). In the game, we also define our own Location system and a Map class that will handle the different movements in the game. Next we define our game processor which is the backbone of the game. Game Processor ensures your score is constantly updated, delegates the movements to the Map class, and detects collisions, to name a few. Lastly, we will cover the importance of interfaces and its application to this Android App. Interfaces will enable us to 1. play CalliBird / Calit2Bird using any form of input we want (using touch, a sensor, a controller, etc.) and 2. render the game in any display we have (a screen, an led block, etc.). There is a lot of freedom with this game so you will be able to spice it up and make it your own!

Monitoring your DragonBoard™ 410c
    -Congratulations! You’ve made it to the last module of Course 2! In this Module we will cover a more advanced NDK Application. This application is a bit more challenging than prior applications because it is coded in both Java and C. Regardless of the rigour, we know you’ll be able to accomplish this feat! As for the application, we will be turning our DragonBoard™ 410c into a web server! This web server will detail information regarding the DragonBoard™ 410c’s connectivity, GPIOs, and any other statuses you may want to add. We will pull the information from the DragonBoard™ and encode it in a JSON format using Java, then use C to establish a server connection and send the data out. We will walk you through our code and thought processes so that you can gain a better understanding of how to use the NDK to run Android Applications as well as a taste of what the Internet of Things is all about.",Internet of Things: Setting Up Your DragonBoard™ Development Platform
https://www.classcentral.com/course/researchforhealth-1568,"This course looks at the various aspects of research as it pertains to health.The course objectives are as follows:
Summarize the format of research
     articles and the research methods included in each section of an article.Analyze and critique research
     questions, study design, methods including sample selection, bias, data
     collection procedures, measures, and analysis plan, results, discussion
     and interpretation of findings.Compare and contrast different quantitative
     study designs.Analyze the validity and reliability
     of measures.Understand the ethical and cultural
     issues related to research methods. 




Week One: Sections of a Research Article, Abstracts, and the Introduction of a Paper (Literature Review, Significance of Problem, Research Questions, and Operational Definitions)

Identify the 4 sections of scientific research articles
Determine the purpose of the abstract
Identify the 2 key components of the introduction section of an article
Identify 3 elements of a research question
Understand why operational definitions are important

Week Two: Methods Section — Study Designs


Answer 5 questions to identify study designs
Understand the relation between types of study designs and the time frame of the study
Identify the data collection procedures by the study design
Identify the strengths and weaknesses of cohort, cross-sectional, and case-control study designs

Week Three: Methods Section — Sample Selection, Setting, Measurement
(Instruments, Validity, and Reliability)

Differentiate a sample from a population
Identify the strengths of probability versus
     non-probability sampling
Determine inclusion versus exclusion criteria when
     developing a plan for sample selection
Identify different types of instruments included in
     research studies
Explain how instruments are determined to be valid and
     reliable
Identify types of internal validity and reliability
Identify data collection procedures
Week Four: Methods Section —Bias, Types of Variables and Rates
(Incidence and Prevalence)

Identify types of bias related to all study designs
Identify types of bias specific to experimental studies
Determine the difference between parametric and
     nonparametric statistics
Differentiate categorical and continuous variables
Identify the difference between incidence and
     prevalence ratesWeek Five: Ethical Issues, Human Subjects Committee / Institutional Review Boards, and the Discussion of a Paper (Clinical Implications, Limitations, and Future Studies)


Understand the history of research ethics
Determine the ethical lessons learned from the Tuskegee Study in the United States (U.S.)
Identify studies conducted in the U.S. that raised new ethical issues
Identify key components of the discussion section of a research article

Week Six: Final Exam",Understanding Research: An Overview for Health Professionals
https://www.classcentral.com/course/ruby-on-rails-intro-4258,"Did you ever want to build a web application?  Perhaps you even started down that path in a language like Java or C#, when you realized that there was so much “climbing the mountain” that you had to do? Maybe you have heard about web services being all the rage, but thought they were too complicated to integrate into your web application. Or maybe you wondered how deploying web applications to the cloud works, but there was too much to set up just to get going.

In this course, we will explore how to build web applications with the Ruby on Rails web application framework, which is geared towards rapid prototyping.  Yes, that means building quickly! At the conclusion of this course, you will be able to build a meaningful web application and deploy it to the “cloud” using a Heroku PaaS (Platform as a Service). Best of all, it will almost feel effortless… Really!

“But wait”, you will say, “there is no way that we can build a useful application if there is no database involved. You need the data for an application to be useful.” Great point! But what if… instead of getting the data from the database, we get it from the internet by tapping into one of the web services out there that readily provides data needed by our application? “Ok, but that’s probably very complicated”, you will say. Take this course and you will be pleasantly surprised at just how easy it is!
      


          Welcome and Setting Up the Development Environment
    -In this module, we will install software required to develop Ruby on Rails applications. We will also demonstrate the use of a popular Ruby on Rails editor called “Sublime Text”. We will finish the module by familiarizing ourselves with a version control system called “Git” that will be used later in the course to submit assignments, as well as to deploy Ruby on Rails applications to a PaaS (platform as a service) called “Heroku”.

Introduction to Ruby
    -In this module, we will explore the different areas of the Ruby programming language.We will start with the basics and continue with more advanced topics, such as arrays and hashes. We will also spend time exploring object oriented programming in Ruby, and finish the module by demonstrating how to perform unit testing.

Introduction to Ruby on Rails
    -In this module, we will become familiar with core concepts behind Ruby on Rails, such as CoC (Convention Over Configuration) and MVC (Model-View-Controller). We will then learn about consuming JSON API with HTTParty, a Ruby gem.  We will then integrate this ability to consume JSON API to serve as the data layer for our Rails application.Finally, to conclude this module we will deploy the application to Heroku and write a unit test that will verify the desired functionality.",Ruby on Rails: An Introduction
https://www.classcentral.com/course/internet-of-things-multimedia-4237,"Content is an eminent example of the features that contributed to the success of wireless Internet. Mobile platforms such as the Snapdragon™ processor have special hardware and software capabilities to make acquisition, processing and rendering of multimedia content efficient and cost-effective. 

In this course, you will learn the principles of video and audio codecs used for media content in iTunes, Google Play, YouTube, Netflix, etc.  You will learn the file formats and codec settings for optimizing quality and media bandwidth and apply them in developing a basic media player application. 

Learning Goals: After completing this course, you will be able to:

1.	Explain the tradeoffs between media quality and bandwidth for content delivery. 
2.	Extract and display metadata from media files.
3.	Implement and demonstrate a simple media player application using DragonBoard™ 410c.
      


          Introduction
    -Welcome to the Internet of Things! Before diving into this course give us a chance to let you know what it is all about! We will walk you through a module by module outline that will give you highlights on the interesting aspects of the course.

Terminology/Cheat Sheet (Beginner)
    -In this course, you will see a lot of new words and acronyms you might not be familiar with. If you feel comfortable with your knowledge of tech terminology, feel free to skip these lessons since they will not affect the overall integrity of the course. If you see something that you want to know a little more about, feel free to watch the video to gain insight on some basic concepts. We do expect you to know the majority of this material before going into the next module, we would recommend going through the lessons as a quick brush up.

Codecs
    -In this module our esteemed Professor Harinath Garudadri will talk about coders and decoders (Codecs). This will allow us to make better use of our multimedia choices when working with the DragonBoardTM 410c. We want to look at the motivation behind using Codecs, the different ways to take advantage of redundancies when using codecs and finally the ability to take advantage of different receiver / transmitter combinations. If we are able to understand the way that information is sent and received over the data plane we can create and use the right codecs.

Computer Vision and our Application
    -In this module we will talk in depth about computer vision. We will talk about a variety of current applications of computer vision, and brainstorm the future applications you all are capable of making! Ultimately we will set up a computer vision development environment on your Linaro/Debian release capable of creating a wide variety of computer vision projects. By the end of this module we will have built a great basic application in Python, we will add a few features and pass the code on to you! Hopefully this code can serve as a great template for you all to use.",Internet of Things: Multimedia Technologies
https://www.classcentral.com/course/edx-a-level-mathematics-for-year-12-course-2-calculus-newton-s-laws-and-hypothesis-testing-13416,"This course by Imperial College London is designed to help you develop the skills you need to succeed in your A-level mathematics exams. You’ll also be encouraged to consider how what you know fits into the wider mathematical world. Over seven modules, covering an introduction to calculus, Newton’s laws and statistical hypothesis testing your initial skillset will be extended to give a clear understanding of how background knowledge underpins the A -level course. You will investigate key topic areas to gain a deeper understanding of the skills and techniques that you can apply throughout your A-level study. These skills include:

Fluency – selecting and applying correct methods to answer with speed and efficiency
Confidence – critically assessing mathematical methods and investigating ways to apply them
Problem solving – analysing the ‘unfamiliar’ and identifying which skills and techniques you require to answer questions
Constructing mathematical argument – using mathematical tools such as diagrams, graphs, logical deduction, mathematical symbols, mathematical language, data handling, construct mathematical argument and present precisely to others
Deep reasoning – analysing and critiquing mathematical techniques, arguments, formulae and proofs to comprehend how they can be applied




Please see course syllabus via the link.","A-level Mathematics for Year 12 - Course 2: Calculus, Newton’s Laws and Hypothesis Testing"
https://www.classcentral.com/course/edx-plato-socrates-and-the-birth-of-western-philosophy--8109,"This philosophy course explores the origins of Western philosophy – a rich tapestry of ideas that began with the most noted ancient Greek and Roman philosophers.
By examining the work of these historic figures, students will attain a strong grasp of Western philosophy’s basic spirit. In doing so, they’ll cultivate deeper thinking abilities, explore noble values, and learn to contemplate the world around them in new ways.
本课程面向各专业本科生，通过课堂讲授与课外阅读讨论的方法，把握古希腊罗马哲学家丰富的思想，探讨哲学精神的起源，揭示古希腊民族的精神取向，阐明古希腊民族思维方式的特征，帮助学生把握哲学的基本精神，养成理论思维的能力，培养高尚的情操，提高人文素质。



Week 1: Introduction (Part I): Philosophy, Religion and Culture
1. Philosophy

Etymology
Definition
The history of philosophy 

2. Religion

Definition
Factors
The relationship with philosophy 

3. Culture

Definition
Axial Period
The spirit of philosophy

Week 2: Introduction (Part II): A Sketch of Ancient Greek Philosophy
1. The setting of the birth of Greek Philosophy

Geography and history
Races and language
Religions and society

2. Periods and schools

The early period
The classical period
The late period 

3. The termination of Ancient Greek Philosophy

Fading
Sublating
Realistic significance

Week 3: Seeking “ shi ”（是）- The Sprout of Rationality
1. A transition to rational thinking

A primitive thinking
A child-state thinking
A poetic metaphysics

2. Heraclitus’ thinking

A dipolar thinking
The features of Heraclitus’ thinking
An analysis to the fragments of Heraclitus’ texts

3. Parmenides’ thinking

A long poem written by Parmenides（on being or “be”）
Rational argument
Evaluation criteria for the birth of philosophy

Week 4: Seeking “ben”（本）- Ontology & Metaphysics, Synopsis of Lecture IV
1. Seeking the origin: the early philosophers

A lexical meaning
An essential question
What is the essence

2. Seeking the essence: Plato’s theory of Form

The allegory of sun
The divided line
The allegory of the cave

3. Seeking to on : Aristotle’s ontology and metaphysics

A lexical meaning
Metaphysics
The First Philosophy

Week 5: Seeking “ zhi ”（知）- The Ancient Epistemology
1. The lexical meaning

The connotation of Chinese character
A corresponding Greek word
Equivalent to wisdom

2. Epistemology

Plato
Cicero
Augustine

3. The features

The objectification of knowledge
Priori
Knowability

Week 6: Seeking “ zhen ”（真）- Methodology & Logic
1. A lexical meaning

True and truth
Two types of reality
Truth and Logos 

2. Plato’s Dialectics（authentic true）

The implication of epistemology
The implication of methodology
The implication of ontology

3. Aristotle’s Logics（judging true）

Establishment
The name of logics
The Chinese translation

Week 7: Seeking “ shi ”（实）- Natural Sciences
1. A lexical meaning

Science
Nature and knowledge
Natural sciences

2. The occurrence and development of the ancient Greek Science

The reason for occurrence
Nature-ology
Practice and theory

3．The technicalization and application of ancient Greek Science

The Hellenization Period
The Roman Empire Period
Some reflections

Week 8: Seeking “mei”（美）- Odes to the Love
1. A Lexical meaning

Beauty
Love
Aesthetics

2. Plato’s theory of Love

The essence and principle of love
A psychological view on love
Platonic Love

3. The high praise to the love god: A reading on Symposi um

A brief introduction
Six viewpoints
Conclusion, philosophy of love

Week 9: Seeking “ shan ”（善）- An Ethical Thought
1. A lexical analysis

Goodness
The ultimate goodness
Ethics

2. The development of the Classic Greek Ethics

The early period
The middle period
The late period

3. From the ultimate goodness to the common goodness

To reach the ultimate goodness
To converge to the common goodness
Some reflection on the goodness

Week 10: Seeking “ ren ”（仁）- A Humanism
1. A lexical meaning

A man with benevolence is a true man
Humanistic
Humanistic spirit

2. Ancient humanistic trend of thoughts

Traditional viewpoints
Social setting
The sophistic movement

3. A theoretical summary 
Week 11: Seeking “ yi ”（义）- On Justice
1. A lexical analysis

Justice and righteousness
Chinese words
Justice in Greek

2. The story of Gyges

A synopsis of the story
An explanation
A conclusion

3. The Ancient theory of justice

Plato’s essential justice
Cicero’s natural justice
Augustine’s justice in theodicy 

Week 12: Seeking “ li ”（礼）- States and Legislation
1. An explanation to the related words.

Physis
Normos
Politeia

2. A Platonic Republic

The influence from Socrates
Rule the state by virtues
Rule the state by law

3. Cicero’s people’s Republic

Being relevant to Plato’s thoughts
Definition of state
Natural law

Week 13: Seeking “ fu ”（福）——A Spirit of Religions
1. A lexical analysis

Blessings
Fortunate
The true fortunate

2. The religious trends in the late period of ancient Greek philosophy

The fading of the traditional religions
The birth and development of Christianity
The rationalization of Christianity

3. The collision between faith and reason (Tertullian) 
Week 14: Seeking “ sheng ”（圣） - Communion with gods
1. An explanation to the related words.

Sacredness
Mystery
Mysticism 

2. Communion with gods.

Communion with gods by rituals
Communion with gods by ration
Communion with gods by ecstasy

3. Plotinus’ mystical system of thoughts 
Week 15: A General Summary - A Basic Spirit of the Ancient Greek Philosophy, Synopsis of Lecture XV.
1. The local characteristics of the ancient Greek Philosophy.
2. The progressive universalization of the ancient Greek Philosophy.
3. The basic spirits of the ancient Greek Philosophy.","Plato, Socrates, and the Birth of Western Philosophy | 西方哲学精神探源"
https://www.classcentral.com/course/edx-come-fare-ricerca-nelle-scienze-sociali-12124,"Per fare questo occorre capire l'importanza della metodologia della ricerca, non sempre immediatamente evidente a chi si trova a leggere un saggio sociologico, né tanto meno ai giovani che intraprendono un percorso di studio nel campo delle scienze sociali. Il corso, dunque, affronta il tema della logica del metodo scientifico e della sua applicazione nelle scienze sociali. L'obiettivo è di consentire agli studenti di impostare e condurre correttamente il lavoro di indagine empirica, nonché di orientare la scelta degli strumenti di raccolta dati in relazione ai diversi tipi di ricerca, fornendo indicazioni circa la loro costruzione e somministrazione. Il corso comprende anche una introduzione alle tecniche di analisi statistiche con cui è possibile trovare risposte agli interrogativi iniziali formulati in sede di disegno
della ricerca. 
To achieve this, we need to understand the importance of research methodology, and this is not immediately obvious to people reading a sociology book, or even to students starting their Social Sciences course. This MOOC, therefore, looks at logic and the scientific approach and how it is applied to the Social Sciences. The objective is to enable students to learn how to set up and implement an empirical study, including the right choice of instruments for data collection according to the specific study, and how to construct and administer them. The course also provides an introduction to statistical analysis which enables us to answer the questions that were set when the research was designed.



            Read more",Come fare ricerca nelle scienze sociali
https://www.classcentral.com/course/graph-analytics-4249,"Want to understand your data network structure and how it changes under different conditions? Curious to know how to identify closely interacting clusters within a graph? Have you heard of the fast-growing area of graph analytics and want to learn more? This course gives you a broad overview of the field of graph analytics so you can learn new ways to model, store, retrieve and analyze graph-structured data.

After completing this course, you will be able to model a problem into a graph database and perform analytical tasks over the graph in a scalable manner.  Better yet, you will be able to apply these techniques to understand the significance of your data sets for your own projects.
      


          Welcome to Graph Analytics
    -Meet your instructor, Amarnath Gupta and learn about the course objectives.

Introduction to Graphs
    -Welcome! This week we will get a first exposure to graphs and their use in everyday life.  By the end of the module you will be able to create a graph applying core mathematical properties of graphs, and identify the kinds of analysis questions one might be able to ask of such a graph.  We hope the you will be inspired as to how graphical representations might enable you to answer new Big Data problems!

Graph Analytics

Graph Analytics Techniques
    -Welcome to the 4th module in the Graph Analytics course. Last week, we got a glimpse of a number of graph properties and why they are important. This week we will use those properties for analyzing graphs using a free and powerful graph analytics tool called Neo4j. We will demonstrate how to use Cypher, the query language of Neo4j, to perform a wide range of analyses on a variety of graph networks. 

Computing Platforms for Graph Analytics
    -In the last two modules we have learned about graph analytics and graph data management. This week we will study how they come together. There are programming models and software frameworks created specifically for graph analytics.  In this module we'll give an introductory tour of these models and frameworks.  We will learn to implement what you learned in Week 2 and build on it using GraphX and Giraph.",Graph Analytics for Big Data
https://www.classcentral.com/course/wireless-communications-7503,"This course will provide an introduction and history of cellular communication systems that have changed our lives during the recent four decades and will become an essential and inseparable part of human life. The principles of wireless communication theory are covered with emphasis on the essential concept delivery to non-major learners in the easiest way. Then, it will be covered how such principles are realized and how multimedia services can be delivered in practical LTE cellular systems by which learners are connected and enjoys together in their lives.

After completing this course, learners will be able to understand
1. What a cellular system is and how it has been developed so far 
2. The very basic principles how information can be delivered efficiently using radio
3. How such principles are realized in LTE systems.
4. How people can be connected and multimedia services can be delivered in LTE systems
      


          Introduction and History of Cellular Communication Systems
    -In this part of the course, we will learn the introduction and history of cellular communication system. First, we will take a example of cellular communication system with cell phone. And then, learn about the what a cellular system is and how it has been developed so far. Lastly, we will briefly look into the concepts of future cellular systems.

Principles of Wireless Communication Theory
    -In this part of the course, we will learn the fundamental principles of wireless communication theory. I will raise five fundamental questions in the first lecture as follows: i) 'how can we represent information into a binary format?', ii) 'how can information be transferred?', iii) 'how does wireless digital MODEM work?', iv) 'how can high-rate data be delivered reliably?', and v) 'how can many users access simultaneously?'. During the following 5 lectures, you will have the answers.

Principles of Wireless Resource Management
    -In this part of the course, we will discuss the basic concept of wireless resource management. I will raise six interesting questions as follows: i) 'how does the interference affect the capacity of wireless networks?', ii) 'why does the cellular system look like as of today?', iii) 'Increasing the number of cells increases the capacity?', iv) 'how is 5G cellular being shaped?', v) 'how does the interference management increase the capacity?' and Ⅵ) 'how does scheduling increase the average capacity?'.

Multiple Antenna Technologies
    -In this part of the course, we will learn how multiple antennas can be efficiently used in different strategies for communication system enhancement. First, we look in to the basics of antenna, and then learn about the three main gains that are achievable by multiple antennas: array, diversity, and spatial multiplexing. Lastly, we briefly look in to the concepts of single-user MIMO and multi-user MIMO.

Physical Layer Design of LTE systems
    -In this part of the course, we will learn how the fundamental principles of wireless communication theory, resource management, and multiple antenna technology are implemented in the LTE system. 

LTE Cellular Networks and Services
    -In this course, we will discuss LTE cellular networks.",Wireless Communications for Everybody
https://www.classcentral.com/course/swayam-health-research-fundamentals-5218,"National Institute of Epidemiology [NIE], Indian Council of Medical Research [ICMR] is offering online programmes on conduct of human bio-medical research. The programme will be offered as NIE-ICMR e-Certificate – NIeCer - Courses. The first in this series, NIeCer 101:Health Research Fundamentals, is a basic level course in health research methods. It will explain the fundamental concepts in epidemiology and bio-statistics related to research methods. This course will provide an overview of steps and principles for designing bio-medical and health research studies among human participants. We expect this course to be useful for individuals interested in pursuing health research in the roles of study investigators, clinical/public health researchers (physicians, counselors, research associates, social scientists, nurses, pharmacists, technicians, data and quality managers etc.), scientists, ethics committee members and project managers.INTENDED AUDIENCE : Any current or potential health researcherPRE-REQUISITES : Undergraduate students in medical/dental/nursing/AYUSH streamsGraduate in any disciplineINSTITUTIONS SUPPORT : Government/ private sector, public health service institutions/ agencies, Post graduate institutions in biomedical and allied sciences, Medical colleges/ Universities, NGOs engaged in health research, Clinical research organizations, Pharma companies and marketing research organizations 
      


COURSE LAYOUT Week 1: Conceptualizing a research study Introduction to health research – Dr. Sanjay Mehendale Formulating research question, hypothesis and objectives – Dr. P Manickam Literature review – Dr. P GaneshkumarWeek 2: Epidemiological considerations in designing a research study (1/2) Measures of disease frequency - Dr. R Ramakrishnan Descriptive study designs - Dr. Prabhdeep Kaur Analytical study designs - Dr. Manoj MurhekarWeek 3: Epidemiological considerations in designing a research study (2/2) Experimental study designs: Clinical trials - Dr. Sanjay Mehendale Validity of epidemiological studies - Dr. Tarun Bhatnagar Qualitative research methods: An overview - Dr. Tarun BhatnagarWeek 4: Bio-statistical considerations in designing a research study Measurement of study variables – Dr. R Ramakrishnan Sampling methods – Dr. R Ramakrishnan Calculating sample size and power – Dr. R RamakrishnanWeek 5: Planning a research study (1/2) Selection of study population – Dr. P Ganeshkumar Study plan and project management – Dr. Sanjay Mehendale Designing data collection tools – Dr. Tarun BhatnagarWeek 6: Planning a research study (2/2) Principles of data collection – Dr. Prabhdeep Kaur Data management – Dr. P Manickam Overview of data analysis - Dr. P ManickamWeek 7: Conducting a research study Ethical framework for health research – Dr. Sanjay Mehendale Conducting clinical trials - Dr. Sanjay MehendaleWeek 8: Writing a research protocol Preparing a concept paper for research projects – Dr. P Manickam Elements of a protocol for research studies – Dr. Tarun Bhatnagar",Health Research Fundamentals
https://www.classcentral.com/course/new-technologies-business-leaders-10365,"This introductory course is developed for high level business people (and those on their way) who want a broad understanding of new Information Technologies and understand their potential for business functions (e.g. marketing, supply change management, finance). This is not a course for people looking for guidance on how to become a deep technical expert or implement these technologies.  
From Blockchain over Artificial Intelligence to Virtual Reality technologies: This course will empower business leaders to embrace the concepts and bring the state of the art information technologies into their organizations to improve client and customer engagement and ultimately the bottom line of their businesses. Instead of digital disruption, the new technologies and management methods will become the foundation of a Digital Transformation journey for better customer relationship management and client satisfaction.  
The content is structured in a way that promotes discussions on challenges that business management and marketing functions face due to the rise of new technologies such blockchain, cryptocurrencies, internet of things (IoT), virtual, mixed and augmented reality (VR/AR), artificial intelligence (AI) and big data.  This course will use case studies to explore frameworks, tools, and strategies that are already proven in the real world and prepare ourselves and our organizations to have the tools needed to succeed in a fast and changing world. This course is not a deep technical curriculum, but based on thousands of hours helping (often C-level) executives to grasp the technologies' potential in their own areas of expertise.

This course is available in English.
      


            Read more
          



          INTRODUCTION TO DIGITAL TRANSFORMATION
    -This module will introduce business professionals to the concept and underlying trends of Digital Transformation as they relate to business strategy and especially to customer engagement. Compared to the earlier industrial revolutions, the so called fourth revolution, Digital Transformation, opens opportunities, creates challenges and requires new and creative cross functional collaboration at a much accelerated trajectory.  Business leaders need to have an understanding of Digital Transformation and assess the current state of their companies regarding the use, misuse, or lack of the new technologies. The module provides the comprehensive understanding of the technology driven revolution and frameworks to discuss and implement digital transformation projects that can include VR/AR, Big Data, Artificial Intelligence, the Internet of Things and Blockchain technologies.

AUGMENTED, VIRTUAL AND MIXED REALITY
    -This module discusses Virtual Reality (VR), Augmented Reality (AR) and everything in-between.  We will start by identifying changes in the media market and the impact they had on consumers based on the interaction provided.  We then will explore technologies and buzzwords, and finally, we will look at examples of how these technologies are used in the real world today and discover clues for leveraging them in our own environments. 

INTERNET OF THINGS
    -This module introduces fundamental concepts, terms and technologies behind Internet of Things and how they are being used to improve business processes and specifically marketing and customer retention.  We will demonstrate different applications and products that are leading the market and how marketers can think about this technology as an opportunity to attract and retain customers. The customer journey model will be introduced and used for the IoT scenario as a general tool for leading a digital transformation.

ARTIFICIAL INTELLIGENCE AND BIG DATA
    -This module provides an overview of the key terms and technologies about  “Big Data” and “Artificial Intelligence (AI)” and how these technologies allow new ways of customer engagement and management. ​It promotes a discussion about ethical and moral implications around Artificial Intelligence.  Examples from different industries about the use of big data and AI are provided.

Blockchain technology applications and crypto currencies
    -This module introduces the fundamentals of Blockchain technology, as a key accelerator of the evolving customer engagement including and far beyond the crypto currencies. The module presents practical scenarios by industry and how Blockchain can change current business models to benefit the customer and client relationship and also discuss how Blockchain technology combined with IoT and AI creates synergies for organizations.  Finally, we will provide a list of communities created around Blockchain. ​",New Technologies for Business Leaders
https://www.classcentral.com/course/swayam-introduction-to-remote-sensing-7918,"The proposed course provides basic understanding about satellite based Remote Sensing technology. Presently, remote sensing datasets available from various earth orbiting satellites  are being used extensively in various domains including in civil engineering, water resources, earth sciences, transportation engineering, navigation etc. Google Earth has further made access to high spatial resolution remote sensing data available to non-experts with great ease.



Introduction to Remote Sensing
About the courseThe proposed course provides basic understanding about satellite based Remote Sensing technology. Presently, remote sensing datasets available from various earth orbiting satellites  are being used extensively in various domains including in civil engineering, water resources, earth sciences, transportation engineering, navigation etc. Google Earth has further made access to high spatial resolution remote sensing data available to non-experts with great ease.Intended audienceIt is an Elective Course for Under graduate engineering and post graduate science students.Pre-requisitesCurrent students of engineering students and current post graduate science students.Industries that will recognize this courseGeoinformatics companies, e.g NIIT, ESRI India, Leica Geoinformatics, MapmyIndia etc.






 
Course InstructorDr. Arun K. Saraf is Ph. D. (Remote Sensing) from University of Dundee, United Kingdom. Presently he is working as Professor in the Department of Earth Sciences, Indian Institute of Technology, Roorkee, and teaches courses on Geographic Information Systems (GIS), Advanced GIS, Remote Sensing, Geomorphology etc. to under- and post-graduate students of Geological Technology and Applied Geology. He was also Head of Department of Earth Sciences between Jan. 2012 – Feb. 2015. He was first in the country to introduce GIS course to post-graduate students in the year 1990. In 1986, he was awarded “National Fellowship to Study Abroad” by Govt. of India for his doctoral degree. Further, in 1993 he was awarded “Indo-US S&T Fellowship” and worked in Goddard Space Flight Centre, NASA, USA for Post Doctoral Research. He has been also awarded “National Remote Sensing Award-2001” by Indian Society of Remote Sensing and “GIS Professional of the Year Award-2001” by Map India 2002 for his outstanding research contributions in the fields of Remote Sensing and GIS. Earlier, he has also been given several Khosla Research Awards and Prizes by then University of Roorkee. So far Prof. Saraf has published more than 100 research papers in journals of repute (ISI) and supervised 11 Ph.Ds. He was also Associate Editor of International Journal of Remote Sensing during 2003-2015. Through funding from DST, Min. of Earth Sciences, CSIR, Prof. Saraf has been able to establish and operating NOAA-HRPT Satellite Earth Station at IITR since Oct. 2002, first in any educational institute in the country. This Earth Station is still operational and acquiring data from NOAA-18 & 19 day-and-night.Course Plan
Week-1 :
 
What is satellite based remote sensing?
Development of remote sensing technology and advantages.
Different platforms of remote sensing.
EM spectrum, solar reflection and thermal emission remote sensing.
Interaction of EM radiation with atmosphere including atmospheric scattering, 
absorption and emission.
 
Week-2 :
 
Interaction mechanisms of EM radiation with ground, spectral response curves.
Principles of image interpretation.
Multi-spectral scanners and imaging devices.
Salient characteristics of LANDSAT, IRS, Cartosat, ResourceSat etc. sensors.
Image characteristics and different resolutions in Remote Sensing.
 
Week-3 :
 
Image interpretation of different geological landforms, rock types and structures.
Remote Sensing integration with GIS and GPS.
Georeferencing Technique.
Basic image enhancement techniques.
Spatial filtering techniques.
 
Week-4 :
 
Image classification techniques.
InSAR Technique and its applications.
Hyperspectral Remote Sensing.
Integrated applications of RS and GIS in groundwater studies.
Limitations of Remote Sensing Technique.",Introduction to Remote Sensing
https://www.classcentral.com/course/everyday-chemistry-7435,"##
This free online course explores a range of chemistry-based topics relating to our everyday lives, with an emphasis on the important role of organic chemistry – the study of carbon-containing organic compounds. Activities include experimenting ‘in the kitchen’ with hands-on projects ranging from extracting a plant fragrance, to testing the activity of spices against microbes.
The course will be particularly useful for sixth formers who are interested in developing independent learning skills to help the transition to university.
Use real-life examples to study organic compounds
During each week of the course, we will use real-life examples to show you how an understanding of the structure and shape of organic compounds can be used to explain their reactivity and properties.

Week 1: The chemical attraction of perfumes and pheromones
We’ll identify a range of natural and synthetic attractants; understand current theories that help to explain how chemical structure is related to smell; and make a molecular model.

Week 2: The race for new antibiotics
We’ll describe the mode of action of antibiotics; understand bacterial resistance; identify promising new areas of research to design smarter drugs; and explore pattern recognition in structure-activity relationships.

Week 3: The chemistry of brewing
We’ll describe the process of brewing; identify key flavouring compounds in beer, tea and coffee; understand the role of modern analytical methods; and analyse spectroscopic data.

Week 4: The chemistry of sport
We’ll explore innovations that are changing the game; identify modern materials that improve performance and aid protection; and model the structures of polymers.
Learn with organic chemistry experts from the University of York
The University of York is a centre of excellence in chemical education, being the home of Salters' Advanced Chemistry (Science Education Department), the A-level magazine Chemistry Review, and it has a notable history and track record in outreach, principally by our CIEC group, including The Essential Chemical Industry website.
The course is designed for anyone with an interest in chemistry (a GCSE level of science is recommended), but will be particularly useful for sixth formers to aid the transition to study science at university.
You can use the course to support your UCAS personal statement and prepare for university study, by broadening your chemistry knowledge and developing your independent learning skills.



            Read more",Exploring Everyday Chemistry
https://www.classcentral.com/course/canvas-network-digital-design-with-vhdl-2616,"This course provides basic knowledge about digital design and implementation using VHDL as the description language, as well as skills in the use of computer-based design and simulation tools.



The course is divided into five parts with the following contents:

Introduction to the design of digital electronic systems: Motivation to use hardware description languages, design flow; development tools; types of integrated circuits
Basics of the language VHDL: Code models; component model; gates; entity; architecture; identifier object; variables, signals, data types, operators of relationships
Parallel and sequential processing: Modeling for simulation, simulation cycle, parallel and sequential sets; instantiation of components
Construction of combinatorial logic: Timing and delays in digital circuits; hazard; arithmetic units; ROM; design example
Design of sequential logic: Timing of synchronous systems; synchronous processes; latches; flip-flops; initialization; Mealy and Moore machines; counters; registers; RAM",Digital Design with VHDL
https://www.classcentral.com/course/parallel-programming-in-java-8909,"This course teaches learners (industry professionals and students) the fundamental concepts of parallel programming in the context of Java 8. Parallel programming enables developers to use multicore computers to make their applications run faster by using multiple processors at the same time. By the end of this course, you will learn how to use popular parallel Java frameworks (such as ForkJoin, Stream, and Phaser) to write parallel programs for a wide range of multicore platforms including servers, desktops, or mobile devices, while also learning about their theoretical foundations including computation graphs, ideal parallelism, parallel speedup, Amdahl's Law, data races, and determinism.

Why take this course?

•	All computers are multicore computers, so it is important for you to learn how to extend your knowledge of sequential Java programming to multicore parallelism.
•	Java 7 and Java 8 have introduced new frameworks for parallelism (ForkJoin, Stream) that have significantly changed the paradigms for parallel programming since the early days of Java.
•	Each of the four modules in the course includes an assigned mini-project that will provide you with the necessary hands-on experience to use the concepts learned in the course on your own, after the course ends.
•	During the course, you will have online access to the instructor and the mentors to get individualized answers to your questions posted on forums.

The desired learning outcomes of this course are as follows:

•	Theory of parallelism: computation graphs, work, span, ideal parallelism, parallel speedup, Amdahl's Law, data races, and determinism
•	Task parallelism using Java’s ForkJoin framework
•	Functional parallelism using Java’s Future and Stream frameworks
•	Loop-level parallelism with extensions for barriers and iteration grouping (chunking)
•	Dataflow parallelism using the Phaser framework and data-driven tasks

Mastery of these concepts will enable you to immediately apply them in the context of multicore Java programs, and will also provide the foundation for mastering other parallel programming systems that you may encounter in the future  (e.g., C++11, OpenMP, .Net Task Parallel Library).
      


            Read more
          



          Welcome to the Course!
    -Welcome to Parallel Programming in Java! This course is designed as a three-part series and covers a theme or body of knowledge through various video lectures, demonstrations, and coding projects.

Task Parallelism
    -In this module, we will learn the fundamentals of task parallelism. Tasks are the most basic unit of parallel programming. An increasing number of programming languages (including Java and C++) are moving from older thread-based approaches to more modern task-based approaches for parallel programming. We will learn about task creation, task termination, and the “computation graph” theoretical model for understanding various properties of task-parallel programs.  These properties include work, span, ideal parallelism, parallel speedup, and Amdahl’s Law. We will also learn popular Java APIs for task parallelism, most notably the Fork/Join framework.

Functional Parallelism
    -Welcome to Module 2!  In this module, we will learn about approaches to parallelism that have been inspired by functional programming.  Advocates of parallel functional programming have argued for decades that functional parallelism can eliminate many hard-to-detect bugs that can occur with imperative parallelism.  We will learn about futures, memoization, and streams, as well as data races, a notorious class of bugs that can be avoided with functional parallelism.  We will also learn Java APIs for functional parallelism, including the Fork/Join framework and the Stream API’s.

Talking to Two Sigma: Using it in the Field
    -Join Professor Vivek Sarkar as he talks with Two Sigma Managing Director, Jim Ward, and Software Engineers, Margaret Kelley and Jake Kornblau, at their downtown Houston, Texas office about the importance of parallel programming.

Loop Parallelism
    -Welcome to Module 3, and congratulations on reaching the midpoint of this course!  It is well known that many applications spend a majority of their execution time in loops, so there is a strong motivation to learn how loops can be sped up through the use of parallelism, which is the focus of this module.  We will start by learning how parallel counted-for loops can be conveniently expressed using forall and stream APIs in Java, and how these APIs can be used to parallelize a simple matrix multiplication program.  We will also learn about the barrier construct for parallel loops, and illustrate its use with a simple iterative averaging program example.  Finally, we will learn the importance of grouping/chunking parallel iterations to reduce overhead.

Data flow Synchronization and Pipelining
    -Welcome to the last module of the course!  In this module, we will wrap up our introduction to parallel programming by learning how data flow principles can be used to increase the amount of parallelism in a program.  We will learn how Java’s Phaser API can be used to implement “fuzzy” barriers, and also “point-to-point” synchronizations as an optimization of regular barriers by revisiting the iterative averaging example.  Finally, we will also learn how pipeline parallelism and data flow models can be expressed using Java APIs.  

Continue Your Journey with the Specialization ""Parallel, Concurrent, and Distributed Programming in Java""
    -The next two videos will showcase the importance of learning about Concurrent Programming and Distributed Programming in Java. Professor Vivek Sarkar will speak with industry professionals at Two Sigma about how the topics of our other two courses are utilized in the field.",Parallel Programming in Java
https://www.classcentral.com/course/opensap-sap-cloud-platform-essentials-8945,"SAP Cloud Platform is the enterprise platform-as-a-service, with comprehensive application development services and capabilities. It enables customers to achieve business agility, create a truly integrated and optimized enterprise, and accelerate digital transformation across the business – all without the requirement of maintaining or investing in on-premise infrastructure.

Since its introduction in 2012, SAP Cloud Platform has been continually improved and additional functionality has been delivered. In this basics course, you’ll get an overview of the platform in its most up-to-date state yet, including the Cloud Foundry-based offering.

In week 1, we’ll start with a theoretical introduction to SAP Cloud Platform, its value proposition and use cases. We’ll also cover its architecture, capabilities, and data center strategy. This part of the course is especially interesting for IT decision makers, but should also be valuable for application developers and operation experts as it provides a broad understanding of the platform. In the following weeks, we’ll go deeper into applications, persistence, connectivity, and security, with theory and practice. In the final week, we’ll cover the IoT and Mobile Services offering, as well as the new services for Workflow and Business Rules.

This course is applicable to learners with all levels of knowledge about SAP Cloud Platform. Even if you’ve joined a previous version of this course or other courses about SAP Cloud Platform before, this course should be interesting for you because for the first time, it also covers our Cloud Foundry-based offering, as well as some new services like the offering for Workflow and Business Rules.

The registration, learning content, and final exam are free of charge. You’ll be able to get some practical experience of the platform by using a free trial account. We’ll explain how you can access this at the start of the course.
      


            Read more
          



Week 1: OverviewWeek 2: ApplicationsWeek 3: PersistenceWeek 4: ConnectivityWeek 5: SecurityWeek 6: Additional ServicesWeek 7: Final Exam",SAP Cloud Platform Essentials
https://www.classcentral.com/course/spacebooks-4103,"Since the invention of the telescope in 1608, outer space has been turned into an abode, a place scientific speculation and literary imagination could thrive on simultaneously. The human mind was sent on a journey to visit other planets – and time after time it returned from there with breathtaking news, disturbing images or philosophical insight. And, of course, with a lot of questions: Why funeral customs on the Moon include cannibalism and orgies? Is it true that the people of Mars do live according to higher moral standards than we do? And where does this weird alien obsession with terrestrial paper actually come from?These are some of the questions we will be addressing within this course. Moreover, we will watch the birth of the alien reader, we will explore the logics of space invasion and the history of space colonies well. We will examine the inventory of extraterrestrial libraries and survey the competing projects of galactic encyclopedias. Next to well-known authors as Kepler, Cyrano de Bergerac, Stapledon or Lem, you will also be introduced to neglected and forgotten texts. Finally, we might even understand how literature itself was transformed by this journey throughout the universe – and how it finally became a true interstellar medium.The soundtrack to this MOOC will be provided by Swiss artists Bit-Tuner and Darkspace.Keywords: Science Fiction, Sci-Fi, Extraterrestrial Literature, Spacebooks  



            Read more
          



INTRODUCTION: WHAT IS EXTRA-TERRESTRIAL LITERATURE?Main Source: Jonathan Swift, Travels into Several Remote Nations of the World. In Four Parts. 
By Lemuel Gulliver, First a Surgeon, and then a Captain of Several Ships (1727), Part III, Chapters 1-3.MODULE I: CONSTRUCTING OTHER WORLDSLearning objective: Literature is not a interstellar medium of a second
order, but organizes outer space as we see it.Main Source: Johannes Kepler, The dream, or a lunar astronomy (1609/1634)
Lesson 1: The Book And The Telescope - Kepler vs. GalileiLesson 2: The Demon And The Mind's Eye - Kepler's ""Dream""MODULE II: TRAVELLING THE EARLY MODERN COSMOSLearning objective: The early-modern age reflects interstellar
travelling as a journey made possible by literature and literary imagination.Main Sources: Francis Godwin, The Man in the Moone (1629/1638)  / Cyrano de Bergerac, The Other World: Comical History of the States and Empires of the Moon (1657) Lesson 3: Godwin or The Secret Passage Of FantasyLesson 4: Cyrano or The Universe As A Literary MarketMODULE III: THE 18TH CENTURY ALIEN
Learning objective: The idea of an inhabited solar system evokes a
cosmical hierarchy of morals.  

Main Sources: Eberhard Christian Kindermann, The Speedy Journey (1744) / Immanuel Kant, Universal Natural History and Theory of Heaven (1755), Part Three, paragraphs 1-12 / Emanuel Swedenborg, Earths In The Universe (1758), Passages 27-29.Lesson 5: The Golden Chain Of The Cosmos - Kindermann's Trip To The Martian MoonLesson 6: Kant, Swedenborg, And The Nature Of The Alien ReaderMODULE IV: READING MARSLearning objective: The Age of the Martians is linked to the galactic
expansion of evolutionary theory.
Main Sources: Kurd Lasswitz, Two Planets (1897) / H.G. Wells, The Crystal Egg (1897)  Lesson 7: The Canals or The Rise (And Fall) Of Martian UtopiaLesson 8: Colonizing Earth, Colonizing MarsMODULE V: CULTURE INDUSTRY AND THE 20th CENTURY ALIEN Learning objective: The organization of Space Fiction in magazines shapes the perception of the genre - and the perception of its consumers as well, including sexual stereotypes. While the superficial
notion of space fiction registers a vivid tradition of sexist clichés, outer
space is in fact a fertile ground for diversive concepts of sexual identity.Main Sources: Pulp / Donna Haraway, Monkeys, Aliens, and Women: Love, Science, and Politics at the Intersection of Feminist Theory and Colonial Discourse(1989)Lesson 9: The Cosmos Of PulpLesson 10: The Gender Of SpaceMODULE VI: EMPIRE - OUTER SPACE AS A POLITICAL BATTLEGROUNDLearning objective: As outer space becomes an arena of political
conflicts, wars become an integral element of space fiction. However: The emergence of the Galactic Empire shows us that space politics have less to do with enemies and warfare than with control and communication. Main Sources: Robert A. Heinlein, Starship Troopers (1959) / Frank Herbert, Dune (1965) Lesson 11: Empire As A Drug - Frank Herbert's DuneLesson 12: Empire As A Suit - Robert A. Heinlein's Starship troopersMODULE VII: EXTRA-TERRESTRIAL LIBRARIESLearning objective: Organizing cosmic knowledge is not longer a
bureaucratic task, but a story in itself, a turning point in literary
consciousness.

Main Sources: Ludovico Ariosto: Orlando Furioso (1516), Canto 34 / Isaac Asimov, Foundation (1942-1950) / Douglas Adams, The Hitchhiker's Guide to the Galaxy (1978-1980)Lesson 13: The DumpLesson 14: The ArchiveMODULE VIII: POST-TERRESTRIAL LITERATURELearning objective: Despite being confronted with »true« interstellar
media, literature finds its place in an earthless universe. 
Main Source: Philip K. Dick, Do Androids Dream of Electric Sheep? (1968) / Carl Sagan, Contact (1985) / Reinhard Jirgl, Nichts von Euch auf Erden/Deserted Earth (2013) / Christopher Nolan, Interstellar (2014)Lesson 15: Books Vs. Signals or The End Of Human Totalitarianism Lesson 16: Man Beyond Earth, Books Beyond Man",Spacebooks. An Introduction To Extraterrestrial Literature
https://www.classcentral.com/course/edx-microsoft-enterprise-mobility-suite-4100,"Users expect to be productive across a variety of device types, with access to the applications they need. The phrase “work from anywhere” has evolved throughout the years and these days working from anywhere is the norm for many industries. So much so that “working anywhere and from any device” has become the new reality for most enterprises.
But it was only when companies set off understanding the value of cloud computing—particularly as it related to how they could leverage its resources to be more agile and to reduce costs—that they also discovered their users were already consuming cloud resources on their own devices.
This course will prepare you to use Microsoft Enterprise Mobility Suite (EMS) to solve the unique challenges your organization is facing today—and to plan ahead for your organization’s long-term success. Starting with enabling hybrid identity, you will quickly learn how to secure corporate data access, protect your employees’ personal information, and manage iOS, Android, and Windows devices. With this introduction to the EMS, you will be guided through the process of implementing EMS to support Mobile Device Management (MDM) of both company-owned devices and personally-owned devices in your enterprise environment.
Using a combination of MDM scenarios and, you will obtain a working knowledge of the independent technologies that make up EMS:

Microsoft Azure AD Premium
Azure Rights Management Services (RMS)
Microsoft Intune

Module 1 introduces you to the four elements (users, devices, apps, and data) involved in any enterprise mobility strategy. These basic elements are used as examples throughout the course. Knowing that the core of any enterprise mobility solution must include these elements will make it easier for you to understand how EMS can enable organizations to embrace a mobile workforce.
This course takes you through:

Module 1: Understanding Enterprise Mobility Suite
Module 2: Cloud Identity with Azure AD Premium
Module 3: Directory Synchronization
Module 4: Implementing Device Enrollment and Management
Module 5: Data Access and Protection

The target audience for this course is comprised of enterprise IT Pros who are either tasked with implementing EMS for their organizations or just want to learn more about the technologies included in EMS. While it is not possible to cover every nuance of the technologies included in EMS in a single course, we have included content that will provide you with the solid foundation you will need as you embark on your own EMS implementation.



            Read more",Microsoft Enterprise Mobility Suite
https://www.classcentral.com/course/edx-a-level-mathematics-for-year-12-course-1-algebraic-methods-graphs-and-applied-mathematics-methods-12873,"This course by Imperial College London is designed to help you develop the skills you need to succeed in your A-level maths exams.You will investigate key topic areas to gain a deeper understanding of the skills and techniques that you can apply throughout your A-level study. These skills include:

Fluency – selecting and applying correct methods to answer with speed and efficiency
Confidence – critically assessing mathematical methods and investigating ways to apply them
Problem solving – analysing the ‘unfamiliar’ and identifying which skills and techniques you require to answer questions
Constructing mathematical argument – using mathematical tools such as diagrams, graphs, logical deduction, mathematical symbols, mathematical language, construct mathematical argument and present precisely to others
Deep reasoning – analysing and critiquing mathematical techniques, arguments, formulae and proofs to comprehend how they can be applied

Over seven modules, your initial skillset will be extended to give a clear understanding of how background knowledge underpins the A -level course. You’ll also be encouraged to consider how what you know fits into the wider mathematical world.
      


Module 1  Indices and Surds

Recognise and use the laws of indices for all rational exponents
Use and manipulate surds, including rationalising the denominator
Solve a variety of problems that include surds and indices

Module 2  Inequalities

Solve linear and quadratic inequalities in a single variable and interpret these solutions graphically
Express the solutions to linear and quadratic inequalities usingnumber lines and inequality notation, and using the terms ‘and’and ‘or’and set notation
Represent linear and quadratic inequalities in two variables graphically, using standard A-level conventions

Module 3  The Factor Theorem & Algebraic Division

Manipulate polynomials algebraically, using the factor theorem to write a polynomial as the product of linear factors or a combination of linear and quadratic factors
Divide one polynomial by another of a lower order by equating coefficients

Module 4  Coordinate Geometry 

Solve problems using the coordinate geometry of the circle
Complete the square to find the centre and radius of a circle from its equation
Solve problems using the properties of the angle in a semicircle, the perpendicular from the centre to a chord, and a tangent from a poin

Module 5  Graphical Transformation and Curve Sketching

Use curve sketching techniques based on the the shapes and symmetries of standard curves
Identify key features of a curve from its equation and transform the equations of linear, quadratic, rational and trigonometrical curves using translations, rotations and stretches
Use knowledge of the symmetry and asymptotes of standard curves to create sketches

Module 6  An Introduction to Mechanics 

Interpret and accurately use the term distance, speed, displacement, velocity, and acceleration
Interpret graphs to do with speed against time, distance against time, velocity against time and acceleration against time, and solve problems involving motion in a straight line with constant acceleration
Apply the formulae for constant acceleration to solve problems involving motion in a straight line

Module 7  An Introduction to Statistics

Identify the ideas of a population and a sample and use simple sampling techniques to draw informal inferences about populations
Apply critical thinking to issues of representative sampling
Interpret histograms to draw informal inferences about univariate data
Interpret scatter diagrams, regression lines and the ideas of correlation to draw informal inferences about bivariate data","A-level Mathematics for Year 12 - Course 1: Algebraic Methods, Graphs and Applied Mathematics Methods"
https://www.classcentral.com/course/watershed-1367,"Watershed education is an excellent way to introduce students to rich, interdisciplinary studies of one of the most important resources located in students’ backyards—water! The goal of the course is to increase your content knowledge on watershed topics and to help you develop outdoor learning experiences for your students.In this course you will:Increase literacy around watershed issuesPrepare to implement watershed content using engaging and effective instructional strategies in the classroom and on the school groundsShare and reflect on your practice in a collaborative online environmentThe course is designed for science and social studies teachers in grades 4 through 8. No prior knowledge is required. Teaching experience and access to students in a classroom is recommended.Montana pre-service and in-service classroom educators only may apply for undergrad and graduate credits from the University of Montana. Check here for more information.



Session 1: Introduction to Geo-literacyGoal: Explain the importance of geo-literacy for science and social studies classrooms.Session 2: The Water Cycle and WatershedsGoal: Develop an understanding of the water cycle and how it operates within a watershed.Session 3: Mapping WatershedsGoal: Develop an understanding of how to use GIS and mapping in the classroom.Session 4: Water Quality and Watershed HealthGoal: Develop an understanding of how to determine the health of a watershed based on water quality parameters.Session 5: Outdoor Learning ExperiencesGoal: Understand the importance of outdoor education to promote student connections with the environment and community.Session 6: Small Actions (local) Contribute to Big Solutions (global)Develop an understanding of how integration of watershed education, outdoor education, and geo-education in classroom instruction can help the learners prepare young people to become geo-literate.Course ProjectThe course project consists of developing an action plan to incorporate watershed and outdoor education in their classroom. In this action plan, learners will develop or adapt an outdoor activity that aligns to the curriculum they teach and the geo-literacy framework (the 3 I’s: interactions, interconnections, implications).In Sessions 1-4: Learners develop an action plan using Action Plan Template and the Action Plan Rubric.In Session 4:  Learners submit a draft of this plan.In Session 5: Learners provide feedback, using the Action Plan Rubric, to two of their peers’ drafts and perform a self-assessment of their project. In Session 6: Learners incorporate their peers’ feedback, and submit their final action plan for their peers to review in the “Course Project Gallery” discussion forum. Learners will also provide final feedback to at least three of their peers’ final plans.",FLOW Education: Facilitating Learning through Outdoor Watershed Education
https://www.classcentral.com/course/edx-m-a-free-cash-flow-fcf-modeling-3834,"One of the primary functions of a broker-dealer’s M&A desk is advisory services – consulting clients as they seek to grow through M&A.;
In this course, you will learn to use the Free Cash Flow metric to evaluate acquisition opportunities. You will learn about the components of Free Cash Flow and its relationship with market value. You will also learn about the process of capital budgeting and guidelines to follow.
This course is part of the New York Institute of Finance’s popular Mergers & Acquisitions Professional Certificate program.



Session 1: Introduction to Free Cash Flow and the Objective of the Firm

Lesson 1: Need for Free Cash Flow
Lesson 2: Understanding Free Cash Flow
Lesson 3: Relationship between Free Cash Flow and Market Value
Lesson 4: Return on Investment
Lesson 5: Adjusting Accounting Data to Get to Free Cash Flow
Lesson 6: Components of Free Cash Flow
Lesson 7: Show Me
Lesson 8: Adjustments to Net Investment
Class Exercise 

Session 2: Components of Free Cash Flow

Lesson 1: Focus on Free Cash Flow
Lesson 2: Understanding the Components of Free Cash Flow

Session 3: Cost of Capital

Lesson 1: Understanding Cost of Capital
Lesson 2: CAPM & WACC
Class Exercise 

Session 4: Capital Budgeting Using Free Cash Flow

Lesson 1: Capital Budgeting: Overview
Lesson 2: Guidelines for Capital Budgeting
Lesson 3: Q&A
Lesson 4: Caveats 

Session 5: Modified Free Cash Flow

Free Cash Flow and Interim Financial Results 

Session 6: Using Free Cash Flow to Evaluate Acquisition Opportunities

Lesson 1: Overview
Lesson 2: Acquisition Analysis
Lesson 3: Objective to add Shareholder Value
Lesson 4: Synergies and Integration Costs
Lesson 5: Q&A
Lesson 6: Other Metrics
Class Exercise
Lesson 7: Incentive Compensation 

Session 7: Integration of Acquisitions

Lesson 1: Integration Best Practices
Lesson 2: Integration Planning 

Session 8: Implementation Issues",M&A: Free Cash Flow (FCF) Modeling
https://www.classcentral.com/course/udacity-software-development-process-2335,"This class is offered as CS6300 at Georgia Tech where it is a part of the Online Masters Degree (OMS). Taking this course here will not earn credit towards the OMS degree.In SDP, you will learn how to select and implement the ideal software process for your development project. Through Professor Orso's engaging examples and interviews with industry insiders, you will learn both conceptual and practical aspects of software engineering. The course covers requirements engineering, architecture and design, testing and maintenance, and software quality in general. The goal of this class is to equip you with the skills necessary to define requirements, set up an integrated development environment (IDE), learn Git (and Github!) and use Unified Modeling Language (UML) to design and build an Android application. We will also examine several testing practices and refactoring techniques that are helpful before the launch of your software project. While everyone working with software should have these skills, they are particularly important for Software Engineers and Engineering Managers.Why Take This Course?Software engineering isn’t just about programming. It isn’t just about building a technology stack.This course introduces the idea of software engineering as an iterative, systematic process. You will learn to use Github and Eclipse as you get introduced to the development life cycle, design processes and software testing. Software Development Processes will show you the skills and processes needed to complement technical understanding of software products in order to make you a more effective developer in an engineering team.



            Read more
          



Lesson 1: Introduction and OverviewImportance of Software EngineeringDiscipline of Software EngineeringThe Software CrisisSoftware PhasesLesson 2: Life Cycle ModelsIntroduction with Barry BohemRequirements EngineeringDesignMaintenance Software Process Model IntroductionWaterfall ProcessSpiral ProcessEvolutionary Prototyping ProcessRational Unified Process Agile ProcessChoosing a ModelLifecycle DocumentsLesson 3: Integrated Development EnvironmentEclipse IntroductionIDE OverviewPlug-InsEclipse Demo: Create Java ProjectEclipse Demo: Create a ClassEclipse Demo: Run ConfigurationEclipse Demo: DebuggingLesson 4: Version Control SystemsInterview with John BrittonVersion Control System IntroductionTwo Main Types of VCSIntroduction to GitGit WorkflowGit Demo: Intro to GitGit Demo: Git + EclipseGit Demo: GithubGit Recap: Local RepositoriesGit Recap: Remote RepositoriesLesson 5: Requirements EngineeringInterview with Jane Cleland-HuangGeneral RE DefinitionSoftware Intensive SystemsFunctional and Nonfunctional RequirementsUser and System RequirementsModeling RequirementsAnalyzing RequirementsRequirements PrioritizationRequirements Engineering ProcessLesson 6: OO Software and UMLObject Orientation IntroductionUML Structural Diagrams: Class DiagramsClass Diagram: Creation TipsUML Structural Diagrams: Component DiagramUML Structural Diagram: Deployment DiagramUML Behavioral Diagram: Use CaseUse Case Diagram: Creation TipsUML Behavioral Diagrams: SequenceUML Behavioral Diagrams: State Transition DiagramLesson 7: Software ArchitectureInterview with Nenad Medvidovic What is Software Architecture?Prescriptive vs. Descriptive Architecture Architectural EvolutionArchitectural Degradation Architectural RecoveryArchitectural ElementsComponents, Connectors, and ConfigurationDeployment Architectural PerspectiveLesson 8: A Tale of Analysis and DesignAnalyzing RequirementsRefining Classes and AttributesAdding AttributesIdentifying OperationsRefining the Class DiagramLesson 9: Design PatternsPatterns CataloguePattern FormatFactory Method PatternStrategy PatternChoosing a PatternNegative Design PatternsLesson 10: Unified Software ProcessUse-Case DrivenInception PhaseElaboration PhaseConstruction PhaseTransition PhasePhases and IterationsLesson 11: General ConceptsFailure, Fault and ErrorVerification ApproachesPros and Cons of ApproachesTesting IntroductionTesting Granularity LevelsAlpha and Beta TestingBlack and White Box Testing IntroductionLesson 12: Black-Box TestingSystematic Functional Testing ApproachTest Data SelectionCategory Partition MethodProduce and Evaluate Test Case SpecificationsGenerate Test Cases from Test Case SpecificationsModel Based TestingFinite State MachinesLesson 13: White-Box TestingCoverage Criteria IntroStatement CoverageControl Flow GraphsTest Criteria SubsumptionMC/DC CoverageLesson 14: Agile Development MethodsCost of ChangeAgile Software DevelopmentExtreme Programming (XP)XP’s Values and PrinciplesTest First DevelopmentRefactoringPair ProgrammingContinuous IntegrationTesting StrategyHigh Level Scrum ProcessLesson 15: Software RefactoringReasons to RefactorRefactoring DemoRefactoring RisksCost of RefactoringWhen Not to Refactor",Software Development Process
https://www.classcentral.com/course/edx-engr1-0x-introduction-to-engineering-and-engineering-mathematics-2529,"The goal of this course is to provide high school students and college freshman a broad outline of engineering and help them decide on a career in engineering. The first part of this course is focused on exploring the different disciplines of engineering and providing participants with a broad background in different areas of engineering.
 
Do you want to learn how race-cars are built? How robots are able to work independently? How unmanned vehicles are designed and built? How is energy harvested? How is energy stored? How are organs built? How is the body imaged? How do you design an aircraft? How do electrons travel in micro and nanoelectronics? How are drugs delivered in the body? How do you build on soils that are unstable? How do robots see? How is light used in devices? How is data stored and managed? How is pollution mitigated? How are electrical signals processed? How are strong and tough materials designed and built? How is thermal energy managed? How is data transmitted? How are systems integrated? How do you make sure goods and services reach their destination? How do you start a company? What are the underlying ethical and social responsibilities of being a professional engineer? These are all things that engineers are dealing with on a daily basis and will form the basis of the first part of the course.
 Introduction to Engineering Mathematics
 
Mathematics is an integral part of engineering and Engineering Mathematics is the process of applying the principles of mathematics to solve real life engineering problems.  A reference textbook will be used for this part of the course and is entitled “Introductory Mathematics for Engineering Applications” by Kuldip S. Rattan and Nathan W. Klingbeil. Publisher: John Wiley and Sons, ISBN:978-1-118-14180-9.
 
Topics to be covered in mathematics will include: application of algebra in engineering in linear and quadratic equations, trigonometry in motion of robots, application of complex numbers in electrical circuits, use of systems of equations to solve problems in statics, dynamics and DC circuits. Concepts of derivatives will be introduced and its application in engineering problems such as dynamics, electrical circuits and mechanics will be explored. In a similar fashion concepts of integrals will be examined in the context of engineering applications such as statics, dynamics and electrical circuits. The intent of this course is not to establish mastery of mathematics but rather develop an understanding of the role played by mathematics to help solve engineering problems. Participants in this course will have a better understanding of calculus and differential equations and their relevance in solving engineering problems as they progress in their engineering education.Learn more about our High School and AP* Exam Preparation Courses.
      


            Read more",ENGR1.0x: Introduction to Engineering and Engineering Mathematics
https://www.classcentral.com/course/russians-1379,"In the course “Understanding Russians: Contexts of Intercultural Communications"": we will:

1)	Build skills in the analysis of the intercultural communication process using Russian-Western communication as an example.  
2)	Apply the knowledge of interrelations between different contexts of communication (cultural, institutional, professional, social, interpersonal, etc.) to the cultural history and national psychology of Russians.

The purpose of the course is to provide the students with a broad overview of the basic principles governing the past, the present and the future interactions between Russia and the West, with a focus on the culture and national psychology of Russians and Western Europeans.

For example, we will look at the cases when basic cultural values of Russians show up through the linguistic choices shaping language production which is consequently misattributed by Western partners. No matter what the language of intercultural communication is – Russian, or English – the meaning of many linguistic expressions may be reconstructed wrongly by the representatives of another culture.

Some of the basic questions we will tackle are:

•	What are the concepts of culture that have the strongest influence on communication?
•	What are Russian basic cultural values and how they shape modern Russian consciousness?
•	What are the specific communication patterns of modern Russians, including those of public and electronic discourse?
•	What is important to know about communication with Russians in organizational contexts?

Importantly, this course is NOT just a list of practical instructions of dos and don’ts of dealing with Russians. The course contains a substantial academic component introducing the key notions and concepts of the Theory of Communication, which will be extensively introduced throughout the first few modules of the course. These theoretical grounds will be further on used as a tool for analyzing the intercultural communications with Russians.

Do you have technical problems? Write to us: coursera@hse.ru
      


            Read more
          



          Introduction to the Course
    -Dear Student, welcome to the first module of the course ""Understanding Russians: Contexts of Intercultural Communication""! My name is Mira Bergelson and I will teach this class, assisted by Yulia Badryzlova, Tatiana Golubeva and the team of Coursera and HSE technical specialists. Thanks for joining us and for your interest in the Russian communication patterns. 

Intercultural Communication as an Academic Discipline
    -We want this course to be not only a learning experience, but a cultural journey full of discoveries and fun. We will begin by introducing the notion of Intercultural Communication. We will look at ICC as an academic field: have a glimpse of its history, look at its place among other disciplines, discover possible approaches to it, and see why it is important to study the context of cultural events and phenomena. 

Culture in Intercultural Communication
    -This lecture will focus around Culture per se and the language we need to be able to discuss it.  The more complex and less formalized is the subject of the discussion, the more crucial are its instruments. We will introduce various dimensions that are applicable to different cultures and will also start to discuss the Russian culture in these terms. Starting this week we will also present short interviews of Prof. Bergelson's with people (non-Russians culturally) who have lived and worked in Russia, and who will serve as experts on various issues and contexts of communication with Russians. As stereotypes are one of the central concepts in the cross-cultural discourse, this week we will see interviews centered on this topic. The experts you will meet -- and not only this week -- are Anna Skaya (CEO VisualDNA Russia),  Michael Johnston, (Private Equity Sector Lead  Director of Strategy at Deloitte), and Ilya Gnoensky who specializes  in crisis management.

Theory of Communication
    -In this week's lectures we will shift our focus, and will be looking at the basics of communication in order to apply them later to the Russian communication style.  We hope you will find this information useful for understanding various motives that govern the way people (not only Russians!) interact. Anna Skaya and Michael Johnston will continue to be our experts, and your weekly quiz will await you as well. We wish you a nice learning experience in this section of the course.

Culture’s Impact on Communication: Politeness 
    -The lectures you'll see this week will be devoted to the linguocultural aspects of Politeness in Russian communication style and to other dimensions of Russian communication. We will meet an exciting new expert, Jennifer Eremeeva, an American author and blogger based in Moscow. And it's time for the first peer-reviewed assignment, ""Critical incident analyzed"". It offers you a critical incident of communication with Russian partners, in which you are expected to both simulate your response and give your analysis of what is culturally sensitive in this piece of discourse. 

Communication in Organizational Contexts
    -This week of the course is devoted to Russian communication in organizational contexts. Organizations are crucial: they shape culture and are shaped by culture. You will learn how Russian organizational culture developed throughout Russian history and how it influenced the way today's Russians behave in organizational and buziness environment. Our guests Michael Johnston and Ilya Gnoensky will add to the discussion by sharing their impressions on the Russian corporate culture and management styles. 

Social Stratification and Occupational Cultures in Russia
    -The material covered in the remaining weeks of the class will contain less theory of intercultural communications and more information about contemporary Russia, its ways of life and their historic background. This week we will speak about the social stratification (plus the recent history of the social strata) in Russia, as well as the Russian professional and occupational communication (including the recent changes in it) – both domestically and in the context of international contacts. The lecture will be wrapped up with a case study in which Prof. Bergelson took part some time ago to demonstrate intercultural communications studies at work – in the analysis of an international educational program between a major Russian and a major US university. As in the previous weeks, we will have guest experts to enrich the lecture material with their first-hand experience of living and working in Russia: Margaret Sullivan will describe what it is like to work for an NGO in Russia; Dirk Meissner will speak about teaching students and doing academic work at our home university, the Higher School of Economics. 

Interpersonal Communication
    -This week we will talk about the specific Russian features of interpersonal communication, communication across genders, and the generational discourse systems.Specifically, we will have a look at such issues as: friendship, dating, role of women; family structure, having and raising children, education, demographic and generational issues, ideological orientations, cross-gender communication, and forms and modes of address across various discourse systems. The Weekly Reading (one of which is optional) will provide further lively examples and evidence about some of these topics.Our guest speakers Anna Skaya and Jennifer Eremeeva will will share their experience of cross-gender communication in Russia. 

Culture as a Narrative
    -Sad to say, this is the last week of lectures in our course. And in this last week we present not factual data or charts or tables, but rather a narrative -- this time a narrative of Russian history in broad impressionistic strokes. We do believe in narratives: they are never complete, but they provide attitudes. And culture – more than anything else – is a narrative.This time we will look at narratives as a source of knowledge about a culture, and, specifically, at such cultural narratives as: national Russian holidays, the key events of Russian history, personal stories of Russians in the 20th century, and Russian jokes and humor. Two video interviews with Jennifer Eremeeva will be dealing with some of these topics.",Understanding Russians: Contexts of Intercultural Communication
https://www.classcentral.com/course/opensap-enterprise-deep-learning-with-tensorflow-9366,"Deep learning is a sub-field of machine learning that has led to breakthroughs in a number of artificial intelligence tasks, achieving state-of-the-art performance in computer vision, speech recognition, and natural language processing. Not surprisingly, many companies are looking for ways to start applying deep learning to their business processes and data assets to realize the vision of an intelligent enterprise. However, building deep learning models and deploying them to enterprise applications requires specialized skills in neural networks, plus an understanding of enterprise engineering principals.

The objective of this course is to provide a hands-on introduction to deep learning, with emphasis on practical enterprise applications. Taking an engineering approach to deep learning, the course focuses on building deep neural network models for typical enterprise problems, including when to use deep learning, examples of industry applications, and how to deploy deep learning in enterprise systems. The course features experts from academia and industry to show different perspectives on deep learning. All examples are implemented using Google’s TensorFlow deep learning framework.
      


Week 1: Getting Started with Deep LearningWeek 2: Shallow Neural NetworksWeek 3: Deep Networks and Sequence ModelsWeek 4: Convolutional NetworksWeek 5: Industry Applications of Deep LearningWeek 6: Advanced Deep Learning TopicsWeek 7: Final Exam",Enterprise Deep Learning with TensorFlow
https://www.classcentral.com/course/ml-foundations-4352,"Do you have data and wonder what it can tell you?  Do you need a deeper understanding of the core ways in which machine learning can improve your business?  Do you want to be able to converse with specialists about anything from regression and classification to deep learning and recommender systems?

In this course, you will get hands-on experience with machine learning from a series of practical case-studies.  At the end of the first course you will have studied how to predict house prices based on house-level features, analyze sentiment from user reviews, retrieve documents of interest, recommend products, and search for images.  Through hands-on practice with these use cases, you will be able to apply machine learning methods in a wide range of domains.

This first course treats the machine learning method as a black box.  Using this abstraction, you will focus on understanding tasks of interest, matching these tasks to machine learning tools, and assessing the quality of the output. In subsequent courses, you will delve into the components of this black box by examining models and algorithms.  Together, these pieces form the machine learning pipeline, which you will use in developing intelligent applications.

Learning Outcomes:  By the end of this course, you will be able to:
   -Identify potential applications of machine learning in practice.  
   -Describe the core differences in analyses enabled by regression, classification, and clustering.
   -Select the appropriate machine learning task for a potential application.  
   -Apply regression, classification, clustering, retrieval, recommender systems, and deep learning.
   -Represent your data as features to serve as input to machine learning models. 
   -Assess the model quality in terms of relevant error metrics for each task.
   -Utilize a dataset to fit a model to analyze new data.
   -Build an end-to-end application that uses machine learning at its core.  
   -Implement these techniques in Python.
      


            Read more
          



          Welcome
    -Machine learning is everywhere, but is often operating behind the scenes. This introduction to the specialization provides you with insights into the power of machine learning, and the multitude of intelligent applications you personally will be able to develop and deploy upon completion.We also discuss who we are, how we got here, and our view of the future of intelligent applications.

Regression: Predicting House Prices
    -This week you will build your first intelligent application that makes predictions from data.We will explore this idea within the context of our first case study, predicting house prices, where you will create models that predict a continuous value (price) from input features (square footage, number of bedrooms and bathrooms,...).  This is just one of the many places where regression can be applied.Other applications range from predicting health outcomes in medicine, stock prices in finance, and power usage in high-performance computing, to analyzing which regulators are important for gene expression.You will also examine how to analyze the performance of your predictive model and implement regression in practice using a Jupyter notebook.

Classification: Analyzing Sentiment
    -How do you guess whether a person felt positively or negatively about an experience, just from a short review they wrote?In our second case study, analyzing sentiment, you will create models that predict a class (positive/negative sentiment) from input features (text of the reviews, user profile information,...).This task is an example of classification, one of the most widely used areas of machine learning, with a broad array of applications, including ad targeting, spam detection, medical diagnosis and image classification.You will analyze the accuracy of your classifier, implement an actual classifier in a Jupyter notebook, and take a first stab at a core piece of the intelligent application you will build and deploy in your capstone.  

Clustering and Similarity: Retrieving Documents
    -A reader is interested in a specific news article and you want to find a similar articles to recommend.  What is the right notion of similarity?  How do I automatically search over documents to find the one that is most similar?  How do I quantitatively represent the documents in the first place?In this third case study, retrieving documents, you will examine various document representations and an algorithm to retrieve the most similar subset.  You will also consider structured representations of the documents that automatically group articles by similarity (e.g., document topic).You will actually build an intelligent document retrieval system for Wikipedia entries in an Jupyter notebook.

Recommending Products
    -Ever wonder how Amazon forms its personalized product recommendations?  How Netflix suggests movies to watch?  How Pandora selects the next song to stream?  How Facebook or LinkedIn finds people you might connect with?  Underlying all of these technologies for personalized content is something called collaborative filtering. You will learn how to build such a recommender system using a variety of techniques, and explore their tradeoffs. One method we examine is matrix factorization, which learns features of users and products to form recommendations.  In a Jupyter notebook, you will use these techniques to build a real song recommender system.

Deep Learning: Searching for Images
    -You’ve probably heard that Deep Learning is making news across the world as one of the most promising techniques in machine learning. Every industry is dedicating resources to unlock the deep learning potential, including for tasks such as image tagging, object recognition, speech recognition, and text analysis.In our final case study, searching for images, you will learn how layers of neural networks provide very descriptive (non-linear) features that provide impressive performance in image classification and retrieval tasks.  You will then construct deep features, a transfer learning technique that allows you to use deep learning very easily, even when you have little data to train the model.Using iPhython notebooks, you will build an image classifier and an intelligent image retrieval system with deep learning.   

Closing Remarks
    -In the conclusion of the course, we will describe the final stage in turning our machine learning tools into a service: deployment.We will also discuss some open challenges that the field of machine learning still faces, and where we think machine learning is heading.  We conclude with an overview of what's in store for you in the rest of the specialization, and the amazing intelligent applications that are ahead for us as we evolve machine learning.",Machine Learning Foundations: A Case Study Approach
https://www.classcentral.com/course/edx-understanding-classroom-interaction-7198,"Have you ever wondered why some classroom discussions are lively and engaging and others more like painful interrogations? Why some students always have an answer ready, but others never participate? Why everybody (or nobody) laughs at a teacher’s jokes? What role multiple languages should play in classroom talk?
This course gives classroom teachers at all levels and subject areas the analytic tools to answer these and more questions about classroom communication.
Each lesson introduces fundamental concepts and techniques of classroom discourse analysis, developing an analytic toolkit and promoting critical reflection on pedagogical practices over five weeks.



Week One: Introduction to classroom interaction (What is it and why do it?)
Introduction to previous classic research and reasons for studying classroom interaction.  Introduction to basic terminology of the field and brief examples of how this terminology can be used to focus our observation of classroom talk. 
 
Week Two: Turn-taking patterns and question types
Introduction to typical turn-taking patterns, the different types of questions teachers and students ask and the consequences for student engagement and learning.  Students will view examples of different types of questions and analyze the way classroom discussions develop around them. 
 
Week Three: Beyond Language: The role of intonation, gesture and other non-linguistic cues on interaction
Introduction to the concept of “contextualization cues,” that is the role of gesture, posture, dress, and appearance in cueing how teachers and students understand and contribute to classroom interaction.
 
Week Four: Types and functions of classroom storytelling
Review of classic research literature on storytelling in classrooms, from pre-school “sharing time” to literature and science discussions. Examples illustrate techniques of narrative analysis in everyday classroom settings. 
 
Week Five: Types of participation and their effects
Introduction to different participant structures with emphasis on the joint nature of any classroom talk (from group work to teacher-delivered lectures). Examples of how different frameworks for participation in classrooms affects who talks, what gets said, and how.",Understanding Classroom Interaction
https://www.classcentral.com/course/edx-scrolls-in-the-age-of-the-book-3508,"This course is an introduction to the making and use of scrolls in the European Middle Ages. The codex, with its portability and instant access to any place in the text, became the dominant container for writing after the 4th century BCE, but scrolls continued to be made. Why and how did the scroll format remain popular and relevant in the age of the codex? This course proposes four main reasons, which 
account for essentially every kind of scroll that still exists today. We will see and examine in detail a number of beautiful objects, and come to understand the thinking of those who chose the scroll format for their texts.
This module features four main units, each of which is based on one of the reasons for scroll-making:

Scrolls of indeterminate length
Scrolls in long format
Ceremonial and archaizing scrolls
Portable scrolls

Scrolls in the Age of the Book also features a guided tour of an exhibition on Harvard University’s collection of medieval scrolls, held at Houghton Library, Harvard’s special collections library, in Spring 2014. Each scroll featured in the exhibit has been fully digitized by Harvard’s Preservation Services division, and participants will have the opportunity to interact with them in unprecedented fashion using Mirador, a state-of-the-art web application developed by Harvard and Stanford Universities.
This is a module in the series The Book: Histories Across Time and Space.
HarvardX requires individuals who enroll in its courses on edX to abide by the terms of the edX honor code. HarvardX will take appropriate corrective action in response to violations of the edX honor code, which may include dismissal from the HarvardX course; revocation of any certificates received for the HarvardX course; or other remedies as circumstances warrant. No refunds will be issued in the case of corrective action for such violations. Enrollees who are taking HarvardX courses as part of another program will also be governed by the academic policies of those programs.
HarvardX pursues the science of learning. By registering as an online learner in an HX course, you will also participate in research about learning. Read our research statement to learn more.
Harvard University and HarvardX are committed to maintaining a safe and healthy educational and work environment in which no member of the community is excluded from participation in, denied the benefits of, or subjected to discrimination or harassment in our program. All members of the HarvardX community are expected to abide by Harvard policies on nondiscrimination, including sexual harassment, and the edX Terms of Service. If you have any questions or concerns, please contact harvardx@harvard.edu and/or report your experience through the edX contact form.



            Read more",Scrolls in the Age of the Book
https://www.classcentral.com/course/edx-humanity-and-nature-in-chinese-thought--2079,"We make ethical or behaviour guiding right / wrong judgments all the time but have you ever wondered where Ethics comes from, what it is about and why it is important? This course provides an introduction to traditional Chinese ethical thought and focuses on the pervasive contrast in the way Chinese and Westerners think about ethical guidance or guidance concerning what is right and what is wrong, good or bad. Traditional Western orthodoxy uses the metaphor of a law – in its most familiar popular form, the command of a supernatural being backed by a threat of eternal punishment or reward – to explain ethical guidance. The Classical Chinese philosophers by contrast were all naturalists. They talked about ethical guidance using a path metaphor – a natural dào.
We will look at two rival directions this natural dào model took in ancient China. The first direction views ethical paths as generated from human sources such as human history and past social practices. The other Confucian version views guidance as arising from a distinctly human guiding organ, something like a combination of our faculties of heart and mind. This organ issues the right/wrong or this/not-that judgements naturally. This internal map to moral choices branches, like a plant, as we mature. The alternative to human-based naturalism in China treated normative guidance as natural in a broader sense, such as the dào of water or one guided by what is beneficial vs harmful. Finally, we will take a brief look at a development after the classical period that resulted from the invasion of the more super-naturalist, Indo-European way of thinking about guidance – Medieval Chinese Buddhism.
Although Chinese concepts will be the focus of our discussion, all the content of this course is intended to be accessible to beginner students. For those who are beginners in Philosophy, we will include a brief introduction to the ideas of logic that further shape the Western metaphor of a law and help us understand its role in Western ethics, science and psychology so you can better understand the different ways these two philosophical metaphors explain where norms of behaviour come from, what they are about and why they are important.
我们常常判断事物的正误，但你是否思考过什么是道德/行为准则，它来自哪里，为什么重要？本课程介绍中国传统道德思想，关注中西哲学关于道德准则、正误、好坏的不同理解。传统西方观念以“法”（即超自然个体的指令以及遵循或违背该指令所意味的奖惩后果）来解释道德准则。与此截然不同，中国古代哲学家们则均为自然主义者，他们以“道”为喻体来讨论道德标准。
本课程重点关注“道”在中国古代沿着两个不同方向竞相演变的过程。一种方向认为道德准则来自于人类历史以及以往社会的实践。另一个方向则认为道德标准源自人本身的一种类似于心脑结合的感官，该感官自然的发出正误、此彼等判断。有如我们内心的一幅导图，像植物一样，随着我们的成长日渐丰茂强大。中国的这种不以人本身为基础的自然主义对待道德准则的方式，从广义角度看待自然，比如水之道，善与恶之道。课程结尾部分我们会简单探讨古代中国之后随着超自然、印欧哲学被引入中国而出现的一个新事物，即中世纪中国佛教。
尽管课程重点讨论的是中国传统哲学思想，不熟悉中国哲学的学生也会发现课程内容浅显易懂。针对哲学初学者，课程包含了关于逻辑这一概念的简单介绍，以及它如何加强西方“法”的概念，以便帮助我们了解“法”在西方道德、科学以及心理学领域的作用，以利于学生更好地了解中西哲学思想间对于行为准则的来源、内容、及其重要性的不同理解。
课程目标：
• 学习描述中国古代哲学思想中的人类与自然观；
• 学习辩证思考中国哲学思想中的人类与自然观，明辨其优缺；
• 反思人类与自然的关系；
• 培养解释说明及分析辩证技巧。



            Read more",Humanity and Nature in Chinese Thought | 中国哲学思想中的人类与自然观
https://www.classcentral.com/course/opensap-abap-development-for-sap-hana-2360,"All SAP products are moving to SAP HANA, the most talked about SAP innovation in recent times. This evolution intensifies the demands on SAP NetWeaver Application Server ABAP (AS ABAP) to best leverage the features and capabilities of the SAP HANA database. As an ABAP developer you might ask, what is important and necessary to know concerning ABAP development for SAP HANA?
This course is aimed at answering this and other related questions. You are welcome to follow the course without prior technical knowledge of ABAP development or SAP HANA, although prior knowledge is beneficial.
After completing the course, you will understand the important concepts in ABAP development for SAP HANA, how to detect and analyze the performance of your ABAP coding, and which features AS ABAP provides for database-oriented programming.
Registration, learning content, and the final exam are free of charge. However, to gain maximum benefit from the course, you can access a fee-based system environment where you can develop your own code. We’ll explain how you can access this system environment in the first week of the course.
Course Requirements

Basic knowledge of ABAP programming and Open SQL
Basic programming skills
Beneficial: A general understanding of SAP HANA, for example, from the openSAP course ""An Introduction to SAP HANA by Dr. Vishal Sikka""




Week 1: Getting Started
The first week is dedicated to getting you on board and introducing technical concepts and architecture information, primarily from an ABAP developer’s point of view. As well as the important concepts of ABAP development for SAP HANA, there will be an introduction to the development tools.
Week 2: ABAP Coding – Where to Optimize?
What happens when you migrate coding to SAP HANA? This and related questions are answered in the second week of this course. There are a large variety of tools available in AS ABAP to detect and analyze ABAP coding, for example, to ensure functional correctness and to analyze performance. You’ll learn about guided performance analysis tools and optimized components like the well-known ABAP List Viewer, which have been enhanced to dramatically improve performance.
Week 3: ABAP Coding – Ready, Set, Optimize!
Having learned about where to optimize ABAP coding, this week is dedicated to introducing the new features and capabilities of AS ABAP 7.4, with special emphasis on database-oriented programming. Beside the Open SQL enhancements, you’ll learn about advanced view definition capabilities by means of Core Data Services.
Week 4: Digging Deeper and Outlook
The capabilities of AS ABAP 7.4 discussed in the previous week do not span the full feature set of SAP HANA. Therefore, ABAP for SAP HANA developers might need to dig even deeper and work more natively with SAP HANA. We’ll see how AS ABAP 7.4 supports this task. Finally, we’ll give an example of how the presented features can be used in an analytical app. Beside the Open SQL enhancements, you’ll learn about advanced view definition capabilities by means of Core Data Services.
Week 5: Final Exam",ABAP Development for SAP HANA
https://www.classcentral.com/course/inductive-reasoning-6618,"How to Reason Inductively

Think Again: How to Reason and Argue
Reasoning is important. This series of four short courses will teach you how to do it well. You will learn simple but vital rules to follow in thinking about any topic at all and common and tempting mistakes to avoid in reasoning. We will discuss how to identify, analyze, and evaluate arguments by other people (including politicians, used car salesmen, and teachers) and how to construct arguments of your own in order to help you decide what to believe or what to do. These skills will be useful in dealing with whatever matters most to you.

Courses at a Glance:
All four courses in this series are offered through sessions which run every four weeks. We suggest sticking to the weekly schedule to the best of your ability. If for whatever reason you fall behind, feel free to re-enroll in the next session.We also suggest that you start each course close to the beginning of a month in order to increase the number of peers in the discussion forums who are working on the same material as you are. While each course can be taken independently, we suggest you take the four courses in order.

Course 1 - Think Again I: How to Understand Arguments
Course 2 - Think Again II: How to Reason Deductively
Course 3 - Think Again III: How to Reason Inductively
Course 4 - Think Again IV: How to Avoid Fallacies

About This Course in the Series:
Think Again: How to Reason Inductively 
Want to solve a murder mystery? What caused your computer to fail? Who can you trust in your everyday life? In this course, you will learn what distinguishes inductive arguments from deductive arguments and then how to analyze and assess five common forms of inductive arguments: generalizations from samples, applications of generalizations, inference to the best explanation, arguments from analogy, and causal reasoning. The course closes by showing how probability can be used to help us make decisions of all sorts.

Suggested Readings
Students who want more detailed explanations or additional exercises or who want to explore these topics in more depth should consult Understanding Arguments: An Introduction to Informal Logic, Ninth Edition, Concise, Chapters 8-12, by Walter Sinnott-Armstrong and Robert Fogelin.

Course Format
Each week will be divided into multiple video segments that can be viewed separately or in groups. There will be short ungraded quizzes after each segment (to check comprehension) and a longer graded quiz at the end of the course.
      


            Read more
          



          Welcome to the Course
    -Welcome to Think Again: How to Reason Inductively!  This course is the third in a series of four courses jointly titled Think Again: How to Reason and Argue. We are excited that you are taking this course, and we hope that you will take all four courses in the series, because there is a great deal of important material to learn.In the series as a whole, you learn how to analyze and evaluate arguments and how to avoid common mistakes in reasoning. These important skills will be useful to you in deciding what to believe and what to do in all areas of your life. The first part of this course introduces the series and the course. It also clarifies some peculiarities you may find with this course. We encourage you to watch the ""Introduction to the Course"" video first as it will help you learn more from the materials that come later. 

Inductive Arguments
    -CONTENT: This week begins by distinguishing inductive arguments from deductive arguments. Then we discuss four common forms of inductive argument: generalizations from samples (such as in political polls), applications of generalizations to particular cases (such as in predicting weather on a certain day), inferences to the best explanation (such as in using evidence to determine who committed a crime), and arguments from analogy (such as in identifying the use of one archaeological artifact by comparing it to other artifacts). We will expose the most common mistakes in these kinds of reasoning. Some of the ""lectures"" this week are a bit experimental (and perhaps weird!), as you will see. We hope that you enjoy them.LEARNING OUTCOMES: By the end of this week's material you will be able to do: distinguish inductive from deductive arguments classify inductive arguments into five kinds identify and evaluate arguments that generalize from samplesidentify and evaluate arguments that apply generalizations to casesidentify and evaluate inferences to the best explanation by applying standards that good explanations must meetidentify and evaluate arguments from analogyOPTIONAL READING: If you want more examples or more detailed discussions of these kinds of inductive arguments, we recommend Understanding Arguments, Ninth Edition, Chapters 8 and 9.

Causal Reasoning
    -CONTENT: This module will focus on how to decide what causes what. Students will learn how to distinguish necessary conditions from sufficient conditions and how to use data to test hypotheses about what is and what is not a necessary condition or a sufficient condition. Then we will distinguish causation from correlation (or concomitant variation) and explain the fallacy of post hoc ergo propter hoc. It is sad that some diners had to die to make this lesson possible, as you will see.

LEARNING OUTCOMES: By the end of this week’s material you will be able to do: 

 analyze causal reasoning
distinguish necessary from sufficient conditions
determine what is necessary or sufficient for what
separate causation from correlation



OPTIONAL READING: If you want more examples or more detailed discussions of these topics, we recommend Understanding Arguments, Ninth Edition, Chapter 10.


Chance and Choice
    -CONTENT: This week will cover chance and choice—in other words, probability and decision making. Probability is useful for measuring the strength of inductive arguments and also for deciding what to believe and what to do. You will learn about the nature and kinds of probability along with four simple rules for calculating probabilities. An optional honors lecture will then explain Bayes’ theorem and the common mistake of overlooking the base rate. Next we will use probabilities to evaluate decisions by figuring their expected financial value and contrasting financial value with overall value. LEARNING OUTCOMES: By the end of this week’s material, you will be able to do:  solve some classic paradoxes of probabilityapply simple rules of probabilityuse Bayes’ theorem to calculate conditional probabilitiesavoid fallacies of probabilityapply probabilities to calculate expected financial valuesdistinguish financial value from overall valueuse simple rules to aid decisions under uncertaintyOPTIONAL READING: If you want more examples or more detailed discussions of these topics, we recommend Understanding Arguments, Ninth Edition, Chapters 11 and 12 

Catch-Up and Final Quiz
    -This week gives you time to catch up and review, because we realize that the previous weeks include a great deal of challenging material. It will also be provide enough time to take the final quiz as often as you want, with different questions each time. We explain the answers in each exam so that you can learn more and do better when you try the exam again. You may take the quiz as many times as you want in order to learn more and do better, with different questions each time. You will be able to retake the quiz three times every eight hours. You might not need to take more than one version of the exam if you do well enough on your first try. That is up to you. However many versions you take, we hope that all of the exams will provide additional learning experiences.",Think Again III: How to Reason Inductively
https://www.classcentral.com/course/canvas-network-understanding-the-scientific-method-2608,"Based on Next Generation Science Standards, this course provides an introduction to the role of science in society, feedback and regulation mechanisms, and using a systems approach to solve scientific problems. Participants will explore the nature of scientific inquiry and learn how to analyze scientific data.",Understanding the Scientific Method
https://www.classcentral.com/course/portfolio-selection-risk-management-7039,"When an investor is faced with a portfolio choice problem, the number of possible assets and the various combinations and proportions in which each can be held can seem overwhelming. In this course, you’ll learn the basic principles underlying optimal portfolio construction, diversification, and risk management. You’ll start by acquiring the tools to characterize an investor’s risk and return trade-off. You will next analyze how a portfolio choice problem can be structured and learn how to solve for and implement the optimal portfolio solution. Finally, you will learn about the main pricing models for equilibrium asset prices.

Learners will:
•	Develop risk and return measures for portfolio of assets
•	Understand the main insights from modern portfolio theory based on diversification
•	Describe and identify efficient portfolios that manage risk effectively
•	Solve for portfolio with the best risk-return trade-offs
•	Understand how risk preference drive optimal asset allocation decisions
•	Describe and use equilibrium asset pricing models.
      


          Module 1- Introduction & Risk and Return
    -This module introduces the second course in the Investment and Portfolio Management Specialization. In this module, we discuss one of the main principles of investing: the risk-return trade-off, the idea that in competitive security markets, higher expected returns come only at a price – the need to bear greater risk.  We develop statistical measures of risk and expected return and review the historical record on risk-return patterns across various asset classes. 

Module 2: Portfolio construction and diversification
    -In this module, we build on the tools from the previous module to develop measure of portfolio risk and return. We define and distinguish between the different sources of risk and discuss the concept of diversification: how and why putting risky assets together in a portfolio eliminates risk that yields a portfolio with less risk than its components. Finally, we review the quantitative tools that help us identify the ‘best’ portfolios with the least risk for a given level of expected return by considering a numerical example using international equity data.

Module 3: Mean-variance preferences
    -In this module, we describe how investors make choices. Specifically, we look at how utility functions are used to express preferences. We review measures to describe investors’ attitude towards risk. Finally, we discuss how we can summarize investors’ preferences using a specific utility function: mean-variance preferences. 

Module 4: Optimal capital allocation and portfolio choice
    -In this module, you will learn about mean-variance optimization: how to make optimal capital allocation and portfolio choice decisions when investors have mean-variance preferences. This was one of the ground-breaking ideas in finance. We will formally set up the investor’s portfolio choice problem and learn step-by-step how to solve for the optimal allocation and risky portfolio choice given a set of risky securities. You will also have an opportunity to apply these techniques to a numerical example. This module is slightly more technical than the others. Stick with it… you will not regret it!

Module 5: Equilibrium asset pricing models 
    -In this module, we build on the insights obtained from modern portfolio theory to understand how risk and return are related in equilibrium. We first look at the main workhorse model in finance, the Capital Asset Pricing Model and discuss the expected return-beta relationship. We then turn our attention to multi-factor models, such as the Fama-French three-factor model.",Portfolio Selection and Risk Management
https://www.classcentral.com/course/edx-biblical-archaeology-the-archaeology-of-ancient-israel-and-judah-12494,"Join me for an introductory course on biblical archaeology of ancient Israel and Judah during the Iron Age (ca. 1200-586 BCE). 
In this course, we will use cutting-edge, inter-disciplinary archaeological research to explore the fascinating field of archaeology, the history of this era, and it's ""players""(e.g. Israel, Judah, Philistine, Mesopotamia, Phoenicia, Aram, Moab, Edom, ancient Egypt etc.). 
Special focus will be given to complex relationship between archaeology, history and the bible, and how modern research interfaces between these different, and at times conflicting, sources. In particular, how can archaeology be used to understand the biblical text - and vice a versa. 
The course will combine short video lectures with extensive illustrative materials, on-site discussions at relevant archaeological locations, display 3D images and discuss relevant archaeological finds. 
In addition, it includes interviews with leading researchers in the field, both to discuss specific aspects, finds and sites, as well as to present different sides of debated issues.



Week 1: Introduction 

What is Archaeology and what is Biblical Archaeology?
What time periods and areas will the course cover?
What is the relationship between archaeology and the Bible?
What is the ""toolbox"" of the modern archaeologist?
How does science impact modern biblical archaeology?
The Bronze Age background of biblical Israel and Judah.

Week 2: The early Iron Age 

Who are the early Israelites?
How do we define them?
How, when, and where did the early Israelites appear?
How does the archaeological evidence for the appearance of early Israel compare to the biblical description?

Week 3: The First Kingdoms? A ""United Monarchy"" of David and Solomon? 

Was there a ""United Monarchy""?
What does archaeology and the Bible tell us and how does this compare?
What are the historical and archaeological evidence of this kingdom and these figures?

Week 4: The Northern Kingdom of Israel: ca. 930-722 BCE 

Historical sources on the Israelite Kingdom.
What is the archaeological evidence of the Israelite Kingdom?
The end of the Israelite Kingdom.

Week 5: The Southern Kingdom of Judah: ca. 930-586 BCE 

Historical sources on the Judahite Kingdom.
What is the archaeological evidence of the Judahite Kingdom?
What is the relationship between the Kingdoms of Judah and Israel
The end of the Kingdom of Judah.

Week 6: Daily Life and Material Culture of Ancient Judah and Israel 

Social structure in biblical Israel and Judah.
Urban and rural life in biblical Israel and Judah.
Food and drink in biblical Israel and Judah.
Religion and cult in biblical Israel and Judah.
Death and Burial in biblical Israel and Judah.
Warfare in biblical Israel and Judah.
Language, writing, and literacy in biblical Israel and Judah.

Week 7: Neighboring Cultures in the Iron Age II 

Philistines
Phoenicians
Transjordanian peoples
Aram
Egypt
Mesopotamia

Week 8: Aftermath of Iron Age Israel and Judah and Course Epilogue 

Judahite exiles in Mesopotamia and Egypt?
The Persian Period restoration (ca. 500-330 BCE).
What Archaeology contributes to the understanding of ancient Israel and Judah.
Insights on the relationship between Archaeology and the Biblical Texts.
What to do if you want to expand your knowledge and experience in Biblical Archaeology.",Biblical Archaeology: The archaeology of ancient Israel and Judah
https://www.classcentral.com/course/bacterial-genomes-access-and-analysis-11907,"Use computational tools to investigate microbial genomes
Applying increasingly powerful computation to genomics contributes to important medical breakthroughs.
On this course, you will discover the basic principles of microbial bioinformatics analysis, and comparative genomics. Using Artemis, a free genome browser, you will find out how to investigate whole bacterial genomes, and through the analysis of bacterial genes and proteins, you will explore the genomic features of pathogens.
By the end of this course, you will be able to use genomic data to increase your knowledge of microbial genomes.
This course would benefit those interested in learning how to use tools to investigate bacterial genomes, and acquire bioinformatics skills to evaluate the role of microbial genes in disease. Using analytical tools to access and probe genomes, learners will find out how to perform comparative analyses of genes and their protein products.
The course will be of interest to undergraduates, post-graduates, researchers, bioinformaticians, microbiologists, and healthcare professionals.  The opportunity to use online computational tools to probe bacterial genomes will also be of interest to teachers and their 16-18-year-old science and computing students.
Bacterial Genomes: From DNA to Protein Function using Bioinformatics is a recommended pre-requisite.  Scientific terminology is explained.
This course will give you an opportunity to learn about and use Artemis, a free genome browser and annotation tool. To run this software effectively, you will require a computer (Windows, Mac or Linux) with 2GB RAM. The current version of Artemis requires version 1.11 of Java to run successfully. Java can be downloaded from this link.



            Read more",Bacterial Genomes: Accessing and Analysing Microbial Genome Data
https://www.classcentral.com/course/swayam-programming-data-structures-and-algorithms-in-python-6709,"Week 1Informal introduction to programmin, algorithms and data structures viagcdDownloading and installing Pythongcd in Python: variables, operations, control flow - assignments, condition-als, loops, functions
Week 2Python: types, expressions, strings, lists, tuplesPython memory model: names, mutable and immutable valuesList operations: slices etcBinary searchInductive function denitions: numerical and structural inductionElementary inductive sorting: selection and insertion sortIn-place sorting
Week 3Basic algorithmic analysis: input size, asymptotic complexity, O() notationArrays vs listsMerge sortQuicksortStable sorting
Week 4DictionariesMore on Python functions: optional arguments, default valuesPassing functions as argumentsHigher order functions on lists: map, lter, list comprehension
Week 5Exception handlingBasic input/outputHandling filesString processing
Week 6Backtracking: N Queens, recording all solutionsScope in Python: local, global, nonlocal namesNested functionsData structures: stack, queueHeaps
Week 7Abstract datatypesClasses and objects in Python""Linked"" lists: find, insert, deleteBinary search trees: find, insert, deleteHeight-balanced binary search trees
Week 8Effcient evaluation of recursive denitions: memoizationDynamic programming: examplesOther programming languages: C and manual memory managementOther programming paradigms: functional programming","Programming, Data Structures and Algorithms in Python"
https://www.classcentral.com/course/origins-668,"The Origins course tracks the origin of all things – from the Big Bang to the origin of the Solar System and the Earth. The course follows the evolution of life on our planet through deep geological time to present life forms.
      


          Origin of the Elements, the Solar System and the Planets
    -In the first module of Origins Jim Connelly and Henning Haack go through the evolution that resulted in the Solar System with the planets that we know today. Jim will tell you about how the elements of the periodic table were formed. Without these elements there would be no Solar System, no planets and no life at all. We have added a couple of more videos that we hope you will also find interesting. One gives you an introduction to Geological time. Videos 1.7-1.9 deals with some of our most interesting meteorites from the collections at the Natural History Museum of Denmark. Much of the evidence for the theories presented in Module 1 has been obtained from meteorites. 


The early Earth and origin of life
    -In this module we are going to have a look at our own planet, just after it formed. Emily Pope will introduce you to the most important geological principles and processes that characterize our Earth.  This should make it easier for you to understand how we use geology to reconstruct the evolution of our planet and the life forms that inhabit it.  With such tools in hand, Emily will take you on a tour back in deep geological time and tell you about the earliest evolution of our planet and the oldest evidence for life on Earth. We will also take you on a trip to Greenland where Minik Rosing will show the rocks in which he found the oldest evidence for life on Earth.


Origin of the microbial world / The Cambrian Explosion and Exceptional Preservation
    -In this module Jan Audun Rasmussen and Danny Eibye-Jacobsen will show you how life evolved during the first 4 billion years since the creation of the Earth. As you will see, it is very challenging to study the oldest life forms of our planet. During this enormous time span – which covers about 80% of the Earth’s history – microbial life slowly evolved to form a crucial component of the biosphere. Toward the end of the period the deepest foundations of the different groups of animals evolved. All of the life forms surrounding us today can be traced back to this time. 


Transition from Microbial to Macrobial Life: Snowball Earth and the Ediacara Biota / Eukaryotic Evolution and the Phylogeny of All Life
    -In this module, we take a closer look at how the physical and biological conditions that made the Cambrian Explosion possible arose. In the first lectures Svend Stouge will tell you about the dramatic consequences of climate changes seen toward the end of the Precambrian. Geological evidence supports the idea that the Earth was completely covered in ice during periods that we, for obvious reasons, refer to as Snowball Earth. In the remaining lectures Martin Sørensen will tell you about one of the most significant building blocks of life on Earth – the cell – and how the early bacterial cells evolved and became capable of forming the huge variety of life that we see today. Martin Sørensen will also show how different evolutionary trends of cells resulted in six major organism groups, of which several gave rise to multicellular life. 


Origin of the marine Cambrian and Palaeozoic Evolutionary Faunas / Diversity in deep time / Origin of predation and the Mesozoic Arms race
    -In module 5, Arne Thorshøj Nielsen and Jan Audun Rasmussen will show you how the higher life forms, particularly the marine animals, evolved in the oceans, after the sudden appearance of a hard skeleton in many different animal groups during the Cambrian Explosion 540 My ago. You will be introduced to the changing major evolutionary faunas through time, and also see how clever strategies to kill or avoid being killed, major extinction events and many other factors controlled the evolution that eventually resulted in the modern marine faunas.


Oxygenation and Animals
    -In module 6 Tais Wittchen Dahl will take a detailed look at one of the most important factors controlling the evolution of life - oxygen. In the previous lectures you have already heard that the oxygen levels have changed in the past. Tais will show you what the mechanisms behind changes in global oxygen levels are and what are the most important consequences. One of the amazing possible consequences was that during the Carboniferous, dragonflies had wing spans of up to 75 cms! Higher oxygen levels not only allowed for the evolution of higher life forms, it may also have limited the size of insects and predatory fish, and ultimately furthered the evolution of intelligent life. Without the increase in oxygen, it would be impossible for us to understand the lectures in this course!


Origins and Early Development of Plants / The Origin and Diversification of Flowering Plants
    -In module 7, we will have a closer look at the biggest source of oxygen – the plants. Up till now we have heard a lot about the evolution of higher life forms in the oceans. While evolution took a giant step forward in the oceans, the continents remained totally barren for another approx. 100 million years. Vivi Vajda from the Lund University in Sweden and Gitte Petersen will tell you how the plants began to inhabit the terrestrial environment, thus paving the way for other life forms living on land. Land plants have managed to adapt to a very different environment, with new challenges and possibilities. Some of the early plants have survived as fossils – whereas others are still alive. Some of these living fossils will be presented in the videos. We will also have a close look at the biggest group of plants – which has evolved in close collaboration with insects, birds and even some mammals – the flowering plants.

The Evolution of Insects and their Role in Terrestrial Ecosystems
    -In module 8, Lars Vilhelmsen will take a close look at the insects which account for more than 50% of today’s biodiversity and biomass. Part of the story behind the success of the insects is their remarkable adaption to a wide range of environments. Insects mastered powered flight early in their evolution, and also developed highly specialized relationships with land plants almost from the start. Different insects feed on almost everything: various plant parts, nectar, blood from vertebrates, or other insects. Other remarkable types of specializations are found in social insects that act as a single organism, capable of performing highly complex tasks, such as farming. 


Colonization of the continents and the Origin of the Dinosaurs and Birds/Mass Extinction Events and Their Causes
    -In module 9, we will explore how vertebrates colonized dry land. Jesper Milàn will tell you about how this happened and give you examples of some of the first vertebrates that gradually adapted to a life on land. In the following lecture Gilles Cuny will tell you about how the early primitive vertebrates evolved into the highly diverse groups that we see today. He will show you many interesting examples of our distant relatives and discuss many of the processes, which we believe controlled their evolution and diversification. One of the important factors driving evolution is mass extinction events. Gilles will introduce you to the topic and Bent Lindow will give you a detailed look at mass extinction events. What were the causes, what happened and what were the consequences? Many questions remain unanswered but one thing is certain – mass extinctions have had a great impact on the evolution of life on Earth. Without mass extinctions life would have evolved in a completely different way and humans, like most other recent species, would not be here. 


Origin of Recent Climate Change / The Molecular Clock
    -In module 10, we will tell you about two very different topics – recent climate changes and the molecular clock. Michael Houmark will tell you about the changes in global climate over the past 50 million years. During this period the warm temperatures in the Eocene were gradually replaced by the much lower, present day temperatures. Michael will show you how much better records of sea level, temperature, CO2, volcanic activity, and continental drift in the recent past allow us to piece together a detailed picture of these dramatic changes in Earth’s climate. Our records of recent climate change also allow us to better understand the processes controlling the climate on short, medium, and long time scales. Ole Seberg will tell you about the molecular clock. This is a new technique, which has significantly improved our understanding of the evolution of life on our planet. Looking at molecular data of present species, we can not only determine how closely the species are related to each other, we can also estimate the age of their common ancestors. 


Primate Origins and Evolution / Human Origins and Evolution
    -Finally, we have come to the evolution of the primates – the group to which humans belong. Bent Lindow tells you about the evolution of primates, leading up to the early humans. Bent will also introduce you to a web-based exercise called “The Human Animal” (http://snm.ku.dk/english/school_services/human_animal/). In this exercise you will explore skulls of living as well as extinct hominids. Apart from the exercise itself the “Human animal” includes some background reading material and some interesting videos. Included is footage from the dissection of a dead chimpanzee from a Danish Zoo; do not watch this if you think it will make you uncomfortable. In order to do the exercise you need a computer with a mouse (since you need to measure distances in 3D between different parts of the skulls that you will be studying).  It will not run on iPads and iPhones. Finally, Tom Gilbert will tell you about how the early modern humans (Homo sapiens) managed to colonize almost every land mass of our planet. Although many details of our own evolution still remain obscure, recent advances in genomics have given us a much better understanding of how extant humans colonized the entire planet after leaving their original home in Africa. 

Modern Diversity
    -In the last set of lectures we will look at the modern biodiversity. There is an enormous difference between the biodiversity of different types of habitats on our planet – from the equator to the arctic, from deserts to rainforests, and from isolated islands like the Galapagos to large continents. Jon Fjeldså will take you on a trip around the planet and give you many interesting examples of these variations. He will explain how we can use them to get a better understanding of how evolution works. 
This concludes the Origins course. Thank you for following it, we hope it has enhanced your understanding of how life evolved and diversified on our planet, and that it will inspire you to see natural phenomena in a new light.","Origins - Formation of the Universe, Solar System, Earth and Life"
https://www.classcentral.com/course/screening-4793,"Current and future public health is characterized by the increase of chronic and degenerative diseases, corresponding to the worldwide ageing of the population. The increasing prevalence of these conditions together with the long incubation period of the chronic diseases and the continual technological innovations, offer new opportunities to develop strategies for early diagnosis.

Public Health has an important mandate to critically assess the promises and the pitfalls of disease screening strategies. This MOOC will help you understand important concepts for screening programs that will be explored through a series of examples that are the most relevant to public health today.  We will conclude with expert interviews that explore future topics that will be important for screening.

By the end of this MOOC, students should have the  competency needed to be involved in the scientific field of screening, and understand the public health perspective in screening programs.

This MOOC has been designed by the University of Geneva and the University of Lausanne. 
This MOOC has been prepared under the auspices of the Ecole romande de santé publique (www.ersp.ch) by Prof. Fred Paccaud, MD, MSc, Head of the Institute of Social and Preventive Medicine in Lausanne (www.iumsp.ch), in collaboration with Professor Antoine Flahault, MD, PhD, head of the Institute of Global Health, Geneva (https://www.unige.ch/medecine/isg/en/) and Prof. Gillian Bartlett-Esquilant (McGill University, Quebec/ Institute of Social and Preventive Medicine, Lausanne).
      


            Read more
          



          Introduction to Key Concepts in Screening
    -This module will provide a brief welcome by Dr. Fred Paccaud and Dr. Antoine Flahault.  An overview of screening and an introduction on how the course is organized and evaluated will be provided by Dr. Gillian Bartlett-Esquilant.  Dr. Idris Guessous, a Senior Lecturer in the Population Epidemiology Unit in the Department of Community Medicine, Primary Care and Emergency Medicine  (Geneva), and in the Department of Ambulatory Care and Community Medicine (PMU Lausanne) & Division of Chronic Diseases at the Institute of Social and Preventive Medicine (Lausanne) will provide lectures on definitions of screening. Natural history of diseases and the characteristics of subclinical conditions allowing early diagnosis will be presented. A quiz on the key concepts for screening will complete this module.  

Screening Metrics
    -The second module, provided by Dr. Idris Guessous, will address the metrics of screening with concepts related to robustness, validity and impact. A quiz on screening metrics will complete this module. 

Screening in Pregnancy and Newborns
    -This module on screening in the prenatal (pregnancy) and perinatal (newborn) stage of life is given by Professor Murielle Bochud, MD, PhD, head of the Institute of social and preventive medicine in Lausanne, Switzerland. A quiz will complete this module.

Screening for Cardiometabolic Conditions
    -Senior lecturer Arnaud Chiolero, MD, PhD, from the Division of Chronic Diseases at the Institute of Social and Preventive Medicine in Lausanne will be presenting three case studies related to the increasingly prevalent condition of cardiometabolic disease.  Three different diseases will be explored in terms of burden of disease, benefits and harms, evidence and issues followed by recommendations about whether screening should be implemented. A quiz will complete this module.

Cancer Screening
    -Cancer is a classical field for screening because of both the improvement of the prognosis for most cancers and the usually long incubation period. This part of the MOOC will present current data, evidence and policies regarding the most important cancer sites that include colorectum, prostate, lung, cervix, breast and skin. This module is given by several experts including Elisabetta Rapiti from the Geneva Cancer Registry at the Institute of Global Health in Geneva; Professor Antoine Flahault, who is the Head of the Institute of Global Health in Geneva; and Jean-Luc Buillard who is a Senior Lecturer in the Division of Chronic Diseases at the Institute for Social and Preventive Medicine in Lausanne. A quiz will complete this module.

Public Mental Health and Screening in Ageing
    -This module explores the topics of public mental health and screening in the ageing population for neuropsychiatric conditions and physical impairments such as hearing loss. This module is given by several experts including Emiliano Albanese, assistant professor in public mental health in the Department of Psychiatry at the University of Geneva and the Director of the WHO Collaborating Center for Research and Training in mental health at the University of Geneva; Professor Christophe Bula who is the head of the geriatric and geriatric rehabilitation service at the Vaudois University Hospital Centre; Professor Armin von Gunten who is the head of the university service for geriatric psychiatry at the Vaudois University Hospital Service. A quiz will complete this module.

Screening in Low and Middle-Income Countries and Migrants
    -The globalization of non-communicable diseases is a major challenge in low and middle income countries (LMIC). At the same time, migration is occurring between these countries and high income countries. Screening for cardiovascular diseases and for cancer in low and middle income countries will be presented and discussed.  In addition, the special consideration of screening of migrants from these countries will be addressed. This module is given by: Professor Pascal Bovet from the Division of Chronic Diseases at the Institute of Social and Preventive Medicine in Lausanne; Dr. Catherine Sauvaget from the International Agency for Research on Cancer (IARC) in Lyon, France; and Professor Patrick Bodenmann from the Polimedical University Clinic and head of the Centre for Vulnerable Populations. A quiz will complete this module.

Evaluation, Planning, Implementation and the Future of Screening Programs
    -In this final module, important aspects of for the evaluation, planning and decision making about the implementation or stopping of screening programs will be presented. This material is given by Senior lecturer Jean-Luc Bulliard who is an epidemiologist in the Division of Chronic Diseases at the Institute for Social and Preventive Medicine in Lausanne. The conclusion of the module will be a series of interviews with experts on the future of disease screening in public health conducted by Dr. Gillian Bartlett-Esquilant, a visiting professor at the Institute for Social and Preventive Medicine at Lausanne. A quiz will close this module.",Disease Screening in Public Health
https://www.classcentral.com/course/france-universite-numerique-emerging-and-re-emerging-viruses-18158,"About this MOOC/ À propos de ce MOOC Emerging and re-emerging viruses are key players among the different pathogens that have caused recent epidemics, as attested by several severe outbreaks affecting humans such as Ebola, chikungunya, influenza, Zika, dengue, SARS and MERS or outbreaks affecting animals such as rabies and bluetongue disease.  This MOOC aims to provide a fundamental knowledge about the different viruses that are involved in viral emergence and describes the associated molecular mechanisms and conditions that drive their emergence. Those range from mutations to climate change, the impact of urbanization to alterations in human behaviour.  Special attention will be given to the global “One Health” approach. The MOOC will also provide basic insights on viral epidemiology and outbreak modelling as well as on detection, early management and infection control mechanisms. It will focus on the scientific and medical measures to prevent and counteract the emergence or re-emergence of viruses, but it will also envision the response of governments and agencies such as the World Health Organization (WHO) to encounter the worldwide viral dissemination. The MOOC is built up on the profound expertise from international experts in the field of emerging and re-emerging viruses and takes advantage of the worldwide Institut Pasteur Network.   Les virus émergents, et ré-émergents constituent un élément majeur parmi les différents agents pathogènes responsables d’épidémies récentes, comme en témoignent les nombreux épisodes récents d’Ebola, chikungunya, grippe, Zika, dengue, SARS ou MERS, ainsi que les épisodes affectant les animaux tels la rage ou la fièvre catarrhale ovine. Le présent MOOC présente les différents virus impliqués dans l’émergence virale, et décrit les mécanismes moléculaires et conditions responsables d’une telle émergence. Ceux-ci s’étendent tant à l’apparition de mutations qu’aux conséquences des changements climatiques, jusqu’à l’impact de l’urbanisation et des changements d’activités et de comportements humains.  Une mention spéciale sera faite sur l’approche “Santé Globale” (“One Health”). Ce MOOC fournira également des bases d’épidémiologie virale et de modélisation des épidémies, ainsi que sur la détection, les mesures sanitaires précoces et les mécanismes de contrôle des épidémies. Il portera également sur les stratégies scientifiques et médicales pour prévenir et lutter contre l’émergence virale, et apportera une vision sur la réponse des gouvernements et agences internationales, telle l’Organisation Mondiale de la Santé (O.M.S.), pour contrer et maîtriser les épidémies. Ce MOOC s’appuie sur l’expérience reconnue d’experts internationaux dans le domaine et les activités du Réseau International des Instituts Pasteur.



            Read more
          



Course syllabus /plan du cours Chapter 1 – Introduction/Introduction  W1-1: General Introduction / Introduction générale (Albert Osterhaus, Amsterdam)   W1-2: Definition: Emerging and re-emerging /  Définitions : émergents et ré-emergents (Antoine Gessain, Institut Pasteur)  W1-3 : Principles : Vectors, Hosts, Reservoirs… / Principes : vecteurs, hôtes, réservoirs... (Anna-Bella Failloux, Institut Pasteur)  W1-4: One Health / Santé globale (Hervé Bourhy, Institut Pasteur)  Chapter 2 – Molecular mechanisms that drive viruses to be emerging or re-emerging /Mécanismes moléculaires qui conduisent à l’émergence ou la ré-émergence d’un virus /  W2-1 : Newly identified viruses /Nouveaux virus identifiés (Marc Eloit, Institut Pasteur)  W2-2 : Avian Influenza /La grippe aviaire (Jean-Claude Manuguerra, Institut Pasteur)  W2-3: Previously known viruses that acquired additional virulence traits: Influenza viruses 1 and 2 / Virus précédemment connus qui ont acquis des caractères de virulence supplémentaires: virus grippaux 1 et 2 (Sylvie van der Werf, Institut Pasteur)   W2-4: Control of the host on the virus Contrôle de l'hôte sur le virus (Carla Saleh, Institut Pasteur) Chapter 3 – Conditions that favor emergence or re-emergence of viruses/Conditions qui favorisent l’émergence ou la ré-émergence d’un virus  W3-1: Changes in urbanization, human behavior / Changements dans l'urbanisation, le comportement humain  (Pascal Handschumacher UNISTRA)   W3-2: Changes in Climate, deforestation, Natural disasters Changements climatiques, déforestation, catastrophes naturelles (Joacim Rocklöv (Université d’Umea, Sweden)   W3-3 : Coronavirus : SARS, MERS-CoV Coronavirus : SARS, MERS-CoV (Luis Enjuanes, Madrid)   W3-4: Yellow Fever Fièvre jaune (Nolween Jouvenet, Institut Pasteur)   W3-5: Hantavirus and Lassa Fever Hantavirus et fièvre de Lassa  (Noel Tordo, Institut Pasteur)   W3-6: Human-nonhuman primate contact as a driver of viral emergence Le contact humain-non humain avec les primates comme moteur de l'émergence virale  (Tamara Gilles-Vernick)   W3-7: A 20 year experience of Bluetongue circulation in Europe / Une expérience de 20 ans de la circulation de la fièvre catarrhale du mouton en Europe  (Damien Vitour)  Chapter 4 – One health/ Santé globale  W4-1: Bornavirus diseases /  Maladies à Bornavirus (Hilde Angermeier, Institut Pasteur EUPHEM)   W4-2: Nipah Virus / le virus Nipah (Birgit Nikolai)  W4-3: Dengue /  La Dengue (Marie Flamand, Institut Pasteur)  W4-4: Rift valley fever /  La fièvre de la vallée du Rift (Benjamin Brennan, Glascow)   W4-5: Crimean-Congo virus / Virus Crimée-Congo (Claudia Filippone, Institut Pasteur Madagascar)  W4-6: Hepatitis E /  L'hépatite E (Nicole Pavio, ANSES Maisons-Alfort) Chapter 5 : Epidemiology and Modelling / Epidémiologie et modélisations  W5-1: Phylogeny and viruses/ Phylogénie et virus  (Noël Tordo, Institut Pasteur)  W5-2: Epidemiology of Zika /  L'épidémiologie de Zika (Arnaud Fontanet, Institut Pasteur)   W5-3: Epidemiology of Hepatitis C in Egypt / L'épidémiologie de l'hépatite C en Egypte (Arnaud Fontanet, Institut Pasteur)  W5-4: Ebola virus outbreak: From the field to the lab /  Épidémie de virus Ebola: du terrain au laboratoire(Christophe Peyrefitte, Institut Pasteur Dakar)  W5-5: Quasispecies and viruses / Quasi-Espèces et virus (Esteban Domingo, Madrid)   W5-6: Modelling the epidemiology of viral infection / Modélisation de l'épidémiologie de l'infection virale  (Simon Cauchemez, Institut Pasteur) Chapter 6 : Detection, Early management and infection control/Détection, prise en charge et contrôle de l’infection  W6-1 : Surveillance of vectors / Surveillance des vecteurs  (Norbert Becker, Heidelberg)  W6-2 : Surveillance of viral diseases /  Surveillance des maladies virales(Harold Noël, Santé Publique France)  W6-3 : Molecular epidemiology / Epidémiologie moléculaire  (Antoine Gessain, Institut Pasteur)  W6-4 : CIBU and Arboviruses / CIBU et Arbovirus  (Jessica Vanhomwegen, Institut Pasteur)  Chapter 7 : Prevention and response/Prévention et réponse aux virus émergents EMV W7-1: Vector control activities /  Activités de contrôle des vecteurs (Norbert Becker, Heidelberg)   W7-2: Bioterrorism lessons from the past and Orthopoxvirus Antiviral strategy approach / Enseignements tirés du bioterrorisme du passé et approche stratégique des antiviraux à orthopoxvirus (Christophe Peyrefitte, Institut Pasteur Dakar)   W7-3: Preparedness /  Préparation (Marie-Paule Kieny, Inserm)  W7-4: Example: OITF of IP /  Un exemple : OITF de l'IP(Eileen Farnon/Amber Kunkel/Jean-Claude Manuguerra)   W7-5: Public health response: from science to politics /  Action de santé publique: de la science à la politique (Didier Houssin, DGS)   W7-6: Vaccines /  Vaccins (Frédéric Tangy, Institut Pasteur)  W7-7: Therapeutics/ Therapeutique  (Etienne Decroly, AFMB Polytech, Luminy)   W7-8: WHO list of blueprint priority diseases /  Liste OMS des maladies prioritaires (Marie-Paule Kieny, WHO)",Emerging and re-emerging viruses
https://www.classcentral.com/course/mobile-interaction-design-8643,"Every mobile app gives you something. It could be not only something tangible like the pair of jeans you've ordered using the app but also a piece of work like waking you up in the morning. It could be a feeling, for instance, a feeling of enjoyment obtained from watching a video clip or a feeling of closeness flashed out after receiving an old photo from a loving person via some instant messenger. That ""something"" is actually the reason why you use the app, it is the heart of the product, and in this course we will not talk about it. Surprised? You shouldn’t be. There are always two sides of a coin. There should be a person who makes that ""something"" accessible. It is astonishingly important because the use of the product loses its meaning if users can’t get what they want.

The main objective of the course is to teach you to shape mobile products and services for people’s use. To do that, you’ll need to learn:
- Interaction design activities and their place in the whole product design process
- User research methods with a focus on the qualitative ones
- Usability inspection and empirical usability evaluation methods
- The process of design creation and best practices from interaction design, information architecture and visual design fields of study with a focus on the former
Interfaces of handheld devices and tablets are in the spotlight. However, the processes and techniques covered by the course can be successfully applied to design interactions with mobile web apps and wearables. It should be noted that this course does not cover topics such as design management and mobile development, and it will as well not teach you how to use wireframing and prototyping tools.

What makes the course unique is a focus on the way of thinking during a design process, the representation of a designer’s decisions in the form of design questions that make the continuous reflection on the design process possible and leads to the growth of the number of proposed design alternatives. The second unique thing about this course is a focus on the explanation of the concept of usability problems, and the processes of discovering and analysing them.

Upon completion of the course, you will be able to:
- Improve designs by eliminating different kinds of interaction problems
- Design huge chunks of user interfaces in the case of adding a new feature to a product
- Redesign a complete app by a given set of functions (e.g., extending an existing product to a new platform)

The practical part of the course will require you to discover and eliminate interaction problems of a chosen mobile app. You will go through running guerrilla usability study, analysing gathered data, and making evidence-based design changes, which will enable you to create your first case study.

This course was designed for those who are involved in creating digital interactive products (not necessarily for mobile) but do not have considerable experience in interaction design. If you are a UX professional in a junior position, a developer, manager or visual designer, this class is for you. This is not an introductory level course, so if you are new to the field, we recommend you take the “Introduction to User Experience Design” course from Georgia Institute of Technology before taking this one. Also, parts of this course such as the aforementioned process of design creation and approach to usability inspection can be useful for experienced designers.

Do you have technical problems? Write to us: coursera@hse.ru
      


            Read more
          



          WEEK 1: Mobile Interaction Design: An introduction
    -The first week is introductory in nature. It examines the place of interaction design activities in the whole product design process as well as essential concepts such as usability and the context of use that you need to comprehend before proceeding to the next week. At the end of this week, you’ll also get acquainted with such thing as design-informing models and learn how to create personas that I recommend you to do while working on your practical task.

WEEK 2: User Research
    -This week gives you the whole idea of ​​the methods used for studying the context of use. It also examines how to look for participants in detail, plan and conduct Cooper's ethnographic interviews and qualitative data analysis. This knowledge will enable you to drill down into the usage context of the mobile app you’ve chosen.

WEEK 3: Usability Inspection Methods & Intro to Usability Evaluation
    -The third week covers the overview of usability evaluation methods, the examination of essential usability evaluation concepts and models such as user interface idioms, Norman’s Stages-of-action model, usability problems and so on, as well as detailed discussion of several usability inspection methods including Cognitive walkthrough, Scenario-based walkthrough, and design reviews. At the end of this week, you’ll learn how to make sense of data gathered through formative usability evaluation methods. Here you can find the first graded peer-review assignment dedicated to forming recruitment criteria for guerrilla usability tests you’ll conduct later.

WEEK 4: Guerrilla Usability Testing & Field Visits
    -This week is solely dedicated to two methods: Guerrilla usability testing and field visits aimed at evaluating usability. It examines how to plan and conduct them in detail. You’ll apply the knowledge acquired through this week to develop a test plan and submit it as a part of the second graded peer-review assignment.

WEEK 5: The Process of Design Creation
    -The process of design creation is a structured way to come up with as many interaction design solutions as possible which are designed to support your creativity. In combination with the appropriate way of selecting among the solutions examined in this week too, the process enables you to find the most usable solutions within existing constraints. This week examines the process of design creation and all related topics in detail.

WEEK 6: Accumulated Design Knowledge & Task Redesign
    -Designers base their solutions on design decisions already made by their fellow designers. This week is dedicated to the discussion of the knowledge that is already there and where to find it. In this week you’ll also learn basic design principles and examine the aspect that is very important for mobile interaction design: How to redesign user tasks. This week you will need to conduct the guerrilla usability testing according to the plan you have and record all its sessions. Some of these recordings may be submitted as part of the optional peer-review assignment. This will allow you to get feedback on how you moderated the study.

WEEK 7: Navigation Design & Design Rationale
    -The organisation of a mobile user interface and navigation between its parts is a crucial aspect of mobile interaction design. The first part of this week examines different iOS and Android navigational patterns and their application in real world context. At the end of this week, you’ll learn how to write design rationale, an explicit justification of decisions behind an interaction design. This knowledge will enable you to complete the last graded peer-review assignment in one of the following weeks.

WEEK 8: Intro to Visual Design
    -Designing aesthetically pleasant user interfaces is no less important than designing usable interfaces. This week is solely dedicated to the former. You’ll learn how to choose and customise types, apply different types of colour schemes, select and use images, create a sign and design a harmonious layout of the mobile screen. Here you can find the peer-review assignment dedicated to the analysis of data gathered through guerrilla usability testing.

WEEK 9: Catch Up Week
    -This week has no theoretical material and is designed to give you time to work on your practical task.

WEEK 10: Final Week
    -This week includes the last graded peer-review assignment that is dedicated to the elimination of interaction problems found earlier.",Mobile Interaction Design: How to Design Usable Mobile Products and Services
https://www.classcentral.com/course/javascript-jquery-json-9568,"In this course, we'll look at the JavaScript language, and how it supports the Object-Oriented pattern, with a focus on the unique aspect of how JavaScript approaches OO. We'll explore a brief introduction to the jQuery library, which is widely used to do in-browser manipulation of the Document Object Model (DOM) and event handling. You'll also learn more about JavaScript Object Notation (JSON), which is commonly used as a syntax to exchange data between code running on the server (i.e. in PHP) and code running in the browser (JavaScript/jQuery).

It is assumed that learners have already taken the Building Web Applications and Building Database Applications in PHP courses in this specialization.
      


          Introduction to JavaScript
    -We take a quick look at the JavaScript language. We assume that you already know PHP - so it is a pretty quick introduction focusing on what is different about JavaScript.

JavaScript Objects
    -We do a quick look at how the JavaScript language supports the Object-Oriented pattern.  This is the second time we look at the OO pattern so we focus on the unique aspect of how JavaScript approaches OO.

Using JQuery
    -This is a brief introduction to the JQuery library which is widely used to do in-browser manipulation of the Document Object Model(DOM) and event handling.

JSON - JavaScript Object Notation
    -In this section we look at JavaScript Object Notation (JSON). JSON is commonly used as a syntax to exchange data between code running on the server (i.e. in PHP) and code running in the browser (JavaScript/JQuery).","JavaScript, jQuery, and JSON"
https://www.classcentral.com/course/edx-introduction-to-water-and-climate-2157,"Water is essential for life on Earth and of crucial importance for society. Water also plays a major role in affecting climate. Its natural cycle, from ocean to atmosphere by evaporation, then by precipitation back to land returning via rivers and aquifers to the oceans, has a decisive impact on regional and global climate patterns.
For students of engineering, climate science and environmental studies, this course offers a first introduction to the physics of water systems and their role in climate. In addition, we show you the state-of-the-art engineering interventions that can be applied to water systems. These can improve coastal safety and increase the availability of water supplies worldwide.
The course welcomes students from all over the globe, so we actively encourage discussion of water and climate issues you may experience in your location, now and in the coming decades.
After taking this course, you will be able to:

Understand the different processes at play in the global water cycle.
Identify and describe the flows of water and sand in different riverine, coastal and ocean systems.
Identify mechanisms of climate change and explain the interplay between climate change, sea level, clouds, rainfall and future weather.
Explain why, when and which engineering interventions are needed in rivers, coastal and urban environments.
Explain why water for food and water for cities are the main challenges in water management and propose solutions.
Explain and confront the challenges in better understanding and adapting to the impact of climate change on water over the coming 50 years.

The course consists of knowledge clips, movies, exercises, and exam assignments. There are opportunities to discuss course materials with your fellow students and the Course Team through our online forum. We also provide interactive feedback video sessions in which the lecturers discuss issues raised by students.
Delft University of Technology (TU Delft) has a unique reputation when it comes to water and climate, with faculty experts in the fields of climate research, water management and hydraulic engineering. The course introduces you to many aspects of water and climate: from the micro scale of raindrops to the macro scale of oceans, and from understanding the physics of the different water systems to practical engineering solutions that may help societies adapt to the present and future impacts of climate change on water.
Together with the courses ""Drinking water treatment"" and ""Urban Sewage Treatment"" this course forms the Water XSeries, from the Faculty of Civil Engineering and Geosciences at TU Delft.



            Read more",Introduction to Water and Climate
https://www.classcentral.com/course/planning-climate-change-african-cities-9146,"Climate change poses a threat to economic growth and long-term prosperity of many countries around the world. Africa is not an exception, considering the actual and potential impacts of climate change and climate variability that will threaten its vulnerable sectors and human populations. African countries are projected to experience changing rainfall patterns, rising sea levels, and higher temperatures that will affect food security, agricultural production, water availability, and public health, among others. These climate change impacts and climate variability can further produce social and political problems, such as rural-urban migration and water resource disputes.   

Furthermore, the low levels of development in many African countries, as well as limited institutional, infrastructural, and technical capacities to respond successfully to climate change impacts and climate variability, can exacerbate the situation. In terms of contribution to greenhouse gas (GHG) emissions, although African countries are the lightest polluters, it has also become apparent that alternative energy sources can offset the increasing energy demand and dependence on biomass. Addressing climate change offers possibilities for low-carbon development. Moreover, there are promising mechanisms that can address both climate change actions and development goals simultaneously. 

At the city level, strengthening resilience, or the ability to respond to and absorb the effects of a hazardous event in a timely and efficient manner and to sustain this ability in the future, and adaptation; the process of adjusting to actual or expected climate change stimuli or their effects, should be at the forefront of planning.  Local governments have an important role to play through the provision of adequate infrastructure, regulation of land use, and other public services that are crucial for urban resilience. Mobilizing local governments, in collaboration with national governments, non-governmental organizations, and international organizations, among others, is also critical for an integrated multi-sectoral approach to climate change. 

The Course on Planning for Climate Change in African Cities provides the foundation for understanding cities’ exposure and sensitivity to climate change, and how cities can manage these impacts in the face of growing uncertainty. It does so by introducing the basic concepts of urban resilience and adaptation, by using illustrative case studies in different African cities. Furthermore, this module provides lectures on the different approaches for climate change planning, whether ad hoc, strategic or mainstreaming; introduces the different steps in the planning cycle – from initial assessment to monitoring and evaluation; and presents the different decision support and assessment tools for prioritizing climate change actions. This course broadens the discussion on planning for climate change by engaging learners to apply their knowledge and practice their decision-making skills in a simulated exercise.

In line with development that minimizes the harm caused by climate change impacts, while maximizing the many human development opportunities presented by a more resilient future, we ask: what are the connections between urban risk and vulnerability? How is climate change and urban resilience conceptualized and applied in practice? Which policies and measures should be introduced to address climate change? Finally, how to choose among different measures that address climate change adaptation, urban resilience, and other development objectives? 

Course Objectives:
At the end of this course, learners should be able to:

•	Recognize the effects, impacts, and drivers of climate change in cities
•	Understand the drivers of urban risk and vulnerability in the context of climate change 
•	Distinguish the typologies, approaches, and tensions of climate change adaptation 
•	Explain the different approaches and steps in climate change planning 
•	Examine the decision support and assessment tools for climate change
•	Develop a climate change plan based on participants’ city contexts
      


            Read more
          



          Welcome to the Course

Climate Change and Cities
    -This week provides an introduction to climate change and what this means for cities around the world. First, we provide some background on climate change science. Next, we move onto the sources, effects and impacts of climate change globally. After this, we focus on what a changing climate means for all cities around the world, concentrating on the influence cities have had on climate change and how these activities have increased greenhouse gas emissions. We will see how they are already changing cities as we know them, with examples from the African continent. Lastly, this module will discuss climate change policies on an international scale, focusing on climate change negotiations and global policy making.

Defining and Assessing Urban Risk and Vulnerability
    -Climate Change Vulnerability is a concept that evolved in science in order to include the multiple risks that cities, populations or ecosystems are facing from various sources, including climate change but without discounting the role that existing and future socio-economic and political conditions play. In the first video you will understand the evolution of the concept of climate vulnerability and distinguish between different forms of vulnerability.  Social Vulnerability refers to the distinction between the biophysical and human dimensions of vulnerability. This distinction is important because it emphasizes the characteristics of people and social groups that make them more or less vulnerable to climate change hazards and that also influence their ability to respond. In the second video you will understand what are these factors and will be able to assess certain hazards and their risk factors for social vulnerability. Social Vulnerability to climate change can be operationalized, i.e. assessed or calculated for a given region or population. Scholars have developed different methods to do so. In the third video you will learn about two most of the most common approaches to calculating Social Vulnerability, which is often done with a composite index and mapping. An example from a Social Vulnerability Assessment in Southern Africa will be used as case study. The fourth video identifies some of the main hazards facing African urban centres, and then explores the drivers of vulnerability for individuals, groups of urban residents, and cities. It concludes that both external threats and internal factors will shape the experiences of African cities in a context of climate change. 

Climate Change Adaption and Resilience
    -Climate change policy – including both mitigation and adaptation - has become an essential component of urban policy. Cities around the world are beginning to understand the progress that can be made by managing policies that already exist, such as civil protection, health management, urban design and planning. The first video will briefly explain the differences between adaptation in natural and human systems and then focus, by means of examples, on one of the two typologies of adaptation that is reactive adaptation. In contrast to reactive adaptation, done in reaction to a disaster event, anticipatory adaptation involves deliberate policy decision based on the awareness that conditions have changed or are expected to change. In the second video several examples of anticipatory adaptation are presented in different countries across the world. The concept of autonomous adaptation, or adaptation done without any government support by citizens, is also introduced. The intention is that of showing how proactive, long term decisions about adaptation are overall less expensive than reactive, short term ones.Climate change costs and impacts are not evenly spread across countries. The third video will explain the underlying reasons for this divide rooted in political and socio-economic differences among countries influencing their ability to ultimately recover from disasters and put in place strategies to anticipate climate impacts. Based on the choice of adaptation frameworks the lecture will also explain what are some of the factors that influence what successful adaptation may look like. Climate resilience is a component of climate adaptation. There are at least 25 definitions of urban resilience in the academic literature. Although this signifies that urban resilience is a thriving topic in the field of urban studies, there are concerns that it is becoming an empty term. How can climate adaptation be related to urban resilience and what are the conceptual tensions surrounding the implementation of this desired characteristic on the ground? The fourth video will try to answer these questions by illustrating three of the six conceptual tensions present in urban climate resilience. The fifth video illustrates the last three tensions in applying the concept of urban climate resilience on the ground. It also illustrates some of the existing urban climate resilience frameworks developed by donor and multi-later agencies, explaining in more depth the components of climate resilience as understood by the Urban Resilience Framework developed by the Institute for Social and Environmental Transition-International, a comprehensive framework for resilience building. Many of the issues driving risk, and that need to be addressed to ensure adaptation, cut across geographical boundaries and sectors. Addressing these issues requires what is often referred to as multi-level governance. The sixth video will introduce the concepts of multi-level governance and adaptive governance, which will help you to make practical suggestions about appropriate strategies for urban climate change adaptation. The way in which decisions are made in cities has a significant impact on the way in which risk is addressed and the success of adaptation. Urban governance is not only a matter for local authorities, but involves a wide range of linkages within the city, from civil society to the private sector, and outside the city, from national to global institutions. The seventh video describes some of the key actors involved in governance for adaptation and risk, explores the relationships that they have to each other, and provides examples of different governance strategies that have proven successful in this area.

Planning for Climate Change
    -In previous videos, you have learnt about the impacts of climate change in cities. We have two main activities to undertake in order to reduce these impacts, namely mitigation and adaptation. In week four, we focus on the process of planning for climate change in cities. This series of videos discusses the planning approaches that cities can take to mitigate and adapt to climate change. Planning plays a key role in helping our cities to reduce greenhouse gas emissions and minimize vulnerability to the impacts of climate change. 
First, we introduce the approaches to planning, namely ad-hoc, strategic, and mainstreaming. Then we discuss the main steps of planning for climate change, from greenhouse gas emissions inventory and vulnerability assessments to setting of objectives and targets, assessment, selection, and implementation of measures, and lastly, monitoring and evaluation.  Additionally, we provide practical examples of both climate change mitigation and adaptation planning in African cities. In video 7 you will learn that even the best-laid plans do not work sometimes. There can be barriers along the way and this video provides you with knowledge regarding the existing barriers of implementing these actions in practice. Finally, in video 8, we also highlight the guiding principles for city climate action planning. 

Decision Making Analysis for Climate Change
    -Choosing the right mixture of measures and policies for the short and long term is challenging both in technical and political terms. Which approaches and techniques will work best in order to investigate and assess measures and actions at the city and neighborhood level? This leads to the evaluation and assessment of urban climate change policies/actions as important elements of an effective urban climate change planning approach. Developing, adjusting and applying the appropriate decision support tools to assess and evaluate climate change policies and measures is deemed necessary in order to help urban planners to design a climate resilient and sustainable urban development path.
This week we introduce decision making analysis for climate change issues. First, we introduce the different decision support and assessment tools, namely cost benefit analysis, cost effectiveness analysis, and multiple criteria analysis. We explore the use of cost effectiveness analysis for adaptation and then provide an economic case for low carbon development with an actual case study in Kigali, Rwanda.
Among the different tools, we would specifically focus on the multiple criteria analysis approach which has been widely used in environmental and climate change assessment and decision making on prioritizing different policies, actions, measures against multiple criteria. Often climate change actions generate multiple sustainability benefits (co-benefits) other than purely environmental related ones. Cities should explore how to incorporate these multiple sustainability benefits of actions in their decision making. 


Final Assessment: Developing a Climate Change Action Plan",Planning for Climate Change in African Cities
https://www.classcentral.com/course/edx-paradigms-of-computer-programming-1487,"*Note - This is an Archived course*
This is a past/archived course. At this time, you can only explore this course in a self-paced fashion. Certain features of this course may not be active, but many people enjoy watching the videos and working with the materials. Make sure to check for reruns of this course.
This course gives an introduction to all major programming concepts, techniques, and paradigms in a unified framework. We cover the three main programming paradigms: functional, object-oriented, and declarative dataflow. We explain the four ways to do data abstraction and discuss the trade-offs between objects and abstract data types. We present declarative dataflow, the most useful paradigm for concurrent programming, and show how it avoids race conditions. We give a simple formal semantics for all concepts and illustrate them with practical code that runs on the accompanying open-source platform, the Mozart Programming System. This course is targeted toward people with a basic knowledge of programming. It will be most useful to beginning programming students, but the unconventional approach should be insightful even to seasoned professionals.
To learn more about the practical organization of the course, watch our second introductory video: http://youtu.be/M0Dlswd_hIQ
All required readings are available within the courseware, courtesy of The MIT Press. A print version of the course textbook, Concepts, Techniques, and Models of Computer Programming, is also available for purchase. The MIT Press is offering enrolled students a special 30% discount on books ordered directly through the publisher’s website. To take advantage of this offer, please use promotion code CTMCP30 at The MIT Press site.
Before, during, and after the course, check out the course's official Facebook page for announcements and discussions.
At the end of this course, the successful participant will be able to :

Specify problems, break them down into their basic steps, and design algorithms and abstractions to solve them
Choose the right programming paradigm and write a program in this paradigm to solve a problem
Use formal semantics to reason about program correctness
Write small concurrent programs in the deterministic dataflow paradigm




            Read more",Paradigms of Computer Programming
https://www.classcentral.com/course/edx-introduction-to-machine-learning-19081,"Want to learn how to analyze the huge amounts of data? In this course you will learn modern methods of machine learning to help you choose the right methods to analyze your data and interpret the results correctly.
This course is an introduction to machine learning. It will cover the modern methods of statistics and machine learning as well as mathematical prerequisites for them. We will discuss the methods used in classification and clustering problems. You will learn different regression methods.
Various examples and different software applications are considered in the course. You will get not only the theoretical prerequisites, but also practical hints on how to work with your data in MS Azure.



Week 1: Introduction to machine learning and mathematical prerequisites. The concepts of machine and statistical learning are introduced. We discuss the main branches of ML such as supervised, unsupervised and reinforcement learning, give specific examples of problems to be solved by the described approaches. Besides, we show that ML is not as powerful as one can think. Finally, we remind you of some basic concepts of mathematics used in further lectures.
Week 2: Regression (linear, polynomial, multivariable regression). Regression problem is one of the main problems in supervised learning. We start with the heuristic approach trying to solve a very practical problem and come to rigorous mathematical construction of the simple linear regression model. We go further and describe statistical properties of the model: confidence intervals for the model's parameters, hypothesis testing of linear dependence. Finally, we come to a so-called multivariable linear and polynomial regressions and show some examples and applications.
Week 3: Logistic regression. The second branch of supervised learning is a classification problem. We deal with a two-class logistic regression and emphasise that it is not a regression at all. Then why is it called so? It's construction is closely connected with linear regression described in the 2nd lecture. We remind you a maximum likelihood estimation method and its applications to logistic regression. Finally, we discuss some applications of the logistic regression to a football game predictions and describe ROC analysis or a quality testing approach for the described model.
Week 4: Naïve Bayes and K-nearest neighbours. In this lecture we continue with classification problem. We introduce a so-called naive Bayes approach to classification widely used in e-mail spam recognition until 2010. Then we come to a multi-class classification using K-nearest neighbours method. What are the metrics that we will use? How does a particular metric influences the result? What is K and how do you choose it solving a particular problem? These are the questions that are rigorously discussed in the lecture.
Week 5: Clustering methods: hierarchical and k-means clustering. Clusterization problem is at the heart of unsupervised learning. We have a lot of data and nothing else: we don't know the amount of classes, similarities in objects, we know almost nothing. We show how to establish some order in the given chaotic data using hierarchical clustering method and k-means approach. How to establish the initial clusters, what metric to choose, what actually means ""close and far"" objects? These questions are discussed in the lecture.",Introduction to Machine Learning
https://www.classcentral.com/course/edx-quantum-mechanics-and-quantum-computation-367,"Quantum computation is a remarkable subject building on the great computational discovery that computers based on quantum mechanics are exponentially powerful. This course aims to make this cutting-edge material broadly accessible to undergraduate students, including computer science majors who do not have any prior exposure to quantum mechanics. The course starts with a simple introduction to the fundamental principles of quantum mechanics using the concepts of qubits (or quantum bits) and quantum gates. This treatment emphasizes the paradoxical nature of the subject, including entanglement, non-local correlations, the no-cloning theorem and quantum teleportation. The course covers the fundamentals of quantum algorithms, including the quantum fourier transform, period finding, Shor's quantum algorithm for factoring integers, as well as the prospects for quantum algorithms for NP-complete problems. It also discusses the basic ideas behind the experimental realization of quantum computers, including the prospects for adiabatic quantum optimization and the D-Wave controversy.
Before your course starts, try the new edX Demo where you can explore the fun, interactive learning environment and virtual labs. Learn more.
Do I need a textbook for this class?
No. Notes will be posted each week. If you wish to consult other references, a list of related textbooks and online resources will be provided.
What is the estimated effort for course?
About 5-12 hrs/week.
Why is the work load range so wide?
How long you spend on the course depends upon your background and on the depth to which you wish to understand the material. The topics in this course are quite open ended, and will be presented so you can understand them at a high level or can try to follow it at a sophisticated level with the help of the posted notes.
How much does it cost to take the course?
Nothing! The course is free.
Will the text of the lectures be available?
Yes. All of our lectures will have transcripts synced to the videos.
Do I need to watch the lectures live?
No. You can watch the lectures at your leisure.



            Read more",Quantum Mechanics and Quantum Computation
https://www.classcentral.com/course/logical-fallacies-6621,"How to Avoid Fallacies

Think Again: How to Reason and Argue
Reasoning is important. This series of four short courses will teach you how to do it well. You will learn simple but vital rules to follow in thinking about any topic at all and common and tempting mistakes to avoid in reasoning. We will discuss how to identify, analyze, and evaluate arguments by other people (including politicians, used car salesmen, and teachers) and how to construct arguments of your own in order to help you decide what to believe or what to do. These skills will be useful in dealing with whatever matters most to you.

Courses at a Glance:
All four courses in this series are offered through sessions which run every four weeks. We suggest sticking to the weekly schedule to the best of your ability. If for whatever reason you fall behind, feel free to re-enroll in the next session.We also suggest that you start each course close to the beginning of a month in order to increase the number of peers in the discussion forums who are working on the same material as you are. While each course can be taken independently, we suggest you take the four courses in order.

Course 1 - Think Again I: How to Understand Arguments
Course 2 - Think Again II: How to Reason Deductively
Course 3 - Think Again III: How to Reason Inductively
Course 4 - Think Again IV: How to Avoid Fallacies

About This Course in the Series:
We encounter fallacies almost everywhere we look. Politicians, salespeople, and children commonly use fallacies in order to get us to think what they want us to think. Think Again: Fallacies will show how to identify and avoid many of the fallacies that people use to get us to think the way they want us to think.

In this course, you will learn about fallacies. Fallacies are arguments that suffer from one or more common but avoidable defects:  equivocation, circularity, vagueness, etc. It’s important to learn about fallacies so that you can recognize them when you see them, and not be fooled by them. It’s also important to learn about fallacies so that you avoid making fallacious arguments yourself.

Suggested Readings
Students who want more detailed explanations or additional exercises or who want to explore these topics in more depth should consult Understanding Arguments: An Introduction to Informal Logic, Ninth Edition, Concise, Chapters 13-17, by Walter Sinnott-Armstrong and Robert Fogelin.

Course Format
Each week will be divided into multiple video segments that can be viewed separately or in groups. There will be short ungraded quizzes after each segment (to check comprehension) and a longer graded quiz at the end of the course.
      


            Read more
          



          Welcome to the Course
    -Welcome to Think Again: How to Avoid Fallacies!  This course is the fourth in a series of four courses jointly titled Think Again: How to Reason and Argue. We are excited that you are taking this course, and we hope that you will take all four courses in the series, because there is a great deal of important material to learn. In the series as a whole, you learn how to analyze and evaluate arguments and how to avoid common mistakes in reasoning. These important skills will be useful to you in deciding what to believe and what to do in all areas of your life. We encounter fallacies almost everywhere we look. Politicians, salespeople, and children commonly use fallacies in order to get us to think what they want us to think. Think Again: How to Avoid Fallacies will show how to identify and avoid many of the fallacies that people use to get us to think the way they want us to think. The first part of this course introduces the series and the course. It also clarifies some peculiarities you may find with this course. We encourage you to watch the ""Introduction to the Course"" video first as it will help you learn more from the materials that come later.

Fallacies of Unclarity 
    -CONTENT: In this week's material we will describes two phenomena that are both common and useful in the languages that human beings speak, but both of which give rise to the potential for fallacious reasoning.  A word or phrase is vague when its meaning is not precise, and it is ambiguous when it has more than one meaning.  When we use vague or ambiguous phrases in our reasoning, it is very easy for us to make a number of different kinds of fallacies.  This week will teach you what these different kinds of fallacies are, and give us some practice in spotting them, so you can make sure to avoid them in the future. LEARNING OUTCOMES : By the end of this week's material you will be able to: define what a fallacy is distinguish various kinds of fallacies understand the linguistic phenomena that give rise to fallacies identify various kinds of slippery slop fallacies where they occur identify various kinds of fallacies of equivocation where they occur OPTIONAL READING: If you want more examples or more detailed discussions of the fallacies that result from vaguness or ambiguity, we recommend Understanding Arguments, Ninth Edition, Chapters 13-14.

Fallacies of Relevance
    -CONTENT: This week describes two of the most common fallacies that people make:  ad hominem fallacies and appeals to authority.  Part of what makes these fallacies so common, and so difficult to avoid, is that many ad hominem arguments, and many appeals to authority, are actually not fallacies at all!  Only some of them are.  And figuring out which of them are fallacies is more of an art than a science.  There is no simple recipe, but there are some rules of thumb you can use.  We hope that the practice that you get in this week will help you to improve your skills at distinguish the fallacious from the non-fallacious instances of ad hominem reasoning, as well as appeal to authority. LEARNING OUTCOMES: By the end of this section you will be able to: determine whether an ad hominem argument is a fallacy determine whether an appeal to authority is a fallacy OPTIONAL READING: If you want more examples or more detailed discussions of these topics, we recommend Understanding Arguments, Ninth Edition, Chapter 15.

Fallacies of Vacuity and Circularity 
    -CONTENT: Now we will describe another common set of fallacies:  fallacies that occur when an argument makes no progress from its premises to its conclusion.  Sometimes, arguments make no progress because the conclusion is already contained in the premises.  Sometimes, arguments make no progress because the conclusion is presupposed by the premises.  And sometimes, arguments make no progress because the premises don’t make any claim at all, even if they might sound like they do.  When you know how to identify such fallacies, you will find that they are more common than you think! LEARNING OUTCOMES: By the end of this section you will be able to: identify various kinds of circularity or vacuity where they occur OPTIONAL READING: If you want more examples or more detailed discussions of these topics, we recommend Understanding Arguments,Ninth Edition, Chapter 16.

Refutation: Its Varieties and PItfalls
    -CONTENT: This week we will teach you various strategies for refuting a fallacious argument.  To refute an argument is to show that the argument is unsuccessful.  Even if you are able to identify a fallacious argument as a fallacy, you might still not be able to prove to others that it is a fallacy.  In this week, you will learn a variety of techniques for proving to others that the argument is a fallacy. LEARNING OUTCOMES: By the end of this week you will be able to: refute fallacious arguments OPTIONAL READING: If you want more examples or more detailed discussions of these topics, we recommend Understanding Arguments, Ninth Edition, Chapter 17.

Catch-Up and Final Quiz
    -This week gives you time to catch up and review, because we realize that the previous weeks include a great deal of challenging material. It will also be provide enough time to take the final quiz as often as you want, with different questions each time. We explain the answers in each exam so that you can learn more and do better when you try the exam again. You may take the quiz as many times as you want in order to learn more and do better, with different questions each time. You will be able to retake the quiz three times every eight hours. You might not need to take more than one version of the exam if you do well enough on your first try. That is up to you. However many versions you take, we hope that all of the exams will provide additional learning experiences.",Think Again IV: How to Avoid Fallacies
https://www.classcentral.com/course/independent-deep-learning-for-natural-language-processing-8097,"This is an advanced course on natural language processing. Automatically processing natural language inputs and producing language outputs is a key component of Artificial General Intelligence. The ambiguities and noise inherent in human communication render traditional symbolic AI techniques ineffective for representing and analysing language data. Recently statistical techniques based on neural networks have achieved a number of remarkable successes in natural language processing leading to a great deal of commercial and academic interest in the field
This will be an applied course focussing on recent advances in analysing and generating speech and text using recurrent neural networks. We will introduce the mathematical definitions of the relevant machine learning models and derive their associated optimisation algorithms. The course will cover a range of applications of neural networks in NLP including analysing latent dimensions in text, transcribing speech to text, translating between languages, and answering questions. These topics will be organised into three high level themes forming a progression from understanding the use of neural networks for sequential language modelling, to understanding their use as conditional language models for transduction tasks, and finally to approaches employing these techniques in combination with other mechanisms for advanced applications. Throughout the course the practical implementation of such models on CPU and GPU hardware will also be discussed.
This course will be lead by Phil Blunsom and delivered in partnership with the DeepMind Natural Language Research Group. Example lecturers include:

Phil Blunsom (Oxford University and DeepMind)
Chris Dyer (Carnegie Mellon University and DeepMind)
Edward Grefenstette (DeepMind)
Karl Moritz Hermann (DeepMind)
Andrew Senior (DeepMind)
Wang Ling (DeepMind)
Jeremy Appleyard (NVIDIA)

Learning outcomes
After studying this course, students will:

Understand the definition of a range of neural network models;
Be able to derive and implement optimisation algorithms for these models
Understand neural implementations of attention mechanisms and sequence embedding models and how these modular components can be combined to build state of the art NLP systems.
Have an awareness of the hardware issues inherent in implementing scalable neural network models for language data.
Be able to implement and evaluate common neural network models for language.

Prerequisites
This course will make use of a range of basic concepts from Probability, Linear Algebra, and Continuous Mathematics. Students should have a good knowledge of basic Machine Learning, either from an introductory course or practical experience. No prior linguistic knowledge will be assumed. The course will contain a significant practical component and it will be assumed that participants are proficient programmers.
Synopsis
This course will cover a subset of the following topics:

Introduction/Conclusion: Why neural networks for language and how this course fits into the wider fields of Natural Language Processing, Computational Linguistics, and Machine Learning.
Simple Recurrent Neural Networks: model definition; the backpropagation through time optimisation algorithm; small scale language modelling and text embedding.
Advanced Recurrent Neural Networks: Long Short Term Memory and Gated Recurrent Units; large scale language modeling, open vocabulary language modelling and morphology.
Scale: minibatching and GPU implementation issues.
Speech Recognition: Neural Networks for acoustic modelling and end-to-end speech models.
Sequence to Sequence Models: Generating from an embedding; attention mechanisms; Machine Translation; Image Caption generation.
Question Answering: QA tasks and paradigms; neural attention mechanisms and Memory Networks for QA.
 Advanced Memory: Neural Turing Machine, Stacks and other structures.
Linguistic models: syntactic and seminatic parsing with recurrent networks.
Syllabus
Recurrent Neural Networks, Backpropagation Through Time, Long Short Term Memory, Attention Networks, Memory Networks, Neural Turing Machines, Machine Translation, Question Answering, Speech Recognition, Syntactic and Semantic Parsing, GPU optimisation for Neural Networks
Reading list
As the material covered in this course is based on recent research results there is not a relevant textbook for the area. The readings for the course will thus be based on published papers and online material. 



            Read more",Deep Learning for Natural Language Processing
https://www.classcentral.com/course/microsoft-introduction-to-computer-science-18416,"Please note on June 30, 2020, this program will be retiring and no longer available on edX. If you are interested in earning the Professional Certificate you must complete the program by June 30, 2020, in order to earn the certificate. 
Millions of people use computers every day but few understand how computers do what they do. Even if you don’t plan to be a professional programmer, you’ll benefit from understanding the very basics of digital machines and from learning to write basic programs in a managed but powerful environment. By understanding how a computer works and learning to think logically, you’ll write better programs and be able to troubleshoot technical problems more easily.
This Professional Certificate will start you at the absolute beginning teaching you about the fundamental binary language of modern computers. You’ll learn about the Turing Machine—a model for the digital computer. You’ll also learn the basics of analytic logic and how learning and applying basic principles of logic can help you both work with and work on technical solutions. You’ll work in a managed environment and learn to code your very first program in Python – a powerful but simple programming language used by app developers and data scientists.
You’ll be able to monitor your progress through regular assessments and hands-on projects will give you the foundational experiences you need to understand modern digital machines. The exercises and assessments will help you continually evaluate your learning and help you focus on the areas where you need to improve your skills. The courses in this certificate program will provide you with a solid foundation for working with computers in any field.



            Read more
          



Courses under this program:Course 1: Introduction to Python: Absolute Beginner
In this course that's perfect for true beginners, learn Python basics and start coding right away.
Course 2: Introduction to Python: Fundamentals
Build on what you learned in the ""Introduction to Python: Absolute Beginner"" course, and dig into data structure basics.
Course 3: Logic and Computational Thinking
Build a solid foundation for programming by learning basic logic and exploring how logic forms the foundation of computer programs.",Introduction to Computer Science
https://www.classcentral.com/course/science-behind-forensic-science-11765,"Discover the biology and chemistry behind forensic science
How does forensic science really work? How are scientific principles applied in crime scenes? Answer these questions and more with this course from the team who teach the longest-running forensic science programme of its type in England.
On the course you will get an introduction to the chemistry and biology of forensic science. You will examine the methods used in forensic science and learn about how these technique are used in crime scenes and explained in the court room.
This course is for anyone interested in discovering more about forensic science. It will be especially useful if you’re thinking of studying forensic science in the future or if you work in a field related to forensic science (for example law or the police force) and want to find out more.",The Science Behind Forensic Science
https://www.classcentral.com/course/smart-cities-6479,"Learn about Smart Cities within the context of management of urban infrastructures. The introduction of Smart urban technologies into legacy infrastructures has resulted in numerous challenges and opportunities for contemporary cities and will continue to do so. This course will help you to understand how to make the best of these smart technologies in your cities’ legacy infrastructures.  
Over the past few years, advances in the Information and Communication Technologies (ICTs) have significantly challenged the traditionally stable land scape of urban infrastructure service provision. This has resulted in increasing interest from both technology vendors and public authorities in the transition of cities towards so-called “Smart Cities”. Although such “Smart technologies” can provide immense opportunities for citizens and service providers alike, the ICTs often act as disruptive innovators of urban infrastructure service provision.
In this MOOC, you will gain a thorough understanding of the challenges and opportunities associated with the Smart urban infrastructures, namely Smart urban transportation and Smart urban energy systems. Over the journey of this 5-week online course you will learn about the most important principles for the management of Smart urban infrastructures as well as the applications of these principles in the transportation and energy sectors. 
This course does not have any prerequisites. However, to take the most away from of this MOOC, we strongly encourage you to enroll in our other MOOC on the Management of Urban Infrastructures, which has been widely praised by learners. 
Through this course, you will:
- Gain a deep understanding of the nature of disruptive innovations (smart technologies) in urban infrastructure systems;
- Learn about state-of-the-art strategies for effectively managing the transition from legacy infrastructures to smart urban systems;
- Study the management of the transition phase from legacy infrastructure systems to smart cities by supporting innovations while avoiding early lock-in; and
- Understand potential applications of the materials learned in this course within the context of the management of smart urban transportation systems as well as smart urban energy systems.
      


            Read more
          



          Introduction to Smart Urban Infrastructures and Smart Cities
    -‘Smart City’ is a notion that is widely, and sometimes not appropriately, used by urbanists across the globe. This week will help you to get a more clear understanding of this notion by using a rigorous conceptual framework, which is based on the systems theory. In this week, we will explain the concept of Smart Cities by reviewing different conceptual approaches to Smart Cities and discussing the pros and cons of each approach.

Smart Urban Energy Systems
    -Smart Energy Systems are one of the top priorities on the agenda of local governments, nation states and technology suppliers. In this week, we deep dive into the energy sector to explore some of the most important managerial considerations in the transition phase and operation of Smart Urban Energy Systems. 

Smart Urban Transportation Systems
    -Many Smart Transportation Technologies are already tested on the roads and in cities across the globe. Driverless vehicles as well as car and ride sharing solutions are not anymore futuristic visions for urban transportation systems; but realities that pose significant opportunities and threads for legacy urban transportation systems. In this week, we deep dive into the urban transportation sector and discuss some of the most important managerial considerations to facilitate the transition phase, and operation of Smart Urban Transportation Systems, thanks to availability of data. 

Towards Smart Cities: part 1
    -The transition of legacy cities to Smart Cities is not a spontaneous process. To get the transition process right, and to the benefit of citizens, cities have to adopt effective management and governance approaches to successfully deal with numerous complexities of this process. This week will help you to understand the most important factors in the transition phase of legacy cities to Smart cities and their managerial implications.

Towards Smart Cities: part 2
    -Management of Smart Cities calls for different approaches from conventional urban management approaches. In this week, we focus on the role of city government in the network of actors who play an important role in management of Smart Cities.",Smart Cities – Management of Smart Urban Infrastructures
https://www.classcentral.com/course/edx-future-cities-2070,"Understanding a city as a whole, its people, components, functions, scales and dynamics, is crucial for the appropriate design and management of the urban system. While the development of cities in different parts of the world is moving in diverse directions, all estimations show that cities worldwide will change and grow strongly in the coming years. Especially in the tropics over the next 3 decades, it is expected that the number of new urban residents will increase by 3 times the population of Europe today. Yet already now, there is an extreme shortage of designers and urban planners able to understand the functioning of a city as a system, and to plan a sustainable and resilient city. To answer questions like: Which methods can contribute to the sustainable performance of a city, and how can we teach this to the next generations, the ETH Future Cities Laboratory in Singapore has produced over the last 3 years many necessary research results. “Future Cities” aims to bring these latest results to the places where they are needed most.
The only way to better understand the city is by going beyond the physical appearance and by focusing on different representations, properties and impact factors of the urban system. For that reason, in this course we will explore the city as the most complex human-made “organism” with a metabolism that can be modeled in terms of stocks and flows. We will open a holistic view on existing and new cities, with a focus on Asia. Data-driven approaches for the development of the future city will be studied, based on crowdsourcing and sensing. At first, we will give an overview of the components and dynamics of the future cities, and we will show the importance of information and information architecture for the cities of the future. The course will cover the origins, state-of-the-art and applications of information architecture and simulation. “Future Cities” will provide the basis to understand, shape, plan, design, build, manage and continually adapt a city. You will learn to see the consequences of citizen science and the merging of Architecture and information space. You will be up-to-date on the latest research and development on how to better understand, create and manage the future cities for a more resilient urban world.



            Read more",Future Cities
https://www.classcentral.com/course/edx-juryx-deliberations-for-social-change-3188,"Today, you are the law.
What does it mean to be a citizen? It means to participate in your society, to connect with others, and to decide, with them, the issues that you face.
It starts with you.
We need to learn to talk civilly with each other about the issues of consequence, but are we capable of learning how to speak together, listen together, and decide together?
In JuryX: Deliberations for Social Change, an experiment in online civic discourse, you are invited to engage with Professor Nesson and others with an understanding that each of us starts from a place of anonymity. Through a series of asynchronous and synchronous online group activities, you will explore a deliberative system by which emotionally charged issues can be discussed.
Although you will learn a bit about the history of jury and even serve as a member of a virtual jury for a mock criminal case, this experiment is about active participation in the deliberative process and how you might use that framework to facilitate dialogue within your own affinity group or community.
The program consists of six modules. Each week, you will learn and apply a new step in a system designed to foster meaningful dialogue. Starting with an introduction to the course’s deliberative framework, you will move from a traditional jury-based application to a live social issue unfolding in real time: the Massachusetts referendum for the “Legalization, Regulation, and Taxation of Marijuana.” As citizens of the Commonwealth of Massachusetts deliberate on this issue, so will you and your JuryX peers. What arguments will shape this debate, and what will the final outcome be?
Can we, civilly, discuss an issue like marijuana regulation?
Two synchronous small-group online deliberations will be held using Google Hangout. Participation is optional, but highly recommended.
JuryX: Deliberations for Social Change is, ultimately, about the most fundamental of human interactions: communication. By listening, speaking, persuading, and being persuaded, you will learn about yourself and others.
If you have faith, faith will be given to you.
Honor Code
HarvardX requires individuals who enroll in its courses on edX to abide by the terms of the edX honor code. HarvardX will take appropriate corrective action in response to violations of the edX honor code, which may include dismissal from the HarvardX course; revocation of any certificates received for the HarvardX course; or other remedies as circumstances warrant. No refunds will be issued in the case of corrective action for such violations. Enrollees who are taking HarvardX courses as part of another program will also be governed by the academic policies of those programs.
Research Statement
HarvardX pursues the science of learning. By registering as an online learner in an HX course, you will also participate in research about learning. Read our research statement to learn more.
Nondiscrimination/Anti-Harassment
Harvard University and HarvardX are committed to maintaining a safe and healthy educational and work environment in which no member of the community is excluded from participation in, denied the benefits of, or subjected to discrimination or harassment in our program. All members of the HarvardX community are expected to abide by Harvard policies on nondiscrimination, including sexual harassment, and the edX Terms of Service. If you have any questions or concerns, please contact harvardx@harvard.edu and/or report your experience through the edX contact form.



            Read more
          



Week 1: Deliberations for Social Change
Explore a system for deliberating emotionally charged issues. Explain the origins of jury. Introduce yourself and discuss challenges related to online identity. Share feedback.
Week 2: The Trilemma of the Maroons
Explore the pre-deliberation stage. Discuss the “Trilemma of the Maroons” question using an asynchronous pseudonymous discussion tool. Share feedback.
Week 3: The Art of Deliberation – Part I
Consider a system for deliberation within a jury-based context. Prepare for the deliberation stage by reviewing a stimulus for Commonwealth v. Hebert. Identify best practices for engaging in thoughtful deliberation. Participate in a pre-deliberation activity. Share feedback.
Week 4: The Art of Deliberation – Part II
Deliberate Commonwealth v. Hebert as a member of a virtual jury. Share your verdict. Reflect upon your deliberation experience.
Week 5: The Legalization, Regulation, and Taxation of Marijuana – Part I
Consider how a system for deliberation can facilitate the discussion of a real and emotionally charged social issue. Prepare for the deliberation stage by reviewing a stimulus for the “Legalization, Regulation, and Taxation of Marijuana” initiative in Massachusetts. Participate in a pre-deliberation activity. Share feedback.
Week 6: The Legalization, Regulation, and Taxation of Marijuana – Part II
Deliberate the “Legalization, Regulation, and Taxation of Marijuana” initiative as a small group. Share your outcome. Reflect upon your deliberation experience.
Epilogue and Final Thoughts
Compare your decision to what citizens of the Commonwealth of Massachusetts chose. Share feedback.",JuryX: Deliberations for Social Change
https://www.classcentral.com/course/posa-533,"The confluence of multi-core and distributed-core processors, inexpensive mass storage, ubiquitous wireless connectivity, and commodity software platforms is driving the need for software engineers and programmers who understand how to develop concurrent and networked software for mobile devices that connect to cloud computing platforms. Despite many improvements in processors, storage, and networks, however, developing quality software on-time and on-budget remains hard. Moreover, developing high quality reusable  concurrent and networked software apps and services is even harder.  The principles, methods, and skills required to develop such software are best learned by attaining mastery of patterns, pattern languages, and frameworks.
A pattern describes a reusable solution to a common problem that arises within a particular context. When related patterns are woven together they form a pattern language that defines a vocabulary and a process for the orderly resolution of software development problems. A framework is an integrated set of components that collaborate to provide a reusable architecture for a family of related apps or services.  Frameworks can also be viewed as concrete realizations of pattern languages that facilitate direct reuse of detailed design and source code.
This MOOC describes by example how to apply patterns, pattern languages, and frameworks to alleviate the complexity of developing concurrent and networked software for mobile devices via the use of object-oriented design techniques, Javaprogramming language features, and Android middleware. An extended case study project will be used throughout the MOOC to showcase pattern-oriented software design and programming techniques for concurrent and networked mobile devices and clouds.
Note: This course is part of a trans-institution sequence of MOOCs entitled Mobile Cloud Computing with Android
This MOOC and two others, taught by Dr. Adam Porter from the University of Maryland and Dr. Jules White from Vanderbilt University, have been designed to complement each other as part of the first trans-institution sequence of MOOCs taught on the Coursera platform, structured as follows:
 

The University of Maryland MOOC, Programming Mobile Applications for Android Handheld Systems, will run from January 21st - April 28th. It focuses on the design and programming of user-facing applications.  
The first Vanderbilt MOOC in the sequence, Programming Mobile Services for Android Handheld Systems, will run from May 12th - July 6th. It focuses on middleware systems programming topics, such as synchronous and asynchronous concurrency models, background service processing, structured data management, local inter-process communication and networking, and integration with cloud-based services.  
The second Vanderbilt MOOC in the sequence, Programming Cloud Services for Android Handheld Systems, will be run from July 21st - September 29th. It focuses on how to connect Android mobile devices to cloud computing and data storage resources, essentially turning a device into an extension of powerful cloud-based services on popular cloud computing platforms, such as Google App Engine and Amazon EC2. 
The final Capstone project MOOC in the sequence will run from October 1st - November 3rd. For this first offering of the Mobile Cloud Computing with Android (MoCCA) Specialization only students in the Signature Track who receive a ""Verified Certificate with Distinction"" are eligible to enroll in the Capstone project course.

 
Some of the programming assignments and the iRemember integrative project for these MOOCs will be coordinated.  
If you just want to take some of the MOOCs in this sequence or take them all in different order you’re certainly welcome to do so, and you’ll still learn a lot. However, if you take all the MOOCs in this sequence in the order presented you’ll gain a deeper, end-to-end understanding of handheld systems, their applications and services, as well as their integration into the cloud.



            Read more
          



The course is organized into the following sections:

Section 0: Course Introduction

Part 1: Overview of Mobile Cloud Computing with Android
Part 2:Course Structure and Topics
Part 3: Course Prerequisites and Learning Strategies
Part 4: Overview of Patterns and Frameworks


Section 1: Android Concurrency

Module 1: Concurrency Motivations and Challenges

Part 1: Concurrency Motivations
Part 2: Concurrency Challenges


Module 2: Java Concurrency Mechanisms

Part 1: Overview of Java Threads (Part 1)
Part 2: Overview of Java Threads (Part 2)
Part 3: Motivating Java Synchronization & Scheduling Mechanisms
Part 4: Java Synchronization and Scheduling Classes
Part 5: Java ReentrantLock
Part 6: Java ReentrantReadWriteLock
Part 7: Java Semaphore
Part 8: Java ConditionObject
Part 9: Java CountDownLatch
Part 10: Java Synchronization and Scheduling Example
Part 11: Java Built-in Monitor Objects


Module 3: Android Concurrency Frameworks

Part 1: Overview of Android Concurrency Frameworks and Idioms
Part 2: Android Looper
Part 3: Overview of Android Handler
Part 4: Posting and Processing Runnables to Android Handler
Part 5: Sending and Handling Messages to Android Handler
Part 6: The AsyncTask Framework (Part 1)
Part 7: The AsyncTask Framework (Part 2)
Part 8: Programming with Android Concurrency Frameworks (Part 1)
Part 9: Programming with Android Concurrency Frameworks (Part 2)




Section 2: Android Services and Security

Module 1: Android Services and IPC

Part 1: Overview of Started and Bound Services
Part 2: Programming Started Services (Part 1)
Part 3: Programming Started Services (Part 2)
Part 4: Android IntentService
Part 5: Activity and Service Communication
Part 6: Service to Activity Communication Using Android Messenger
Part 7: Programming Bound Services with Messengers (Part 1)
Part 8: Programming Bound Services with Messengers (Part 2)
Part 9: Programming Bound Services with AIDL


Module 2: Android App Security and Risks

Part 1: Traditional App Accounts
Part 2: Mobile vs. Traditional App Accounts
Part 3: App Account Mapping to Linux Users
Part 4: Apps Lie & Steal
Part 5: How Android Protects Apps
Part 6: What Android Doesn't Protect
Part 7: Avoid Storing Sensitive Data in Public Locations
Part 8: Risks of Insecure File Permissions

Module 3: Building More Secure Android Apps

Part 0: The Challenge of Secure Coding
Part 1: Security Vulnerability Walkthrough
Part 2: Principles of Secure Abstractions
Part 3: Avoid Coupling Data & Security State
Part 4: Build Abstractions that are Hard to Use Insecurely
Part 5: Bound & Strongly Type Security State
Part 6: Avoid Conditional Logic in Secure Pathways
Part 7: Prevent Secure Pathways from Being Broken at Runtime
Part 8: Privilege Escalation Concepts
Part 9: Privilege Escalation Scenario
Part 10: Privilege Escalation Code Walkthrough
Part 11: Privilege Escalation Fixes
Part 12: User Interface Attacks
Part 13: Cross-platform User Interface Attacks


Section 3: Concurrency and Communication Patterns in Android

Module 1: Coordinating Concurrent Access to Shared Data

Part 1: The Monitor Object Pattern (Part 1)
Part 2: The Monitor Object Pattern (Part 2)

Module 2: Activating Services on Demand

Part 1: The Activator Pattern (Part 1)
Part 2: The Activator Pattern (Part 2)

Module 3: Passing Commands to Services

Part 1: The Command Processor Pattern (Part 1)
Part 2: The Command Processor Pattern (Part 2)

Module 4: Automating Marshaling and Demarshaling of Data

Part 1: The Proxy Pattern (Part 1)
Part 2: The Proxy Pattern (Part 2)

Module 5: Supporting Object-Oriented Remote Method Calls

Part 1: The Broker Pattern (Part 1)
Part 2: The Broker Pattern (Part 2)

Module 6: Decoupling Producers from Consumers

Part 1: The Publisher-Subscriber Pattern (Part 1)
Part 2: The Publisher-Subscriber Pattern (Part 2)

Module 7: Ensuring Only One Looper Per Thread

Part 1: The Thread-Specific Storage Pattern

Module 8: Passing Message Requests Between Threads

Part 1: The Active Object Pattern

Module 9: Decoupling Synchronous & Synchronous Processing

Part 1: the Half-Sync/Half-Async Pattern




Throughout the MOOC we'll focus on pattern-oriented software architecture, with an emphasis on concurrent and networked programming in the context of Android middleware systems programming mechanisms, such as synchronous and asynchronous concurrency models, background service processing, storage and retrieval of structured data, and local inter-process communication (IPC) and networking. We illustrate by example how key pattern and framework concepts and relationships are applied in Android Services, Content Providers, Broadcast Receivers, and various secure local and remote IPC mechanisms from both an application and infrastructure perspective. Many code examples are shown throughout using Java, with a case study project used to reify the key points throughout all the modules in this section.
The PDF versions of all the slides used in the course will be available online as the videos become available on the course website.",Pattern-Oriented Software Architectures: Programming Mobile Services for Android Handheld Systems
https://www.classcentral.com/course/aids-508,"Did you grow up in a world without red ribbons, AZT, the
AIDS Memorial Quilt, or Project Red? If you did, chances are good that you came
of age before 1981 and are a member of the last generation of humans on this
planet to be able to say that you remember those ‘carefree days when all you
had to worry about was getting pregnant, herpes, and a bad reputation’ (AID
Atlanta).
On June 5, 1981 the CDC released a Morbidity and Mortality Weekly Report describing the first five cases
of what later became known as the Acquired Immune Deficiency Syndrome, or AIDS.
On that day human history broke into two generations: Those who can remember a time before the AIDS pandemic and those who can't.
No matter what generation you grew up in, what we all have
in common is a curiosity about AIDS.  Where
did it come from? Why is it so widespread?  Are we making progress towards
a vaccine? What is it like to be part of a vaccine trial? Has anyone ever been cured of HIV infection? Are some people just
naturally more or less susceptible to HIV than other people
are?
All of this and more will be covered in AIDS. Over the course of nine weeks we will discuss a wide range of
issues, innovations, and controversies regarding HIV/AIDS in the US and around
the world including everything from what circumcision and Truvada have in
common; how school children in Africa are changing the way AIDS education is
done; where you can go online to learn how many cases of AIDS there are in your
area; and how one man’s insistence that AIDS doesn't exist left hundreds of thousands of people without access to life saving drugs.






            Read more
          




Week 1: HISTORY: Focusing on the origin of HIV, its initial discovery in
humans, the early response to HIV (good, bad, and ugly), and its global spread
since then.
Lectures:
Dr. Hagen: The Origin of HIV
Guest Lecture:
Dr. James W. Curran: The History of AIDS

Week 2: SCIENCE: Focusing on how the immune system
works, what HIV does to disable the body’s ability to protect itself against
everyday germs, and important scientific questions about HIV that are as yet
unanswered.
Lectures:
Dr. Hagen: The Normal Immune System
Guest Lecture:
Dr. Eric Hunter: HIV's Effect on the Immune System

Week 3: BEHAVIORAL PREVENTION: Focusing on behavior change, culturally embedded HIV prevention and awareness messages, an exceptionally cost-effective way to reduce HIV transmission rates, and
where to find information about prevention interventions of proven efficacy.
Lectures:
Dr. Hagen: Introduction; Theories of Behavior Change; The DEBI Project
Guest Lectures:
Dr. Kate Winskell: Scenarios from Africa / Global Dialogues
Dr. Susan Allen: Couples Voluntary Counseling and Testing

Week 4: BIOMEDICAL PREVENTION: Focusing on current research in biological ways to reduce transmission between mother and child, in the workplace, and among sero-discordant couples.
Lectures:
Dr. Hagen: Preventing MTCT; PEP; PrEP
Guest Lecture:
Dr. Carlos del Rio: TasP; Male Circumcision

Week 5: VULNERABLE POPULATIONS: Focusing on how HIV affects and is affected by political, cultural, sexual, biological, and gender-based factors.Lectures:Dr. Hagen: Social Determinants of Guest Lectures:Dr. Claire Sterk: WomenDr. Patrick Sullivan: Men who have Sex with MenDr. Rana Chakraborty: Children and Adolescents Dr. Anne Spaulding: PrisonersWeek 6: CLINICAL CARE ISSUES: Focusing on developments in HIV testing, the illnesses that people with HIV/AIDS are at risk from, and crucial issues that can affect the success of HIV treatment.Lectures:Dr. Hagen: HIV Testing; AIDS-defining and Opportunistic InfectionsGuest Lecture:Dr. Marcia Holstad: Health Literacy; Obstacles to Medication AdherenceWeek 7: AIDS VACCINES: Focusing on an explanation of what vaccines are, the requirements
for a successful HIV/AIDS vaccine, what is involved in being a volunteer in a
clinical trial of an experimental AIDS vaccine, and a discussion of vaccine
trial results to date.
Lectures:
Dr. Hagen: Vaccine History and Development
Guest Lecture:
Dr. Paula Frew: Participating in an Experimental AIDS Vaccine Trial

Week 8: FUTURE CHALLENGES: Focusing on key areas in the battle to successfully mitigate global suffering related to AIDS.Lectures:Dr. Hagen: The Economics of AIDSGuest Lecture:Dr. Vincent Marconi: Curing HIVDr. James Curran: The Next 30 YearsWeek 9: RESPONDING TO HIV/AIDS: Focusing on how individuals, organizations, and societies have and are responding to the pandemic.Lectures:Dr. Hagen: On Being a VolunteerGuest Lecture:Dr. John Blevins: The History of AIDS Activism; Religion as a Social Force in HIV",AIDS
https://www.classcentral.com/course/edx-fundamentals-of-nanotransistors-4487,"The transistor has been called the greatest invention of the 20th century – it enables the electronics systems that have shaped the world we live in. Today’s nanotransistors are a high volume, high impact success of the nanotechnology revolution. If you are interested in understanding how this scientifically interesting and technologically important nano-device operates, this course is for you!
This nanotechnology course provides a simple, conceptual framework for understanding the essential physics of nanoscale transistors.  It assumes only a basic background in semiconductor physics and provides an opportunity to learn how some of the fascinating new discoveries about the flow of electrons at the nanoscale plays out in the context of a practical device.
The course is divided into four units:

Transistors fundamentals
Transistor electrostatics
Ballistic MOSFETs
Transmission theory of the MOSFET

The first two units provide an introduction for students with no background in transistors or a quick review for those familiar with transistors.  The third unit treats the ballistic transistor in which electrons move without resistance (in the traditional sense). The last unit uses that Landauer Approach to electron transport, which was developed to understand some striking experiments in nanophysics, to develop an understanding of how electrons flow in modern nanotransistors.  This short course describes a way of understanding MOSFETs that is much more suitable than traditional approaches when the channel lengths are of nanoscale dimensions. Surprisingly, the final result looks much like the traditional, textbook, MOSFET model, but the parameters in the equations have simple, clear interpretations at the nanoscale.
My objective for this course is to provide students with an understanding of the essential physics of nanoscale transistors as well as some of the practical technological considerations and fundamental limits. The goal is to do this in a way that is broadly accessible to students with only a very basic knowledge of semiconductor physics and electronic circuits. The course is designed for anyone seeking a sound, physical, but simple understanding of how nanoscale transistors operate. The course should be useful for advanced undergraduates, beginning graduate students, as well as researchers and practicing engineers and scientists.
This course is the latest in a series offered by the nanoHUB-U project which is jointly funded by Purdue and NSF with the goal of transcending disciplines through short courses accessible to students in any branch of science or engineering. These courses focus on cutting-edge topics distilled into short lectures with quizzes and practice exams.



            Read more
          



Weeks 1 & 2: Transistor Fundamentals
Weeks 3 & 4: MOS Electrostatistics
Weeks 5 & 6: The Ballistic Nanotransistor
Weeks 7 & 8: The Transmission Theory of the MOSFET",Fundamentals of Nanotransistors
https://www.classcentral.com/course/edx-documental-nuevas-tendencias-nuevos-formatos-2150,"Los vídeos serán en español o inglés. Se ofrecerán subtítulos en ambos idiomas. Las actividades se realizarán en ambos idiomas.
*Videos will be in English or Spanish. Transcripts in both languages will be provided. The assessments will be in both languages.
Este curso presenta las nuevas tendencias y formatos del documental audiovisual contemporáneo, prestando especial atención a las prácticas más innovadoras en un contexto interactivo, transmedia y multiplataforma. Incluye una aproximación a los géneros y autores fundamentales, y  cuenta con la participación de profesionales del sector, documentalistas y académicos.
A través de vídeos, infografías, animaciones y timelines y un amplio repertorio de recursos y materiales complementarios, se busca ofrecer al  alumno claves creativas y eficaces en el momento actual.
Este MOOC consta de los siguientes módulos:

El documental está de moda.
Flashback: Introducción a la historia del documental.
Documental web: Reinvención del documental en Internet.
Ciberactivismo y documental político en el ecosistema viral.
F for Fake o falso documental a ritmo de social networking.
Documental de divulgación: Naturaleza, cultura, historia, ciencia.
Documental de creación en tiempos de crowdfunding.
Brand-Documental: Nuevas estrategias publicitarias.

This course features new trends and formats in contemporary documentary film with a focus on innovative works in an interactive and multi-platform environment. It includes an overview of essential authors and genres, as well as the contribution of national and international scholars, professionals of the field and documentary makers.
The learning experience is enhanced with videos, slideshows, infographics and timelines, to provide the learner with an interactive, reflective and entertaining experience.
This MOOC is divided into the following segments:

Documentary film is in vogue.
Flashback: Introduction to documentary film history.
Web documentary: Reinventing documentary film on the Internet.
Cyberactivism and political documentary in a viral ecosystem.
F for Fake or false documentary moving to the rhythm of social networking.
News and thematic documentary: Nature, culture, history, science.
Creative documentary film in times of crowdfunding.
Brand-Documentary: New strategies in advertising.

 



            Read more","DOCUMENTAL! Nuevas tendencias, nuevos formatos"
https://www.classcentral.com/course/clinicalsimulations-13804,"This 7-week course provides you with key strategies to help understand the foundation of Clinical Simulations.  During each module, you will learn about 7 key components of Clinical Simulation Across the Health Professions and its' impact in your current position as a healthcare professional.  Please utilize all of the Resources provided by each of the modules to support and enhance your understanding of each concept.  You will learn about the following topics in this course:

Module 1:  Getting Started in Clinical Simulation-the Fundamentals
Module 2:  INACSL Standards of Best Practice:  Simulation
Module 3:  Implementing Simulation in the Curriculum
Module 4:  Developing a Simulation Center
Module 5:  Basics of Debriefing in Simulation
Module 6:  Evaluation Methods in Simulation
Module 7:  SPs in Simulation

About The George Washington University School of Nursing

Ranked among the top nursing schools by U.S. News & World Report, the George Washington University School of Nursing educates and inspires nurses to provide high-quality, compassionate person-centered health care. The school develops leaders actively engaged in health promotion, patient advocacy and healthcare innovation, and prepares exceptional nurse educators who pursue quality and advance the profession. The School of Nursing is committed to improving the health and wellbeing of people and communities locally, nationally and globally. The school values lifelong learning and its students advance nursing practice, leadership and education as they make a difference in the world.

For more in-depth simulation education, please see the GW Nursing Simulation Initiatives.
https://nursing.gwu.edu/gw-nursing-simulation-initiatives
      


            Read more
          



          Getting Started in Clinical Simulation
    -This module will provide information on creating clinical simulations and foundational basics when a health professional educator is considering the use of simulation pedagogy into a course, program, and/or curriculum.  Based on a building analogy, the learner will navigate the steps of getting started using the simulation pedagogy outlining major steps, basic fundamentals, and considerations to “get started.”  In addition as an educator adopts this use of this pedagogy, major activities, concepts, a simulation theory, and research findings are discussed so the foundation of  your simulation program is grounded in theory and best practices that can lead to policy implications for your simulation center.

INACSL Standards of Best Practice: Simulation
    -During this module, you will learn about the historical perspectives in the development of the INACSL Standards of Best Practice: Simulation and the template which is consistent across each standard. We will discuss the importance (the WHY) of the standards in simulation-based education as guideposts in developing your simulation program. As we progress through each video, you will learn about each standard (The WHAT) with in-depth descriptions of criteria to meet the standard (the HOW). You will be able to identify where your simulation program is, relative to the standards. The module concludes with you developing a plan for implementation of the INACSL Standards of Best Practice: Simulation.

Implementing Simulation in the Curriculum
    -This module will provide information on best practices in the implementation of simulation in a course, program and/or curriculum.  The learner will be introduced to the concept of a strategic vision for integration involving all stakeholders and a plan for assessment and evaluation. A six-step approach to curricular development is presented. In addition, learners are introduced to key simulation concepts, methodologies, and educational strategies. 


Developing a Simulation Center 
    -Implementation of a simulation center is full of complex issues including staff, faculty, simulation scenario development, professional development, budget, equipment, assets, supplies, and much more.  This module will provide information to begin the development of a simulation center that meets the standards of best practice for simulation operations. It will provide strategic thinking related to budgeting, revenue, equipment and assets. This is an introduction to center development and is not a comprehensive course. 

Basics of Debriefing in Simulation
    -This module provides an introduction to simulation debriefing. It includes information about how to facilitate debriefing, common simulation debriefing methods and the role of feedback in debriefing. In session one, a history of debriefing will be reviewed. The INACSL Standards of Best Practice: Simulation Debriefing will be reviewed, and the role of feedback will be presented. Session two includes several communication strategies that are important with debriefing. Finally, session three presents information about common healthcare debriefing methods.


Evaluation Methods in Simulation 
    -In simulation evaluation, beginning with the end in mind is critical. Why was the simulation scenario written in the first place? What need is this simulation filling within your program? Or, if simulation is already being used, is some modification needed to get your simulation or course where you want it to be? Is my simulation program contributing to improved patient care, higher test scores for learners?  Evaluations provide useful data for educators, deans, hospital administrators, stake holders, funding agencies, and yes, even the learners themselves.  This module will introduce you to Kirkpatrick’s 4 Levels of Evaluation, a commonly used framework in simulation.  We will consider some current existing tools to evaluate simulation experiences and facilitators.  And we will provide suggestions for ways to evaluate your simulation program.  A word about translating this evaluation approach to your own culture. My approach to evaluation is a very western model. Please consider what I say here and adapt this to fit with your own country or cultural approach to evaluation.

Begin with the end in mind- as you start a simulation program. Evaluation is continuous and ongoing…we can evaluate the scenarios, teaching or facilitation of a scenario, student outcomes, etc. 


SPs in Simulation
    -Welcome to Module 7: SPs and Simulation. This module consists of four sessions. We will start this session by clarifying the term SP and introducing the Association of Standardized Patient Educators (ASPE) Standards of Best Practice (SOBP) which will be referenced throughout all of the sessions. Then I will discuss the role and function and SPs in simulation. The second session will focus on developing SP scenarios or cases. The third session will focus on recruiting SPs and training them for role portrayal. In the last session, I will discuss SP program management and opportunities for professional development for those training SPs and administering SP activities. So let’s get started.",Essentials in Clinical Simulations Across the Health Professions
https://www.classcentral.com/course/edx-data-storage-and-processing-19068,"Want to learn data processing and interpreting the result you’ve got? This course is for you! Get acquainted with preparing and analyzing large amount of data, as well as data storage fundamentals.
This course is an introduction to initial data processing. We will start with data types and sources, methods of data preparation: cleaning, filling in the missing values, data smoothing and normalization. The course will familiarize you with the descriptive statistics and data visualization methods. You will also learn how to analyze time series and find trends.
Get acquainted with the fundamentals of data storage and access: databases types, relational and NoSQL databases, big data initials.
No previous programming knowledge needed.



Week 1: Data preprocessing. Basic concepts of data processing. Stages of data analysis (collection, sorting, transformation, building models and interpretation). Data measurements and scales. Data types and sources. Data preparing. 
Week 2: Data processing tools and visualization. Digital spreadsheets. Data visualization goals. Methods and purposes of correct data visualization. 
Week 3: Data processing. Descriptive statistics. Data normalization and transformation. Time-series analysis and forecasting. Types of time-series smoothing. Trends, seasonal time series modelling.
Week 4: Relational databases management systems. Introduction to relational DBMS starting from relational data model. SQL statements and queries creation. Database indexes and transactions requirements.
Week 5: NoSQL. Main characteristics of not only SQL databases. Non-structured and semi-structured data and scalability of NoSQL databases. Types of NoSQL databases: column-oriented, key-value store, document store and graph databases.",Data Storage and Processing
https://www.classcentral.com/course/mobilecloudsecurity-3080,"A key challenge of mobile platforms is that the apps installed on a device increase the number of potential security vulnerabilities. Mistakes in app development or cloud services can lead to vulnerabilities that cause users data to be stolen, charges to user accounts, and spread of malware to a user’s friends. Ensuring that mobile cloud application developers are aware of potential vulnerabilities and avoid introducing them into their code is an essential part of building a more secure app ecosystem.The course is designed to help students understand how to write more secure mobile cloud applications for Android. Students will be introduced to specific vulnerabilities that have affected well-known apps and be given a wide view of app threats on Android. Developers will also be introduced to the secure coding techniques that can be used to help prevent the introduction of app and cloud service vulnerabilities.The Mobile Cloud Computing with Android (MoCCA) SpecializationThis is the 6th course of the six-course Mobile Cloud Computing with Android (MoCCA) Specialization. It has been designed as part of a Coursera Specialization designed to help learners create complex, cloud-based Android Applications, and includes a final “capstone” project for those who earn Verified Certificates across all six courses.Note: We are proud to announce that the MoCCA specialization has already reached hundreds of thousands of learners around the globe. In its last iteration, we worked with Google to provide Nexus tablets, feedback from the Google App team, and the potential to be featured in the Google Play store to top course completers.This time around, we are providing more flexibility for all of you busy learners. We are running the Programming Mobile Applications courses in more digestible one-month-long sections, each with a meaningful mini-project at the end. Additionally, we will be re-offering the courses more frequently. For example, new sessions of my two introductory courses will be launched on a monthly basis, so that you can find a convenient time to join us or pick up where you left off if you didn’t quite finish before.For previous MoCCA students: If you have already earned a Verified Certificate in the previous version of this course, ""Pattern-Oriented Software Architectures: Programming Mobile Services for Android Handheld Systems” offered in May 2014, you do not need to retake this course to continue towards the Specialization certificate and final project in 2015. Please consult the Specializations Help Center or contact the Coursera support team if you are not sure whether you qualify.This MOOC and five others, taught by Dr. Adam Porter from the University of Maryland and Dr. Jules White from Vanderbilt University, have been designed to complement each other as part of the first trans-institution sequence of MOOCs taught on the Coursera platform, structured as follows:The first two courses by Dr. Adam Porter, of the University of Maryland, are Programming Mobile Applications for Android Handheld Systems Part 1 and Part 2. They focus on the design and programming of user-facing applications.  The third and fourth courses by Dr. Douglas Schmidt, of Vanderbilt University, are Programming Mobile Services for Android Handheld Systems: Concurrency and Communication. They focus on middleware systems programming topics, such as synchronous and asynchronous concurrency models, background service processing, structured data management, local inter-process communication and networking, and integration with cloud-based services.  The fifth and sixth courses by Dr. Jules White, of Vanderbilt University, are Programming Cloud Services for Android Handheld Systems: Spring and Security.  They focus on how to connect Android mobile devices to cloud computing and data storage resources, essentially turning a device into an extension of powerful cloud-based services on popular cloud computing platforms, such as Google App Engine and Amazon EC2. The final “capstone” project will require students to develop a complex mobile cloud computing application from the ground up.Some of the programming assignments and the iRemember integrative project for these MOOCs will be coordinated.  If you just want to take some of the MOOCs in this sequence or take them all in different order you’re certainly welcome to do so, and you’ll still learn a lot. However, if you take all the MOOCs in this sequence in the order presented you’ll gain a deeper, end-to-end understanding of handheld systems, their applications and services, as well as their integration into the cloud.
      


            Read more
          



This MOOC describes, by example, the basics of securing mobile applications and back-end cloud services. The class is taught in the context of Java, Android, and the Java Spring Framework. Although the cloud service topics in this course will be taught in the context of connecting mobile devices to the cloud, the concepts are broader and will give students the ability to create the cloud services to support large-scale web applications, such as social networking applications; cloud services for embedded systems, such as the Internet of Things and Industrial Internet; and wearable computing devices.The course is organized into the sections outlined below (additional lectures may be provided live once the MOOC has begun):Module 1: Android App Security and RisksPart 1: Traditional App AccountsPart 2: Mobile vs. Traditional App AccountsPart 3: App Account Mapping to Linux UsersPart 4: Apps Lie & StealPart 5: How Android Protects AppsPart 6: What Android Doesn't ProtectPart 7: Avoid Storing Sensitive Data in Public LocationsPart 8: Risks of Insecure File PermissionsModule 2: Building More Secure Android AppsPart 0: The Challenge of Secure CodingPart 1: Security Vulnerability WalkthroughPart 2: Principles of Secure AbstractionsPart 3: Avoid Coupling Data & Security StatePart 4: Build Abstractions that are Hard to Use InsecurelyPart 5: Bound & Strongly Type Security StatePart 6: Avoid Conditional Logic in Secure PathwaysPart 7: Prevent Secure Pathways from Being Broken at RuntimePart 8: Privilege Escalation ConceptsPart 9: Privilege Escalation ScenarioPart 10: Privilege Escalation Code WalkthroughPart 11: Privilege Escalation FixesPart 12: User Interface AttacksPart 13: Cross-platform User Interface AttacksModule 3: Secure HTTP CommunicationPart 1: Man in the Middle Attacks Public Key InfrastructurePart 2: HTTPSPart 3: Challenges of Storing Secrets on MobilePart 4: WebView Security Issues & Best PracticesModule 4: What was I Saying: Keeping Track of SessionsPart 1: SessionsPart 2: Spring Security OverviewPart 3: Spring Security Configuration in JavaPart 4: Building a Custom UserDetailsServicePart 5: Setting up a custom UserDetailsServicePart 6: The PrincipalPart 7: Spring Security Role AnnotationsPart 8: More Complex Expression-based Pre Post Authorize AnnotationsPart 9: Spring Security Controller Code WalkthroughPart 10: Spring Security Controller Test Code WalkthroughModule 5: Authenticating Mobile Clients with OAuthPart 1: Stateful Sessions with Cookies Why They Aren't Ideal for MobilePart 2: Stateless Sessions with TokensPart 3: OAuth 2.0Part 4: Spring Security OAuth 2.0Part 5: A Spring OAuth 2.0 Secured ServicePart 6: A Retrofit Oauth 2.0 Client for Password Grants",Programming Cloud Services for Android Handheld Systems: Security
https://www.classcentral.com/course/edx-writing-case-studies-science-of-delivery-4908,"This course introduces you to the main elements of a good “science of delivery” case study and teaches you how to plan your research, conduct interviews, and organize your writing.    
The “science of delivery” begins with a simple observation. We often have a vision of the right policies or strategies for improving health, safety, and economic well being, but the real problem is getting things done. Even a simple policy intervention such as child vaccination requires much more than nurses and a stock of vaccine to be effective.
Case studies are a vital tool for sharing insight about the how of policy implementation and institutional reform. They trace the steps taken to produce results, show solutions people have devised to address anticipated challenges and overcome unanticipated obstacles. Case studies help us think about how to adapt approaches so that they work in different contexts.
This social science course is most suitable for:

Practitioners who want to document and analyze their efforts to implement a program or build a new institution
Researchers who want to trace how programs achieved results
Graduate students who want an introduction to one type of case study method

No certificates, statements of accomplishment, or other credentials will be awarded in connection with this course.",Writing Case Studies: Science of Delivery
https://www.classcentral.com/course/motors-circuits-design-12098,"This course can also be taken for academic credit as ECEA 5341, part of CU Boulder’s Master of Science in Electrical Engineering degree.

This is our second course in our specialization on Embedding Sensor and Motors. To get the most out of this course, you should first take our first course entitled Sensors and Sensor Circuits. Our first course gives you a tutorial on how to use the hardware and software development kit we have chosen for the lab exercises. This second course assumes that you already know how to use the kit.

After taking this course, you will be able to:
●	Understand how to specify the proper AC or DC motor for a machine design.
●	Integrate the motor to a machine, based on analysis of motor equations for voltage, current, torque and speed.
●	Implement the motor and accompanying rotary sensor into a motor control circuit in both hardware and software.
●	Add a motor and motor control circuit into a microprocessor based development kit.
●	Create hardware and firmware to process motor feedback data to a microprocessor for further evaluation.

You will need to buy the following components to do the two course projects based on the videos in this module. Note that if you have already purchased the PSOC 5LP PROTOTYPING KIT, you do not need to buy it again. 
These parts may be purchased off the Digikey web site, www. Digikey.com. Or, you may obtain the specs from the site, and purchase them elsewhere. 

These are the part numbers for the above table, the lab on Motor Voltage and Current Measurement. You can copy and paste them into the search engine on the Digikey web site. You need one of each except for the AA batteries (N107-ND), which you would need 3.

428-3390-ND
P14355-ND
FQU13N10LTU-ND
N107-ND
1N5393-E3/54GICT-ND 
RNF14FTD1K00CT-ND 
P0.62W-1BK-ND


These are the part numbers for the above table, so you can copy and paste them into the search engine on the Digikey web site. You will need one of each.

428-3390-ND
987-1188-ND
      


            Read more
          



          AC Motor Designs
    -In module 1 you will learn principles of operation of AC induction motors, both single and 3-phase types. You well then learn how to interpret data from torque speed curves, and how to optimize data in these curves based on electrical resistance, inductance, and capacitance. Then you will learn about different types of single phase motors, featuring a video analysis of a split phase motor used in a clothing dryer. You will also learn about typical applications for single phase motors, which will assist you in picking the right one for an application. 

AC Motor Control
    -In module 2 you will learn the details of AC motor specifications and enclosures, as well as how these details are governed by national and international design standards. Then you will learn a detailed methodology for researching design requirements for AC motors, and how to use these requirements to pick the right motor for your needs. Afterwards, you will have lessons on AC motor control components and systems, both manual and automatic. This will culminate in training for you on AC variable speed drives.

DC Motors
    -In module 3 you will learn principles of DC motors, traditional brushed motors, as well as electronically driven brushless motors. We will discuss shunt wound, series wound, compound wound, servo, stepper, and torque motors, with detailed explanation of how commutation and control is implemented in these designs. We will have a lab exercise for you on DC motor speed measurement. We will have another video analysis for you, this time featuring teardown of a paper shredder.  Then you will learn a detailed methodology for researching design requirements for DC motors, and how to use these requirements to pick the right motor for your needs.

DC Motor Control and Stepper Motors
    -In module 4 you will start off with another lab exercise, this time gaining hands-on experience with DC motor control. Then, we will illustrate a simplified stepper motor drive, so you will understand the basic principles involved in stepper motor control. Next, you will do a deep dive into stepper motor specs, operation and commercial driver chips and packages. You will then do another lab exercise, this time on actuating a rotary sensor. We end the module with a comparison of DC vs. AC motors, so you take away a core understanding of their pros and cons.  

Course Projects
    -In this module you will perform your lab work for the Course. There will be two labs",Motors and Motor Control Circuits
https://www.classcentral.com/course/fmri-1035,"In this course we will explore the intersection of statistics and functional magnetic resonance imaging, or fMRI, which is a non-invasive technique for studying brain activity. We will discuss the analysis of fMRI data, from its acquisition to its use in locating brain activity, making inference about brain connectivity and predictions about psychological or disease states. A standard fMRI study gives rise to massive amounts of noisy data with a complicated spatio-temporal correlation structure. Statistics plays a crucial role in understanding the nature of the data and obtaining relevant results that can be used and interpreted by neuroscientists.
      


          Week 1 Module 1: Introduction to fMRIModule 2: Basic MR PhysicsModule 3: Image FormationModule 4 K-SpaceModule 5: fMRI Signal and NoiseWeek 2 Module 6: fMRI Data StructureModule 7: Experimental DesignModule 8: Pre-processing IModule 9: Pre-processing IIWeek 3Module 10: The General Linear ModelModule 11: GLM EstimationModule 12: Model Building IModule 13: Model Building IIModule 14: Noise ModelsModule 15: InferenceWeek 4 Module 16: Group-level Analysis IModule 17: Group-level Analysis IIModule 18: Multiple ComparisonsModule 19: FWER CorrectionModule 20: FDR CorrectionModule 21: More Multiple ComparisonsWeek 5Module 22: Brain ConnectivityModule 23: Functional ConnectivityModule 24: Multivariate Decomposition MethodsModule 25: Effective ConnectivityModule 26: Comments on ConnectivityWeek 6 Module 27: Multi-voxel Pattern AnalysisModule 28: Performing MVPA IModule 29: Performing MVPA IIModule 30: MVPA Example Module 31: Farewell",Statistical Analysis of fMRI Data
https://www.classcentral.com/course/recsys-1029,"Recommender systems have changed the way people find products, information, and even other people. They study patterns of behavior to know what someone will prefer from among a collection of things he has never experienced. The technology behind recommender systems has evolved over the past 20 years into a rich collection of tools that enable the practitioner or researcher to develop effective recommenders. We will study the most important of those tools, including how they work, how to use them, how to evaluate them, and their strengths and weaknesses in practice.

The algorithms we will study include content-based filtering, user-user collaborative filtering, item-item collaborative filtering, dimensionality reduction, and interactive critique-based recommenders. The approach will be hands-on, with six week projects, each of which will involve implementation and evaluation of some type of recommender.

In addition to topical lectures, this course includes interviews and guest lectures with experts from both academia and industry.

Beginning in February 2015, you will be able to earn a Verified Certificate by verifying your identity via a webcam and a government-issued ID. This option will provide formal recognition of your achievements in the course and includes the University of Minnesota logo. Before then, you can complete a “test run” of the exam. You can then re-take the exam after the Verified Certificate becomes available. For information regarding Verified Certificates, see https://courserahelp.zendesk.com/hc/en-us/articles/201212399-Verified-Certificates
      


            Read more
          



Introduction to Recommender SystemsThis module introduces recommender systems and the course.  It includes a detailed taxonomy of the types of recommender systems, and also includes a detailed tour of Amazon.com’s recommenders.  There is an introductory assessment in the final lesson that leads you through exploring recommender systems on their own.Non-Personalized RecommendersThis module covers non-personalized recommender systems, including recommendation based on summary statistics and on product-association rules.  These recommenders, which are widely used in practice, include overall popularity (how many people like this?  what’s the average rating?) and product-to-product recommenders such as “people who bought this item also bought” recommenders.  There is an assessment at the end of the module that has you compute non-personalized recommendations.  Content-Based RecommendersThis module covers content-based recommender systems.  These systems build a profile of content preferences based on the content attributes associated with items the users has liked or disliked.  We’ll discuss common mechanisms for building and maintaining content preference profiles and have an assessment that has you complete hand computations of content profiles and recommendations.
User-User Collaborative FilteringThis module covers user-user collaborative filtering recommender systems.  This classic method matches a user against other users with similar preferences and then combines the preferences of those “nearest neighbor” users to form predictions and recommendations.  We cover a number of tunings and variations on the algorithm, and have an assessment where you implement your own user-user CF recommender in a spreadsheet.  
EvaluationThis module focuses on metrics and evaluation.  It introduces a variety of metric types, individual metrics, experimental techniques, and evaluation goals.  In many ways, it is at the heart of the course -- what’s the point in having lots of different algorithms if you can’t tell which is better in a situation?  The assessment at the end of this module takes you through a set of situations to test your understanding of effective evaluation.  
Item BasedThis module introduces item-item collaborative filtering, an early innovation that improved run-time performance by computing relationships among items from user rating data.  We also look at the interesting case of unary implicit data (like it or don’t know) and have an assessment that has you compute item-item recommendations in a spreadsheet.
Dimensionality ReductionThis module introduces matrix factorization recommendation algorithms, the class of algorithms that seems to be among the most promising today for good recommendation quality and scalability.  We introduce you to the concepts behind these algorithms, some specific implementations, and a look at current directions.  Your last assessment in the course involves computing predictions and recommendations from factored-matrix representations of ratings matrices.  
Advanced TopicsThis is our concluding module; it includes coverage of topics such as security threats and the cold-start problem as well as a number of other practical issues.  This module also consists of a three-part final exam, covering modules 6-8.",Introduction to Recommender Systems
https://www.classcentral.com/course/artificialvision-1311,"Artificial
vision applications, such as object detection in natural images and automatic
segmentation of medical acquisitions, rely on models that interpret the visual
information provided to a computer. The model provides a compromise between the
support given by the observations and the prior domain knowledge. This course
is concerned with the two computational problems that arise when using such models
in practice.
Inference
(Energy Minimization):
Given a visual observation (for example, an image or an MRI scan), we
are interested in estimating its most likely interpretation (i.e. the location of all
the objects in the image, or the segments of the MRI scan) according to the
model. While the problem cannot be solved optimally, we will describe state of the art approximate algorithms that provide very accurate solutions in
practice. While the theoretical properties of the algorithms will be discussed
briefly, the main emphasis will be on their application.
 Learning
(Parameter Estimation):
Given a set of training samples consisting of inputs and their desired
outputs, (for example, images and the location of the objects, or MRI scans and
their segmentations) we would like to estimate a model that is suited to the
task at hand. We will show how the problem of learning a model can be
formulated as empirical risk minimization. Furthermore, we will present
efficient algorithms for solving the corresponding optimization problem.



            Read more
          



Lecture
1: Introduction to artificial vision with discrete graphical models: In this lecture, the interdisciplinary nature of
computational vision is briefly introduced along with its potential use in
different application domains. Subsequently, the concept of discrete modeling
of artificial vision tasks is introduced from theoretical view point along with
short examples demonstrating the interest of such an approach in low, mid and
high-level vision. Examples refer to blind image deconvolution, knowledge-based
image segmentation, optical flow, graph matching, 2d-to-3d view-point invariant
detection and modeling and grammar-driven image based reconstruction.Lecture
2: Reparameterization and dynamic programming: In this lecture, we provide a brief introduction to
undirected graphical models. We also provide a formal definition of the problem
of inference (specifically, energy minimization). We introduce the concept of
reparameterization, which forms the building block of all the inference
algorithms discussed in the course. We describe a simple inference algorithm
known as dynamic programming, which consists of a series of reparameterization.
We show how dynamic programming can be used to perform exact inference on
chains.
 Lecture
3: Maximum flow and minimum cut:  In this lecture, we introduce the concept of functions on arcs of a directed graph. We
focus on a special function known as the flow function. Associated with this
function is the combinatorial optimization problem of computing the maximum
flow of a directed graph. We also introduce the concept of a cut in a directed
graph, and prove that the minimum cost cut is equivalent to the maximum flow.
We describe a simple algorithm for solving the maximum flow, or equivalent the
minimum cut, problem.Lecture
4: Minimum cut based inference: In this lecture, we show how the problem of inference for undirected
graphical models with two labels can be formulated as a minimum cut problem. We
characterize the energy function that can be minimized optimally using the
minimum cut problem. We show examples using the image segmentation and texture
synthesis problems, which can be formulated using two labels. We consider the
multi-label problem, and devise approximate algorithms for inference based on
the minimum cut algorithms. We show examples using the stereo reconstruction
and the image denoising problems.
Lecture
5: Belief propagation: In this lecture we present the basic concepts of
message passing and belief propagation networks. The concept is initially
demonstrated using chains, extended to the case of trees and then eventually to
arbitrary graphs. The strengths and the limitations of such an optimization
framework are presented. The image completion and texture synthesis problems
are considered as examples to demonstrate the interest of such a family of
optimization algorithms.
Lecture
6: Linear programing and duality:  In this lecture, discrete inference is addressed through concepts coming
from linear programming relaxations. In particular, we explain how a
graph-optimization problem can be expressed as a linear programing one and then
how one can take benefit of the duality theorem to develop efficient
optimization methods. The problem of optical flow and its deformable
registration variant in medical image analysis is considered as an example to
demonstrate the interest of such optimization algorithms.Lecture
7: Dual decomposition and higher order graphs: In this lecture, we introduce the dual decomposition
framework for the optimization of low rank and higher order graphical models.
First, we demonstrate the concept of the method using a simple toy example and
then we extend to the most general optimization problem case. Three different
examples are considered in the context of higher order optimization, the
problem of linear mapping between images, the case of dense deformable graph
matching and the development of pose invariant object segmentation methods in
the context of medical imaging.
Lecture 8: Parameter learning: In this lecture, we introduce two frameworks for estimating the parameters
of a graphical model using fully supervised training data. The first framework
maximizes the likelihood of the training data while regularizing the
parameters. The second framework minimizes the empirical risk, as measured by a
user-defined loss function, while regularizing the parameters. We provide a
brief description of the algorithms required to solve the related optimization
problems. We show the results obtained on standard machine learning
datasets.",Discrete Inference and Learning in Artificial Vision
https://www.classcentral.com/course/foundations-strategic-business-analytics-4371,"Who is this course for?  
This course is designed for students, business analysts, and data scientists who want to apply statistical knowledge and techniques to business contexts. For example, it may be suited to experienced statisticians, analysts, engineers who want to move more into a business role. 

You will find this course exciting and rewarding if you already have a background in statistics, can use R or another programming language and are familiar with databases and data analysis techniques such as regression, classification, and clustering.
However, it contains a number of recitals and R Studio tutorials which will consolidate your competences, enable you to play more freely with data and explore new features and statistical functions in R.

With this course, you’ll have a first overview on Strategic Business Analytics topics. We’ll discuss a wide variety of applications of Business Analytics. From Marketing to Supply Chain or Credit Scoring and HR Analytics, etc. We’ll cover many different data analytics techniques, each time explaining how to be relevant for your business.

We’ll pay special attention to how you can produce convincing, actionable, and efficient insights. We'll also present you with different data analytics tools to be applied to different types of issues.
By doing so, we’ll help you develop four sets of skills needed to leverage value from data: Analytics, IT, Business and Communication. 

By the end of this MOOC, you should be able to approach a business issue using Analytics by (1) qualifying the issue at hand in quantitative terms, (2) conducting relevant data analyses, and (3) presenting your conclusions and recommendations in a business-oriented, actionable and efficient way.

Prerequisites : 1/ Be able to use R or to program 2/ To know the fundamentals of databases, data analysis (regression, classification, clustering)

We give credit to Pauline Glikman, Albane Gaubert, Elias Abou Khalil-Lanvin (Students at ESSEC BUSINESS SCHOOL) for their contribution to this course design.
      


            Read more
          



          Introduction to Strategic Business Analytics
    - In this module, we will introduce you to the course and instructional approach. You will learn that Strategic Business Analytics relies on four distinct skills: IT, Analytics, Business and Communication.

Finding groups within Data
    -In this module, you will learn how identifying groups of observations enables you to improve business efficiency. You will then learn to create those groups in a business-oriented and actionable way. We will use examples to illustrate various concepts. The assessments will also provide you with opportunities to replicate these examples.

Factors leading to events
    -In this module, you will learn why using rigorous statistical methods to understand the relationship between different events is crucial. 

We’ll cover two examples: first, using a credit scoring example, you will learn how to derive information about what makes an individual more or less likely to have a strong credit score? Then, in a second example drawn from HR Analytics, you will learn to estimate what makes an employee more or less likely to leave the company. 
As usual, we invite you to replicate those examples thanks to the recital 
and to use the assessments provided at the end of the module to strengthen your understanding of these concepts.

Predictions and Forecasting
    - In this module you will learn more about the importance of forecasting the future.

You will learn through examples from various sectors: first, using the previous examples of credit scoring and HR Analytics, you will learn to predict what will happen. Then, you will be introduced to predictive maintenance using survival analysis via a case discussion. Finally, we’ll discuss seasonality in the context of the first example discussed in this MOOC: using analytics for managing your supply chain and logistics better. 


Recommendation production and prioritization
    -So far, you’ve learnt to use Business Analytics to glean important information relevant to the success of your business. In this module, you’ll learn more about how to present your Business Analytics work to a business audience. This module is also important for your final capstone project presentation.You’ll learn that it is important to find an angle, and tell a story.Instead of presenting a list of results that are not connected to each other, you will learn to take your audience by the hand and steer it to the recommendations you want to conclude on.You’ll learn to structure your story and your slides, and master the most used visualization tips and tricks. The assessment at the end of this module will provide an opportunity for you to practice these methods and to prepare the first step of the capstone project.",Foundations of strategic business analytics
https://www.classcentral.com/course/futurelearn-through-engineers-eyes-engineering-mechanics-by-experiment-analysis-and-design-5418,"When you design anything, how do you know that the design will work? You need Engineering Mechanics - the science-based analysis that engineers use to predict how their designs will perform, so they can meet their responsibilities for performance and safety.
It starts with physics - forces, equilibrium, acceleration, gravity - but then engineers adapt it to their own purposes.
In this free online course, you will learn analytical skills, use them to understand experiments, and apply them in design. You will be living in the engineer’s world.
An unusual approach to learning Engineering Mechanics
Each of the seven weeks of this course has:

an introduction to set the scene;
experiments to introduce physical reality;
analysis videos, paper and pencil tutorials and in some weeks on-line Adaptive Tutorials to help you develop insights and skills; 
a design activity to give you engineering context (except Week 1);
and a review process to consolidate your learning.

Experiments will be a special feature. You can do them yourself using common household items such as rubber bands, paper clips, string and cardboard, a toy vehicle. Videos and downloadable instructions will guide you. We hope you’ll do some of them, but if not, you can get what you need from watching the videos.
Adaptive Tutorials will be another special feature. They provide a personalised learning experience through virtual ‘learning by doing’ activities that adapt to your progress.
Here are two examples of typical weekly activities:

Week 3 - the experiments and analysis will present tools for finding forces by applying equilibrium, and for the design activity you will specify the size of a bolt that acts as a pin on a fold-out frame.
Week 6 - the experiments will explore various types of resistance to motion, the analysis will introduce concepts of work and energy, and for the design activity, you will estimate the power requirement and range of an electric car.

A life-changing experience
On completing this course you will have:

learnt how to manipulate forces as vectors;
learnt techniques and skills in using free-body diagrams and equilibrium to analyse and predict forces;
understood centres of gravity, friction and various types of resistance;
and apply these capabilities to design.

And by living in the world of the engineer, you will see how they operate effectively and safely. You will have begun to develop “Engineers’ Eyes”.
You will need elementary mathematical skills - basic algebraic manipulation and basic trigonometry. If your maths is rusty, there will be time to catch up.
You will also need access to a scientific calculator and know how to use it (many mobile phones have one -you might have to hold the basic calculator sideways to find it). Calculus is NOT required.



            Read more","Through Engineers' Eyes: Engineering Mechanics by Experiment, Analysis and Design"
https://www.classcentral.com/course/cdt208-1053,"In this 17-week course we will introduce the fundamentals of computational arts–covering basic programming, simple image processing and elementary sound recording. This class has been taught for seventeen years at Stony Brook University, and is an accessible introduction to combining arts and computing.*
For programming we will be using the free and open source programming language and integrated development environment, Processing. The course will provide the essentials of programming in a visual context, allowing you to visualize, design, and create generative art with Processing.
For visuals we will cover Photoshop CS5 and GIMP, which is a free open-source tool offering the same functionality as Photoshop. Whether you have access to one or the other, you will learn how to create and manipulate digital images, and most importantly, you will become comfortable enough to expand on what you learn here, after the end of our course.
For sound we will teach both Logic and Soundation. Logic is Apple’s DAW or Digital Audio Workstation while Soundation is a free web-based multi-track audio editor. We’ll be teaching the basics of digital audio–including recording, and automating effects.
You will complete both technical assignments and artistic projects, and learn how to participate in an aesthetic critique. We’ll cover the history of sound and art in the Twentieth and 21st Centuries to give context for your artistic endeavors.
Peer review is integral to the success of this class; we will also teach you how to give constructive criticism. By the end of the 15 weeks you should have a strong foundation for how computers work and deal with data, specifically how image and sound are represented by the computer.
Additionally, you will create an online portfolio of digital art projects, and be able to communicate ideas about art.  
Each week you will watch two video series - one on the theory and one on the practice. There will be technical assignments and artistic projects which will be peer reviewed. We’re looking forward to working with you.
*If you are interested in just a part of this course, you may want to consider enrolling in the individual segments in the Spring (Intro to Computational Arts Processing, Visual Arts and Audio.)  These courses will not include the use of eportfolio and will not have a summative capstone. 
      


            Read more
          



 
Introduction to Computational Arts Consortium for Digital Arts & Technology (CDACT) Stony Brook University and Coursera
COURSE INFORMATION 
Instructors Dr. Margaret Schedel Catherine Katsafouros (TA)
Course Description This multidisciplinary production class serves as an introduction to, and exploration of electronic media in the arts. Lectures will cover concepts and presentations of artists working in various capacities with computers, as well as tutorials on specific software packages.
Prerequisite No prerequisites or prior knowledge needed. Familiarity with computers is helpful but not necessary.
Course Requirements


Internet connection
Windows or Apple computer
Ability to install software on your machine (admin account) 
Processing software: http://processing.org/
Visual arts software: You may use either
Photoshop: http://www.adobe.com/products/photoshopfamily.html  or Gimp: http://www.gimp.org/
Sound software: You may use either 
Logic: http://www.apple.com/logic-pro/  (Mac ONLY)  or Soundation http://soundation.com/
Digication e-Portfolio account (links and details will be provided)


Course Learning Outcomes  Learners who successfully complete this course will have learned basic skills in three programs: Processing, Photoshop or Gimp, and Logic or Soundation. Throughout the three primary modules, students will be learn to give critical feedback to their peers about technical and artistic matters through a grounding in the history of technology and the arts. A digital portfolio will showcase your work from this course which culminates in a computational artwork using all three programs. 
Processing Outcomes:


Understand the basics of computers, input and output devices, memory, and disks as demonstrated through quizzes and projects
Navigate file systems in Windows and Mac OS X
Demonstrate creative/conceptual awareness of generative design through peer critique
Install and set-up a digital environment using Processing language.
Generate and manipulate type, image and sound, incorporating principles of color, shape and grids.


Visual Arts Outcomes:


Create, edit, manipulate digital images using the basic functions of visual arts software
Demonstrate creative/conceptual awareness of visual design through peer critique
Produce an artistic image using software


Sound Art Outcomes:


Record, edit, and process digital sound using the basic functions of a Digital Audio Workstation.
Demonstrate creative/conceptual awareness of sound art through peer critique
Produce an effective 1-3 minute sound work with a formal structure


Textbook & Course Materials 
Required Text: No required texts Optional Texts: PROCESSING:  Generative Design: Visualize, Program, and Create with Processing by Hartmut Bohnacker (Author), Benedikt Gross (Author), Julia Laub (Author), Claudius Lazzeroni (Editor) ISBN-13: 978-1616890773  Publisher: Princeton Architectural Press
VISUALS: Art of the Digital Age by Bruce Wands  ISBN-13: 978-0500286296 Publisher: Thames & Hudson
MUSIC: Electronic Music (Cambridge Introductions to Music)  by Nick Collins  (Author) , Margaret Schedel  (Author) , Scott Wilson  (Author) ISBN-13: 978-1107648173 Publisher: Cambridge University Press
WEB: HTML and CSS: Design and Build Websites  by Jon Duckett  ISBN-13: 978-1118008188 Publisher: Wiley
GRADING POLICY & COURSE REQUIREMENTS
Grading  Assignments and projects are graded through a peer-review process; quizzes are multiple-choice and are graded by the computer. Your work on the assignments, projects and group presentation will be assessed two ways: your individual work to complete the assignment, project or presentation, and your own review of your peers’ work. Peer review counts as the participation component of your own grade, which means for everything you hand in you will also make substantive comments on the assignments which will be graded, and rate others’ comments
 
Description                Weight                     Participation Component
Quizzes (14)                    15 %                                       0 %
Assignments (12)            20 %                                     20 %  
Project 1 (visual)             20 %                                     25 %
Project 2 (sound)            20 %                                     25 %
Final Project (visual, sound, programming)     25 %                       25 %
 
Passing Grade = 75%
Quizzes 
After watching each video lecture series, you will take a multiple choice quiz which will count towards your final grade. You can only take these quizzes once. There are also “in-video questions,” and you must answer these questions correctly in order to advance the video, but these questions are NOT graded, you can re-do the “in-video” quiz as many times as you need to.
Assignments Assignments are purely technical; each module will include a detailed explanation of how to complete and grade each assignment. There will be 1 assignment (which may have multiple components)  every week that there is no project due.  Each assignment should take you no more than one hour.
Projects Projects are both aesthetic and technical; there will be an explanation of how to grade projects but you must remember that art is subjective. There are only three projects, and together they are worth the majority of your grade. You can expect these projects to take at  least 3-4 hours to complete. (Final project should take 6 hours.)
Group Presentation In groups of 4-7, you will create a five-minute presentation that the other students can view. You can use any method or technology for loading this that works with your eportfolio site and collaborating. There will be a list of topics to choose from on a movement in twentieth or 21st century art or music.
Disclaimer: “The course schedule, policies, procedures, and assignments in this course are subject to change in the event of extenuating circumstances, by mutual agreement, and/or to ensure better student learning.”
COURSE SCHEDULE
Week 01-04 Introduction to Computing and Processing Week 05-09 Introduction to Digital Art and Photoshop/Gimp Week 10-14: Introduction to Electronic Music and Logic/Soundation Week 15: Putting it All Together: Programming, Visuals and Sound
Assignments due:
Week 1    Install Programs
Week 2    Processing Assignment 1
Week 3    Processing Assignment 2
Week 4    Processing Assignment 3
Week 5    Image Assignment 1
Week 6    Image Assignment 2
Week 7    Image Assignment 3
Week 8    Image Assignment 4
Week 9    Project 1 (Image)
Week 10   Sound Assignment 1
Week 11   Sound Assignment 2
Week 12   Sound Assignment 3
Week 13   Project 2 (Sound)
Week 14   Portfolio Assignment 1
Week 15   Project 3 (Processing, Sound and Image)
Week 16 & 17 Project completion and peer grading 
Course Questions - FAQ Have a question about the content of the course? Check the Course FAQs discussion board and if you don’t see the answer to your question there, create a new thread and post your question.  The course instructors will monitor the FAQ discussion board and will respond to questions posted.   
Technical Assistance Technical problems with Coursera should be reported to the support forums in two ways:

Click: HELP WITH COURSERA 
Using the in-context “report a problem” links on the course pages.

Be sure to note: The page where the problem occurred and what problem you had.
 
PEER FEEDBACK GRADING RUBRIC
You will grade each other’s work, and also grade each other’s comments. There will be instructions on how to grade the assignments, projects, and presentation, and each assignment will come with it's own grading chart (rubric) to follow.",Introduction to Computational Arts
https://www.classcentral.com/course/wind-energy-5552,"How tall is a modern wind turbine and how can it possibly generate power from the wind? This course gives an overview of key aspects in wind energy engineering. Whether you are looking for general insight in this green technology or your ambition is to pursue a career in wind energy engineering, 'Wind Energy' is an excellent starting point. 

Experts located in the wind pioneering country of Denmark will take you on a tour through the most fundamental disciplines of wind energy research such as wind measurements and resource assessment, aerodynamics, wind turbine technology, structural mechanics, materials, financial and electrical systems. 

You will gain a rational understanding of wind energy engineering and, through hands-on exercises, you will learn to perform wind energy calculations based on simple models. Working with the different course disciplines will give you a taste of what wind energy engineering is all about. This allows you to identify the most interesting or relevant aspects of wind energy engineering to be pursued in your future studies or in your professional career.

View our video: https://youtu.be/he4UWTGHxrY
      


           About this course
    -This module gives you an overview of the course content and learning objectives. You will see the recommended prerequisites for following the course and find out how to earn points towards your course certificate.

Introduction to wind energy
    -In this module, you will learn why there is a need for wind energy and how wind energy projects are planned. When you have completed the module, you will be able to explain why there is a need for wind energy and what an EIA is. You will also know how to get the most out of the course through interaction with other course participants.

Wind resources
    -It is all about the wind! In this module you will learn how the wind varies with height and during the day and night. You will find out how the wind power density and the power production can be modeled for an area based on different terrain properties. When you have completed the module, you will be able to apply basic engineering models for wind speed and determine the annual energy production for a wind turbine.

Test and measurements
    -‘Test and measurements’ is about different ways to measure the wind and how to to interpret wind observations. When you have completed this module, you will be able to analyse measured wind data and determine the mean wind speed and turbulence.

Economy
    -In this module you will learn about financial aspects during the entire lifetime of a wind turbine. When you have completed the module, you will be able to perform simple calculations for assessing wind farm projects and for calculating the cost of energy from wind.

Wind turbine technology
    -It is now time to focus on the wind turbine itself. In this module you will learn about different wind turbine designs including the modern three-bladed turbine. When you have completed the module, you will be able to account for the configuration and energy production of different wind turbine designs.

Aerodynamics
    -This module on ‘Aerodynamics’ will outline the fundamental principle of a wind turbine and you will learn what makes it turn. When you have completed the module, you will be able to carry out calculations of thrust and power for a wind turbine.

Materials
    -Wind turbines are composed of a variety of materials. In order to create stronger and lighter wind turbine components, especially the blades, new types of materials are being invented. When you have completed this module, you will be able to calculate the mass of a turbine blade based on different material’s properties.

Structural mechanics
    -In this module you will discover which forces act on a wind turbine blade. A blade can be considered as a beam and therefore beam theory is applied. When you have completed the module, you will be able to define boundary conditions and loads on beams and calculate reactions and internal forces.

Electrical systems
    -One of the biggest challenges in wind energy engineering is to integrate the very variable power production from wind turbines into the electrical system. In this module, you will learn to account for the role of wind energy in the energy supply. When you have completed the module, you will be able to apply a strategy for controlling the rotor speed of a variable speed wind turbine.",Wind Energy
https://www.classcentral.com/course/energy-4888,"##
Energy is essential to life at many levels and its transformation from one form to another – whether in the cells of our bodies or the machines that enable modern society – is governed by the laws of thermodynamics.
This free online course provides you with an introduction to these laws, and the application of thermodynamics to both everyday examples and issues of global concern.
Anyone interested in finding out more about the course can visit our Thermodynamics Facebook page
Thermodynamics, sustainability and nature’s limits
Over five weeks, you will explore some of the challenges associated with energy supply and consumption. You will also perform simple experiments in your kitchen, to develop your appreciation of the significance of the laws of thermodynamics. These will help you discover new ways of thinking about energy, and how we use it and lose it.
Gaining new perspectives on the sustainable energy debate is an important skill you will develop, and this will help you to comprehend how we are limited by the laws of nature.  You will also discuss new research that explores the boundaries of these limitations.
Understand thermodynamics with a global network of learners
You will learn with me, Eann Patterson, the AA Griffith Chair of Structural Materials and Mechanics at the University of Liverpool. I will bring my experience of teaching and lecturing in the UK, USA and China, and give you the chance to work alongside University of Liverpool undergraduates, who will be taking this online course as part of their degree course.
If you are interested in reading more before the course starts, you can find background information in Peter Atkin’s book “The Entropy Vector: Connecting Science and Business”, although this is not compulsory. You can also visit my blog.
Develop your skills or career as an engineer
The knowledge you gain from this course may prompt you to consider a career as a professional engineer.
You may even wish to take your learning further, with the University of Liverpool’s Mechanical Engineering or Aerospace Engineering degrees.
The course is aimed at anyone with a need or desire to learn more about the laws governing energy.  Some knowledge of physics and mathematics will be assumed.



            Read more",Energy: Thermodynamics in Everyday Life
https://www.classcentral.com/course/deep-learning-business-9431,"Your smartphone, smartwatch, and automobile (if it is a newer model) have AI (Artificial Intelligence) inside serving you every day. In the near future, more advanced “self-learning” capable DL (Deep Learning) and ML (Machine Learning) technology will be used in almost every aspect of your business and industry. So now is the right time to learn what DL and ML is and how to use it in advantage of your company. This course has three parts, where the first part focuses on DL and ML technology based future business strategy including details on new state-of-the-art products/services and open source DL software, which are the future enablers. The second part focuses on the core technologies of DL and ML systems, which include NN (Neural Network), CNN (Convolutional NN), and RNN (Recurrent NN) systems. The third part focuses on four TensorFlow Playground projects, where experience on designing DL NNs can be gained using an easy and fun yet very powerful application called the TensorFlow Playground. This course was designed to help you build business strategies and enable you to conduct technical planning on new DL and ML services and products.
      


          Deep Learning Products & Services 
    -For the course “Deep Learning for Business,” the first module is “Deep Learning Products & Services,” which starts with the lecture “Future Industry Evolution & Artificial Intelligence” that explains past, current, and future industry evolutions and how DL (Deep Learning) and ML (Machine Learning) technology will be used in almost every aspect of future industry in the near future. The following lectures look into the hottest DL and ML products and services that are exciting the business world. First, the “Jeopardy!” winning versatile IBM Watson is introduced along with its DeepQA and AdaptWatson systems that use DL technology. Then the Amazon Echo and Echo Dot products are introduced along with the Alexa cloud based DL personal assistant that uses ASR (Automated Speech Recognition) and NLU (Natural Language Understanding) technology. The next lecture focuses on LettuceBot, which is a DL system that plants lettuce seeds with automatic fertilizer and herbicide nozzles control. Then the computer vision based DL blood cells analysis diagnostic system Athelas is introduced followed by the introduction of a classical and symphonic music composing DL system named AIVA (Artificial Intelligence Virtual Artist). As the last topic of module 1, the upcoming Apple watchOS 4 and the HomePod speaker that was presented at Apple's 2017 WWDC (World Wide Developers Conference) is introduced.

Business with Deep Learning & Machine Learning
    -The second module “Business with Deep Learning & Machine Learning” first focuses on various business considerations based on changes to come due to DL (Deep Learning) and ML (Machine Learning) technology in the lecture “Business Considerations in the Machine Learning Era.” In the following lecture “Business Strategy with Machine Learning & Deep Learning” explains the changes that are needed to be more successful in business, and provides an example of business strategy modeling based on the three stages of preparation, business modeling, and model rechecking & adaptation. The next lecture “Why is Deep Learning Popular Now?” explains the changes in recent technology and support systems that enable the DL systems to perform with amazing speed, accuracy, and reliability. The last lecture “Characteristics of Businesses with DL & ML” first explains DL and ML based business characteristics based on data types, followed by DL & ML deployment options, the competitive landscape, and future opportunities are also introduced.

Deep Learning Computing Systems & Software
    -The third module “Deep Learning Computing Systems & Software” focuses on the most significant DL (Deep Learning) and ML (Machine Learning) systems and software. Except for the NVIDIA DGX-1, the introduced DL systems and software in this module are not for sale, and therefore, may not seem to be important for business at first glance. But in reality, the companies that created these systems and software are indeed the true leaders of the future DL and ML business era. Therefore, this module introduces the true state-of-the-art level of DL and ML technology. The first lecture introduces the most popular DL open source software TensorFlow, CNTK (Cognitive Toolkit), Keras, Caffe, Theano, and their characteristics. Due to their popularly, strong influence, and diverse capabilities, the following lectures introduce the details of Google TensorFlow and Microsoft CNTK. Next, NVIDIA’s supercomputer DGX-1, that has fully integrated customized DL hardware and software, is introduced. In the following lectures, the most interesting competition of human versus machine is introduced in the Google AlphaGo lecture, and in the ILSVRC (ImageNet Large Scale Visual Recognition Challenge) lecture, the results of competition between cutting edge DL systems is introduced and the winning performance for each year is compared.

Basics of Deep Learning Neural Networks
    -The module “Basics of Deep Learning Neural Networks” first focuses on explaining the technical differences of AI (Artificial Intelligence), ML (Machine Learning), and DL (Deep Learning) in the first lecture titled “What is DL (Deep Learning) and ML (Machine Learning).” In addition, the characteristics of CPUs (Central Processing Units) and GPUs (Graphics Processing Units) used in DL as well as the representative computer performance units of FLOPS (FLoating-Point Operations Per Second) and IPS (Instructions Per Second) are introduced. Next, in the NN (Neural Network) lecture, the biological neuron (nerve cell) and its signal transfer is introduced followed by an ANN (Artificial Neural Network) model of a neuron based on a threshold logic unit and soft output activation functions is introduced. Then the extended NN technologies that uses MLP (Multi-Layer Perceptron), SoftMax, and AutoEncoder are explained. In the last lecture of the module, NN learning based on backpropagation is introduced along with the learning method types, which include supervised learning, unsupervised learning, semi-supervised learning, and reinforcement learning.

Deep Learning with CNN & RNN 
    -The module “Deep Learning with CNN & RNN” focuses on CNN (Convolutional Neural Network) and RNN (Recurrent Neural Network) technology that enable DL (Deep Learning). First the lectures introduce how CNNs used in image/video recognition, recommender systems, natural language processing, and games (like Chess and Go) are made possible through processing in the convolutional layer and feature maps. The lecture also introduces how CNNs use subsampling (pooling), LCN (Local Contrast Normalization), dropout, ensemble, and bagging technology to become more efficient, reliable, robust, and accurate. Next, the lectures introduce how DL with RNN is used in speech recognition (as in Apple's Siri, Google’s Voice Search, and Samsung's S Voice), handwriting recognition, sequence data analysis, and program code generation. Then the details of RNN technologies are introduced, which include S2S (Sequence to Sequence) learning, forward RNN, backward RNN, representation techniques, context based projection, and representation with attention. As the last part of the module, the early model of RNN, which is the FRNN (Fully Recurrent NN), and the currently popular RNN model LSTM (Long Short-Term Memory) is introduced.

Deep Learning Project with  TensorFlow Playground
    -The module “Deep Learning Project with TensorFlow Playground” focuses on four NN (Neural Network) design projects, where experience on designing DL (Deep Learning) NNs can be gained using a fun and powerful application called the TensorFlow Playground. The lectures first teach how to use the TensorFlow Playground, which is followed by guidance on three projects so you can easily buildup experience on using the TensorFlow Playground system. Then in Project 4 a “DL NN Design Challenge” is given, where you will need to make the NN “Deeper” by adding hidden layers and neurons to satisfy the classification objectives. The knowledge you obtained in the lecture of Modules 1~5 will be used in these projects.",Deep Learning for Business
https://www.classcentral.com/course/edx-data-science-and-agile-systems-engineering-19101,"Modern systems today must be designed for agility in order to outpace the competition. Concepts like Agile, DevOps, and Data Science were once considered only for the technology-based companies. Today that means every company. Because there is no greater currency than timely information for optimizing operations and meeting the needs of customers.
Modern product management requires that every development and operations value stream is identified and continuously improved. This means using Lean and DevOps principles to streamline handoffs and information flows across teams. It means reorienting towards self-service and automation wherever possible. And to avoid incrementalism, it means a robust Agile development process to keep innovations important and aggressive enough to make noticeable improvements in value delivery.
Agile systems in a DevOps environment requires that products are built completely differently from a traditional designs. Modularity, open set architectures, and flexible data management paradigms are a starting point. The evolutionary nature of the product with so much change enables functionality, design, and technology to drive and influence each other simultaneously. And beneath it all is a data collection and feedback loop essential for anticipating and reacting to business needs both for operations and marketing.
Data science and analytics are the lifeblood of any product organization, and enable product managers to tackle risks early. Luckily, new technologies allow us to collect and integrate data without extreme upfront constraints and onerous controls. This means all data is fair game, and when tagged and stored properly, can be made available at nearly any scale for preparation, visualization, analysis, and modeling.
We’ll teach you the paradigms, processes, and introduce some key technologies that make the data-driven product organization the optimal competitor in the market.



            Read more
          



Module 1: Agile Systems Engineering 
Module 2: DevOps Principles for Business Agility 
Module 3: Data Science for Product Risk Management 
Module 4: Implementing Data-Driven Controls using Technology and Teams",Data Science and Agile Systems Engineering
https://www.classcentral.com/course/harvardx-data-science-18421,"The demand for skilled data science practitioners in industry, academia, and government is rapidly growing. The HarvardX Data Science program prepares you with the necessary knowledge base and useful skills to tackle real-world data analysis challenges. The program covers concepts such as probability, inference, regression, and machine learning and helps you develop an essential skill set that includes R programming, data wrangling with dplyr, data visualization with ggplot2, file organization with Unix/Linux, version control with git and GitHub, and reproducible document preparation with RStudio.
In each course, we use motivating case studies, ask specific questions, and learn by answering these through data analysis. Case studies include: Trends in World Health and Economics, US Crime Rates, The Financial Crisis of 2007-2008, Election Forecasting, Building a Baseball Team (inspired by Moneyball), and Movie Recommendation Systems.
Throughout the program, we will be using the R software environment. You will learn R, statistical concepts, and data analysis techniques simultaneously. We believe that you can better retain R knowledge when you learn how to solve a specific problem.



Courses under this program:Course 1: Data Science: R Basics
Build a foundation in R and learn how to wrangle, analyze, and visualize data.
Course 2: Data Science: Visualization
Learn basic data visualization principles and how to apply them using ggplot2.
Course 3: Data Science: Probability
Learn probability theory -- essential for a data scientist -- using a case study on the financial crisis of 2007-2008.
Course 4: Data Science: Inference and Modeling
Learn inference and modeling, two of the most widely used statistical tools in data analysis.
Course 5: Data Science: Productivity Tools
Keep your projects organized and produce reproducible reports using GitHub, git, Unix/Linux, and RStudio.
Course 6: Data Science: Wrangling
Learn to process and convert raw data into formats needed for analysis.
Course 7: Data Science: Linear Regression
Learn how to use R to implement linear regression, one of the most common statistical modeling approaches in data science.
Course 8: Data Science: Machine Learning
Build a movie recommendation system and learn the science behind one of the most popular and successful data science techniques.
Course 9: Data Science: Capstone
Show what you've learned from the Professional Certificate Program in Data Science.",Data  Science
https://www.classcentral.com/course/chimp-13137,"Chimpanzees are one of our closest living relatives, yet almost nothing was known about their behavior in the wild until Jane Goodall started her groundbreaking study of the chimpanzees of Gombe, Tanzania in 1960. This study continues today, following the same chimpanzee families that Jane Goodall first encountered over 55 years ago. Guided by three course instructors who have lived and worked with the Gombe chimpanzees, you will learn how Goodall’s early discoveries changed our view of human uniqueness. By completing the course, you will gain a new appreciation of the deep similarities between chimpanzees and humans in intelligence, tool use, hunting, personality and social relationships, as well as some key differences. You will learn how chimpanzees interact with their environment and how their behavior is influenced by ecology, as well as the severe conservation challenges they face today. And you will employ your new knowledge of chimpanzees to construct a persuasive argument for their protection. This course is open to everyone interested in learning more about these fascinating and complex beings. Knowledge of high-school level biology is beneficial but not required. Please keep in mind, however, that the content of this course will cover all aspects of chimpanzee life, including scientific discussion of sexual and aggressive behaviors.
      


          Introduction 
    -Welcome! We are glad you chose to join us to learn more about chimpanzees. We are looking forward to sharing what we've learned while we have studied chimpanzees. Please watch our welcome video to get started. 

The Early Days 
    -For this week, learners will experience the adventure and risks that Jane Goodall undertook in launching her research at Gombe.  Learners will be able to recognize why it's important to study chimpanzees and the kinds of research questions we can ask by studying them. Learners will be able to identify different techniques used to collect the different kinds of data necessary to answer the research questions. Additionally, learners will be able to identify the range of chimpanzee populations across Africa and the structure of chimpanzee communities.

Early Life and Mother-Infant Bonds
    -In this week, learners will understand key similarities and differences in birth and motherhood in chimpanzees and humans and will be able to list and explain major development milestones in infant and juvenile chimpanzees.  Additionally, learners will be able to classify types of infant play and recognize the value of play for chimpanzee development.  

Making a Living in the Forest
    -Upon completion of this week's materials, learners will be able to create a framework to outline a typical day in the life of a chimpanzee.  This includes being able to identify important food sources for chimpanzees and being able to relate differences in diet to changes in behavior.  Learners will also be able to hypothesize about the cognitive skills required for chimpanzees to forage and hunt successfully.  

Social Lives and Relationships
    -In this week, learners will be able to identify the types of competitive and friendly behavior that chimpanzees demonstrate between and within groups. They will appreciate the importance of dominance hierarchies and how these are determined and be able to evaluate the importance of close social bonds for chimpanzees.  Learners will also be able to identify both male and female mating strategies, including female sexual swellings and when they occur.  Additionally, by the end of this week learners will be able to explain why there can be conflict between males and females over mating and why inbreeding is worse for females than males.  

Protecting Chimpanzees
    -In this week, learners will be able to identify and describe threats to chimpanzee populations and evaluate the role that captive chimpanzees play in chimpanzee conservation.  Learners should also be able to make an effective argument against the use of chimpanzees in entertainment in terms of effects on conservation efforts and attitude, as well as assess the importance of education and human wellness in conservation outcomes.  Lastly, learners should be inspired to contribute to the goal of chimpanzee conservation through actions and outreach.",Chimpanzee Behavior and Conservation
https://www.classcentral.com/course/it-project-management-7183,"The concepts and use of project management tools, techniques and methodologies are becoming all pervasive. This course addresses project management in the context of IT projects, including software projects. Using the framework of project life cycle, the course covers various aspects pertaining to (i) project initiation, (ii) project planning and scheduling, (iii) project monitoring and control, and (iv) project termination. For planning and scheduling of projects, the use of project network and estimation of time and cost are covered in detail.  Scheduling of projects with resource limitations is covered next.

Risk assessment methods including simulation and risk reduction approaches are also be covered. The students will be required to use the software @risk to simulate project completion times. The use of Earned Value Analysis for Project Monitoring and Control is emphasized. For Software Project Management, the Waterfall Model and Agile Project Management are covered in detail.
      


          Introduction and Real Options
    -The first topic in this module is Introduction and Overview of the course.  We first define what a project is and give some examples of IT projects. The three parameters or metrics for project management are presented. The importance of project management is then discussed. The concept of project life cycle and the four phases of project life cycle are presented. The topics to be covered in the four different modules are also given.The second topic in this module is on the Organization Structure for projects. Three different forms of Organization structure and their implications for project management including the project manager are discussed in detail. Communication plan and its importance for project management are then presented.The next topic in this module is about the use of real options for project selection. The material in this topic is well developed for valuation of financial assets but its use for project selection is a relatively new development. We define what options are and give a taxonomy of real options. In future, ‘Options Thinking” and valuation of real options are expected to play an important role in project selection. Next, we discuss six case studies where options thinking played a dominant role in accepting / modifying the projects. Valuation of real options is in its infancy and for the for valuation of real options is easily understand and we present a simple example to illustrate the approach.Towards the end of the module, we present some practical aspects pertaining to the concepts covered. This is done through a Q & A format with Mr. Prashun Dutta, Advisor - Gaiga Smart Cities 

Project Network Scheduling and Crashing
    -This module will cover Project Planning which is the second phase of Project Life Cycle. We first look at what Project Scope is and what scope creep refers to. Work Breakdown structure leading to work packages or activities with the associated precedence relationships are treated in detail.  The next topic is about scheduling of the activities which requires the estimation of activity durations. The estimation of duration, cost and resource required for the identified activities are covered later as a separate topic. Here, using the same software development project, assuming that the durations of the activities have been estimated and ignoring the resource requirements for the different activities, we show how a schedule for the activities can be arrived at. The next topic is the estimation of durations, cost and resources required for the activities. Three popular estimating procedures are covered. The next topic covers the various reasons, possible benefits and different alternatives for reducing project duration. We then discuss in detail, one approach to reducing project duration viz. by incurring additional incremental direct cost for reducing activity durations and show how we can arrive at the least incremental direct cost for any specified project completion time. While the approach presented is conceptually sound it is difficult to implement for large projects. So, the next topic covers a linear programming approach to solve the same problem even if the project under consideration is large in terms of the number of activities.   As in the previous module, towards the end of this module also, we present some practical aspects pertaining to the concepts covered. This again is done through a Q & A format with Mr. Prashun Dutta, Advisor - Gaiga Smart Cities

Resource Scheduling and Risk Management
    -Activities in a project typically require the use of resources such as people, material, equipment and working capital. The schedule for the activities that we had calculated in the previous module assumes that adequate resources are available as and when required. However, in practice often adequate resources may not be available as required and the schedule may have to be modified. There are two types of problems when resource requirements are considered. One is the Resource Smoothing Problem and the other is the Resource Limitation problem. In the first one, i.e. the Resource Smoothing Problem, although the resources are available as and when required, we would want to find a schedule that “smoothes” the use of resources without delaying the project completion time.  Critical Chain Project Management (CCPM) is the next topic dealt with in this module.  CCPM has not gained universal acceptance although it is being used by some organizations with positive results. CCPM places a lot of emphasis on aggressive estimation of activity durations and provides for buffers to take care of some delays.  With Risk Management, we first define what risk is and then discuss the risk management process including risk identification, risk assessment and various ways of reducing exposure to risk. Risk monitoring and control including change control process are also covered. Finally, the Program Evaluation and Review Technique (PERT) including a simulation approach to finding the distribution of the project completion time is covered as the last topic in this module. As in the previous modules, towards the end of this module, we present some practical aspects pertaining to the concepts covered. This again is done through a Q & A format with Mr. Prashun Dutta, Advisor - Gaiga Smart Cities

Agile Project Management, Monitoring and Control
    -The first topic in this module is Agile Project Management which is useful in software development projects where the requirements are not well defined and the client is not able to articulate them clearly. The traditional sequential plan driven project is covered first followed by the agile project development cycle. The manifesto and agenda for agile project management are also covered.The next topic in this module is Monitoring and Control. The projects in progress should be reviewed at pre-specified intervals. The process of monitoring and control including the analysis of the status of the project are covered. The last two topics to be covered are Audit and Closure of projects. The audit may be of an ongoing project or of a completed project. The various steps involved in the audit process including the staffing of the audit team, functioning of the team, data collection, analysis and reports are covered in detail.The closure of a project may be a normal closure or a premature closure. The various tasks involved including the delivery of the output of the project, evaluation of the team as well as the project manager are spelt out. Towards the end of this module, we present some practical aspects pertaining to the concepts covered. This is done through a Q & A format with Mr. Prashun Dutta, Advisor - Gaiga Smart Cities",IT Project Management
https://www.classcentral.com/course/edx-introduction-to-probability-11423,"Probability and statistics help to bring logic to a world replete with randomness and uncertainty. This course will give you tools needed to understand data, science, philosophy, engineering, economics, and finance. You will learn not only how to solve challenging technical problems, but also how you can apply those solutions in everyday life. 
With examples ranging from medical testing to sports prediction, you will gain a strong foundation for the study of statistical inference, stochastic processes, randomized algorithms, and other subjects where probability is needed.




Unit 0: Introduction, Course Orientation, and FAQ
Unit 1: Probability, Counting, and Story Proofs
Unit 2: Conditional Probability and Bayes' Rule
Unit 3: Discrete Random Variables
Unit 4: Continuous Random Variables
Unit 5: Averages, Law of Large Numbers, and Central Limit Theorem
Unit 6: Joint Distributions and Conditional Expectation
Unit 7: Markov Chains",Introduction to Probability
https://www.classcentral.com/course/designingcities-1047,"Please Note: Designing Cities will close for new learner enrollment on September 30, 2019. Enrolled learners have until March 28, 2020 to complete all graded assignments and earn a Course Certificate. 

Each module in Designing Cities will focus on a different aspect of city design including: How Today’s City Evolved; The Ideas That Shape Cities; Tools for Designing Cities; Making Cities Sustainable; Cities in the Information Age; Preserving Older Cities; Designing New Cities, Districts and Neighborhoods; The Challenges of Informal Cities and Disadvantaged Neighborhoods; and Visionary Cities.  Materials will be presented by the instructors and guest faculty from PennDesign through a series of five or more lessons per module, each typically 10-12 minutes long.   

The first lesson in each module will be a roundtable discussion among professors Stefan Al, Jonathan Barnett, and Gary Hack introducing the big issues associated with the subject.  Each succeeding module will be a self-contained illustrated presentation of a set of ideas and images. There will be a list of suggested readings for those who wish to follow up on the ideas in each module.

Everyone enrolled in Designing Cities will be expected to complete 3 assignments.  These will be posted on the course site and they will be in the form of peer assessments.  There will be a great deal to be learned from the ideas participants submit, reflecting cities of all sizes and circumstances across the globe so once you submit your assignment, you'll be able to see what your peers have done.
      


            Read more
          



          How Today’s City Evolved
    -Sometimes people talk about cities as if they are outside people’s control, like the weather. We are using the word designing in the name of our course, because everything that happens to shape cities is actually the result of decisions made by governments, business investors, and citizens. Our course is about understanding how and why these decisions get made, and how they can be organized and improved. In other words, the ways cities are designed, and ways people can design them to be better. 

Almost everyone lives in or near a city, and some people taking this course will just want to find out more about the forces that shape where they live. Other people who enroll in our course will come from the design professions: architects, landscape architects, urban planners, or students in these subjects. Others may come from economics, engineering or the social sciences. We hope some will be government officials or people active in organizations that try to improve their communities. 

There are courses on line in engineering, mathematics, or the sciences, where you can be tested about whether you have mastered the material. Other courses are about understanding and evaluating something like a book, a film, or a painting, where your responses are clearly shaped by what you are studying. Designing Cities draws on so many subjects, and responds to so many different geographical and social conditions, that we have structured our assignments to draw you into a conversation, or as close to a conversation as we can get with so many participants. We will be asking you to identify and evaluate situations in your own communities based on what you will be learning in our course. We will select a few representative assignments to discuss after each assignment is due, and we hope that you will continue the discussion in the Forums. 

As you will see from the schedule on the course website, each week will have a theme, and there will be 4 or 5 modules related to that theme you should watch each week. There will be 3 assignments. In addition to the presentations we and our guest lecturers will be making, we will provide you with suggested reading assignments for each module. We think the presentations stand on their own; but, if you have access to the books we suggest, you will be able to deepen your understanding, and find ways to go beyond our course on subjects that particularly interest you. 

So again, welcome. More and more people in the world are being drawn to cities. How to design cities so they are sustainable and provide a better life for everyone could not be more important: right now and in the future. 

Ideas That Shape Cities
    -During the opening week we have given you a very quick sketch of the evolution of cities from pre-industrial times to today’s multi-centered urban regions. Of course you understand that charting the development of cities encapsulates almost everything that has happened in the last 200 years. We can’t possibly tell the whole story, but we hope we have a provided a useful framework. In this second week we will be introducing you to some of the ideas that have shaped the design of cities. We start with Modernist City Design, which is not so modern any more as it began in the 1920s, but is still a major force. Then we discuss Traditional City Design which builds on ideas about public space that go back before the industrial revolution. Green City Design, our next topic, is increasingly important today because of the need to preserve natural resources and adapt to climate change – but some of the ideas about Green City Design go back thousands of years, particularly in China, Korea and Japan. Systems City Design also has deep historical roots, but big advances in systems thinking about cities have been made possible by computers. We present these ideas as being of equal importance in their different ways, and remind you that the distinctions we make are to some extent artificial: city designers may need to draw on all four, depending on the situation. But there are people who take sides. Modernists attack traditional design as unsuitable today; traditionalists say that modernism makes cities unlivable. Green urbanists say that landscape should be primary, not buildings; and systems designers can assert that other kinds of design are inefficient and not based on objective standards. You are free to take sides, yourselves, if you wish, and most people will have preferences for one kind of design over another. But we think that treating city design ideas as exclusive ideologies is a mistake; improving cities is difficult enough already. It is important, however, to understand where city design ideas come from, to be able to recognize them in your own communities, and to know how to draw on these ideas when you make your own designs. 

Tools for Designing Cities
    -We have seen that powerful design ideas can have a big influence on cities: towers surrounded by open space, a tree-lined boulevard, houses set amid lawns and gardens, a corridor of denser buildings supported by a transit line. But city design is not an “act of will” by an individual designer. It is a complicated process involving government, private investment, and the public – acting as both consumers, and as concerned local citizens. 

During this week we will begin discussing some of the important ways to manage the design and development of cities, such as investments in infrastructure, writing codes and design guidelines, and creating financial incentives for better city design, plus negotiation as a means of resolving disagreements – and sometimes outright controversy. 

Governments and utilities decide where to locate water and sewer pipes, electricity, phone and cable wires, highways and bridges, trains and transit, airports and ports – and all these decisions have a powerful shaping effect on cities. The inclusive name for all these services is infrastructure. We will make a preliminary presentation about them this week, but infrastructure issues will be a recurring theme as our course goes forward. Later on in the course we will also be discussing informal settlements which have grown up without much infrastructure. The issue then becomes how to retrofit these places and give them necessary support. 

Government regulation is another big shaping force for cities. Most development does not go forward without some kind of official permit. If the public is getting the development it is officially requiring, the question becomes: is this really the best development, and – if not – why not? How to write codes and regulations to produce the most desirable city is another big city design issue which we will begin discussing this week. 

Real-estate investment is obviously another powerful force shaping cities. Every city design concept raises questions about who benefits and who is going to pay. This week we will begin discussing the financial incentives which can help implement city designs. 

Finally, people often disagree about what is best for a city. Resolving these differences requires negotiation, sometimes after confrontation. In your own community you may well have seen zoning disputes about a new shopping center or a tall building; controversies about changes in highways or transit routes; or concerns about the preservation of landscape and open space. These are all city design issues, and they demonstrate how important achieving the right kind of city design is for everyone. 

Making Cities Sustainable
    -Last week we learned about tools that manage the design and development of cities, including infrastructure investments, codes and design guidelines, financial incentives for better city design, and negotiations for common goods between those who build cities and those who make sure the public interest is served. These tools are even more important today, since climate change poses an acute threat to our cities, and the way in which our cities have been designed has been part of the problem. 

This week we will deal with some of the most important ways of making our cities more sustainable. We will discuss topics such as ecological urbanism, transportation as a growth armature, managing water -including floods and water scarcity, and green infrastructure and renewable energy. 

Landscape architecture has gained momentum lately as an important instrument of urban development. Landscape urbanism, ecological urbanism, and landscape infrastructure are some recent concepts about how to synthesize cities with nature. This is not simply about topography and trees, but more broadly about ecologically driven infrastructure, public space, and urbanization. 

Transportation is more than moving people from place to place. It has the ability shape the form, function, and quality of life of cities. We will look at some of the ways in which transportation can contribute to the creation and continuing viability of great urban centers, using fewer resources. 

As temperatures are increasing, glaciers are receding, ocean levels are rising, and storms are intensifying, how should we rethink the design and location of cities, especially coastal cities? As global warming shrinks freshwater supplies while populations continue to grow, how can we improve cities’ provision of water? We will look at some of the most important ways for cities to manage water, including how to fight water scarcity and prevent or mitigate floods. 

Urban green spaces should not be seen just as places for leisure time, but also as a viable alternative to grey infrastructure. For instance, green roofs, bio swales, and constructed wetlands can perform such functions as storm water management and water purification. Finally, instead of using traditional energy sources in cities that contribute to heating up our atmosphere, we can achieve zero-carbon communities by using renewable energy from natural sources that are continually replenished, including solar power, wind, biomass and geothermal heat. Today, as the effects of climate change become apparent, cities around the world should increasingly build green infrastructure and use renewable energy. 

Cities in the Information Age
    -This week we focus on the issue of communication in cities. The ability to communicate with others is becoming the central purpose of cities as they become more and more centered on service economies. It determines where people wish to live, their travel patterns, the needs for electronic networks and the need for public places. We explore here what designers can do to create modern information centered places. Week 4 ended with a discussion of green infrastructure and renewable energy. The first session of Week 5 follows up on this, focusing on how cities can manage energy consumption. Energy is the essential input for cities, and the form, layout and energy sources play a large role in determining how efficiently cities operate. The second session joins energy and communication, by focusing on the electronic networks that are an essential infrastructure of cities. Energy is not simply electrons operating within wires or over space, but also the vehicle for conveying meaningful information. We see how cities control their systems, protect from threatening incidents, and promote communication between their residents. While new electronic networks allow people to live at a distance from each other, they have also promoted face-to-face communication. The public and private spaces in cities provide the settings for people to meet, see others and interact. How they are designed can make a large difference in whether cities are considered sociable. Finally, we explore the desire by many people to live in places that are near their work, shopping and recreation. Some cities have always had such places, but many more recent cities were founded on the modernist idea of separating the functions of cities. We will look at examples of successful mixed use buildings and neighborhoods. We are also in the midst of the second assignment, which asks you to identify great places in your city. Keep in mind the lessons of this and the past week’s sessions as you take photographs of places that you value. 

Preserving Older Cities
    -We ended last week describing how mixing home, work, culture and recreation, rather than separating them by regulation is the key to creating 21st century cities. Inherited environments almost always have part of that urban mix already. This week we will deal with some of the most important ways of preserving the valuable qualities of older cities. Historic preservation is the practice that conserves, redevelops and interprets these environments. We will discuss topics such as landmarks and historic districts, adaptive re-use of old buildings, and preserving the industrial heritage. The first session deals with landmarks and historic districts: recognizing and listing historic buildings, and the public policy and design tools that help city designers preserve and regulate historic environments. But historic preservation is not just about congealing a place in time. While a curatorial approach to preservation restores buildings to specific periods, the urbanistic tradition of preservation seeks to preserve the whole place and life, while promoting economic vitality. As we reduce, reuse and recycle waste, so we can give buildings a new life when their use expires. This is what we call adaptive reuse: to give a disused building a new purpose in order to help prolong its lifespan, instead of outright demolition. Adaptive reuse helps preserve a building’s heritage features and ensures them for future generations. How can we adapt historic structures such as churches, palaces, and houses to the needs of the present, without destroying their authenticity? Old industrial buildings are often unique spaces. Built to withstand heavy industrial processes, and to accommodate large equipment, they often have thick walls, high ceilings, and exposed structures that give this rugged industrial look that is now all too fashionable. But as cities move from an industrial to post-industrial economy, what to do with our historic factories, warehouses and power stations? We will look at some of the most important examples of preserving and adapting our industrial heritage. Finally, toward the end of this week we will select some of your second assignments and review them. 

Designing New Cities, Districts and Neighborhoods
    -Last week we focused on ways to maintain and capitalize on the unique aspects of a city’s past, through creating historic districts and designating historic buildings, and re-using and sometimes repurposing older structures. Preservation has cultural importance, as well as contributing to the identity of a city. This week we turn to the opportunities to create new portions of cities and new places. One longstanding proving ground for new ideas about designing cities has been the process of creating new towns. After our introduction, the first module this week is on new towns. It comes in two parts, because there is so much to say about this aspect of urban design. Then we turn our attention to how to think about the task of designing smaller new urban places. How can the special natural features of sites be reflected in what is built? How important is compatibility in the new additions to a city? These issues often preoccupy urban designers and those reviewing plans. In the final module of the week, we discuss the subject of how to create walkable neighborhoods. Many of the older neighborhoods of cities are walkable, and much loved for it, while many of the modernist areas of cities are difficult to navigate on foot, and are organized to make driving almost a necessity. What constitutes walkability, and how can it be designed into communities? Foot power is the oldest form of locomotion, and may be the most relevant for a future where we seek to minimize energy usage and carbon levels. We also begin the final assignment this week. It is an opportunity to apply the ideas you have seen and thought about over the past several weeks to an issue or area of your city that you could imagine being better designed. Think expansively, and see what you can come up with! 

The Challenges of Informal Cities and Disadvantaged Neighborhoods
    -Much of our discussion to this point in Designing Cities has focused on more developed cities in Europe, North America and Asia. But over the next several decades, the rapidly multiplying cities of Latin America, Africa and South Asia will represent a large fraction of the World’s urbanization. As David Gouverneur describes in his module, much of the urbanization will occur as informal settlements that need to be provided with facilities and services later. These are a different kind of challenge for urban designers, and interesting models are emerging in Latin American Cities. Two modules are devoted to essential techniques for upgrading the quality of such settlements. The first focuses on adjustments to land tenure, to provide security for informal settlements, and to allow a better designed transition from rural to urban development. The second looks at how services and infrastructure can be inserted into ongoing living informal settlements. The approach is that of surgical urban design. Finally we address the issue of what role urban design can play in combating poverty and urban deterioration. We look at examples of upgrading efforts that elevate both the spirit and economic prospects of areas of cities. We see that design is much more than a cosmetic exercise of producing beautiful cities

Visionary Cities
    -So far we have focused on city designs that were actually built. But throughout history, architects, artists and philosophers, have imagined and drawn up visionary cities. Many of these designs are what we call “paper” projects, since they were typically relegated to the drawing boards only, and never built. Despite this, some were very influential, and inspired generations of city designers. 

This week we will look at visionary cities. A range of new historical conditions, whether technological progress, political situations, or environmental problems, have inspired designers to radically rethink the future of cities. We will focus on four kinds: technological visions, revolutionary visions, ecological visions, and self-organizing cities. 

What would it be like to live in a walking robot, a floating city, or a flying spaceship? Is this mere science fiction, or the shape of cities to come? In the first lecture we will look at the most experimental cities of the past century, conjured up by designers electrified by technological progress. 

What if our cities were covered with large domes to be more energy efficient, or if floating pods housed climate refugees and cleaned carbon-saturated air? In the second class we will look closer at some of the most visionary eco-cities. 

Designing cities is also a form of colonization, a tool to help establish political control over a territory. In the third class we will look at visionary cities drawn up by designers armed with a radical political mission: to subvert or overthrow the establishment. 

In reality, many parts of the world do not follow grand designs. As we have seen last week, informal settlements follow a different logic, often characterized by self-help housing construction. In the final lecture, we will see how some designers have tried to harvest some of the self-organizing processes in cities. 

As you are handing in your third assignment this week, we hope that some of the examples shown will inspire you to rethink the way in which we organize our cities. 


 Concluding Comments
    -We have come to the end of our course, and while we could say much more, you need a break from our thoughts and images. As we have said in past reviews, the assignments submitted have spanned the globe, and brought to us very interesting observations about what makes cities great.But let us add a few thoughts now: Most of the video lectures of Designing Cities have focused on the ideas about how to design cities – in history, today, and in the future. These ideas have had currency across national boundaries, and it is hard to find any place today that isn’t the product of ideas that can be traced to other countries and societies. However, to put ideas into action, there are strong local traditions about how city design is carried out. Some cities are largely built by city or national governments, acting as developers. Many of China’s recent new towns fit this description, as do some of the national capitals we have shown. Other cities are largely the result of private actions, often influenced by development regulations that governments impose. This is the case in most North American cities, as we have noted. Many European cities guide development more strictly by creating urban design plans that private developers must respect. Still other areas are created by special purpose entities chartered for the purpose of carrying out important projects, as with the British new towns and Battery Park City in New York. Cities also differ in the role of professionals and citizens in influencing development. In many countries, procedures have been created that provide an avenue for citizens to react to development plans and projects. England’s planning inquiries, and the public participation and hearing procedures of many American cities are examples. Some American cities have created design commissions, with a membership of design professionals and informed citizens, who review plans and projects before they are considered for approval. But in other countries, decisions on controversial changes to cities are part of the electoral process, with political candidates or parties running on their positions on projects. And in still others, unfortunately, staging protests can be the only meaningful way for citizens to be heard. These differences reflect the unique political and governance traditions of societies. Even within countries, there can be considerable differences in how city design decisions are handled from city to city. There is no single best process for creating a good city. If you wish to see your ideas implemented, the first step is to understand the formal and informal channels of influence on city development issues. In most cities there are opportunities for involvement in city design for people who have good ideas about how to make cities better, grounded in a realistic assessment of what is needed and what is possible. We hope what you have learned in this course will not only help you understand city design, but inspire you to participate in improving cities. Finally, let us say how much we have enjoyed sharing our ideas with you in this course.",Designing Cities
https://www.classcentral.com/course/edx-health-in-numbers-quantitative-methods-in-clinical-public-health-research-448,"Quantitative Methods in Clinical and Public Health Research is the online adaptation of material from the Harvard T.H. Chan School of Public Health's classes in epidemiology and biostatistics. Principled investigations to monitor and thus improve the health of individuals are firmly based on a sound understanding of modern quantitative methods. This involves the ability to discover patterns and extract knowledge from health data on a sample of individuals and then to infer, with measured uncertainty, the unobserved population characteristics. This course will address this need by covering the principles of biostatistics and epidemiology used for public health and clinical research. These include outcomes measurement, measures of associations between outcomes and their determinants, study design options, bias and confounding, probability and diagnostic tests, confidence intervals and hypothesis testing, power and sample size determinations, life tables and survival methods, regression methods (both, linear and logistic), and sample survey techniques. Students will analyze sample data sets to acquire knowledge of appropriate computer software. By the end of the course the successful student should have attained a sound understanding of these methods and a solid foundation for further study.
 
FAQ
How much does it cost to take the course?
Nothing! The course is free.
When will assignments be due?
The course is organized into weeks, and each week will have its own set of assignments. Students will be expected to complete their homework each week.
Do I need any other materials to take the course?
Nope, as long as you’ve got a Mac or PC, you’ll be ready to take the course.
Will the course use any textbooks or software?
Yes! We'll have free access to the book ""Principles of Biostatistics"" written by Marcello Pagano (one of the Professors) and Kimberlee Gauvreau.
In addition to the textbook, we'll use Stata (a piece of software for doing statistical analysis).
Thanks to our friends at Statacorp, we'll have free copies of Stata available for all students to use for the duration of the course (Mac and PC only).
Do I need to watch the lectures live?
No. You can watch the lectures at your leisure.
Will certificates be awarded?
Yes. Online learners who achieve a passing grade in a course can earn a certificate of achievement. These certificates will indicate you have successfully completed the course, but will not include a specific grade. Certificates will be issued by edX under the name of either HarvardX, MITx or BerkeleyX, designating the institution from which the course originated. For the courses in Fall 2012, honor code certificates will be free.
HarvardX requires individuals who enroll in its courses on edX to abide by the terms of the edX honor code : https://www.edx.org/edx-terms-service. HarvardX will take appropriate corrective action in response to violations of the edX honor code, which may include dismissal from the HarvardX course; revocation of any certificates received for the HarvardX course; or other remedies as circumstances warrant. No refunds will be issued in the case of corrective action for such violations. Enrollees who are taking HarvardX courses as part of another program will also be governed by the academic policies of those programs.
HarvardX pursues the science of learning. By registering as an online learner in an HX course, you will also participate in research about learning. Read our research statement : http://harvardx.harvard.edu/research-statement to learn more.
Harvard University and HarvardX are committed to maintaining a safe and healthy educational and work environment in which no member of the community is excluded from participation in, denied the benefits of, or subjected to discrimination or harassment in our program. All members of the HarvardX community are expected to abide by Harvard policies on nondiscrimination, including sexual harassment, and the edX Terms of Service. If you have any questions or concerns, please contact harvardx@harvard.edu and/or report your experience through the edX contact form : https://www.edx.org/contact-us.
 



            Read more",Health in Numbers: Quantitative Methods in Clinical & Public Health Research
https://www.classcentral.com/course/introduction-computer-science-programming-18878,"This specialisation covers topics ranging from basic computing principles to the mathematical foundations required for computer science. You will learn fundamental concepts of how computers work, which can be applied to any software or computer system. You will also gain the practical skillset needed to write interactive, graphical programs at an introductory level. The numerical mathematics component will provide you with numerical and computational tools that are essential for the problem solving and modelling stages of computer science.
      


          Course 1: Introduction to Computer Programming - This MOOC provides you with the foundational skill set required to write computer programs. If you are interested in learning how to write interactive, graphical programs from an introductory level in a real programming language, this is the course for you. You will begin by learning the basics of editing and running programs. Then you will learn how to create 2D graphics using shapes and coordinates. Finally, you will learn how to create interactive graphics that you can control with the mouse. You will even solve a set of interactive puzzles using your coding skills in the Sleuth game which has been created especially for this course. The course uses the Javascript language and the p5.js library.Course 2: How Computers Work- Computers are everywhere, they aren't just the desktops and laptops we use for work but the phones in our pockets and even the watches on our wrists are also computers. You probably use a computer every day and in fact you are reading this on a computer! Just because we use computers all the time, doesn't mean that we understand them, or find them easy to use. Computer Science is the science of computers, it is the field of knowledge that experts use to understand computer systems. Knowing a little computer science will help you understand the computers all around you. This isn't a how-to course for a particular piece of software, instead you will learn some fundamental concepts that you can apply to any software or computer system. You'll apply these concepts to the kind of computer systems we use every day, including word processing applications, e-commerce, the internet and web sites. You will learn how to apply computer science concepts to solve problems in daily computer use and generally be a better computer user. Taking this course could be the start of your career in computer science, and the course is an introduction to the Bachelors in Computer Science from University of London, but it is also for you if you just want to learn a little computer science to help you better understand the computers you use in your ordinary life.Course 3: Mathematics for Computer Science- “Welcome to Introduction to Numerical Mathematics. This is designed to give you part of the mathematical foundations needed to work in computer science in any of its strands, from business to visual digital arts, music, games. At any stage of the problem solving and modelling stage you will require numerical and computational tools. We get you started in binary and other number bases, some tools to make sense of sequences of numbers, how to represent space numerical using coordinates, how to study variations of quantities via functions and their graphs. For this we prepared computing and everyday life problems for you to solve using these tools, from sending secret messages to designing computer graphics. If you wish to take it further you can join the BSc Computer Science degree and complete the full module ‘Numerical Mathematics’. Enjoy!”",Introduction to Computer Science and Programming
https://www.classcentral.com/course/posacommunication-3078,"This MOOC describes by example how to apply patterns and frameworks to alleviate the complexity of developing concurrent software for mobile devices via the use of object-oriented design techniques. A pattern describes a reusable solution to a common problem that arises within a particular context. A framework is an integrated set of components that collaborate to provide a reusable architecture for a family of related apps or services.  Frameworks can also be viewed as concrete realizations of patterns that facilitate direct reuse of detailed design and source code.This MOOC will cover fundamental techniques, patterns, and frameworks related to communicating with local and remote services. In particular, this MOOC course will cover Android mechanisms for interacting with local bound and started services via Intents, Messengers, and the Android Interface Definition Language (AIDL).  It will also focus on interacting with remote web services using HTTP and data marshalling with JSON. Remote interaction models, ranging from request on demand, polling, push, and sockets will be discussed. Students that complete this MOOC will have a solid understanding of how to build Android applications and local services that can interact with remote services, handle data marshaling, and perform error handling. Hands-on programming projects will require students to develop Android applications that interact with REST-based services.The Mobile Cloud Computing with Android (MoCCA) SpecializationThis is the fourth course of the six-course Mobile Cloud Computing with Android (MoCCA) Specialization. It has been designed as part of a Coursera Specialization designed to help learners create complex, cloud-based Android Applications, and includes a final “capstone” project for those who earn Verified Certificates across all six courses.Note: We are proud to announce that the MoCCA specialization has already reached hundreds of thousands of learners around the globe. In its last iteration, we worked with Google to provide Nexus tablets, feedback from the Google App team, and the potential to be featured in the Google Play store to top course completers.This time around, we are providing more flexibility for all of you busy learners. We are running the Programming Mobile Applications courses in more digestible one-month-long sections, each with a meaningful mini-project at the end. Additionally, we will be re-offering the courses more frequently. For example, new sessions of my two introductory courses will be launched on a monthly basis, so that you can find a convenient time to join us or pick up where you left off if you didn’t quite finish before.For previous MoCCA students: If you have already earned a Verified Certificate in the previous version of this course, ""Pattern-Oriented Software Architectures: Programming Mobile Services for Android Handheld Systems” offered in May 2014, you do not need to retake this course to continue towards the Specialization certificate and final project in 2015. Please consult the Specializations Help Center or contact the Coursera support team if you are not sure whether you qualify.This MOOC and five others, taught by Dr. Adam Porter from the University of Maryland and Dr. Jules White from Vanderbilt University, have been designed to complement each other as part of the first trans-institution sequence of MOOCs taught on the Coursera platform, structured as follows:The first two courses by Dr. Adam Porter, of the University of Maryland, are Programming Mobile Applications for Android Handheld Systems Part 1 and Part 2. They focus on the design and programming of user-facing applications.  The third and fourth courses by Dr. Douglas Schmidt, of Vanderbilt University, are Programming Mobile Services for Android Handheld Systems: Concurrency and Communication. They focus on middleware systems programming topics, such as synchronous and asynchronous concurrency models, background service processing, structured data management, local inter-process communication and networking, and integration with cloud-based services.  The fifth and sixth courses by Dr. Jules White, of Vanderbilt University, are Programming Cloud Services for Android Handheld Systems: Spring and Security.  They focus on how to connect Android mobile devices to cloud computing and data storage resources, essentially turning a device into an extension of powerful cloud-based services on popular cloud computing platforms, such as Google App Engine and Amazon EC2. The final “capstone” project will require students to develop a complex mobile cloud computing application from the ground up.Some of the programming assignments for these MOOCs will be coordinated.  If you just want to take some of the MOOCs in this sequence or take them all in different order you’re certainly welcome to do so, and you’ll still learn a lot. However, if you take all the MOOCs in this sequence in the order presented you’ll gain a deeper, end-to-end understanding of handheld systems, their applications and services, as well as their integration into the cloud.
      


            Read more
          



          The course is organized into the following sections:Section 0: Course IntroductionPart 1:Course Structure and TopicsPart 2: Course Prerequisites and Learning StrategiesSection 1: Android Services and Local IPCPart 1: Overview of Started and Bound ServicesPart 2: Activity and Service CommunicationPart 3: Service to Activity Communication Using Android MessengerPart 4: Programming Started ServicesPart 5: Android IntentServicePart 6: Programming Bound Services with MessengersPart 7: Overview of the Android Interface Definition Language (AIDL)Part 8: Programming Bound Services with AIDLSection 3: Android Remote IPCPart 1: Overview of Hyper-Text Transfer Protocol (HTTP)Part 2: Designing Mobile Applications with HTTP CommunicationPart 3: Better Client-side Communication Abstractions for HTTPSection 4:  Communication Patterns in AndroidPart 1: Activating Services on Demand with the Activator PatternPart 2: Passing Commands to Services with the Command Processor PatternPart 3: Automating Marshaling and Demarshaling of Data with the Proxy PatternPart 4: Supporting Object-Oriented Remote Method Calls with the Broker PatternThroughout the MOOC we'll focus on pattern-oriented software architecture, with an emphasis on concurrent and networked programming in the context of Android middleware systems programming mechanisms, such as synchronous and asynchronous concurrency models, background service processing, and local/remote inter-process communication (IPC) and networking. We illustrate by example how key pattern and framework concepts and relationships are applied in Android Services and various local and remote IPC mechanisms from both an application and infrastructure perspective. Many code examples are shown throughout using Java, with a case study project used to reify the key points throughout all the modules in this section.The PDF and PowerPoint versions of all the slides used in the course will be available online as the videos become available on the course website.",Programming Mobile Services for Android Handheld Systems: Communication
https://www.classcentral.com/course/swayam-introduction-to-materials-science-and-engineering-10064,"This course is designed as a first introduction to microstructure and mechanical properties of engineering materials for undergraduate engineering students. The focus will be on clear presentation of basic fundamentals of structure and defects of crystalline materials. This will then be used to understand the transformations, heat treatments and mechanical behavior of structural materials. The course will also include several classroom and laboratory demonstrations. The course will also be useful as an introduction to materials science for engineers and scientists in industry, research labs and academic institutions.INTENDED AUDIENCE: Undergraduate students from all disciplines in engineering. Could be useful for students of solid state physics and solid state chemistry as well as   engineers in industry looking for fundamentals of materials sciencePREREQUISITES : Science at school level equivalent to 10+2 of Central Board of Secondary Education (CBSE), India.INDUSTRY SUPPORT : Any industry concerned with materials, in particular automobile and manufacturing industries. Condensed versions of this course have been offered at   Maruti Udyog Limited, Gurugram, and Terminal Ballistic Research Lab of DRDO, Chandigarh, India. 
      


COURSE LAYOUT Week 1  : Lattice and crystal, 7 crystal systems, 14 Bravais lattices, Symmetry.Week 2  : Miller indices of directions and planes, Weiss Zone Law, Bragg's Law, Close-Packed structures: CCP, HCP.Week 3  : Voids in close-packed structures, Solid solutions: interstitial, substitutional, ordered, disordered. Hume-Rothery rules.  Graphene, graphite and diamond.Week 4  : Carbon nanotubes, Buckminsterfullerene.Ionic Solids: NaCl, CsCl, ZnS, BCC vs CsCl. Amorphous solids. Polymers:  thermoplastic, thermosets, tacticity, copolymers, crystallinity.Week 5  : Defects: zero-, one- and two-dimensional. Vacancies. Dislocations: edge, screw and mixed. Burgers vectors and burgers  circuit. Constancy of Burgers vector. Elastic energy of a dislocation.Week 6  : Dislocation cannot end abruptly inside a crystal, dislocation loop, dislocation node, dislocation motion: glide, climb and cross slip. 2D defects: free surfaces, grain boundaries, twin boundary, stacking faults, tilt and twist boundaries, ball bearing model.Week 7  : Phase diagrams. Phases and components. Phases present in the system. Composition of phases: Tie-Line rule.  Proportion of Phases: Lever Rule. Microstructure Evolution. Invariant reactions: eutectic, eutectoid, peritectic, peritectoid. Gibbs phase rule.  Fe-C diagram.Week 8 : Fe-C diagram (Continued). Eutectoid, hypoeutectoid and hypereutectoid steels.  Diffusion: Fick's First and Second Laws. Error function solution of Fick's second law. Atomistic mechanisms of  diffusion: interstitial and substitutional diffusion. Diffusion paths: lattice, grain boundary, dislocation and surface.   Steady vs. unsteady state diffusion.Week 9 : Phase transformation. Nucleation: Homogeneous and heterogeneous. Nucleation and capillary rise. Growth and  overall transformation. TTT diagrams. Heat treatment of steels. TTT diagrams of eutectoid steels.Week 10 :Quenching and martensite, Austempering and Bainite. Tempering and tempered martensite. Residual stresses and  quench cracks. Marquenching and Martempering. TTT diagram of hypoeutectoid, hypereutectoid and alloy steels.   Hardenability of steels. Glass ceramics.       Mechanical behaviour of materials. Tensile test. Plastic deformation and crystal structure. Slip. Resolved shear stress  and critical resolved shear stress. Schmid's law.Week 11 :CRSS: theory vs. experiment. Strengthening mechanisms: strain hardening, grain size hardening, solid solution hardening and age hardening. Dislocation density. Frank-Read source. Annealing of cold-worked materials: Recovery, Recrystallisation, Grain Growth.Week 12 :True stress and true strain.Creep. Effect of stress and temperature. Creep mechanisms. Composites: isostrain and isostress modulus. Fracture. Ductile and brittle fracture. Role of crack size: Griffith's criterion. Stress concentration. Ductile-to-brittle transition. Enhancing fracture resistance. Toughening of glass: tempering and ion-exchange.  Fatigue. Sub-critical crack growth.",Introduction to Materials Science and Engineering
https://www.classcentral.com/course/independent-frank-lloyd-wright-and-the-xx-century-2775,"Architecture is the crystallization of the spirit of its age, and this certainly applies to the architecture of Frank Lloyd Wright (1867 – 1959). Wright pioneered Modern Architecture in response to industrialization, new materials, and changes in society. Then he created a new home for the 20th century in response to the decentering brought about by the end of perspective painting, the end of absolute space and time in physics, and end of a privileged position for humans in science and society. And Wright created a new notion of who we can be as human beings, bringing together the individual of the West, and the integration in the flow of nature of the East.
Before Wright, most architecture was based on the past, as we see, for example in the Beaux Arts that referred back to ancient Rome. After Wright, architecture, including that of the leading European Modern Architects, was based on an honest expression of the functions, spaces, materials, and structure of a building. Wright worked in the Midwestern United States, a region that prided itself on being remote Europe, where he developed a uniquely American, modern, and democratic architecture.
We begin with a brief overview of Wright’s work, a biographical sketch, and a look at the architecture at the time he began his career. Then we go into some depth on each of Wright’s major works: his Prairie Style houses, Fallingwater, Johnson Wax, the Guggenheim Museum, and more.
But we are not done. Next we will look at the culture of decentering that defined the 20th century and Wright’s role in its unfolding. And finally we will look at what Wright meant by Organic Architecture, and how it unifies the cultures of the West and the East and creates the potential for a new way of being human.
This is paragraph 2 of the long course description. Add more paragraphs as needed. Make sure to enclose them in paragraph tags.
COURSE STRUCTURE
WEEK 1: INTRODUCTION
WEEK 2: EARLY WORK
WEEK 3: CALIFORNIA HOUSES AND OTHER WORK
WEEK 4: WRIGHT IN THE 1930s
WEEK 5: WRIGHT IN THE 1950s
WEEK 6: PATTERNS IN WRIGHT’S WORK
WEEK 7: WRIGHT AND THE 20TH CENTURY
WEEK 8: ORGANIC ARCHITECTURE
WEEK 9: WHAT WRIGHT TELLS US ABOUT TODAY
WEEK 10: RE-CREATING WHO WE ARE AS HUMAN BEINGS
LEARNING OUTCOMES
On completing this course you will be familiar with the arc of Frank Lloyd Wright’s career and have an in-depth understanding of some of his key buildings. You will understand how the relationship between Wright’s architecture and that of key European architects, as well as with Picasso’s Cubism and Einstein’s relativity. You will understand how the 20th century decentered us in every aspect of our lives. You will have an understanding of how architecture is the crystallization of its culture, why architecture is called the mother of the arts, and how architecture embodies and even creates our notion of who we are as human beings. And you will have the ability to apply this broad approach to the understanding of art, architecture, and culture to other areas of your interests.
WORKLOAD
Your main obligation is to watch, absorb, and enjoy the lectures. Reading and the viewing of online videos is at a minimum. Watch the lectures and enjoy the images and descriptions of some of the most important buildings of the 20th century.
If you have time to watch the videos and do some brief reading and viewing of online videos, you have time to take this course.
ASSESMENTS
You will be assigned discussion groups on suggested topics, and there will be a peer graded final exam.
CERTIFICATION
Those completing the course requirements, including viewing all lectures, participation in the discussion groups, taking quizzes, and passing the final exam, will be offered a Certificate from Open Online Academy.
 



            Read more",Frank Lloyd Wright And The XX Century
https://www.classcentral.com/course/edx-data-analysis-in-social-science-assessing-your-knowledge-11481,"To learn more about this MicroMasters program, please visit https://micromasters.mit.edu/ds/.This course consists of an assessment that tests your knowledge on the course content from 14.310x - Data Analysis for Social Scientists, a statistics and data analysis course that will introduce you to the essential notions of probability and statistics. It will cover techniques in modern data analysis: estimation, regression and econometrics, prediction, experimental design, randomized control trials (and A/B testing), machine learning, and data visualization. It will illustrate these concepts with applications drawn from real world examples and frontier research. Finally, it will provide instruction for how to use the statistical package R and opportunities for students to perform self-directed empirical analyses.This assessment course should only be taken by learners who have completed and passed 14.310x - Data Analysis for Social Scientists and intend to pursue the MicroMasters credential in Statistics and Data Science.  To get credit in this MicroMasters program:

Enroll in both this assessment course and the content course 14.310x - Data Analysis for Social Scientists (Note: There is no additional fee to enroll in the content course),
Complete the content course 14.310x with a passing grade,
Come back to this course and take the exam to earn your verified certificate that will count toward the MicroMasters credential in Statistics and Data Science.

The timed exam will open between November 26, 2019 - December 9, 2019, but enrollment is open until November 12.This assessment course, along with the content course 14.310x - Data Analysis for Social Scientists,  is part of the MITx MicroMasters Program in Statistics and Data Science. Master the skills needed to be an informed and effective practitioner of data science. You will complete this course and three others from MITx, at a similar pace and level of rigor as an on-campus course at MIT, and then take a virtually-proctored exam to earn your MicroMasters, an academic credential that will demonstrate your proficiency in data science or accelerate your path towards an MIT PhD or a Master's at other universities. To learn more about this program, please visit https://micromasters.mit.edu/ds/.



            Read more",Data Analysis in Social Science-Assessing Your Knowledge
https://www.classcentral.com/course/positivepsychology-18544,"The University of Pennsylvania and Dr. Martin E.P. Seligman welcome you to Foundations of Positive Psychology. Our five-course specialization provides you with the key theories and research in the field of positive psychology as well as opportunities for application. Course topics include • Positive Psychology: Martin E.P. Seligman’s Visionary Science with Dr. Martin E.P. Seligman • Positive Psychology: Applications and Interventions with Dr. James Pawelski • Positive Psychology: Character, Grit and Research Methods with Dr. Angela Duckworth & Dr. Claire Robertson-Kraft • Positive Psychology: Resilience Skills with Dr. Karen Reivich • Positive Psychology Specialization Project with Dr. Martin E.P. Seligman



          Course 1: Positive Psychology: Martin E. P. Seligman’s Visionary Science- Dr. Martin E.P. Seligman—renowned worldwide as the “father of Positive Psychology”—has led visionary leaps in the scientific research, empirical data and personal understandings of human flourishing. This course explores the past, present and future of positive psychology as a journey through the key scientific leaps led by Dr. Seligman and his colleagues at the University of Pennsylvania's Positive Psychology Center and Master of Applied Positive Psychology program. There are no prerequisites.Course 2: Positive Psychology: Applications and Interventions- Positive interventions are one of the building blocks for the application of positive psychology in our day-to-day lives. In this course taught by Dr. James Pawelski, we explore positive interventions through theory, research and practice. We provide learners the basic tools for using and measuring positive psychology in professional or personal contexts. Suggested prerequisite: Positive Psychology: Martin E. P. Seligman’s Visionary Science.Course 3: Positive Psychology: Character, Grit and Research Methods- Learners discover how apply to research methods to their study of Positive Psychology. In this course, we study with Dr. Angela Duckworth and Dr. Claire Robertson-Kraft. Through an exploration their work ""True Grit"" and interviews with researchers and practitioners, you develop a research hypothesis and learn how to understand the difference between internal and external validity. You also begin to understand and apply the strengths and weaknesses associated with different types of measurements and evaluation designs. You then interpret the results in an empirical study. Suggested prerequisites: Positive Psychology: Martin E. P. Seligman’s Visionary Science and Positive Psychology: Applications and Interventions.Course 4: Positive Psychology: Resilience Skills- Learn how to incorporate resilience interventions into your personal and professional life with Dr. Karen Reivich. In this course, you are exposed to the foundational research in resilience, including protective factors such as mental agility and optimism. Several types of resilience interventions are explored including cognitive strategies; strategies to manage anxiety and increase positive emotions such as gratitude; and a critical relationship enhancement skill. Throughout the course, you will hear examples of individuals using resilience skills in their personal and professional lives. Suggested prerequisites: Positive Psychology: Martin E. P. Seligman’s Visionary Science, Positive Psychology: Applications and Interventions and Positive Psychology: Character, Grit & Research Methods.Course 5: Positive Psychology Specialization Project: Design Your Life for Well-being- You are encouraged to take the first four courses of the Foundations of Positive Psychology Specialization before starting this course and completing the Specialization Project. This course, taught by Dr. Martin E.P. Seligman brings all the key concepts from the first four courses to practice as you develop and test a new positive intervention for an audience of your choice. You identify opportunities in your daily life to increase the wellbeing by using knowledge you developed in the first four courses of the Specialization. In this final project, you evaluate the efficacy of a positive intervention based on subjective and objective measures. Then, you compare how empirical and non-empirically-based positive interventions can be applied to influence a person's wellbeing. Lastly, you reflect on how the fundamental elements of research methods are important in the everyday application of positive psychology. After completing all five courses, learners earn a certificate signed by Dr. Martin E.P. Seligman, Dr. James Pawelski, Dr. Angela Duckworth, Dr. Claire Robertson-Kraft and Dr. Karen Reivich.",Foundations of Positive Psychology
https://www.classcentral.com/course/edx-fa19-statistical-modeling-and-regression-analysis-8996,"Regression Analysis is the most common statistical modeling approach used in data analysis and it is the basis for more advanced statistical and machine learning modeling.In this course, you will be given fundamental grounding in the use of widely used tools in regression analysis. You will learn the basics of regression analysis such as linear regression, logistic regression, Poisson regression, generalized linear regression and model selection.Throughout this course, you will be exposed to not only fundamental concepts of regression analysis but also many data examples using the R statistical software. Thus by the end of this course, you will also be familiar with the implementation of regression models using the R statistical software along with interpretation for the results derived from such implementations.This course is more about the opportunity for individual discovery than it is about mastering a fixed set of techniques.



Weeks 1-2: Introduction to the most basic regression: Simple Linear Regression with data examplesWeeks 3-4: Introduction to the Analysis of Variance (ANOVA) Model with data examplesWeeks 5-8: Introduction to most popular regression model: Multiple Linear Regression with data examplesWeeks 9-11: Introduction to Logistic Regression and Poisson Regression within the more general regression approach, generalized linear model, with data examplesWeeks 12-14: Introduction to multiple approaches to variable selection illustrated with an extensive data analysis example",FA19: Statistical Modeling and Regression Analysis
https://www.classcentral.com/course/edx-cs50-for-lawyers-16857,"This course is a variant of Harvard University's introduction to computer science, CS50, designed especially for lawyers (and law students). Whereas CS50 itself takes a bottom-up approach, emphasizing mastery of low-level concepts and implementation details thereof, this course takes a top-down approach, emphasizing mastery of high-level concepts and design decisions related thereto. Ultimately, it equips students with a deeper understanding of the legal implications of technological decisions made by clients.Through a mix of technical instruction and discussion of case studies, this course empowers students to be informed contributors to technology-driven conversations. In addition, it prepares students to formulate technology-informed legal arguments and opinions. Along the way, it equips students with hands-on experience with Python and SQL, languages via which they can mine data for answers themselves.Topics include algorithms, cloud computing, databases, networking, privacy, programming, scalability, security, and more, with a particular emphasis on understanding how the work developers do and the technological solutions they employ may impact clients. Students emerge from this course with first-hand appreciation of how it all works and all the more confident in the factors that should guide their decision-making.Keywords: law firm, computer programming, programming skills, computer programmers, patent attorney, legal practice, legal services, legal education, patent law
      


            Read more",CS50 for Lawyers
https://www.classcentral.com/course/swayam-introduction-to-environmental-engineering-and-science-fundamental-and-sustainability-concepts-14147,"The objective of this online course is to provide an overview of the environmental issues that all our working professionals should be aware of as per the directive of the Honble Supreme Court of India. The course will cover basic concepts of Ecology, Water Pollution, Water and Wastewater Quality and Treatment, Solid and Hazardous WasteManagement, Soil and Noise Pollution, Sustainability Concepts including Environmental Impact Assessment, Life Cycle Assessment, Waste Minimization, Circular Economy and Sustainable Development Issues.Overall the goal of the course is to:1) Sensitise the young workforce on the basics and complexity ofenvironmental issues associated with global developmental and commercial activity on day to day issues2) Identify the current environmental issues that the globalcommunity is facing and discuss the realistic risk assessment3) Use the tools of green design for sustainable solutions, helpingthe students to grasp the concepts of four I’s: Inherency,Integration, Interdisciplinary, and International. Fundamental science and engineering skills will be applied throughout the course.INTENDED AUDIENCE: Any Interested Learners.PREREQUISITES:     Basic High School Math, Physics and ChemistryINDUSTRY SUPPORT: AECOM, Ramky, Environmental Resource Management (ERM),SENES/ARCADIS,                     L&T, Tata-Projects, and all companies involved in any construction projects in the country. 
      


COURSE LAYOUT Week 1:  Sustainability Concepts – Innovations and ChallengesWeek 2:  Environmental Measurements from Different DisciplinesWeek 3:  Ecology, Population & Environmental ChemistryWeek 4:  Physical Process in EnvironmentWeek 5:  Environmental Biological ConceptsWeek 6:  Environmental Risk Assessments with Concepts of EIA and LCAWeek 7:  Water – Quantity and QualityWeek 8:  Water Treatment BasicsWeek 9: Basics of Wastewater Collection, Treatment & Resource RecoveryWeek 10: Basics of Solid Waste, Soil and Noise PollutionWeek 11: Basics of Air Pollution Issues – Global and LocalWeek 12: Case Studies and Course Wrap-up",Introduction to Environmental Engineering and Science-Fundamental and Sustainability Concepts
https://www.classcentral.com/course/datasciencemethodology-10617,"Despite the recent increase in computing power and access to data over the last couple of decades, our ability to use the data within the decision making process is either lost or not maximized at all too often, we don't have a solid understanding of the questions being asked and how to apply the data correctly to the problem at hand.

This course has one purpose, and that is to share a methodology that can be used within data science, to ensure that the data used in problem solving is relevant and properly manipulated to address the question at hand.

Accordingly, in this course, you will learn:
    - The major steps involved in tackling a data science problem.
    - The major steps involved in practicing data science, from forming a concrete business or research problem, to collecting and analyzing data, to building a model, and understanding the feedback after model deployment.
    - How data scientists think!

LIMITED TIME OFFER: Subscription is only $39 USD per month for access to graded materials and a certificate.
      


          From Problem to Approach and From Requirements to Collection
    -In this module, you will learn about why we are interested in data science, what a methodology is, and why data scientists need a methodology. You will also learn about the data science methodology and its flowchart. You will learn about the first two stages of the data science methodology, namely Business Understanding and Analytic Approach. Finally, through a lab session, you will also obtain how to complete the Business Understanding and the Analytic Approach stages and the Data Requirements and Data Collection stages pertaining to any data science problem. 

From Understanding to Preparation and From Modeling to Evaluation
    -In this module, you will learn what it means to understand data, and prepare or clean data. You will also learn about the purpose of data modeling and some characteristics of the modeling process. Finally, through a lab session, you will learn how to complete the Data Understanding and the Data Preparation stages, as well as the Modeling and the Model Evaluation stages pertaining to any data science problem.

From Deployment to Feedback
    -In this module, you will learn about what happens when a model is deployed and why model feedback is important. Also, by completing a peer-reviewed assignment, you will demonstrate your understanding of the data science methodology by applying it to a problem that you define.",Data Science Methodology
https://www.classcentral.com/course/janux-introduction-to-computer-programming-1586,"This course is designed as an introduction to computer programming using Java. Students will learn how to a) analyze a problem, and identify and define the computing requirements appropriate to its solution b) design, implement, and evaluate a computer-based system, process, component, or program to meet desired needs, and c) apply design and development principles in the construction of software systems of varying complexity. Topics include Computers, programs, Java, input and output, identifiers, variables, assignment statements, constants, memory diagrams, primitive data types, conditional statements, repetition, methods, parameters, arguments, return values, one dimensional arrays, objects, classes, and classes from the Java Application Programmers Interface (API).",Introduction to Computer Programming
https://www.classcentral.com/course/edx-algorithmic-design-and-techniques-10241,"In this course, part of the Algorithms and Data Structures MicroMasters program, you will learn basic algorithmic techniques and ideas for computational problems, which arise in practical applications such as sorting and searching, divide and conquer, greedy algorithms and dynamic programming.
This course will cover theories, including:

how to sort data and how it helps for searching;
how to break a large problem into pieces and solve them recursively;
when it makes sense to proceed greedily;
how dynamic programming is used in genomic studies.

You will practice solving computational problems, designing new algorithms, and implementing solutions efficiently (so that they run in less than a second).



Module 1: Welcome
Here we will provide an overview of where algorithms and data structures are used (hint: everywhere) and walk you through a few sample programming challenges. The programming challenges represent an important (and often the most difficult!) part of this specialization because the only way to fully understand an algorithm is to implement it. Writing correct and efficient programs is hard; please don’t be surprised if they don’t work as you planned—our first programs did not work either! We will help you on your journey through the specialization by showing how to implement your first programming challenges. We will also introduce testing techniques that will help increase your chances of passing assignments on your first attempt. In case your program does not work as intended, we will show how to fix it, even if you don’t yet know which test your implementation is failing on.
Module 2: Introduction
In this module you will learn that programs based on efficient algorithms can solve the same problem billions of times faster than programs based on naïve algorithms. You will learn how to estimate the running time and memory of an algorithm without even implementing it. Armed with this knowledge, you will be able to compare various algorithms, select the most efficient ones, and finally implement them as our programming challenges!
Module 3: Greedy Algorithms
In this module you will learn about seemingly naïve yet powerful class of algorithms called greedy algorithms. After you will learn the key idea behind the greedy algorithms, you may feel that they represent the algorithmic Swiss army knife that can be applied to solve nearly all programming challenges in this course. But be warned: with a few exceptions that we will cover, this intuitive idea rarely works in practice! For this reason, it is important to prove that a greedy algorithm always produces an optimal solution before using this algorithm. In the end of this module, we will test your intuition and taste for greedy algorithms by offering several programming challenges.
Module 4: Divide-and-Conquer
In this module you will learn about a powerful algorithmic technique called Divide and Conquer. Based on this technique, you will see how to search huge databases millions of times faster than using naïve linear search. You will even learn that the standard way to multiply numbers (that you learned in the grade school) is far from the being the fastest! We will then apply the divide-and-conquer technique to design two efficient algorithms (merge sort and quick sort) for sorting huge lists, a problem that finds many applications in practice. Finally, we will show that these two algorithms are optimal, that is, no algorithm can sort faster!
Modules 5 and 6: Dynamic Programming
In this final module of the course you will learn about the powerful algorithmic technique for solving many optimization problems called Dynamic Programming. It turned out that dynamic programming can solve many problems that evade all attempts to solve them using greedy or divide-and-conquer strategy. There are countless applications of dynamic programming in practice: from maximizing the advertisement revenue of a TV station, to search for similar Internet pages, to gene finding (the problem where biologists need to find the minimum number of mutations to transform one gene into another). You will learn how the same idea helps to automatically make spelling corrections and to show the differences between two versions of the same text.",Algorithmic Design and Techniques
https://www.classcentral.com/course/braintargeted-879,"New findings from the neuro- and cognitive sciences have the potential to inform classroom instruction and influence educational practices for children at all developmental levels.  Translating this research to practice, however, is often challenging for educational practitioners.  This course will offer practical application of research by linking it with the Brain-Targeted Teaching® Model (BTT)—a pedagogical framework for using research in the neuro- and cognitive sciences as well as research-based effective instruction to guide teachers in planning, implementing, and assessing a sound program of instruction for all learners. Participants in
the course will examine research from the brain sciences that can inform
educational practice and be able to implement research findings using the
instructional framework, The Brain-Targeted Teaching® Model. This model
presents six stages, or “brain targets” of the teaching and learning process.
The components include (1) establishing the emotional climate for learning, (2)
creating the physical learning environment, (3) designing the learning
experience, (4) teaching for the mastery of content, skills, and concepts, (5)
teaching for the extension and application of knowledge, and (6) evaluating
learning. A central theme of the model is the integration of the arts to foster
retention of new information, conceptual development, and higher-order thinking
and creative problem-solving.Course
objectives:Describe themes in brain research that can inform
educational practice consistent with the Brain-Targeted Teaching® Model.Describe how emotional and physical learning
environments affect learning.Identify themes in brain research
that educators can apply as they design instruction; teach for mastery of
content, skills, and processes; design activities to apply and extend
knowledge; and evaluate learning.




            Read more
          



Sessions 1 & 2:  Course overview; Introduction to the science of learning and the
Brain-Targeted Teaching® Model; ABCs of brain anatomy; BTT Learning UnitThe professional development content will begin with an overview of the
major themes in the new study of the science of learning. A variety of
“neuro-myths” will be described (e.g. brain development is complete by age 3).
The Brain-Targeted Teaching® Model will be introduced, and the six brain
targets will be briefly described.Basic information about brain anatomy and cognitive functions will be
presented as foundational knowledge. Sessions 3 & 4: 

















The Emotional Climate for LearningThis session will focus on strategies to create a positive emotional
climate in classrooms–an environment in which students feel connected to school
and motivated to learn. Through presentations, video, and simulation
activities, participants will learn techniques as well as underlying research
that support promoting an emotional connection to content to increase
motivation for learning. Examples include classroom routines and rituals,
specific praise techniques, ways to disengage and redirect aberrant behaviors,
and strategies that engage students emotionally in content.Sessions 5 & 6: The Physical Learning Environment; The Learning Unit DesignContent will include how environmental factors influence attention learning
consistent with the tenets of BT-2. Participants will brainstorm ways to use
novelty and environmental factors such as lighting, sound, scent, and movement
to promote student attending behaviors.Participants will identify ways they can change classrooms to align with
creating a stimulating environment that supports students’ attending behaviors
and engagement in learning.Participants will review underlying research associated with the
cognitive processes of patterning and “big picture thinking” and will be able
to articulate how concept mapping improves understanding and retention of
content (BT-3).Participants will design concept maps and graphic organizers to be used
as the foundation for planning learning units to promote global understanding
of key lesson topics and objectives. They will use Common Core State Standards
to design learning units that include all components of BTT, including
activities to reinforce content through arts and technology integration. Session 7 & 8: The Learning Unit Design; Teaching for Mastery of Content, Skills, and
ConceptsParticipants will engage in an in-depth examination of the research and
best practices associated with BT-4-- Teaching for Mastery. A wide array of
research findings related to memory will be presented, and practical implications
for the classroom will be described. The important role of arts integration in
reinforcing memory for content will be outlined, as will the possibility of
“transfer” from arts to non-arts domains. Technology innovations will also be
discussed as a way to reinforce classroom objectives.Participants will complete the BTT planning guide to describe and
implement BT-4 activities. Participants will reflect on how the activities
enhanced instructional practice.Sessions 9 & 10: Teaching for Mastery of Content, Skills, and Concepts; Teaching for the
Application of Knowledge in Creative Problem-Solving ActivitiesParticipants will be presented with research and best practices
associated with BT-5--Teaching for the Application of Knowledge. The
presentation will include research on executive function and the cognitive
processes of creative and divergent thinking. Through simulated activities,
participants will explore ways that creativity is important for the kind of
real-world problem solving that is important for preparing students to be
college and career ready.Participants will be able to design and use instructional strategies
that promote rigor and deep understand of content through the application and
extension of knowledge in real-world learning activities. They will extend
students’ mastery of content by designing activities delivered in the BTT
learning unit that require higher-order thinking, divergent thinking skills,
and problem-solving in authentic learning tasks.Sessions 11 & 12: Teaching for the Application of Knowledge in Creative Problem-Solving
Activities; Evaluation LearningParticipants will be able to use effective and appropriate techniques
for evaluating students’ learning throughout each BTT learning unit. Evaluation
is considered not only as a means of measuring student progress, but also as a
tool for increasing learning.Research will describe how feedback, active retrieval of information,
and spacing of learning events influence both learning and retention of
information. Through demonstrations and simulated activities, participants will
explore the use of multiple probes to evaluate learning including performance
assessment, student portfolios and reflective journals. They will be able to
use assessment data to modify learning activities. Sessions 13 & 14: Evaluating Learning; The BTT Learning UnitDemonstration of BTT Learning Units: During this session, expert
teachers who have designed learning units will demonstrate their field-tested
BTT learning units. These expert teachers will present the process of learning
unit design and assist participants in designing their own units. Techniques
for arts integration will be demonstrated.    Session 15: Presentation of Learning Units
Individuals and/or collaborative teams will have developed and
field-tested BTT learning units, including instructional activities and
evaluations.Each participant will be expected to turn in a learning unit and a
PowerPoint presentation describing the unit, the implementation process, and
student outcomes.Participants will have the option of providing feedback to other participants.
Participants have the option of publishing their units on the BTT website.",The Brain-Targeted Teaching® Model for 21st Century Schools
https://www.classcentral.com/course/health-dilemmas-of-governance-11946,"Our societies are changing. On one hand, unprecedented socio-demographic changes are underway: albeit unevenly across various settings, life expectancy continues to rise globally, facilitating the rise of numbers of people living with one or more chronic diseases. On the other hand, societies are undergoing major political transformations as well. Examples include the massive transition away from communism resulting from the dissolution of USSR and rise of participation societies in the EU, to name just a few.

In this shifting environment, the issue of health becomes particularly difficult to deal with. Current approaches to governing processes and structures that define people’s health often fall short in responding to the changing health needs of the populations and in being adequate to shifting societal conditions. How to ensure and improve the health of citizens in times of societal transitions? This course invites learners to explore this question using examples from multiple settings.

Aim
This course aims to equip learners with the knowledge and skills needed to assess, develop, and implement options for health policies, programs and services in ways that are responsive to changing population health needs and to societal contexts; and to provide learners with analytical insights into the interconnections between societal transformations, health, and governance to facilitate the development of more responsive and contextually adequate health and health governance approaches.

After completion of this course you will be able to:
1.	Recognize dilemmas in the governance of health and healthcare and the origins of these dilemmas
2.	To be aware of different approaches in governance of health and healthcare; identify the trade-offs in these approaches for particular cases 
3.	Recognize actors and structures pertaining to the governance of health and healthcare on different levels  
4.	Identify problems in policies, programs, structures, and practices pertaining to the governance of health and healthcare in specific settings
5.	Formulate and justify combinations in approaches to health and health governance suitable to various applications in specific settings 

This course was developed by a consortium of five universities: Maastricht University, National Research Tomsk State University, National University of ""Kyiv-Mohyla Academy"",  National Pirogov Memorial Medical University, Vinnytsya, and Siberian State Medical University within the framework of BIHSENA project. BIHSENA stands for “Bridging Innovations, Health and Societies: Educational capacity building in the Eastern European Neighbouring Areas”. BIHSENA project has been funded with support from the European Commission. This course reflects the views only of the authors, and the Commission cannot be held responsible for any use which may be made of the information contained therein.
      


            Read more
          



          Introduction to the course ""Health and healthcare in transition: dilemmas of governance""

Dilemma 1. Definitions: Governance vs Management vs Leadership in Health
    -This course module focuses on the main challenges and global shifts in the healthcare sector, which, in turn, create a demand for more systemic approaches to governance, management, and leadership. It appears to be difficult to differentiate these concepts (governance, management, and leadership) clearly due to their interrelations and complexity. This module will introduce different ways of defining and relating these concepts in order to illustrate challenges to finding a consensus between such definitions. First, you will delve into discussions about definitions of governance and about how to understand good governance. You will then also explore different leadership approaches in healthcare and to discern from specific examples how effective management can improve the performance of a healthcare facility.



Dilemma 2. Health as a Political vs Apolitical Concept
    -Assessing health system governance and performance requires ethical reflection on the following questions: 1) Who is responsible for health? 2) Who are the beneficiaries? There are different approaches in seeking answers to these questions. Healthcare policies entail scientific data, technologies, and expert recommendations that can appear non-political, as well as cultural norms and respect to individual liberty. But, on the other hand, health can become political in the context of decision-making that entails the distribution of resources and the selection of priorities and modes of action. So, in this module we will delve into these complexities and will work to understand what stands behind health policy and governance decisions. We will take a look at different ethical concepts that may underpin political decisions on health governance, health care reforms, or demands for redistributive policies.

 Dilemma 3. Public Participation vs Top-Down Steering
    -On the one hand, citizens’ engagement in governance of health and health care is important for the transparency and responsiveness of decision-making, as well as for ensuring trust and cooperation. Moreover, often citizens themselves demand direct engagement, as exemplified by health activism: from local action to addressing environmental health risks, to global action on HIV/AIDS, and access to medicine. On the other hand, critics suggest that laypersons can add inefficiency, irrationality, and incoherence to health policy decision-making. There can be undesirable features in governance models heavily dependent on public engagement like interest-group competition in rule-making and the professionalization of citizen participation, where not all citizens are necessarily equally empowered to make contributions. This week explores the dilemma between engaging and not engaging the public.

Dilemma 4: Focus on Whole-of-Society vs Focus on Health Services Provision
    -Health governance is a field where the search for best solutions is continuous in all corners of the world. Health systems increasingly struggle with rising costs, ensuring adequate numbers of health professionals and providing access to the best life-saving treatments and technologies. You will hardly find a country that would not attempt to improve health system performance through reforming the health sector and improving health care delivery. But people’s health depends on multiple complex factors (from employment and work to transport and housing) and relates to social processes of industrialization, urbanization and globalization and to differential exposures to risks. Drivers of human health are not constrained to the health care system. Therefore, new and wider approaches to health governance appear: they are based on the idea of extending health governance from sectorial focus to the whole-of-society and whole-of-government level. These approaches argue that the improvement of a population’s health necessitates engaging non-health sectors and actors through policies and initiatives at all levels of governance, with or without the involvement of the health sector itself.  This creates a dilemma for health governance: should it be focused on improving health service provision only, or embrace the whole of society and all sectors of governance?

Dilemma 5. De Jure and de Facto Dimensions of Healthcare Governance
    -Quite often the identification of the gaps or problems in the health care system result in recommendations to change certain regulations, i.e. to adopt a new law, to make the changes in the existing law, to issue an order etc (de jure dimension). For example, authors and experts suggest improving anti-tobacco policies or introducing sanctions for misbehavior of medical doctors. Indeed, the suggestion to improve regulatory dimension can be seen as a systemic approach (discussed in Dilemma 4) because the behavior and practices take place within the specific existing structure. Therefore, regulations are seen as the efficient entry point that has an impact on the numerous practices. 
However, changing structures or policy development requires substantial resources, e.g. political support, time and expertise (as it has been illustrated in Dilemma 2). Also, the rule of law in some countries can be low, meaning that even if the law is adopted, it is not necessary that it will be reflected in actual practices. Sometimes the results are poor not because of lack of law, but because people may simply be lacking knowledge, skills, competences in, for example, organization management. Therefore, introducing new regulations (de jure dimension) is not always the entry point for the new (more healthy, more effective, more transparent etc.) practices (de facto dimension). 
Thus, we discuss a dilemma related to inconsistencies and imbalance between the structures on the one hand, and practices on the other hand, as well as the challenges that arise when only one perspective (de jure or de facto) is taken into account. In this module we explore the dilemma between de jure and de facto dimensions in health care governance.

Dilemma 6. Change, Reforms and Stability in Health and Healthcare Governance
    -The stability of healthcare systems can be equally as important as change, especially in systems that are performing relatively well. The issue of stability and change in sectors and institutions, including health care, is rooted in the socio-cultural and historical context of the country as well as in current capacities for change. We may see that some countries or systems are more inclined to change when compared to others. Indeed, health care reforms have occurred in most post-communist countries after the Soviet Union collapsed, however the healthcare systems of some of the ex-republics continue functioning as they were designed in the Soviet Union. Several decades ago stability was seen as one of the most essential values in this setting, while now nostalgic moods in some of the countries may partially explain difficulties in the implementing reforms. 

In this module we will illustrate the concepts of “stability” and “change” or “reform” by the case of changing tax-based and insurance-based mechanisms of health care system financing, and its performance under varying and transforming socio-cultural and health conditions. The transition in the post-communist countries of Central and Eastern Europe is taken as an illustrative context for the case.",Health and healthcare in transition: dilemmas of governance
https://www.classcentral.com/course/art-science-ml-11073,"Welcome to the art and science of machine learning. In this data science course you will learn the essential skills of ML intuition, good judgment and experimentation to finely tune and optimize your ML models for the best performance.  

In this course you will learn the many knobs and levers involved in training a model. You will first manually adjust them to see their effects on model performance. Once familiar with the knobs and levers, otherwise known as hyperparameters, you will learn how to tune them in an automatic way using Cloud Machine Learning Engine on Google Cloud Platform.
      


          Introduction
    -Course overview highlighting the key objectives and modules. First, you will learn about aspects of Machine Learning that require some intuition, good judgment and experimentation. We call it the Art of ML. You will learn the many knobs and levers involved in training a model. You will manually adjust them to see their effects on model performance. 


The Art of ML
    -In this course you will learn about The Art of Machine Learning. We will review aspects of machine learning that require intuition, judgment and experimentation to find the right balance and what’s good enough (spoiler alert: it's never perfect!). 


Hyperparameter Tuning
    -In this module you will learn how to differentiate between parameters and hyperparameters. Then we’ll discuss traditional grid search approach and learn how to think beyond it with smarter algorithms. Finally you’ll learn how Cloud ML engine makes it so convenient to automate hyperparameter tuning. 


A pinch of science
    -In this module, we will start to introduce the science along with the art of machine learning. We’re first going to talk about how to perform regularization for sparsity so that we can have simpler, more concise models. Then we’re going to talk about logistic regression and learning how to determine performance.


The science of neural networks
    -In this module we will now be diving deep into the science, specifically with neural networks.

Embeddings
    -In this module, you will learn how to use embeddings to manage sparse data, to make machine learning models that use sparse data consume less memory and train faster. Embeddings are also a way to do dimensionality reduction, and in that way, make models simpler and more generalizable.


Custom Estimator
    -In this module we will go beyond using canned estimators by writing a custom estimator. By writing a custom estimator, you will be able to gain greater control over the model function itself.

Summary
    -Review the key concepts we covered in the Art and Science of ML course.",Art and Science of Machine Learning
https://www.classcentral.com/course/canvas-network-life-on-earth-biomes-climates-ecology-and-evolution-9470,"This course is part of the Introduction to Environmental Science open course series. ""Life on Earth: Biomes, Climates, Ecology, and Evolution"" explores the diversity of life on earth. We learn how populations and communities function as ecosystems and the importance of protecting biodiversity found in these complex living systems.","Life on Earth: Biomes, Climates, Ecology, and Evolution"
https://www.classcentral.com/course/edx-open-science-sharing-your-research-with-the-world-11719,"You can become a more visible, effective and impactful researcher by sharing your research data and publications openly. In this course, you will learn the objectives, main concepts, and benefits of Open Science principles along with practices for open data management and open data sharing.
Since research increasingly relies on software which is used to model and simulate, and to deal with the ever growing volume of research data, the course will also introduce FAIR software practices.
You'll learn to establish links between publications, data, software and methods, how to attach a persistent identifier and metadata to your results, and methods for clarifying usage rights. You will also discover ways to apply these principles to your daily research and adapt existing routines. Finally, you'll uncover potential barriers to sharing research and discuss possible solutions.
This course will help you grasp the key principles of Open Science, with answers to questions like:

How can researchers effectively store, manage, and share research data?
What kinds of open access publishing are most effective?
How can researchers increase the visibility and impact of their research?
How can the use of social media contribute to the visibility and impact of research?
How can researchers be acknowledged for the research software they write?

You will apply the topics of the course to a variety of case studies on Open Science adoption, which you will then discuss among fellow students. You will also be presented with a hands-on guide to publishing your research with open access. This will help you to apply Open Science principles in your daily work. It will enable you to implement and benefit from the Open Science policies that are currently being developed by governments and research institutions.
This course is aimed at professionals. Those who will see the most benefit include academic researchers at different levels: PhD students, postdoctoral researchers, and professors; researchers working for governments; researchers working for commercial enterprises; MSc and BSc students interested to learn about the principles of Open Science.
The development of this course is supported by the VRE4EIC project with funding from the European Union's Horizon 2020 Research and Innovation Programme.



            Read more
          



Week 1: Introduction to Open Science
Introduction to the Open Science movement. What are the objectives, main concepts, and benefits of Open Science? This includes:

Discussing the traditional subscription-based journal system with regards to Open Access publishing
Practical Open Science benefits for researchers
Policies of important funding organizations
Programs on Open Data and Open Access publishing and
Case studies on successful application of Open Science by researchers from different backgrounds.

Week 2: Research Data Management
Introduction to effective and secure research data management, including:

Learning the disciplinary standards of FAIR data sharing
Evaluating the strengths and weaknesses of different data storage and backup options
Organizing, documenting, and adding metadata to research data to optimize the visibility of your data
Data archiving, access, sharing and re-use with the use of data repositories
Understanding the different copyright licenses designed to deal with open data
Dealing with confidential data, company restrictions, and third-party agreements through case studies
Evaluating a data management plan
Explaining how Open Data can be applied in your field of research

Week 3: Publishing Open Access
Here you will discuss the main differences between the open access and subscription-based publication model in science, and the main misconceptions about open access publishing. In this week we also introduce the creative commons licenses used by open access journals and self-archiving policies. You will examine how you can maximize the accessibility of publications in subscription-based journals, you will present your opinion of the open access publishing model and assess the 'openness' of the main scientific journals in your field of research.
Week 4: Choose topic(s) depending on your interests:
Increasing your research visibility
Here you discuss and formulate your communication strategy, describing and choosing your social media channels for reaching certain target groups. Finally, conclusions of this course will be discussed and we will reflect on what has been taught in the previous weeks.
Making your research software FAIR
Research relies ever more on software. Software is used to model and simulate, but it is also almost impossible to deal with the ever growing volume of research data without software. Software is used to read, record, collect and generate data; clean, filter and analyse data; present and visualise data.
This module looks at research software: software that is specific to a research field or research project.
In this module you will learn the role of publicly accessible software version control repositories, the importance of choosing the right software licence, how to make your software citable and tips on how to make it easier for other researchers to reuse your software.
Virtual Research Environments
Introduction to Virtual Research Environments (VREs) and multidisciplinary collaboration through VREs. Here you will find and describe a particular Virtual Research Environment, and analyze motivations for sharing and using research data through Virtual Research Environments.",Open Science: Sharing Your Research with the World
https://www.classcentral.com/course/edx-applied-machine-learning-6406,"This course is part of the Microsoft Professional Program Certificate in Data Science.
In this data science course, you will explore the theory and practice of select advanced methods commonly used in data science.
In the first two modules, you will learn about common applications of specialized data types. Then, in the remaining two modules, you will focus on unstructured data. You will work with tools such as R, Python, and Azure Machine Learning to solve advanced data science problems.",Applied Machine Learning
https://www.classcentral.com/course/business-analytics-18904,"This Specialization provides an introduction to big data analytics for all business professionals, including those with no prior analytics experience. You’ll learn how data analysts describe, predict, and inform business decisions in the specific areas of marketing, human resources, finance, and operations, and you’ll develop basic data literacy and an analytic mindset that will help you make strategic decisions based on data. In the final Capstone Project, you’ll apply your skills to interpret a real-world data set and make appropriate business strategy recommendations.
      


          Course 1: Customer Analytics- Data about our browsing and buying patterns are everywhere. From credit card transactions and online shopping carts, to customer loyalty programs and user-generated ratings/reviews, there is a staggering amount of data that can be used to describe our past buying behaviors, predict future ones, and prescribe new ways to influence future purchasing decisions. In this course, four of Wharton’s top marketing professors will provide an overview of key areas of customer analytics: descriptive analytics, predictive analytics, prescriptive analytics, and their application to real-world business practices including Amazon, Google, and Starbucks to name a few. This course provides an overview of the field of analytics so that you can make informed business decisions. It is an introduction to the theory of customer analytics, and is not intended to prepare learners to perform customer analytics. Course Learning Outcomes: After completing the course learners will be able to... Describe the major methods of customer data collection used by companies and understand how this data can inform business decisions Describe the main tools used to predict customer behavior and identify the appropriate uses for each tool Communicate key ideas about customer analytics and how the field informs business decisions Communicate the history of customer analytics and latest best practices at top firmsCourse 2: Operations Analytics- This course is designed to impact the way you think about transforming data into better decisions. Recent extraordinary improvements in data-collecting technologies have changed the way firms make informed and effective business decisions. The course on operations analytics, taught by three of Wharton’s leading experts, focuses on how the data can be used to profitably match supply with demand in various business settings. In this course, you will learn how to model future demand uncertainties, how to predict the outcomes of competing policy choices and how to choose the best course of action in the face of risk. The course will introduce frameworks and ideas that provide insights into a spectrum of real-world business challenges, will teach you methods and software available for tackling these challenges quantitatively as well as the issues involved in gathering the relevant data. This course is appropriate for beginners and business professionals with no prior analytics experience.Course 3: People Analytics- People analytics is a data-driven approach to managing people at work. For the first time in history, business leaders can make decisions about their people based on deep analysis of data rather than the traditional methods of personal relationships, decision making based on experience, and risk avoidance. In this brand new course, three of Wharton’s top professors, all pioneers in the field of people analytics, will explore the state-of-the-art techniques used to recruit and retain great people, and demonstrate how these techniques are used at cutting-edge companies. They’ll explain how data and sophisticated analysis is brought to bear on people-related issues, such as recruiting, performance evaluation, leadership, hiring and promotion, job design, compensation, and collaboration. This course is an introduction to the theory of people analytics, and is not intended to prepare learners to perform complex talent management data analysis. By the end of this course, you’ll understand how and when hard data is used to make soft-skill decisions about hiring and talent development, so that you can position yourself as a strategic partner in your company’s talent management decisions. This course is intended to introduced you to Organizations flourish when the people who work in them flourish. Analytics can help make both happen. This course in People Analytics is designed to help you flourish in your career, too.Course 4: Accounting Analytics- Accounting Analytics explores how financial statement data and non-financial metrics can be linked to financial performance. In this course, taught by Wharton’s acclaimed accounting professors, you’ll learn how data is used to assess what drives financial performance and to forecast future financial scenarios. While many accounting and financial organizations deliver data, accounting analytics deploys that data to deliver insight, and this course will explore the many areas in which accounting data provides insight into other business areas including consumer behavior predictions, corporate strategy, risk management, optimization, and more. By the end of this course, you’ll understand how financial data and non-financial data interact to forecast events, optimize operations, and determine strategy. This course has been designed to help you make better business decisions about the emerging roles of accounting analytics, so that you can apply what you’ve learned to make your own business decisions and create strategy using financial data.Course 5: Business Analytics Capstone- The Business Analytics Capstone Project gives you the opportunity to apply what you've learned about how to make data-driven decisions to a real business challenge faced by global technology companies like Yahoo, Google, and Facebook. At the end of this Capstone, you'll be able to ask the right questions of the data, and know how to use data effectively to address business challenges of your own. You’ll understand how cutting-edge businesses use data to optimize marketing, maximize revenue, make operations efficient, and make hiring and management decisions so that you can apply these strategies to your own company or business. Designed with Yahoo to give you invaluable experience in evaluating and creating data-driven decisions, the Business Analytics Capstone Project provides the chance for you to devise a plan of action for optimizing data itself to provide key insights and analysis, and to describe the interaction between key financial and non-financial indicators. Once you complete your analysis, you'll be better prepared to make better data-driven business decisions of your own.",Business Analytics
https://www.classcentral.com/course/clinical-kidney-transplantation-4422,"Kidney transplantation is a major advance of modern medicine which provides high-quality of life for patients with end-stage renal disease. What used to be an experimental, risky, and very limited treatment option more than 50 years ago is now routinely performed in many countries worldwide. The number of renal transplants is expected to rise sharply in the next decade since the proportion of patients with end stage renal disease is increasing. 

Are you interested in clinical kidney, pancreas and islet transplantation? If you are a (bio) medical student or a health care professional who works in the (pre) clinical transplant field this might be the course for you. This course is also for anyone interested in the research and knowledge on clinical transplantation. The course will be taught by a multidisciplinary team of transplant professionals and will give you the state of the art updates. 

It is divided in 4 modules: 
1) Before the transplant 
2) The surgical procedures and the challenged patient, including the patient with diabetes 
3) Early challenges 
4) Late challenges after transplantation. 

The offered modules will include lectures, interactive patient cases, 3D movies, interviews with well-known experts and with patients and a donor, a serious game to increase knowledge of the field and of course an active forum. Become an expert and join us!

The course is endorsed by The European Society of Organ Transplantation (ESOT), The International Society of Nephrology (ISN) and The Transplantation Society (TTS).

This MOOC has been accredited for Continuing Medical Education (CME). Health care professionals who works in the (pre) clinical transplant field, other health care professionals and general practitioners can obtain CME credit at 'LUMC-Boerhaave CME' upon passing the course. For more information we like to refer to the ""Additional introduction for obtaining CME credit"" module in week 1 of the course 

For another interesting course on organ donation and transplantation, see Organ Donation: From Death to Life from Cape Town University https://www.coursera.org/learn/organ-donation
      


            Read more
          



          Welcome to the course
    -Great that you are joining us! In this course you will learn about clinical kidney, pancreas and islet transplantation and its challenges. Before you start with studying we invite you first go through our introduction module and introduce yourself in the forum to meet your fellow learners. Medical professionals can receive Continuing Medical Education (CME) credit for this course. Information on CME credit and how to obtain credit can be found in our CME credit module. If you encounter any difficulties while studying, please let us know in the forum. For technical difficulties or questions regarding the course certificate, you can always contact the Coursera Learner Helpdesk. Good luck & we hope you enjoy studying in this course!

Before the Transplant
    -Welcome to this first module of the course! We will answer important questions before transplantation. These include: why is transplantation the preferred option for patients with end stage renal disease? What are the immunological barriers for transplantation? And what are the selection criteria before transplantation? Unique 3D movies about the different immunological tests will help you to understand the concepts. There are also optional lectures, including a fascinating movie about the Eurotransplant allocation system and patient/donor interviews. At the end of the module we will link the contents you have learned to clinical patient cases, patient - donor interviews and a quiz. You can find each other on the discussion forum. With the e-tivities you can apply your knowledge. In the honors lessons more in depth immunological testing and pre transplant screening can be obtained. The lesson also includes peer reviews about important preclinical questions. Have fun and good luck with the first module!

The Procedure and the Patient 
    -Now you know the factors of importance before transplantation, including the immunological  barriers and important aspects for patient selection,  we can focus on challenged patient  groups and on surgical procedures. What does a kidney, pancreas and islet transplantation surgical procedure look like? What  is important? And what are the key aspects in elderly patients, patients with diabetes and immunological challenged patients. We have unique visulisations, 360 virtual reality videos and a game about a patient case. Advanced readings will invite you to look at the different subjects in more depth. At the end of the module there are interviews about a patient with diabetes and the transplant recipient and donor to illustrate the impact of life. You can discuss patient cases on the forum together with your peers. In the honors lesson you can apply knowledge about more in depth immunological, surgical and metabolic challenges and living kidney donation. Let’s start and we hope you will enjoy this module.

Early Challenges in Transplantation
    -You are now familiar with the basic knowledge about challenges in transplant recipients and the surgical transplant procedures. Once the transplantation has been successful, it doesn’t mean everything is stable. What are actually the graft survival data? Which challenges do we face in the first months? How can we tackle these challenges? 3D movies about early surgical challenges and about the targets for immunosuppressives, including cell therapy, will help you to understand the concepts. In addition, we invite you to master the advanced knowledge and to give your opinion in the patient cases in the forum. There is also a serious game about a patient case. Can you solve the challenges? And can you think of a scenario for the game and help us with building? We will make a game of the best scenario, which will be incorporated in the course. In the honors lesson you can learn in more detail about immunological concepts, including the complement system. A patient case will help to show you the importance of this knowledge.  Good luck with this module and happy learning!

Late Challenges in Transplantation
    -Now you’ve learned about the challenges in the early period after transplantation. But what about the late period? What is the long term patient and allograft survival? Have we improved in the last decades? What are the main causes for morbidity and mortality? And can we reach tolerance in the future? We invite you to give your opinion in the patient cases and to discuss it on the forum. There are also advanced readings to look at additional subjects, including recurrence of the kidney disease after transplantation, the organization of dermatological care for the transplant recipient and  the role of the patient himself in the whole process. The interview about tolerance gives you insight why pregnancy is of interest to understand the concept of tolerance and which steps have been made from lab research to a clinical protocol. In the honors lesson late challenges will be discussed in more detail, with a focus on infections, recurrence of the kidney disease after transplantation and tolerance. Have fun and good luck with this last module.

Final Quiz 
    -We hope you have enjoyed all the modules. Good luck with the final quiz! 
If you are interested in an intensive course about transplantation go to the course resources.","Clinical Kidney, Pancreas and Islet Transplantation"
https://www.classcentral.com/course/edx-the-multi-scale-brain-11380,"Understanding the brain requires an integrated understanding of different scales of organisation of the brain. This means studying the role that genes, channels, cells, microcircuits, and even whole brain regions have in different types of behaviour: From perception to action, while asleep or when being awake. 
This coursewill take the you through the latest data, models and techniques for investigating the different levels of the brain. We will show how we can put the pieces together and attain new insights and derive new theories. With contributions from more than 10 international neuroscientists from six different research institutions, the MOOC gives a broad overview of the latest tools and techniques for neuroinformatics, analysis, modelling and simulation.
At the same time, several different tutorials on available data and data tools, such as those from the Allen Institute for Brain Science, provide you with in-depth knowledge on brain atlases, gene expression data and modeling neurons. These tutorials will be followed by exercises that give you the opportunity to acquire the necessary skills to use the tools and data for your own research.



1. Introduction
1.1. Introduction to the course, Sean Hill
1.2. Introduction to the Allen Institute for Brain Science data and tools, Terri Gilbert
1.3. Human Brain Atlasing, Danilo Bzdok
1.4. Graded quiz 1 
2. Genetic Mapping of the mouse brain
2.1. Using whole-brain and single-cell gene expression to identify and characterize cell types, Vilas Menon 
2.2. Genetic dissection of neural circuits, Trygve Bakken 
3. Navigating gene expression data.
3.1. Accessing mouse gene expression data, Terri Gilbert
3.2. Navigating the human gene expression data, Terri Gilbert
3.3. Peer-graded assignment gene expression data 
4. Multi-scale connectivity
4.1. Synaptic Mapping with Array Tomography, Forrest Collman
4.2. Mesoscale mapping, Jack Waters
4.3. The connectivity atlas, Terri Gilbert
4.4. Graded assignment mouse connectivity 
5. Multi-scale modeling
5.1. Blue Brain, Sean Hill
5.2. Cell types and modeling, Werner von Geit & Elisabetta Iavarone
5.3. Graded assignment modeling
5.4. Building bio-physiologically constrained models of large-scale phenomena in the brain, Alain Destexhe
5.5. Graded quiz 2 
6. Reconstructing micro-circuitry
6.1. Computational properties of human cortical microcircuits Huib Mansvelder
6.2. Modelling microcircuits, Michael Reimann
6.3. Graded quiz 3 
7. Structure and function of the whole brain
7.1. Whole brain morpho-functional imaging: connecting a single neuron to whole brain, Francesco Pavone
7.2. Functional physiology of the mouse virtual cortex, Saskia de Vries
7.3. Brain observatory data sets, Terri Gilbert
7.4. Peer-graded homework
7.5. Graded quiz 4 
8. Final exam",The Multi-scale brain
https://www.classcentral.com/course/edx-practical-improvement-science-in-health-care-a-roadmap-for-getting-results-5003,"Developed through a collaboration between HarvardX and the Institute for Healthcare Improvement, PH 556x: Practical Improvement Science in Health Care: A roadmap for getting results will provide learners with the valuable skills and simple, well-tested tools they need to translate promising innovations or evidence into practice. A group of expert faculty will explore a scientific approach to improvement — a practical, rigorous methodology that includes a theory of change, measurable aims, and iterative, incremental small tests of change to determine if improvement concepts can be implemented effectively in practice. Faculty will present this science through the lens of improving health and health care, but will also share examples of how improvement can (and does) influence our daily lives.
Each week, learners will dive into engaging, interactive materials and relevant resources to start building an improvement toolkit that will serve them long after the seven-week course ends. Learners will immediately put their new skills to the test as they work each week on a personal improvement project that will show them the power of the science that has improved healthcare — and other industries — around the world for decades.
The only prerequisite for the course is curiosity, but the reward is a lifetime of improvement.
In support of improving patient care, the Institute for Healthcare Improvement is accredited by the American Nurses Credentialing Center (ANCC), the Accreditation Council for Pharmacy Education (ACPE), and the Accreditation Council for Continuing Medical Education (ACCME) to provide continuing education for the healthcare team. This activity has also been approved by the National Association for Healthcare Quality for CPHQ CE credit. If you are interested in earning CEUs for this course, please visit www.IHI.org/PH556X to see the options and steps required prior to enrolling or taking any action on edX.
This collaboration between the Institute of Healthcare Improvement and HarvardX will teach you the skills and tools of improvement science to make positive changes in health, healthcare, and your daily life.



            Read more
          




Lesson 1: What is the Science of Improvement?
Lesson 2: Applying the Model for Improvement
Lesson 3: Introduction to Measurement for Improvement
Lesson 4: Practical Tools that Support Improvement (including a seven-piece toolkit)
Lesson 5: Using Systems Principles to Spread Improvement
Lesson 6: Working within Interprofessional Teams
Lesson 7: Implementing Sustainable Improvement Work",Practical Improvement Science in Health Care: A Roadmap for Getting Results
https://www.classcentral.com/course/edx-probability-basic-concepts-discrete-random-variables-6989,"Our capacity to collect and store data has exponentially increased, but deriving information from data from a scientific perspective requires a foundational knowledge of probability.
Are you interested in a career in the emerging data science field, or as an actuarial scientist? Or want better to understand statistical theory and mathematical modeling?
In this statistics and data analysis course, we will provide an introduction to mathematical probability to help meet your career goals in the exciting new areas becoming known as information science.
In this course, we will first introduce basic probability concepts and rules, including Bayes theorem, probability mass functions and CDFs, joint distributions and expected values.
Then we will discuss a few important probability distribution models with discrete random variables, including Bernoulli and Binomial distributions, Geometric distribution, Negative Binomial distribution, Poisson distribution, Hypergeometric distribution and discrete uniform distribution.
To continue learning about probability, enroll in Probability: Distribution Models & Continuous Random Variables, which covers continuous distribution models, central limit theorem and more.

The Center for Science of Information, a National Science Foundation Center, supports learners by offering free educational resources in information science.



Unit 1: Sample Space and Probability  Introduction to basic concepts, such as outcomes, events, sample spaces, and probability. Unit 2: Independent Events, Conditional Probability and Bayes’ TheoremIntroduction to independent events, conditional probability and Bayes’ Theorem with examples. Unit 3: Random Variables Random variables, probability mass functions and CDFs, joint distributions. Unit 4: Expected Values In this unit, we will discuss expected values of discrete random variables, sum of random variables and functions of random variables with lots of examples. Unit 5: Models of Discrete Random Variables I Bernoulli and Binomial random variables; Geometric random variables; Negative Binomial random variables. Unit 6: Models of Discrete Random Variables II Poisson random variables; Hypergeometric random variables; discrete uniform random variables and counting.",Probability: Basic Concepts & Discrete Random Variables
https://www.classcentral.com/course/emma-business-intelligence-4111,"The amount of data generated by the information society is growing day by day, and will continue to grow thanks to the explosion of social networks, the smarts cities, the big data, mobile devices, sensors, etc. This exponential increase in the volume of data that are generated makes it imperative the use of systems that are capable of analysing and turn them into useful information. For this reason, our society, our businesses and institutions need intelligence at the moment to integrate within their organizational processes and decision, and this involves integrating tools of business analytics or smart data. This course provides an introduction to these tools of business intelligence, the associated main methodologies and current trends within this area.



1.  Introduction to the system of Business Intelligence (BI)BI introduction to the system of BI. Levels of analytics in the company.  Lifespan of information.  Management of BI projects.  BI market trends.2.  Architecture of BI systemsCorporate information and Data Warehouse.  Process ETL. Metadata. Multidimensional design. OLAP.  Control tables. 3.  Business Analytics: ClusteringIntroduction to business analytics.  Hierarchical clustering.  Non-hierarchic clustering: k-means algorithm.  4.  Business Analytics: ClassificationIntroduction to classification problems.  Decision trees.  Support Vector Machines (SVM).5.  Trends in BIOpen Source BI. Big Data systems.  Social BI systems, Geographic BI systems. Customer Experience.",Business Intelligence
https://www.classcentral.com/course/edx-introduction-to-cybersecurity-8651,"This course serves as an introduction to the exciting field of cybersecurity.
As our daily lives become more and more dependent on Internet-based tools and services, and as those platforms accumulate more of our most sensitive data, the demand grows for experts in the field of cybersecurity.
In this course, you will gain an overview of the cybersecurity landscape as well as national (USA) and international perspectives on the field. We will cover the legal environment that impacts cybersecurity as well as predominant threat actors.",Introduction to Cybersecurity
https://www.classcentral.com/course/edx-cyber-security-basics-a-hands-on-approach-7849,"Are you tired of hearing that your computer has a virus? Or that your email account has been hacked? Now, is the time for you to protect yourself by understanding the basics of cyber security.
This computer science course presents an introduction to cyber security showing different aspects of this discipline. You will learn what the main existing cyber security threats are and how to protect yourself against them. The course presents a practical approach in which all required material will be provided to allow you to better understand attacks and establish appropriate countermeasures.
Taught by instructors with years of experience in the field of computer security, this course will pave the way to the security area of IT-related professions.



Lecture 1. Cybersecurity: an overview  This lecture introduces the impact of cybersecurity nowadays, as well as some examples of cyberthreats that motivate the relevance of this area of study. Types of cyberthreats, such as cybercrime or cyberwarfare, are later described, together with an overview of the current cyberthreat landscape. Finally, some well-known cybersecurity events are presented. Lecture 2. Computer forensics  This lecture introduces computer forensics, that is the technique focused on the analysis and preservation of evidences in a particular computer device after an attack occurs. Common forensic traces are defined, namely traces left by deleted files, hidden data and fake emails. Lecture 3. Assembly programming: towards reversing  This lecture introduces the main concepts of reverse engineering, that is, the ability to take an executable element and try to figure out how it works. The definition of this technique is introduced. After some theoretical knowledge, examples of disassembling C codes and decompiling codes in different languages, namely Java and C, are presented. Lecture 4. Cyberdefense  This lecture introduces the main concepts of cyberdefense together with common applied tools. After presenting this topic, firewalls are outlined. The following part involves the description of Intrusion Detection Systems (IDSs). Security Information and Event management (SIEM) systems, which refer to a general approach to manage cyberdefense, are finally presented. Lecture 5. Malware and Advanced Persistent Threats (APTs)  This lecture explains the main concepts related to malware and Advanced Persistent Threats (APTs), together with the main techniques to achieve their identification. The definition and types of malware, APTs and some real cases are introduced. Lecture 6. Vulnerabilities and exposures  This last lesson presents vulnerabilities description and management. It describes and gives examples of the most common vulnerabilities at software, network and web level. The definition, use and application of penetration testing (pentesting) are also presented, as well as some examples applying the well-known tool Metasploit. Repositories of vulnerabilities are finally introduced.",Cyber Security Basics: A Hands-on Approach
https://www.classcentral.com/course/edx-protecting-children-in-humanitarian-settings-14482,"Globally, an unprecedented 131 million people are affected by humanitarian crises worldwide. Children, who constitute just under half of the affected population, are particularly vulnerable in these situations, which present grave risks to their physical health and psychological wellbeing.This course examines how children’s social environments at different levels, such as the family, community and societal levels, influence children’s adversity, development and resilience. Course participants will engage in critical thought about current international child protection practice and how to strengthen it. The course will invite participants to identify opportunities for using the learning from science and practice, to enrich current child protection approaches in humanitarian settings. This course is aimed at child protection practitioners who work internationally in humanitarian settings and is also designed for those who want to learn more about, or start working in, the sector. The course is not intended to provide a comprehensive introduction to child protection programming in humanitarian settings. Instead, it focuses on select areas that are ripe for enrichment.
      



Welcome to the Course

Getting to Know Each Other
How to Take This Course
(Optional) Introduction to Humanitarian Child Protection


Child Development, Adversity, and Resilience

Child Development
Childhood Adversity
Resilience in Children
Relating the Science to Child Protection
Unlocking the Protective Potential of Social Environments


Supporting Children's Agency

Working with Children in Different Cultural Contexts
Children's Agency and Participation
Fostering Child Agency
Do No Harm


Enabling Families as Protective Environments

Families in Different Cultural Contexts
Impact of Humanitarian Crises on Families
Interventions to Support Families During and After Crises
‘Do No Harm’ Issues


Enabling Communities as Protective Environments

Communities As Resources and Risks for Children
Ways of Engaging with Communities
How Community Approaches Can Support Child Protection in Education


Enabling Protective Social Norms and Policies

Social Norms
Approaches to Social Norms Change
Children's Policies
Approaches to Changing Policy


Enriching and Transforming Practice

Bringing Together the Science of Childhood Adversity and Child Protection Practice
Identifying Barriers to Transformation
Identifying Opportunities for Transformation",Protecting Children in Humanitarian Settings
https://www.classcentral.com/course/edx-introduction-to-applied-biostatistics-statistics-for-medical-research-5158,"Want to learn how to analyze real-world medical data, but unsure where to begin?  This Applied Biostatistics course provides an introduction to important topics in medical statistical concepts and reasoning. Each topic will be introduced with examples from published clinical research papers; and all homework assignments will expose learner to hands-on data analysis using real-life datasets. This course also represents an introduction to basic epidemiological concepts covering study designs and sample size computation. Open-source, easy-to-use software will be used such as R Commander and PS sample size software.



Week 1 Basic Statistical Concepts
Introduction to basic statistical concepts, such as descriptive statistics, hypothesis testing, how to enter data in to statistical software and how to use easy R interface.
 
Week 2 Basic Epidemiological Concepts
Introduction to basic epidemiological concepts, such as study designs as well as the difference between observational studies and randomized clinical trials.
 
Week 3 Selecting Proper Statistical Tests
Students will learn how to select a proper statistical test, given scenarios defined by various data types.
 
Week 4  Student T-Test, Man-Whitney U Test, Paired T-test, Wilcoxon Signed Rank Test
Students will learn how to compare means or medians between two groups.
 
Week 5 Risk, Rate and Chi-Square Tests
Students will learn how to analyze binary outcome data.
 
Week 6 Sample Size and Power Analysis
Introduction to basic concepts in computing sample sizes and estimation power for clinical studies.",Introduction to Applied Biostatistics: Statistics for Medical Research
https://www.classcentral.com/course/scholarly-communication-4475,"Scholarly Communication is a concise but comprehensive course on how to write research papers in English. The course will help the candidates gain a better understanding of the rhetorical conventions of English and the common challenges the candidates may face as an academic writer. The course provides instruction, exercises, structure, and deadlines needed to create a publishable paper.

The aim of the course is to improve competence in scholarly communications by deepening knowledge of the core features of the scientific writing style. It presents and analyzes the unwritten rules of scientific writing, the ones candidates most likely never learned in academic writing.

The course will enable the candidates to write clear, detailed and well-structured scientific texts appropriate to a suitable academic journal. In particular, they will develop an awareness of fundamental concepts of academic writing, such as contrastive rhetoric, logical organization, and argumentation. In addition, they will develop skills for self-editing and revision techniques, including editing
for precision and clarity. They will also gain a deeper understanding of how to prepare a scientific paper using the IMRAD format. Finally, the candidates will develop an enhanced understanding of the concept of academic integrity and the ethics of scientific writing.

The candidates will be able to overcome anxiety about academic publishing and get their research papers published in international journals.
      


            Read more
          



          Science Writing
    -MODULE I: SCIENCE WRITING will help you develop an enhanced understanding of English written pattern,  based on Anglo-American rhetorical conventions. The module covers issues relating to writing strategies, style, hedging, clear meaning, organization, and choice of first-person pronouns. The focus is on improving your ability to write academic English appropriate to a research article.

The Challenge
    -MODULE II: THE CHALLENGE covers issues relating to the internal text structures intrinsic to a research article. The module clarifies the usage of three major types of modifiers (squinting, misplaced, and dangling) and suggests a number of strategies to avoid obvious negation. In addition, you will learn how to create stronger academic writing by choosing the right verb form used either in the active or passive voice.  The module teaches the Anglo-American style of outlining, paragraphing, and argumentation to make the reading process easier for the reader. Also, you will develop an awareness of the process of journal analysis.

The Manuscript
    -MODULE III: THE MANUSCRIPT will teach you how to prepare a publishable paper in the IMRaD (Introduction, Methods & Materials, Results, and Discussion) format. The module provides clear instructions on manuscript writing. You will gain a better understanding of four elements that underlie the structure of all stories, including those you write in science – Opening, Challenge, Action, and Resolution, which can be easily mapped on the IMRaD format.

Scientific Communication
    -MODULE IV: SCIENTIFIC COMMUNICATION covers issues concerning the manuscript submission process. The module highlights editorial requirements, scientific integrity, and publishing ethics. In addition, you will learn several self-editing techniques that will enable you to prepare your manuscript for submission. The module suggests ways to self-promote in academia.",Scholarly Communication
https://www.classcentral.com/course/edx-marketing-analytics-data-tools-and-techniques-6746,"Businesses today have access to an increasingly large amount of detailed customer data, and this influx of data is only going to continue. Combined with a detailed history of marketing actions, there is a newfound potential for deriving actionable insights, but you need the tools to do so. Using real-world applications from various industries, this course will help you understand the tools and strategies used to make data-driven decisions that you can put to use in your own company or business. This valuable data may include in-store and online customer transactions, customer surveys as well as prices and advertising. You’ll also learn how to assess critical managerial problems, develop relevant hypotheses, analyze data and, most importantly, draw inferences to create convincing narratives which yield actionable results.
This course is part of Wharton's Digital Marketing Professional Certificate. For more information, see here.



Module 1: Introduction to Data Collection, Market Research and Analysis Module 2: Regression Module 3: Conjoint AnalysisModule 4: Social Media Analytics",Marketing Analytics: Data Tools and Techniques
https://www.classcentral.com/course/edx-analytics-for-decision-making-7517,"Want to know how to avoid bad decisions with data?
Making good decisions with data can give you a distinct competitive advantage in business. This statistics and data analysis course will help you understand the fundamental concepts of sound statistical thinking that can be applied in surprisingly wide contexts, sometimes even before there is any data! Key concepts like understanding variation, perceiving relative risk of alternative decisions, and pinpointing sources of variation will be highlighted.
These big picture ideas have motivated the development of quantitative models, but in most traditional statistics courses, these concepts get lost behind a wall of little techniques and computations. In this course we keep the focus on the ideas that really matter, and we illustrate them with lively, practical, accessible examples.
We will explore questions like: How are traditional statistical methods still relevant in modern analytics applications? How can we avoid common fallacies and misconceptions when approaching quantitative problems? How do we apply statistical methods in predictive applications? How do we gain a better understanding of customer engagement through analytics?
This course will be is relevant for anyone eager to have a framework for good decision-making. It will be good preparation for students with a bachelor's degree contemplating graduate study in a business field.
Opportunities in analytics are abundant at the moment. Specific techniques or software packages may be helpful in landing first jobs, but those techniques and packages may soon be replaced by something newer and trendier. Understanding the ways in which quantitative models really work, however, is a management level skill that is unlikely to go out of style.
This course is part of the Business Principles and Entrepreneurial Thought XSeries.



            Read more",Analytics for Decision Making
https://www.classcentral.com/course/canvas-network-introduction-to-geospatial-technology-using-qgis-3168,"This course provides a rich introduction to the booming technology field of Geographic Information Systems, known as GIS. The GIS industry is exploding at double-digit employment and income numbers and promises employment opportunities well into the future. Students will learn the fundamentals of GIS and how to build digital maps using open source software that allows free unlimited use for private or commercial applications. All data and software required is included in the course.
Topics covered in this course include GIS, cartography, remote sensing, and spatial analysis through a series of lectures and hands-on computer-based exercises. This course is designed to be used as a stand-alone course to complement other disciplines or as an entry level course into a geospatial program. Course content is based upon the United States Department of Labor’s Geospatial Technology Competency Model for entry level geospatial occupations, including Geospatial or GIS Technicians and Technologists.
Learning Outcomes/Competencies

Describe the fundamental concepts of Geographic Information Science and Technology.
Demonstrate proficiency in the basic functions of geospatial software.
Demonstrate awareness of fundamental remote sensing and spatial analysis techniques.
Demonstrate basic proficiency in map creation and design principles, including thematic map display, employment of map projections, and cartographic design.
Demonstrate proficiency in the creation and acquisition of spatial data.

Credit
Students have the option to receive continuing education credit from a regionally accredited college.



            Read more",Introduction to Geospatial Technology Using QGIS
https://www.classcentral.com/course/federicax-introduction-to-political-science-18493,"This Political Science Xseries program uses critical approaches and analytical methods that can be applied to any complex organisation or problem to offer learners a solid understanding of the structure and function of national governments and international political Institutions, and the challenges of contemporary democracy.
Benefiting from leading academics associated with the International Political Science Association, the XSeries program covers, at the introductory level, areas in the study of political science, ranging from research design and methods and critical theory to comparative analysis of different political concepts and systems, world politics and theories of democracy and autocracy.
This series of courses are meant to appeal to three types of audience:

For students considering or starting a degree in Political Science or for those requiring a basic grounding in Political Science before embarking on post-graduate study in a related field, the XSeries is intended to serve as a useful orientation and preparation tool.
For teachers of Political Science at any level who may choose to complement their course material with MOOCs offered by world renowned scholars in an innovative format particularly suitable for the digital generation. They will find that the course acts as a rich and interactive online textbook and a useful reference tool.
For anyone else who is interested in a better understanding of the challenges facing contemporary democracies in the contemporary world.




            Read more
          



Courses under this program:Course 1: Comparative Political Systems
Explored through the lens of different political systems, this course provides the insights neededto understand Democracy today and the challenges faced by democratic governments.
Course 2: Understanding Political Concepts
This course offers an exciting journey through political science concepts. Understand key concepts like party, bureaucracy, andconstitution by using new methods developed for scholars and students; including the innovative ""Hyperpolitics"" tool.
Course 3: Comparative Research Designs and Methods
Explore comparative analysis and itsimportance in the social sciences. You'll learn howto use comparative methods for constructive explanation and theory building and applyit to real-world politics.
Course 4: Democracy and Autocracy: Theories and Empirical Findings
Learn which forms of government can best guarantee a free, fair, and just life by exploringhow democracy and autocracy emerge, evolve, andimpact our lives.
Course 5: Contemporary Issues in World Politics
Explore major issues in world politics and learn how recent developments have challenged world order and peace.",Introduction to Political Science IPSAMOOC
https://www.classcentral.com/course/harvardx-computer-science-for-web-programming-18465,"The web is a crucial part of our everyday lives. We rely on websites not just for entertainment and social networking, but for our professions, our finances, our education, and even aspects of our health care. The technologies that run these services are intricate and varied, but there are frameworks and principles that use common languages like HTML and Python that can give you a jump start in building your own web apps.
This professional certificate series combines CS50’s legendary Introduction to Computer Science course with a new program that takes a deep dive into the design and implementation of web apps with Python, JavaScript, and SQL using frameworks like Flask, Django, and Bootstrap.
Through hands-on projects, you'll learn to write and use APIs, create interactive UIs, and leverage cloud services like GitHub and Heroku. You'll emerge with knowledge and experience in principles, languages, and tools that empower you to design and deploy applications. Join now to program your own web applications and gain critical skills in database design, scalability, security, and user experience.



Courses under this program:Course 1: CS50's Introduction to Computer ScienceAn introduction to the intellectual enterprises of computer science and the art of programming.Course 2: CS50's Web Programming with Python and JavaScriptThis course picks up where CS50 leaves off, diving more deeply into the design and implementation of web apps with Python, JavaScript, and SQL using frameworks like Flask, Django, and Bootstrap.",Computer Science for Web Programming
https://www.classcentral.com/course/open-education-by-blackboard-coasts-and-communities-783,"Environmental problems do not recognize geographic or disciplinary boundaries. In order to develop sustainable solutions to environmental challenges we must incorporate the natural and social sciences and also deeply engage local communities. Through the lens of coastal systems and the human communities dependent upon them, we will explore how coupled human-natural systems interact. Participants will be introduced to fundamental concepts in coastal environmental science and will learn how to collect and evaluate data to solve real-world local environmental problems.
Introduction to Coastal Environmental Science Lab
Unique to this course is the infusion of real environmental scientists who will introduce you to their work in the coastal environments of Massachusetts and guide you in lab and field activities to help you apply in practice concepts from a broad array of topics introduced in the course.
The course is free as a non-credit open course. The course may be taken for credit by registering through UMass Boston (details below).
Prerequisites
The course is best suited for high school seniors and learners with an undergraduate level understanding of environmental science, but is open to everyone interested in the field.
 
For a sample of topics explored in the course, explore this map with video lectures from the Fall 2013 offering of the course, grouped in five main topics:

The Natural History of Your Place
The Human History of Your Place
How Healthy is Your Living Environment?
How Can We Adapt to Climate Change?
How Can We Scale from Local to Global to Local?

 



            Read more
          



          


Week 1              
Topic
The Natural History of Your Place


Lab
Sampling Biodiversity


Week 2
Topic
The Human History of Your Place


Lab
EcoBeaker


Week 3
Topic
How Healthy and Resilient is Your Environment?


Lab
Watersheds and Topographic Maps


Week 4
Topic
Global Change and Variation


Lab
The Rock Cycle


Week 5
Topic
How Can We Scale from Local to Global to Local?


Lab
Weather


Week 6
Topic
How Can We Respond and Adapt to Changes?


Lab
Energy",Coasts and Communities
https://www.classcentral.com/course/quality-healthcare-6316,"Ensuring patient safety and healthcare quality is critical and should be a key focus of everyone in healthcare practice. This course provides healthcare practitioners and others with an introduction to the knowledge and skills needed to lead patient safety and quality improvement initiatives at the micro and macro levels. Participants will explore the foundations of health care quality and the science underlying patient safety and quality improvement, design and select effective health care measures, analyze patient safety problems and processes using tools such as human factors analysis, apply systematic approaches including the Plan-Do-Study-Act (PDSA) model to address quality improvement challenges, and learn strategies to lead a culture of change. The course takes a world view of patient safety and quality, linking participants to research and resources from the World Health Organization (WHO), the US Agency for Healthcare Research and Quality (AHRQ), the Joint Commission and other international organizations. Course highlights include personal stories, lessons learned from other industries and interviews with the President of the National Committee for Quality Assurance (NCQA) and other leaders in quality movement.


About The George Washington University School of Nursing

Ranked among the top nursing schools by U.S. News & World Report, the George Washington University School of Nursing educates and inspires nurses to provide high-quality, compassionate person-centered health care. The school develops leaders actively engaged in health promotion, patient advocacy and healthcare innovation, and prepares exceptional nurse educators who pursue quality and advance the profession. The School of Nursing is committed to improving the health and wellbeing of people and communities locally, nationally and globally. The school values lifelong learning and its students advance nursing practice, leadership and education as they make a difference in the world.
      


            Read more
          



          Establishing a Framework for Quality & Safety
    -Welcome to Module 1! During this module, you'll learn about the current state of healthcare quality and safety in the US and globally, and the essential characteristics and expected outcomes of safe, high-quality healthcare. We'll also discuss the core elements of quality improvement, and the data needed to assess the safety and quality of care. Finally, we'll examine lessons learned from other industries & disciplines that can be applied to healthcare improvement efforts. We're looking forward to getting started!

Safety as a First Principle of Quality
    -Welcome to Module 2! This week, we examine the criticality of patient safety to healthcare and the sciences underlying patient safety. You'll learn a model for systems engineering and a process for anticipating and addressing medical errors. You'll also learn about the importance of a just culture approach to medical error prevention. 

Measures & Measurement
    -Welcome to Module 3! This week we delve into measures and measurement. You'll learn to apply the basic Donebedian framework for measuring quality in healthcare in terms of structure, process and outcomes. We'll  discuss the key attributes of useful (good) healthcare measures and the core concepts of validity and reliability. You'll also learn the most critical elements to consider in choosing and applying a measure or measures to measurement in a given health care setting or situation, and the key characteristics of a measurement process that must be present to provide information that is a valid and useful reflection of quality of care.

Quality and Safety Improvement Science
    -Welcome to Module 4! This week you'll learn how to identify quality improvement opportunities and apply the PDSA cycle to address them. We'll also discuss the importance and benefits of team-based approaches to quality improvement, and the value of Health Information Technologies (HIT) and other innovations in improving health care quality.

Leadership for Quality & Safety
    -Welcome to Module 5! This week we explore the importance of leadership in supporting and advancing quality and safety at all levels of the healthcare organization. We'll discuss strategies that contribute to a quality culture in health care, and examine different models of organizational change that you can apply as you lead your own quality and safety initiatives.",Leading Healthcare Quality and Safety
https://www.classcentral.com/course/edx-data-science-capstone-10354,"To become an expert data scientist you need practice and experience. By completing this capstone project you will get an opportunity to apply the knowledge and skills in R data analysis that you have gained throughout the series. This final project will test your skills in data visualization, probability, inference and modeling, data wrangling, data organization, regression, and machine learning. 
Unlike the rest of ourProfessional Certificate Program in Data Science, in this course, you will receive much less guidance from the instructors. When you complete the project you will have a data product to show off to potential employers or educational programs, a strong indicator of your expertise in the field of data science.",Data Science: Capstone
https://www.classcentral.com/course/iot-wireless-cloud-computing-11982,"IoT (Internet of Things) devices are already abundant, but new products that include IoT modules are now a common trend. Also, almost everything is already connected to a Cloud, and much more will be in the future. Naturally, as this trend continues, in the near future almost all devices and appliances will include IoT modules which will use sensor data collection and control/management based on Clouds. Since we will live in an IoT world supported by Clouds, knowledge of the core technologies and platforms of IoT and Clouds will enable you with the tools to become a true leader in the future product and business world. In this course, the start-of-the-art IoT and wireless networks and Cloud technologies are introduced (for details on 1G to 5G mobile communications and smartphone and smart device technology, please take my course “Smart Device & Mobile Emerging Technologies”). This course ends with projects that teach how to analyze Bluetooth and W-Fi wireless networks and setup and use an EC2 (Elastic Compute Cloud) Virtual Computer in AWS (Amazon Web Service), which is the most powerful and popular Cloud technology in the world. Comparing to the human body, IoT is the neural network and the Cloud is the brain. Thus, I cordially welcome you into the brain and neural network of the future intelligence world!
      


          IoT Business & Products
    -The first module “IoT Business & Products” focuses on the influence of IoT and provides an overview of the trends in North America and the world’s IoT market and industry. The differences in IoT products and services are also described followed by an introduction of the types of leading IoT companies and products, which include Atmel, Android Things, Samsara, ZingBox, and Uber. In addition, IoT services types (i.e., M2M, M2P, P2M, P2P) and their economic impact and the advantages of IoT applications as well as the IoT & M2M ecosystem are introduced. 

IoT Architecture & Technologies
    -The second module “IoT Architecture & Technologies” focuses on the functionality and characteristics of the IoT architecture layers as well as the characteristics of IoT technologies, which include WSN (Wireless Sensor Networks), IoT cloud computing, IoT R&D (Research & Development), and IoT hardware technologies. Further details are provided in the descriptions of the characteristics of IoT sensors types, actuator types, and RFID types as well as the functionality and characteristics of IoT device platforms, which include the Arduino, Raspberry Pi, and BeagleBoard products. Next, a comparison of the representative IoT developer platform products is presented, which include the Raspberry Pi, Raspberry Pi 3 Model B, BeagleBoard, Beaglebone Black, and the Arduino systems Uno R3 (for entry and general purpose), Yun (for IoT), and Lilypad (for wearable). 

IoT Networks
    -The third module “IoT Networks” focuses on the functionality and characteristics of IoT wireless networks, the IoT network architecture, and wearable IoT networks. To describe the frequency requirements, the characteristics and requirements of the ISM (Industrial, Scientific and Medical) band are introduced. Next, the functionality and characteristics of IoT wireless communication technologies based on WLAN (Wireless Local Area Network), WPAN (Wireless Personal Area Network), and LPWAN (Low-Power Wide Area Network) are described. Then further details on WPAN (which include Bluetooth, ZigBee, 6LoWPAN, and IEEE 802.15.4 technology) and LPWAN (which include LoRa, UNB, Sigfox, and NB-IoT) are provided. In addition, the advantages of IoT and 5G mobile communication networks and the characteristics of mMTC (massive MTC) is covered. 

Wi-Fi & Bluetooth
    -The fourth module “Wi-Fi & Bluetooth” focuses on the details of Wi-Fi and Bluetooth technology. First, Wi-Fi technology and the WLAN (Wireless Local Area Network) market is introduced, followed by a description of the functionality of Wi-Fi transmission modes (which include the Infrastructure mode and the Ad-Hoc mode) and wireless APs (Access Points) as well as BSS (Basic Service Set) and ESS (Extended Service Set) network formations. The internal process of Wi-Fi operations and role of DCF (Distributed Coordination Function) and CSMA/CA (Carrier-Sense Multiple Access with Collision Avoidance) are described followed by the characteristics of Wi-Fi standards (which include the IEEE 802.11a, 11b, 11e, 11g, 11n, 11p, 11ac, 11ad, 11ah specifications), Wi-Fi PHY (Physical Layer) modulation schemes, as well as the IFS (Inter-Frame Space) types and how IFSs are used in priority access control. In addition, the advantages of Wi-Fi Dual Band and Wi-Fi Direct are introduced. Second, Bluetooth standards and feature evolution are introduced, which include the specifications from 1.1 to 5 including EDR (Enhanced Data Rate), HS (High Speed), BLE (Bluetooth Low Energy), and Beacon technology. The description incudes the characteristics of Bluetooth piconets and types of operations (which include Classic Bluetooth and BLE (Bluetooth Low Energy)) as well as the channel specifications, advertising, and connection events. 

Cloud Technology
    -The fifth module “Cloud Technology” focuses on the Cloud market analysis, Cloud service types, MCC (Mobile Cloud Computing), and Edge Computing technology. Frist, the characteristics of the world’s top cloud companies and their services including AWS (Amazon Web Service), Microsoft, IBM, Google, and Apple's iCloud are introduced. Then the characteristics of cloud models, which include public cloud, private cloud, community cloud, and hybrid cloud are described along with the differences in cloud service models, which include SaaS (Software as a Service), PaaS (Platform as a Service), and IaaS (Infrastructure as a Service). Based on the service models, the benefits and characteristics of Cloud services are introduced. More details on the operation process are introduced, which include the IaaS and VM (Virtual Machine) administration, PaaS Runtime Environment for application support, and Open SaaS applications access processes. Then the relation between IoT and state-of-the-art mobile cloud technology is introduced. First the differences in MCC (Mobile Cloud Computing) and Edge Computing are described, which includes details on Fog computing, MEC (Mobile Edge Computing), and Cloudlet technology. In addition, the functionality and characteristics of the Cloudlet architecture and its 3 layers are covered. 

IoT Bluetooth & Wi-Fi and EC2 Cloud Projects
    -The sixth module “IoT Bluetooth & Wi-Fi & AWS EC2 Project” focuses on three IoT projects to provide experience in Bluetooth, Wi-Fi, and AWS (Amazon Web Service) EC2 (Elastic Compute Cloud) system details. The first project provides experience on the operation process of Bluetooth in Android and iPhone smartphones, teaching how to scan a Bluetooth packet and identify different Bluetooth versions being used on a smartphone. The second project provides experience on the operation process of Wi-Fi in Android and iPhone smartphones, teaching how to use a Wi-Fi network analyzer, conduct a LAN scan, send ping to a gateway, conduct a Wi-Fi signal scan, and use a Wi-Fi channel graph. The third project provides experience on how to setup an EC2 (Elastic Compute Cloud) Virtual Computer in AWS (Amazon Web Service) and how to use various options and compute a process on EC2 and use S3.",IoT (Internet of Things) Wireless & Cloud Computing Emerging Technologies
https://www.classcentral.com/course/edx-cities-and-the-challenge-of-sustainable-development-9744,"According to the United Nations, urbanization and population growth could result in an increase of 2.5 billion people into urban populations by 2050, with associated impacts ranging from increased transportation needs to more building. How do we make cities sustainable to support this growth?In this mini-series, learn the challenges of local governments to adapt to new technologies, energy systems, modes of transportation and more in order to build the sustainable cities of the 21st century.This mini-series is a companion piece to the SDG Academy's full-length Sustainable Cities course.This course is for:

Anyone new to the concept of sustainable cities or smart cities who wants to understand the foundations of modern urban development
Graduate students and advanced undergraduate students in architecture, real estate development, sustainable development, sustainable business and other related fields who want a concise overview of the concept of sustainable cities
Sustainable development practitioners interested in the basics of sustainable development for cities around the world
Private-sector actors, such as those who work in technology, telecommunications, transportation or the energy industry – whose work can contribute to and redefine this space




Module 1: Introduction to the SDGsProfessor Jeffrey Sachs introduces the SDGs and their importance. This module briefly describes the importance of creating sustainable living spaces and what we can expect from a future that is built on the principles of economic prosperity, social inclusion and environmental sustainability. Module 2: Why Cities? The Importance of SDG 11Professor Sachs talks about the ideas and thought-processes that are used to work towards achieving sustainable cities. He elaborates the circumstances in which SDG 11 was created, and uses current data to estimate future global needs and the expectations that must be fulfilled to establish sustainable cities. The outcomes of modifying and designing cities for the increasing world population are also elaborated.Module 3: The 10-Point Agenda for 21st-Century CitiesProfessor Sachs discusses the pros and cons of advancements in science and technology. He outlines a 10-point agenda for sustainable cities and discusses each topic individually to elaborate the breadth and depth of this complex issue.Module 4: Urban Environment and Energy Systems Professor Sachs highlights the escalating issues due to climate change and pollution and establishes the urgent need to achieve clean and smart cities. To illustrate the limited timeline under which sustainability must be achieved, he uses current data to forecast possible future solutions. This module also includes examples of new methods and cutting-edge technologies that can be used to achieve SDG 11.Module 5: Cities as Hubs of KnowledgeThis concluding module draws on the cross-cutting issues previously discussed, including the importance of developing urban settlements into smart, shared spaces that foster creativity and knowledge growth. Using case studies, Professor Sachs provides further examples of how this is being done across the world, and how this method can be applied in the future.",Cities and the Challenge of Sustainable Development
https://www.classcentral.com/course/edx-the-legacy-of-islamic-civilization-6589,"Learn about Muslim civilization and its valuable contributions and role in the revival of the Greek Classics.
This is not a course about Islam or the Islamic civilization, it is a brief overview and a basic introduction to the achievements of Muslim civilization in the fields of physics, biology, mathematics, architecture and astronomy in a concise manner.



Unit One: The Emergence of Islam

Lesson One - An Introduction to the Emergence of Islam
Lesson Two - A Brief Summary of the Major Expansions by the Rashidun and the Umayyads
Lesson Three - The Diversity of Muslim Societies

Unit Two: Islamic Awakening

Lesson One - Islam and Science
Lesson Two - A Brief Introduction to the Contributions of Muslim Scholars.
Lesson Three - An Overview of the History of Science in the Muslim World, Part One
Lesson Four - An Overview of the History of Science in the Muslim World, Part Two

Unit Three: Muslim Scientists

Lesson One - Astronomers and Mathematicians: Ibn Al-Haytham and Al-Tusi
Lesson Two - Physicians: Ibn Al-Nafis and Ibn Sina
Lesson Three - Philosophers: Al-Kindi and Ibn Rushd

Unit Four: Islamic Architecture Plus an Overview of the Influence of Islamic Civilization

Lesson One: Islamic Architecture I
Lesson Two: Islamic Architecture II
Lesson Three: The Influence of the Islamic Civilization on the West
Lesson Four: Areas of Influence",The Legacy of Islamic Civilization
https://www.classcentral.com/course/edx-landscape-ecology-11699,"What is a landscape? How has it evolved? How do we perceive landscapes? What properties are required to make us feel at home? Are you interested in these topics and want to understand how landscapes function? Then this is the course for you! We will present the discipline of Landscape Ecology, where natural and social sciences meet. You will realize how innovative and collaborative approaches used in Landscape Ecology allow land managers, planners and the public to shape landscapes for future societies. We will teach you the modern tools of Landscape Ecology enabling you to address fundamental research questions. You will also get valuable practical advice in solving existing real landscape issues. Leading Landscape Ecology professors will present case studies from around the world, highlighting tools and methods in Landscape Ecology and how they are used to solve environmental problems.
      


Unit 1 Landscape Ecology Foundations This unit introduces you to the definitions and important concepts of Landscape Ecology. It also explores the forces that shape our landscapes. 1.1 Introduction to Landscape Ecology 1.2 Drivers of Landscape Patterns Unit 2 Land System ModellingThis unit focuses on quantitative assessments and the modelling of landscapes, mostly from a natural science perspective. 2.1 Theory: Landscape Modelling 2.2 Case Study: Oil Exploration and Rare Plant Conservation 2.3 Theory: Landscape Metrics 2.4 Case Study: The Impacts of Transport Infrastructure in Iran on Wildlife Habitat2.5 Theory: Remote Sensing 2.6 Case Study: Urbanisation in the MaldivesUnit 3 Landscape and SocietyThis unit focuses on the socio-economic aspects of landscape science and the interface between people and the environment. 3.1 Theory: Landscape Perception 3.2 Case study: Renewable Energy and Landscape Conflicts 3.3 Case Study: Soundscape Ecology3.4 Theory: Ecosystem Services and Valuation 3.5 Case study: Land Ethics 3.6 Theory: Urban Ecology 3.7 Case study: Urban Ecology in Bangalore",Landscape Ecology
https://www.classcentral.com/course/edx-high-performance-computing-for-reproducible-genomics-2973,"If you’re interested in data analysis and interpretation, then this is the data science course for you.
Enhanced throughput: Almost all recently manufactured laptops and desktops include multiple core CPUs. With R, it is very easy to obtain faster turnaround times for analyses by distributing tasks among the cores for concurrent execution. We will discuss how to use Bioconductor to simplify parallel computing for efficient, fault-tolerant, and reproducible high-performance analyses. This will be illustrated with common multicore architectures and Amazon’s EC2 infrastructure.  
Enhanced interactivity: New approaches to programming with R and Bioconductor allow researchers to use the web browser as a highly dynamic interface for data interrogation and visualization. We will discuss how to create interactive reports that enable us to move beyond static tables and one-off graphics so that our analysis outputs can be transformed and explored in real time.
Enhanced reproducibility: New methods of virtualization of software environments, exemplified by the Docker ecosystem, are useful for achieving reproducible distributed analyses. The Docker Hub includes a considerable number of container images useful for important Bioconductor-based workflows, and we will illustrate how to use and extend these for sharable and reproducible analysis.
Given the diversity in educational background of our students we have divided the series into seven parts. You can take the entire series or individual courses that interest you. If you are a statistician you should consider skipping the first two or three courses, similarly, if you are biologists you should consider skipping some of the introductory biology lectures. Note that the statistics and programming aspects of the class ramp up in difficulty relatively quickly across the first three courses. By the third course will be teaching advanced statistical concepts such as hierarchical models and by the fourth advanced software engineering skills, such as parallel computing and reproducible research concepts.
These courses make up 2 XSeries and are self-paced:
PH525.1x: Statistics and R for the Life Sciences
PH525.2x: Introduction to Linear Models and Matrix Algebra
PH525.3x: Statistical Inference and Modeling for High-throughput Experiments
PH525.4x: High-Dimensional Data Analysis
PH525.5x: Introduction to Bioconductor: annotation and analysis of genomes and genomic assays 
PH525.6x: High-performance computing for reproducible genomics
PH525.7x: Case studies in functional genomics
This class was supported in part by NIH grant R25GM114818.
HarvardX requires individuals who enroll in its courses on edX to abide by the terms of the edX honor code. HarvardX will take appropriate corrective action in response to violations of the edX honor code, which may include dismissal from the HarvardX course; revocation of any certificates received for the HarvardX course; or other remedies as circumstances warrant. No refunds will be issued in the case of corrective action for such violations. Enrollees who are taking HarvardX courses as part of another program will also be governed by the academic policies of those programs.
HarvardX pursues the science of learning. By registering as an online learner in an HX course, you will also participate in research about learning. Read our research statement to learn more.
Harvard University and HarvardX are committed to maintaining a safe and healthy educational and work environment in which no member of the community is excluded from participation in, denied the benefits of, or subjected to discrimination or harassment in our program. All members of the HarvardX community are expected to abide by Harvard policies on nondiscrimination, including sexual harassment, and the edX Terms of Service. If you have any questions or concerns, please contact harvardx@harvard.edu and/or report your experience through the edX contact form.



            Read more",High-performance Computing for Reproducible Genomics
https://www.classcentral.com/course/company-valuation-8826,"This course is a theoretically sound and practical exposure to valuation. As the final course of the Specialization, it will be useful to anyone in executing or critically evaluating company analyses conducted by experts. We have put together everything you have learned in the first three courses, modified frameworks and first applied them to carefully crafted real world situations (or mini-cases), and then presented you with a capstone project to value one of the most well-known companies of the past three decades. This Capstone Project will make you appreciate how finance is both a science and an art form.
      


Overview of Specialization & CourseThis module contains detailed videos and syllabi of both the Specialization and this course. This specialization has been designed to enable you to learn and apply the powerful tools of modern finance to both personal and professional situations. The courses within progress linearly and build on each other and it is important for you to get an understanding of why this specialization may be relevant to your goals, again both personal and professional. Please review the videos and syllabi as they will give you a sense of the specialization and how this specific course fits within. The teaching style and philosophy of the instructors is also presented to you (hopefully) in sufficient detail. Most importantly, it will give you enough information for you to make a decision about whether you want to take this course, by itself or as part of a specialization.Module 1The first module of this course will modify the frameworks introduced in the entire specialization to value companies, where a company is essentially a complex collection of “projects.” We will tackle the difficult but critical first step of identifying a comparable company and analyzing it. A complete valuation framework needed to value a company will follow this analysis. Module 2Module 2 contains a mega example of valuation showcasing the application of alternative methods and preparing you for the Capstone Project at the end of this course and for the real world beyond. The first two modules will enable learners to test their understanding of advanced valuation techniques in two ways: (a) through a set of final exams that capture the key elements of valuation and (b) a Capstone Project that involves the valuation of a real-world company using real data. Module 3This module/week will be spent on a short wrap up video of the course and time for assimilation and review by learners to take the final exams. In the past, learners have really valued this time and hence it is built into this new structure/platform as well. Please note there are two finals that cover materials of Modules 1 & 2, and you need to attempt both.Module 4This module contains the first part of a multi-part Capstone Project designed with the specific purpose of showcasing both the science and the art of financial analysis. It is the natural end to a Specialization that begins with the building blocks of finance, is followed by a modification of the framework to incorporate the complexity of regulations and the tax code, and ends with a capstone-like experience in the last course with rich applications to complex projects and companies. The Capstone Project is therefore a natural end to the Specialization and will involve a detailed valuation analysis of a real company. You are strongly encouraged to spend a lot of time on this project, researching on the web and trying to put together everything you have learned. All the questions you are required to answer as part of this project, though machine-graded, provide you an opportunity to learn about businesses and the critical relation between that understanding and the art and science of valuation.Module 5This module contains the second part of a multi-part Capstone Project designed with the specific purpose of showcasing both the science and the art of financial analysis. It is the natural end to a Specialization that begins with the building blocks of finance, is followed by a modification of the framework to incorporate the complexity of regulations and the tax code, and ends with a capstone-like experience in the last course with rich applications to complex projects and companies. The Capstone Project is therefore a natural end to the Specialization and will involve a detailed valuation analysis of a real company. You are strongly encouraged to spend a lot of time on this project, researching on the web and trying to put together everything you have learned. All the questions you are required to answer as part of this project, though machine-graded, provide you an opportunity to learn about businesses and the critical relation between that understanding and the art and science of valuation.Module 6This module contains the third part of a multi-part Capstone Project designed with the specific purpose of showcasing both the science and the art of financial analysis. It is the natural end to a Specialization that begins with the building blocks of finance, is followed by a modification of the framework to incorporate the complexity of regulations and the tax code, and ends with a capstone-like experience in the last course with rich applications to complex projects and companies. The Capstone Project is therefore a natural end to the Specialization and will involve a detailed valuation analysis of a real company. You are strongly encouraged to spend a lot of time on this project, researching on the web and trying to put together everything you have learned. All the questions you are required to answer as part of this project, though machine-graded, provide you an opportunity to learn about businesses and the critical relation between that understanding and the art and science of valuation.",Valuing Companies
https://www.classcentral.com/course/harvardx-computer-science-and-mobile-apps-18457,"Whether it’s finding a good spot for lunch, posting a photo of that lunch on Instagram, or just getting some work done while on the go, mobile apps have become deeply ingrained in how we live, work, and play. Smartphones have become ubiquitous and the potential to make a dramatic impact on the everyday lives of millions of people has never been greater — but where do you start? How do you go from being a user to a skilled creator? What do you need to know and how do you learn it all?
The CS50 courses at Harvard have taught the art of programming to computer science majors and non-majors alike, to those with serious coding chops and those with no prior computer programming experience. Led by Professor David J. Malan, this program teaches learners how to think algorithmically and solve problems efficiently. The core Introduction to Computer Science course will give you a broad and robust understanding of the fundamentals of programming and computer systems. Then you’ll build on those fundamentals to learn about mobile app development using the React Native Framework.
With problem sets inspired by cryptography, finance, forensics, and gaming, you’ll become familiar with a variety of programming languages, then you’ll build expertise in modern JavaScript and learn the paradigms, app architecture, and user interfaces of JSX (a JavaScript extension) and React Native. The course culminates in a final project for which you'll implement an app entirely of your own design.



            Read more
          



Courses under this program:Course 1: CS50's Introduction to Computer ScienceAn introduction to the intellectual enterprises of computer science and the art of programming.Course 2: CS50's Mobile App Development with React Native
Learn about mobile app development with React Native, a popular framework maintained by Facebook that enables cross-platform native apps using JavaScript without Java or Swift.",Computer Science and Mobile Apps
https://www.classcentral.com/course/harvardx-computer-science-for-artifical-intellige-18468,"The demand for expertise in AI and machine learning is growing rapidly. By enabling new technologies like self-driving cars and recommendation systems or improving old ones like medical diagnostics and search engines, AI is transforming how we live, work, and play. This series will enable you to take the first steps toward understanding programming fundamentals so you can solve important real-world problems and future-proof your career.
This professional certificate series combines CS50’s legendary Introduction to Computer Science course with a new program that takes a deep dive into the concepts and algorithms at the foundation of modern artificial intelligence. This series will lead you through the most popular undergraduate course at Harvard, where you’ll learn the common programming languages, then carries that foundation through CS50’s Introduction to Artificial Intelligence with Python. Through hands-on projects, you’ll gain exposure to the theory behind graph search algorithms, classification, optimization, reinforcement learning, and other topics in artificial intelligence.
By course’s end, students emerge with experience in libraries for machine learning as well as knowledge of artificial intelligence principles that enable them to design intelligent systems of their own. Enroll now to gain expertise in one of the fastest-growing domains of computer science from the creators of one of the most popular computer science courses ever.



            Read more
          



Courses under this program:Course 1: CS50's Introduction to Computer ScienceAn introduction to the intellectual enterprises of computer science and the art of programming.Course 2: CS50's Introduction to Artificial Intelligence with Python
Learn to use machine learning in Python in this introductory course on artificial intelligence.",Computer Science for Artificial Intelligence
https://www.classcentral.com/course/independent-data-visualization-for-storytelling-and-discovery-11702,"Welcome to the Knight Center's new MOOC Data Visualization for Storytelling and Discovery! In this course, you will learn about how to use graphs, maps, charts, diagrams to extract meaning from large amounts of data and how to use data visualization to tell stories to different kinds of audiences.
 



Module 1: INTRODUCTION TO VISUALIZATION PRINCIPLES
GOALS:
This week will offer an introduction to visualization, what it is, how it works, and what ethical considerations are involved in its design. It will also teach how to prepare data before visualizing it, which is something that students will begin doing in Module 2.
Module 1 will cover:

What data visualization is
Visualization ethics: How visualization may mislead, and how it can tell the truth
Data preparation: an explanation of the software videos this week
Will include a Data Wrangler tutorial, along with a few external tutorials that will be useful to students who need to learn more about Excel: “Cleaning Data in Excel,” “Introduction to Pivot Tables, Charts, and Dashboards in Excel (Part 1)” and “Introduction to Pivot Tables, Charts, and Dashboards (Part 2)”.

 
Module 2: VISUALIZATION TO FIND STORIES IN DATA
GOALS:
This week will cover how visualization can be used to explore and discover features that often hide behind data. Students will use software tools that will allow them to import a data set and then visualize it in multiple ways to reveal patterns and exceptions to those patterns.
Module 2 will cover:

INZight for data exploration
Schools in Miami-Dade County
Using histograms and seeing summary statistics
Scatter plots. Trends and outliers
Using maps

 
Module 3: VISUALIZATION FOR COMMUNICATION
GOALS:
This week will explain how visualization can be used to communicate with the public. Students will be introduced to/will learn to use Flourish to design static and interactive maps and charts, and then put them together in sequential narratives.
Module 3 will cover:

How to choose graphic forms for your data
Stories with charts and maps
Visual design for communication
Software tools: an introduction to this week’s practical videos
Will include videos on how to use Flourish for data visualization

 
Module 4: WHERE TO GO FROM HERE
GOALS:
Students will design a visualization based on a topic and data sets of their choice.
Module 4 will cover:

A look at what students have learned in this course and what other resources they can consult to keep learning about visualization. Students will share results in the discussion forum.
A wrap-up that looks at the future of data visualization, as well as pointers for students to consider moving forward.",Data Visualization for Storytelling and Discovery
https://www.classcentral.com/course/edx-implementing-predictive-analytics-with-spark-in-azure-hdinsight-4151,"Are you ready for big data science? In this course, learn how to implement predictive analytics solutions for big data using Apache Spark in Microsoft Azure HDInsight. See how to work with Scala or Python to cleanse and transform data and build machine learning models with Spark ML (the machine learning library in Spark).
Note: To complete the hands-on elements in this course, you will require an Azure subscription and a Windows client computer. You can sign up for a free Azure trial subscription (a valid credit card is required for verification, but you will not be charged for Azure services). Note that the free trial is not available in all regions.edX offers financial assistance for learners who want to earn Verified Certificates but who may not be able to pay the fee. To apply for financial assistance, enroll in the course, then follow this link to complete an application for assistance.



Introduction to Data Science with Spark  Get started with Spark clusters in Azure HDInsight, and use Spark to run Python or Scala code to work with data.Getting Started with Machine Learning Learn how to build classification and regression models using the Spark ML library.Evaluating Machine Learning Models  Learn how to evaluate supervised learning models, and how to optimize model parameters.Recommenders and Unsupervised Models  Learn how to build recommenders and clustering models using Spark ML.",Implementing Predictive Analytics with Spark in Azure HDInsight
https://www.classcentral.com/course/independent-statistical-computing-with-r-a-gentle-introduction-4545,"R is an open source software environment for statistical computing that is rapidly becoming the tool of choice for data analysis in the life sciences and elsewhere. It is developed by a large international community of scientists and programmers and is at the forefront of new developments in statistical computing. Additionally, R is the foundation of Bioconductor, a similar open-source project focussed on the development of bioinformatics analysis tools. Bioconductor rose to prominence when it became the standard environment for the analysis of microarray gene expression data, but it has maintained and extended this position with the advent of new technologies and the integration with different types of ‘omics data. As such, understanding its basic functionality is of benefit to undergraduates, graduates and researchers across diverse fields.
This short course provides a gentle introduction to the R software and programming environment. It should take you approximately 6-8 hours in total to work through the material. There are five sections: Introduction and basics, Variables and data types, Inbuilt functions, Data frames, Plotting. Materials are taught through pdf documents and videos, with quizzes and assignments provided to test your knowledge. Upon completion of the course you will understand how to manipulate data within R, perform basic data analysis procedures and create plots. This course provides a foundation for more advanced topics and techniques.
 



            Read more",Statistical Computing with R - a gentle introduction
https://www.classcentral.com/course/edx-programming-for-data-science-8162,"There is a rising demand for people with the skills to work with Big Data sets and this course can start you on your journey through our Big Data MicroMasters program towards a recognised credential in this highly competitive area.
Using practical activities and our innovative ProcessingJS Workspace application you will learn how digital technologies work and will develop your coding skills through engaging and collaborative assignments.
You will learn algorithm design as well as fundamental programming concepts such as data selection, iteration and functional decomposition, data abstraction and organisation. In addition to this you will learn how to perform simple data visualisations using ProcessingJS and embed your learning using problem-based assignments.
This course will test your knowledge and skills in solving small-scale data science problems working with real-world datasets and develop your understanding of big data in the world around you.



Section 1: Creative code - Computational thinking
Understanding what you can do with ProcessingJS and apply the basics to start coding with colour; Learn how to qualify and express how algorithms work. 
Section 2: Building blocks - Breaking it down and building it up
Understand how data can be represented and used as variables and learn to manipulate shape attributes and work with weights and shapes using code. 
Section 3: Repetition - Creating and recognising patterns
Explain how and why using repetiton can aid in creating code and begin using repetition to manipulate and visualise data. 
Section 4: Choice - Which path to follow
How to create simple and complicated choices and how to create and use decision points in code. 
Section 5: Repetition - Going further
Discussing advantages of repetition for data visualisation and applying and reflecting on the power of repetitions in code. Creating curves, shapes and scale data in code. 
Section 6: Testing and Debugging
Understanding why and how to comprehensively test your code and debug code examples using line tracing techniques. 
Section 7: Arranging our data
Exploring how and why arrays are used to represent data and how static and dynamic arrays can be used to represent data. 
Section 8: Functions - Reusable code
Understand how functions work in ProcessingJS and demonstate how to deconstruct a problem into useable functions. 
Section 9: Data Science in practice
Exploring how data science is used to solve programming problems and how to solve big data problems by applying skills and knowledge learned throughout the course. 
Section 10: Where next?
Understand the context of big data in programming and transform a problem description into a complete working solution using the skills and knowledge you've learned throughout the course, and explore how you can expand the skills learned in this course by participating in future courses.",Programming for Data Science
https://www.classcentral.com/course/ibm-ai-workflow-business-priorities-data-ingestio-17095,"This is the first course of a six part specialization.  You are STRONGLY encouraged to complete these courses in order as they are not individual independent courses, but part of a workflow where each course builds on the previous ones.

This first course in the IBM AI Enterprise Workflow Certification specialization introduces you to the scope of the specialization and prerequisites.  Specifically, the courses in this specialization are meant for practicing data scientists who are knowledgeable about probability, statistics, linear algebra, and Python tooling for data science and machine learning.  A hypothetical streaming media company will be introduced as your new client.  You will be introduced to the concept of design thinking, IBMs framework for organizing large enterprise AI projects.  You will also be introduced to the basics of scientific thinking, because the quality that distinguishes a seasoned data scientist from a beginner is creative, scientific thinking.  Finally you will start your work for the hypothetical media company by understanding the data they have, and by building a data ingestion pipeline using Python and Jupyter notebooks.
 
By the end of this course you should be able to:
1.  Know the advantages of carrying out data science using a structured process
2.  Describe how the stages of design thinking correspond to the AI enterprise workflow
3.  Discuss several strategies used to prioritize business opportunities
4.  Explain where data science and data engineering have the most overlap in the AI workflow
5.  Explain the purpose of testing in data ingestion 
6.  Describe the use case for sparse matrices as a target destination for data ingestion 
7.  Know the initial steps that can be taken towards automation of data ingestion pipelines
 
Who should take this course?
This course targets existing data science practitioners that have expertise building machine learning models, who want to deepen their skills on building and deploying AI in large enterprises. If you are an aspiring Data Scientist, this course is NOT for you as you need real world expertise to benefit from the content of these courses.
 
What skills should you have?
It is assumed you have a solid understanding of the following topics prior to starting this course: Fundamental understanding of Linear Algebra; Understand sampling, probability theory, and probability distributions; Knowledge of descriptive and inferential statistical concepts; General understanding of machine learning techniques and best practices; Practiced understanding of Python and the packages commonly used in data science: NumPy, Pandas, matplotlib, scikit-learn; Familiarity with IBM Watson Studio; Familiarity with the design thinking process.
      


            Read more
          



          IBM AI Enterprise Workflow Introduction
    -The goal of this first module is to introduce you to the overall specialization requirements, evaluate your understanding of some key prerequisite knowledge, and become familiar with several process models being used today.  In this course we will use the process of design thinking, but it is the consistent application of a process in practice that is important, not the exact process itself. There are a number of reasons for choosing the design thinking process, but the most important is that it is being applied in a cross-disciplinary way—that is outside of data science.

Data Collection
    -Throughout this module you will learn or reinforce what you already know about identifying and articulating business opportunities. In this module you will learn the importance of applying a scientific thought process to the task of understanding the business use case. This process has many similarities to that of being an investigator. You will also generate a healthy respect for the need to pause, step back and think scientifically about the main processes in this stage.

Data Ingestion
    -Cleaning, parsing, assembling and gut-checking data is among the most time-consuming tasks that a data scientist has to perform. The time spent on data cleaning can start at 60% and increase depending on data quality and the project requirements. This module looks at the process of ingesting data and presents a case study working a real world scenario.",AI Workflow: Business Priorities and Data Ingestion
https://www.classcentral.com/course/thaimooc------introduction-to-computer-information-science-15240,"คำอธิบายรายวิชา
ความรู้พื้นฐานทางด้านความรู้และทักษะทางด้านเทคโนโลยีคอมพิวเตอร์ องค์ประกอบของระบบคอมพิวเตอร์ ฮาร์ดแวร์ ซอฟต์แวร์ วิธีการทำงานของคอมพิวเตอร์ การจัดการข้อมูล พื้นฐานระบบเครือข่าย อินเทอร์เน็ต โปรแกรมสำนักงานอัตโนมัติ กฏหมายจริยธรรมพื้นฐานที่เกี่ยวข้องกับคอมพิวเตอร์และเทคโนโลยีสารสนเทศ",คอมพิวเตอร์สารสนเทศขั้นพื้นฐาน (Introduction to Computer Information science)
https://www.classcentral.com/course/code-free-data-science-13380,"The Code Free Data Science class is designed for learners seeking to gain or expand their knowledge in the area of Data Science.  Participants will receive the basic training in effective predictive analytic approaches accompanying the growing discipline of Data Science without any programming requirements.  Machine Learning methods will be presented by utilizing the KNIME Analytics Platform to discover patterns and relationships in data. Predicting future trends and behaviors allows for proactive, data-driven decisions.  During the class learners will acquire new skills to apply predictive algorithms to real data, evaluate, validate and interpret the results without any pre requisites for any kind of programming.  Participants will gain the essential skills to design, build, verify and test predictive models.  
You Will Learn
•	How to design Data Science workflows without any programming involved
•	Essential Data Science skills to design, build, test and evaluate predictive models
•	Data Manipulation, preparation and Classification and clustering methods
•	Ways to apply Data Science algorithms to real data and evaluate and interpret the results
      


          Welcome to the world of Big Data
    -Welcome to the first module of the Code Free Data Science course. This first module will provide insight into Big Data Hype, its technologies opportunities and challenges.  We will take a deeper look into the Big Data Analytics  and methodology associated with Data Science approaches.

Introduction to KNIME Analytics Platform
    -This module will introduce the KNIME analytics platform.  Learners will be guided to download, install and setup KNIME.  We will explore and become familiar with the KNIME workflow editor and its components.  In this module we will create the very first basic workflow, and explore the kinds of analysis KNIME empowers users to perform.

Data Manipulation and Visualization

Machine Learning",Code Free Data Science
https://www.classcentral.com/course/udacity-big-data-analytics-in-healthcare-1027,"Data science plays an important role in many industries. In facing massive amount of heterogeneous data, scalable machine learning and data mining algorithms and systems become extremely important for data scientists. The growth of volume, complexity and speed in data drives the need for scalable data analytic algorithms and systems. In this course, we study such algorithms and systems in the context of healthcare applications.In healthcare, large amounts of heterogeneous medical data have become available in various healthcare organizations (payers, providers, pharmaceuticals). This data could be an enabling resource for deriving insights for improving care delivery and reducing waste. The enormity and complexity of these datasets present great challenges in analyses and subsequent applications to a practical clinical environment.Why Take This Course?In this course, we introduce the characteristics of medical data and associated data mining challenges on dealing with such data. We cover various algorithms and systems for big data analytics. We focus on studying those big data techniques in the context of concrete healthcare analytic applications such as predictive modeling, computational phenotyping and patient similarity. We also study big data analytic technology:Scalable machine learning algorithms such as online learning and fast similarity search;Big data analytic system such as Hadoop family (Hive, Pig, HBase), Spark and Graph DB



            Read more
          



Big DataPredictive ModelingDimensionality Reduction & Tensor FactorizationGraph AnalysisHealthcareComputational PhenotypingPatient Similarity MetricsMedical OntologyTechnologiesMapReduceSparkHadoop",Big Data Analytics in Healthcare
https://www.classcentral.com/course/edx-probability-distribution-models-continuous-random-variables-6990,"In this statistics and data analysis course, you will learn about continuous random variables and some of the most frequently used probability distribution models including, exponential distribution, Gamma distribution, Beta distribution, and most importantly, normal distribution.
You will learn how these distributions can be connected with the Normal distribution by Central limit theorem (CLT). We will discuss Markov and Chebyshev inequalities, order statistics, moment generating functions and transformation of random variables.
This course along with the recommended pre-requisite,Probability: Basic Concepts & Discrete Random Variables,will you give the skills and knowledge to progress towards an exciting career in information and data science.

The Center for Science of Information, a National Science Foundation Center, supports learners by offering free educational resources in information science.



Units 1 - 6 are available in ""416.1x Probability: Basic Concepts & Discrete Random Variables"" Unit 7: Continuous Random Variables In this unit, we start from the instruction of continuous random variables, then discuss the joint density/CDF and properties of independent continuous random variables. Unit 8: Conditional Distributions and Expected Values Conditional distributions for continuous random variables, expected values of continuous random variables, and expected values of functions of random variables. Unit 9: Models of Continuous Random Variables In this unit we will discuss four common distribution models of continuous random variables: Uniform, Exponential, Gamma and Beta distributions. Unit 10: Normal Distribution and Central Limit Theorem (CLT) Introduction to Normal distribution and CLT, as well as examples of how CLT can be used to approximate models of continuous uniform, Gamma, Binomial, Bernoulli and Poisson. Unit 11: Covariance, Conditional Expectation, Markov and Chebychev Inequalities Unit 12: Order Statistics, Moment Generating Functions, Transformation of RVs",Probability: Distribution Models & Continuous Random Variables
https://www.classcentral.com/course/edx-programming-in-r-for-data-science-6038,"This course is part of the Microsoft Professional Program Certificate in Data Science.
In this computer science course from Microsoft, developed in collaboration with the Technical University of Denmark (DTU), get the knowledge and skills you need to use R, the statistical programming language for data scientists, in the field of your choice.
In this course you will learn all you need to get up to speed with programming in R. Explore R data structures and syntaxes, see how to read and write data from a local file to a cloud-hosted database, work with data, get summaries, and transform them to fit your needs. Plus, find out how to perform predictive analytics using R and how to create visualizations using the popular ggplot2 package.



Section 1: IntroductionSection 2: FunctionsSection 3: Control flow and LoopsSection 4: Working with Vectors and MatricesSection 5: Reading in DataSection 6: Writing DataSection 7: Reading from SQL ServerSection 8: Working with DataSection 9: Manipulating DataSection 10: SimulationSection 11: Linear modelSection 12: Graphics in R",Programming in R for Data Science
https://www.classcentral.com/course/cryptography-11655,"Investigate the security of encrypted data
Is it possible to prove the security of encrypted data? Will every algorithm fail given sufficient time or computing power?
On this course you will get an introduction to cryptography and cryptanalysis. From ancient examples of secret messages and the spies that cracked them to modern cryptographic applications, you will have the opportunity to explore the foundations of data security.
During the course you will also get an opportunity to try encrypting data yourself by completing a cryptography and cryptanalysis challenge.
The Institute of Coding supported the development of this course in response to consultation with industry representatives from the healthcare, manufacturing and automotive sectors.
This course is for people who want to understand more about the way cryptography keeps our communications safe, either out of curiosity or to prepare for advanced study of the topic.
Please note that the individuals detailed in the ‘Who will you learn with?’ section below, are current staff members and may be subject to change.",An Introduction to Cryptography
https://www.classcentral.com/course/swayam-human-behaviour-12977,"We as intelligent beings have always wondered why we do what we do. The most interesting knowledge that humans beings would kill to possess would be the knowledge to control other people. The basic premise of being human is individual difference (we are all different). One science that helps people in understanding other people and scientifically predicting their actions is the science of psychology. In the present course, I will make an attempt to simplify the science of human behavior.INTENDED AUDIENCE :UG/PG/PhDPREREQUISITES :NILINDUSTRY SUPPORT :NIL 
      


COURSE LAYOUT Week 1: Introduction to the science of human behaviorWeek 2: Sensation & Perception-IWeek 3: Perception-II, LearningWeek 4: Memory and Language-IWeek 5: Language-II and EmotionWeek 6: IntelligenceWeek 7: PersonalityWeek 8: Social influence and cognition",Human Behaviour
https://www.classcentral.com/course/discrete-mathematics-18726,"Discrete Math is needed to see mathematical structures in the object you work with, and understand their properties. This ability is important for software engineers, data scientists, security and financial analysts (it is not a coincidence that math puzzles are often used for interviews). We cover the basic notions and results (combinatorics, graphs, probability, number theory) that are universally needed. To deliver techniques and ideas in discrete mathematics to the learner we extensively use interactive puzzles specially created for this specialization. To bring the learners experience closer to IT-applications we incorporate programming examples, problems and projects in our courses.



          Course 1: Mathematical Thinking in Computer Science- Mathematical thinking is crucial in all areas of computer science: algorithms, bioinformatics, computer graphics, data science, machine learning, etc. In this course, we will learn the most important tools used in discrete mathematics: induction, recursion, logic, invariants, examples, optimality. We will use these tools to answer typical programming questions like: How can we be certain a solution exists? Am I sure my program computes the optimal answer? Do each of these objects meet the given requirements? In the course, we use a try-this-before-we-explain-everything approach: you will be solving many interactive (and mobile friendly) puzzles that were carefully designed to allow you to invent many of the important ideas and concepts yourself. Prerequisites: 1. We assume only basic math (e.g., we expect you to know what is a square or how to add fractions), common sense and curiosity. 2. Basic programming knowledge is necessary as some quizzes require programming in Python. Do you have technical problems? Write to us: coursera@hse.ruCourse 2: Combinatorics and Probability- Counting is one of the basic mathematically related tasks we encounter on a day to day basis. The main question here is the following. If we need to count something, can we do anything better than just counting all objects one by one? Do we need to create a list of all phone numbers to ensure that there are enough phone numbers for everyone? Is there a way to tell that our algorithm will run in a reasonable time before implementing and actually running it? All these questions are addressed by a mathematical field called Combinatorics. In this course we discuss most standard combinatorial settings that can help to answer questions of this type. We will especially concentrate on developing the ability to distinguish these settings in real life and algorithmic problems. This will help the learner to actually implement new knowledge. Apart from that we will discuss recursive technique for counting that is important for algorithmic implementations. One of the main `consumers’ of Combinatorics is Probability Theory. This area is connected with numerous sides of life, on one hand being an important concept in everyday life and on the other hand being an indispensable tool in such modern and important fields as Statistics and Machine Learning. In this course we will concentrate on providing the working knowledge of basics of probability and a good intuition in this area. The practice shows that such an intuition is not easy to develop. In the end of the course we will create a program that successfully plays a tricky and very counterintuitive dice game. As prerequisites we assume only basic math (e.g., we expect you to know what is a square or how to add fractions), basic programming in python (functions, loops, recursion), common sense and curiosity. Our intended audience are all people that work or plan to work in IT, starting from motivated high school students. Do you have technical problems? Write to us: coursera@hse.ruCourse 3: Introduction to Graph Theory- We invite you to a fascinating journey into Graph Theory — an area which connects the elegance of painting and the rigor of mathematics; is simple, but not unsophisticated. Graph Theory gives us, both an easy way to pictorially represent many major mathematical results, and insights into the deep theories behind them. In this course, among other intriguing applications, we will see how GPS systems find shortest routes, how engineers design integrated circuits, how biologists assemble genomes, why a political map can always be colored using a few colors. We will study Ramsey Theory which proves that in a large system, complete disorder is impossible! By the end of the course, we will implement an algorithm which finds an optimal assignment of students to schools. This algorithm, developed by David Gale and Lloyd S. Shapley, was later recognized by the conferral of Nobel Prize in Economics. As prerequisites we assume only basic math (e.g., we expect you to know what is a square or how to add fractions), basic programming in python (functions, loops, recursion), common sense and curiosity. Our intended audience are all people that work or plan to work in IT, starting from motivated high school students. Do you have technical problems? Write to us: coursera@hse.ruCourse 4: Number Theory and Cryptography- We all learn numbers from the childhood. Some of us like to count, others hate it, but any person uses numbers everyday to buy things, pay for services, estimated time and necessary resources. People have been wondering about numbers’ properties for thousands of years. And for thousands of years it was more or less just a game that was only interesting for pure mathematicians. Famous 20th century mathematician G.H. Hardy once said “The Theory of Numbers has always been regarded as one of the most obviously useless branches of Pure Mathematics”. Just 30 years after his death, an algorithm for encryption of secret messages was developed using achievements of number theory. It was called RSA after the names of its authors, and its implementation is probably the most frequently used computer program in the word nowadays. Without it, nobody would be able to make secure payments over the internet, or even log in securely to e-mail and other personal services. In this short course, we will make the whole journey from the foundation to RSA in 4 weeks. By the end, you will be able to apply the basics of the number theory to encrypt and decrypt messages, and to break the code if one applies RSA carelessly. You will even pass a cryptographic quest! As prerequisites we assume only basic math (e.g., we expect you to know what is a square or how to add fractions), basic programming in python (functions, loops, recursion), common sense and curiosity. Our intended audience are all people that work or plan to work in IT, starting from motivated high school students. Do you have technical problems? Write to us: coursera@hse.ruCourse 5: Delivery Problem- We’ll implement (in Python) together efficient programs for a problem needed by delivery companies all over the world millions times per day — the travelling salesman problem. The goal in this problem is to visit all the given places as quickly as possible. How to find an optimal solution to this problem quickly? We still don’t have provably efficient algorithms for this difficult computational problem and this is the essence of the P versus NP problem, the most important open question in Computer Science. Still, we’ll implement several solutions for real world instances of the travelling salesman problem. While designing these solutions, we will rely heavily on the material learned in the courses of the specialization: proof techniques, combinatorics, probability, graph theory. We’ll see several examples of using discrete mathematics ideas to get more and more efficient solutions. Do you have technical problems? Write to us: coursera@hse.ru",Introduction to Discrete Mathematics for Computer Science
https://www.classcentral.com/course/applying-data-analytics-business-in-mark-16865,"This course introduces students to the science of business analytics while casting a keen eye toward the artful use of numbers found in the digital space. The goal is to provide businesses and managers with the foundation needed to apply data analytics to real-world challenges they confront daily in their professional lives. Students will learn to identify the ideal analytic tool for their specific needs; understand valid and reliable ways to collect, analyze, and visualize data; and utilize data in decision making for their agencies, organizations or clients.
      


          Course Introduction
    -With the first module, we will measure and identify satisfied customers to adjust product or service accordingly. To measure the customer satisfaction we will measure expectations, performance and disconfirmation of the offered product or service. We will also provide an overview of marketing analytics used to gauge the effectiveness of different marketing activities. Finally, we will go through measurement and scaling techniques.

Module 2
    -We will explore the marketing world through process of A/B testing, design of experiments, data analysis, and hypothesis testing. Next, we study Analysis of Variance (ANOVA) which is used to determine significant differences between two or more categorical groups. We will study ANOVA’s assumptions, test inference and different types of ANOVA. We also spend some time in designing experiments.

Module 3
    -We will learn about the Binary Outcome model using Logit function. The Logistic regression is sued when the dependent variable has a binary outcome. Next, we cover Multidimensional Scaling (MDS). MDS is used in marketing to understand the pair-wise similarity of the individual cases of data-set.  This technique maps the individual cases onto a 2-dimensional Cartesian graph for visual analysis.

Module 4
    -We will learn about Conjoint Analysis to understand how individuals combine and weigh different attributes.  We will introduce the concept of conjoint analysis and part-worth utilities.  We will survey different approaches before focusing our attention to the classical conjoint analysis. We will reinforce our understanding by studying an example in detail before running examples of the analysis in R",Applying Data Analytics in Marketing
https://www.classcentral.com/course/big-data-language-1-19191,"In this course, students will understand characteristics of language through big data. Students will learn how to collect and analyze big data, and find linguistic features from the data. A number of approaches to the linguistic analysis of written and spoken texts will be discussed.
The class will consist of lecture videos which are approximately 1 hour and a quiz for each week. There will be a final project which requires students to conduct research on text data and language.
      


          Introduction to Big Data and Language

Spoken and Written Data

Corpus and Register

Parts of Speech",Big data and Language 1
https://www.classcentral.com/course/edx-sustainable-energy-design-a-renewable-future-6570,"A transition to sustainable energy is needed for our climate and welfare. In this engineering course, you will learn how to assess the potential for energy reduction and the potential of renewable energy sources like wind, solar and biomass. You’ll learn how to integrate these sources in an energy system, like an electricity network and take an engineering approach to look for solutions and design a 100% sustainable energy system.
This course is an introduction to the Master Programme Sustainable Energy Technology at TU Delft and is aimed at Bachelor students from science and engineering disciplines.



Week 1: Definition of Energy UseThe use of energy in transport, building and manufacturing. Week 2: Generation of Renewable EnergyHow much can you generate from all the different sources? Week 3: Energy BalancesHow can you analyse energy and what are the climate effects? Week 4: Policies for Sustainable EnergyHow to stimulate the use of renewable energy and energy efficiency? Week 5: Wind EnergyTechnologies to generate energy from wind Week 6: Solar EnergyTechnologies to generate Energy with photovoltaic systems Week 7: BiomassTechnologies to generate energy from biomass Week 8: Electrical Power SystemHow to integrate renewable energy in de Electrical Power System Week 9: StorageHow to store energy?",Sustainable Energy: Design a Renewable Future
https://www.classcentral.com/course/edx-big-data-analytics-in-healthcare-9045,"Data science plays an important role in many industries. In facing massive amounts of heterogeneous data, scalable machine learning and data mining algorithms and systems have become extremely important for data scientists. The growth of volume, complexity and speed in data drives the need for scalable data analytic algorithms and systems.
In this course, we study such algorithms and systems in the context of healthcare applications.
In healthcare, large amounts of heterogeneous medical data have become available in various healthcare organizations (payers, providers, pharmaceuticals). This data could be an enabling resource for deriving insights for improving care delivery and reducing waste. The enormity and complexity of these datasets present great challenges in analyses and subsequent applications to a practical clinical environment.
In this course, we introduce the characteristics of medical data and associated data mining challenges in dealing with such data. We cover various algorithms and systems for big data analytics. We focus on studying those big data techniques in the context of concrete healthcare analytic applications such as predictive modeling, computational phenotyping and patient similarity.



          Week 1: Intro to Big Data Analytics/Course Overview Week 2: Predictive Modeling Week 3: MapReduce Week 4/5: Classification evaluation metrics/ Classification ensemble methods/ Phenotyping & Clustering Week 6: Spark Week 7: Medical ontology Week 8: Graph analysis Week 9: Dimensionality Reduction Week 10: Patient similairty Week 11: AWS Week 12: AZURE Week 13: Peer Review for Draft Week 14: Final Project (code+presentation+ final paper) Week 15: Final Exam Week",Big Data Analytics in Healthcare
https://www.classcentral.com/course/edx-responsive-cities-8938,"Responsive cities define the future of urbanization. They evolve from smart cities, with a fundamental difference: The citizens move from the center of attention to the center of action. Responsive citizens use smart technology to contribute to planning, design and management of their cities.
Responsive cities are about bringing cities back to their citizens. Responsive cities change the way the technology of a smart city is used. The first Smart Cities were technology driven and they produced large amounts of data from fixed or centrally controlled sensors. But by now, the citizens and their mobile phones have taken the leading role in direct data generation. Rather than using data that are centrally collected and stored, you will see platforms on which the citizens place the data and the information they decide to share. With this, your own responsibility becomes a foundation of a Responsive City. Cities evolve from being smart to being responsive.
To demonstrate the potential of Responsive Cities, this course will define the concept of Citizen Design Science, a combination of Citizen Design, Citizen Science and Design Science. Experts, citizens and scientists participate in Citizen Design Science. This approach is still in an early stage of development, but with the Responsive Cities Massive Open Online Course, you will be ahead in exploring and defining its possibilities.
‘Responsive cities’ is the fourth edition of the ‘Future Cities’ series on urban MOOCs. The ‘Future Cities’ series is the first and complete series of urban courses dealing with the design, management and transformation of cities for their sustainable and resilient future. With every edition, the series becomes more interactive. It increasingly empowers citizens around the world to become part of the development of their own cities, especially in those places where this knowledge is needed most. Therefore, the course is inclusive for every individual interested in the planning, construction, redevelopment and management of future cities. The course is open to anyone regardless of background, skills, knowledge, or age.



            Read more
          



Week 1: Warmup week
Week 2: Introduction to the Responsive Cities
Week 3: Information Cities
Week 4: Smart Cities
Week 5: From Smart to Responsive
Week 6: Responsive and livable cities
Week 7: Citizen-design science
Week 8: Responsive Governance
Week 9: Responsive building design and city planning
Week 10: Responsive cities",Responsive Cities
https://www.classcentral.com/course/edx-smart-cities-6336,"Cities are first and foremost built for people, and in today’s world, people produce large amounts of valuable data, thus contributing to what we call “smart cities."" As almost every building and every city is a prototype, these communities are in the early stage of development and require specific attention and expertise as we advance.
Smart cities, such as Zurich and Boston, consist of human-made structures or environments that are, in some capacity, monitored, metered, networked and controlled. With this functionality, combined with stationary sensors and mobile devices, data and information have become the new building materials of future cities. Using this data, citizens are now beginning to influence the design of future cities and the re-design of existing ones.
In this architecture course, you will learn the basics of information cities and urban science research, as well as how dynamic behavior and citizen-driven learning differentiate the responsive city from the smart city. The cities we present and develop in this course use the stocks and flows of information as the main drivers of change.
To deepen your knowledge of smart cities and give a perspective on the future of these cities, we also introduce the concept of citizen design science, a combination of citizen science, urban design, and cognitive design computing. Participants will furthermore have unique access to a design research platform for citizen design science. The intelligent use of data and information is at the core of this course, and these concepts will be the next generation of participatory design and design computing environments.
This course is part of the “Future Cities” XSeries, and builds on the experiences from our first two urban MOOCs: Future Cities and Livability in Future Cities.



            Read more",Smart Cities
https://www.classcentral.com/course/harvardx-computer-science-for-game-development-18456,"The video games of the 1970s and 1980s have never lost their appeal. Pong, Super Mario Bros., The Legend of Zelda — these games defined a generation and set the stage for the massive billion-dollar video game industry of today. Even among the current blockbuster action-adventure titles, retro indie games play an important role, but how are these games made? What principles do you need to master to become a game designer and create the next hit title?
These courses will lead you through the most popular undergraduate course at Harvard, CS50, an Introduction to Computer Science. The first course will introduce you to common programming languages, providing a strong foundation to build the skills necessary to design and develop your own game. The second course will introduce you to the fundamentals of game programming itself.
You’ll explore the design of classic games — and newer titles like Angry Birds and Portal — in a quest to understand how video games are built. Through lectures and hands-on projects, you’ll explore the principles of 2D and 3D computer graphics, animation, sound, and collision detection. You’ll learn how to use frameworks like Unity and LÖVE 2D, as well as languages like Lua and C#. Join now to program your own games and gain a thorough understanding of game design and development.



Courses under this program:Course 1: CS50's Introduction to Computer ScienceAn introduction to the intellectual enterprises of computer science and the art of programming.Course 2: CS50's Introduction to Game DevelopmentLearn about the development of 2D and 3D interactive games in this hands-on course, as you explore the design of games such as Super Mario Bros., Pokémon, Angry Birds, and more.",Computer Science for Game Development
https://www.classcentral.com/course/data-science-environmental-modelling-11806,"Discover how data science can help us understand environmental change
Environmental and climate change impact our lives, but what role does data play in informing us about such changes to our world? On this online course, we examine and explore the use of statistics and data science in better understanding the environment we live in.
You will develop data science skills learning from experts and completing hands-on modelling activities using real world environmental data and the powerful programming language R.
You will also consider how data can help plan the use of renewable energy resources such as wind power.
This course is for people with an interest in environment and/or renewable energy and who wish to gain new skills in data science. It will also be suitable for those with an interest in data science and who wish to learn more about applications in environment and renewable energy. You don’t need to be an expert in R to take this course.",Data Science for Environmental Modelling and Renewables
https://www.classcentral.com/course/france-universite-numerique-introduction-to-a-web-of-linked-data-10982,"About this course Among its many evolutions, the Web became a way to exchange data between applications. Everyday we consume and produce these data through a growing variety of applications running on a growing variety of devices. This major evolution of the Web has applications in all domains of activity.  This MOOC introduces the Linked Data standards and principles that provide the foundation of the Semantic web. We divided this introduction into four parts:  the fundamental principles of linked data on the Web the RDF recommendation that provides a standard data model and syntaxes to publish and link data on the Web an overview of the SPARQL query language that allows us to access data sources on the Web the standards supporting the exchange and integration of RDF data with other formats and data sources (R2RML, CSVW, JSON-LD, RDFa, GRDDL, LDP).  Each week alternates short videos and quizzes, as well as supplementary resources, to gradually progress through the different principles and standards. 



Course Syllabus Week 1 Principles of a Web of Linked Data Week 2 The RDF Data Model Week 3 SPARQL Query Language Week 4 Integration with Other Data Formats and Sources Self-Paced Course This course is opened for one year : course materials are completely available at any time. Several dates for delivering ""success attestations"" will be set.",Introduction to a Web of Linked Data
https://www.classcentral.com/course/edx-developing-intelligent-apps-and-bots-6357,"Next generation apps have brought intelligence to software, enabling users to interact with everyday devices in new ways.
In this data science course for developers, you will learn how to create smart applications that use the power of machine learning to engage with users in previously unimaginable ways.",Developing Intelligent Apps and Bots
https://www.classcentral.com/course/seo-fundamentals-5484,"Gain an understanding of search engine algorithms and how they affect organic search results and websites. Building on this knowledge, you’ll learn the key elements for creating an effective SEO strategy, including how to select keywords and perform keyword research; consumer psychology and search behavior; and how to conduct on-page SEO analysis to identify opportunities to improve a website’s search optimization.
      


          Getting Started and Introduction to On-page SEO
    -Welcome to Week 1. This module will introduce you to On-page SEO. The lessons will start with introducing you to key areas of SEO so you’ll have a strong understanding of the differences amongst the strategies. Then we’ll dive into using On-page SEO techniques so that you’ll know how to optimize keywords in meta data as well as perform competitive analysis on a web page.  By the end of this module, you’ll know how to identify meta-tags and use these to make recommendations for On-page SEO.  

Introduction to Off-page SEO
    -Welcome to Week 2. This module will introduce you to Off-page SEO. While these strategies are more indirect than On-page SEO, they’re still important to maximize page authority. This module will clarify what Off-page SEO is as well as help you understand building links to your site and understanding brand recognition through social media. Once you complete this module, you’ll be able to understand link analysis as well as how social media can help improve your page authority. 

Introduction to Technical SEO
    -Welcome to week 3! In the lessons that follow, you will take a close look at the third leg of a solid SEO Strategy: Technical SEO. You’ll see how important structural components like sitemaps, redirects and other components lay a foundation for your content that will help your site get noticed. By the end of this module, you should be able to define Technical SEO and explain some of the basic aspects of this strategy. As you begin creating sitemaps and robot.txt files as well as planning redirects and managing site errors, you’ll learn how to employ best practices in your Technical SEO strategy. 

Keyword Theory & Research
    -Welcome to week 4! In this module, we are going to discover a variety of strategies for developing keywords for your site. This critical step is what helps direct your ideal buyer to the content that meets his or her needs. In the lessons that follow, we’ll learn about keyword theory and how understanding the common behaviors of web searchers can help you hone your list of keywords. We’ll also see how you can use a variety of SEO tools to conduct an audience and use this data to develop personas of your ideal buyer. Once you’ve completed this module, you should be able to craft a list of optimal keywords that will help get your site recognized.",Search Engine Optimization Fundamentals
https://www.classcentral.com/course/edx-fa19-introduction-to-business-for-analytics-8997,"This course provides students and professionals in the analytics field with an accelerated introduction to the basics of management and the language of business.
The objective is to enhance an analytics-focused learner's effectiveness in the business world. Designed for students who possess little background in business, the course provides an introduction to the types business issues and problems that challenge management teams today.
The course is taught as a series of business disciplinary modules. The professors who teach the modules represent a diversity of functional areas, including accounting, finance, marketing, international marketing, industry analysis, and business strategy.
Topics covered include:

basic accounting principles and theory
financial statement formats, usage and analysis
cost accounting, variance analysis, and the use of accounting data for decision making
capital structure and financial analysis techniques
methods of valuating entrepreneurial ventures, sources of entrepreneurial capital
the marketing mix (product, price, promotion, and place) and strategic considerations in market planning
fundamentals of industry analysis, business strategy formulation, and the use of innovation as a competitive weapon.




Financial and Managerial Accounting:

Read, understand, and analyze GAAP Financial Statements – including The Balance Sheet, Income Statement, and Statement of Cash Flows.
Learn how to calculate and use key financial and operational ratios.
Understand the basic accounting principles that provide the guidelines for developing financial statements and recording business activities.
Understand how accounting data is used to determine product costs and to make critical managerial decisions.

Finance:

Understand the differences between accounting profits and economic value added (“EVA”) and the significant of EVA in wealth creation.
Learn how to calculate cost of capital and understand how cost of capital factors into investment decisions.
Describe the financing issues and choices those confront entrepreneurs.
Understand multiple approaches to new venture valuation and important investment criteria.

Marketing:

Understand how market research drives customer identification and segmentation.
Appreciate the importance of target marketing and product positioning and how overall marketing objectives are set.
Understand the significance of the 4 Ps of marketing – Product, Price, Place, and Promotion – and how market plans/tactics for creating demand and a sales pipeline are established.

Business Strategy and Innovation:

Develop an understanding of how industry and internal analysis drives strategic planning and how to apply a number analytical techniques to identify opportunities, and threats, and firm strengths and weaknesses.
Describe the differences between different levels of strategy: corporate, business unit, and functional.
Understand and be able to apply different growth strategies: concentration, vertical and horizontal integration, and diversification.
An understanding of strategy implementation issues and change management models and best practices.",FA19: Introduction to Business for Analytics
https://www.classcentral.com/course/edx-materials-science-and-engineering-8150,"This engineering course presents a broad multidisciplinary approach to understanding and manipulating the mechanical, electrical, optical and magnetic properties of materials.
Materials have always been the keystone of society, and they are playing an increasingly paramount role in our high-tech age. Correspondingly, materials scientists and engineers are highly valued and well-paid specialists.
The course content is closely related to chemical, mechanical, electrical, computing, and bio- and civil engineering. This course will provide key information about fundamental characteristics of a variety of materials including metals, ceramics, polymers, and electronic materials.
Taught by professor Alexander Mukasian, who has decades of experience in various materials science and engineering areas, this course will provide the essential basis for an engineering education.
This course considers:

How the physical properties of metals, ceramics polymers and composites are correlated with their internal. structures (on atomic, molecular, crystalline, micro- and macro- scales) and operational conditions (mechanical, thermal, chemical, electrical and magnetic).
How materials processing, e.g. mechanical working and heat treatment, affects their properties and performance.
The latest achievements in Materials Science and Engineering.




Week 1. Classification and Properties of the Materials 

Introduction to basic materials science concepts, such as classes of materials and their primary properties.
General information about Materials Science and its role in society.

Week 2. Atomic Scale of the Materials: Atomic Bonding, Bond Energy, Bond Stiffness. Atomic Structure and Mechanical Properties of Materials

Explanation of elastic and thermodynamic properties of the materials on the basis of the electron structure of atoms and the specific types of atomic interactions within the material.
Discussion about the major dependence between the mechanical properties of the materials and their atomic structure. 

Week 3. Crystal Lattice Scale of the Materials: Crystal Structures and Their Properties 

Nano and Micro- Scales: Polymorphic Transformations, Defects in Solids, Grains and Grain Boundaries.
General information related to the classification of crystals and dependence between mechanical properties and crystal structure of materials. 
From the dislocations motion to the tin plague: everything that you wanted to know about the microstructure of materials, but were afraid to ask.

Week 4. How to Shape the Microstructure and the Mechanical Properties of the Materials

Introduction to complex techniques, which allows the engineers to alter the properties of materials by modification of materials’ microstructure.

Week 5. X-ray Diffraction Analysis of the Materials. Transmission Electron Microscopy

Basic information about the diffraction and interference of different types of rays and how to use them to investigate the crystal structure of the materials.
General information about one of the most powerful tools of modern microscopy, capable of direct observation of atoms in materials. 

Week 6: Advanced Scanning Electron Microscopy

Overview of the scanning electron microscopy – from the most widely used materials investigation techniques to state-of-art integrated nano-laboratories.

Week 7. Final Exam",Materials Science and Engineering
https://www.classcentral.com/course/edx-fundamentals-of-market-structure-6311,"Taught by instructors with decades of experience on Wall Street, this economics and finance course provides students with a basic foundation in market structure, market structure science, and market mechanics.
You’ll learn about the major elements and concepts that form a market and determine its development. You’ll also learn about key market participants including market makers, brokers, asset managers, hedge funds and more.
This free course is from the New York Institute of Finance, a highly sought after designation that leading financial services and employers know and trust globally.
This free course is a great introduction to market structure. For a deeper understanding of financial markets and to be qualified to perform in the real world and meet the demanding realities of finance, see the NYIF’s professional certificate course Electronic Trading in Financial Markets.



Lesson 1: Introduction to Market Structure
Lesson 2: Introduction to Market Structure Science
Lesson 3: Fundamentals of Market Mechanics",Fundamentals of Market Structure
https://www.classcentral.com/course/edcast-data-lakes-for-big-data-3545,"Each day an astounding amount of data is generated from just about everything around us – from our mobile devices to our health care provider to where we shop for groceries – just to name a few. Big Data is a term used to describe the volume of data, variety or type - both structured and unstructured, and speed (real time or near real time). Businesses have become increasingly focused on analyzing big data to increase revenue, drive down costs, and reduce risk to the business. 
In addition organizations have started to face infrastructure and platform challenges to store, manage and analyze these vast amounts of varied of data for quick turnaround. 
This free, open, online, interactive course will expose you to the value, opportunity, and insights that Big Data can provide. It highlights the Federation Business Data Lake as an integrated solution that stores and provides access to Big Data for real-time, rapid analytics and predictive modeling.



Week 1: What Is Big Data and Data Science?• Introduce Big Data Analytics and Data Science• Describe Big Data and Data Science opportunities• Apply foundational knowledge to current business needs via discussion posts• Prepare for next week's lesson
Week 2: What's the Value of Big Data and Big Data Analytics?• Describe the business value and benefits of Big Data• Explain the roles and responsibilities involved in building a data science team• Describe the tools, people, and processes used in big data analytics• Prepare for next week's lesson
Week 3: What Is the Federation Business Data Lake? • The emergence of data lakes• Introduce the Federation Business Data Lake• Relate the Federation Business Data Lake to learner's business problem via discussion post• Prepare for next week's lesson
Week 4: How is the Data Lake Solution Operationalized? • Describe how the Federation Business Data Lake ingests, stores, and processes data• Describe applications of the Federation Business Data Lake• Work via discussion groups to answer questions related to content",Data Lakes for Big Data
https://www.classcentral.com/course/swayam-probability-and-statistics-5228,"The course entitled “Probability and Statistics” deals with the basics of theory of probability and random variables. This course provides a sound base for the higher studies in probability theory. For mathematics, computer science students, the course in “Probability and Statistics” gives an additional space for widening the applications of the knowledge in their subject area to the various fields of real life. Two dimensional random variables, joint probability distributions etc., are also coming under the structure of this course. The students of Statistics, Mathematics, computer science etc., will be benefited with this course. 
      


COURSE LAYOUT",Probability and Statistics
https://www.classcentral.com/course/gcp-big-data-ml-fundamentals-br-13703,"Este curso intensivo sob demanda tem duração de uma semana e apresentará as funcionalidades de Big Data e Machine Learning do Google Cloud Platform (GCP). Ele fornecerá uma visão geral rápida do Google Cloud Platform e mostrará em detalhes os recursos do processamento de dados.

Ao final deste curso, você poderá:
• Identificar o objetivo e o valor dos principais produtos de Big Data e Machine Learning no Google Cloud Platform
• Usar o Cloud SQL e o Cloud Dataproc para migrar as cargas de trabalho MySQL e Hadoop/Pig/Spark/Hive para o Google Cloud Platform
• Usar o BigQuery e o Cloud Datalab para fazer análises de dados interativas
• Escolher entre o Cloud SQL, o Bigtable e o Datastore
• Treinar e usar uma rede neural com o TensorFlow
• Escolher entre diferentes produtos de processamento de dados no Google Cloud Platform

Para se inscrever neste curso, você deve ter aproximadamente um (1) ano de experiência em um ou mais destes itens:
• Uma linguagem de consulta de uso comum, como SQL
• Atividades de extração, transformação e carregamento
• Modelagem de dados
• Machine Learning e/ou estatísticas
• Programação em Python

Observações sobre a Conta do Google:
• Os serviços do Google estão temporariamente indisponíveis na China.
      


          Introdução à especialização Data Engineering, Big Data, and Machine Learning no Google Cloud Platform
    -Apresentamos o curso Google Cloud Platform Big Data and Machine Learning Fundamentals. Conheça os conceitos básicos da estrutura do curso e os quatro principais desafios de Big Data que você solucionará.

Recomendação de produtos com o Cloud SQL e o Spark
    -Neste módulo, você terá um modelo de recomendação Apache SparkML atual em execução no local. Você conhecerá os modelos de recomendação e aprenderá a executá-los na nuvem com o Cloud Dataproc e o Cloud SQL.

Faça a predição das compras de visitantes com o BigQuery ML
    -Neste módulo, você conhecerá os aspectos básicos do BigQuery e da análise de Big Data em escala. Você aprenderá como criar seu próprio modelo de machine learning personalizado para predizer as compras dos visitantes usando apenas o SQL com BigQuery ML.

Crie pipelines de dados de streaming com o Cloud Pub/Sub e Cloud Dataflow
    -Neste módulo, você projetará e criará um pipeline de dados de streaming com escalonamento automático para ingerir, processar e visualizar dados em um painel. Antes de gerar o pipeline, você conhecerá os conceitos básicos da arquitetura orientada a mensagens e as armadilhas a serem evitadas ao criar e implementar pipelines de dados modernos.

Classifique imagens com modelos pré-criados usando a API Vision e o Cloud AutoML
    -Não quer criar um modelo de ML personalizado do zero? Saiba como aproveitar e ampliar modelos de ML pré-criados, como a API Vision e o Cloud AutoML, para a classificação de imagens.

Resumo
    -Neste módulo final, analisaremos os principais desafios, soluções e tópicos abordados como parte deste curso básico. Também analisaremos os recursos adicionais e as etapas que você pode executar para ter a certificação como engenheiro de dados do Google Cloud.",Google Cloud Platform Big Data and Machine Learning Fundamentals em Português Brasileiro
https://www.classcentral.com/course/edx-market-segmentation-analysis-11387,"Conducting market segmentation analysis and committing to a long-term market segmentation strategy is a complex and challenging journey for any organisation. This course guides you through the entire process of market segmentation analysis and offers a ten-step process that makes customer segmentation efficient and organised. 
This course begins with the decision to conduct market segmentation analysis and continues through to the final stages of evaluating the success of the strategy and monitoring the market for possible changes. We also cover segmentation variables such as geographic segmentation, psychographic segmentation, behavioural segmentation, and demographic segmentation. 
In this course, we will explore how to leverage statistical concepts into the organisation's segmentation strategy, such as the hierarchical clustering and partitioning methods, exploratory data analysis, biclustering, mixture models, and regression models. 
The concepts and skills you will gain in this course are relevant in a wide range of contexts in both the for- and not-for-profit sectors. 
This course enables you to conduct customer segmentation analysis. You can replicate the calculations and visualisations demonstrated in the customer segmentation modelsby downloading the data and the R code. R is a free open-source statistical computing environment, and is widely acknowledged as the universal language of computational statistics. 
This course is based on and taught by the authors of the book Market Segmentation Analysis: Understanding It, Doing It, and Making It Useful. You will have full access to this valuable resource when you enrol in this course.



            Read more
          



Module 1: Introduction and Steps 1 and 2
We define market segmentation analysis, explain why it is the basis of marketing planning, and why it informs both strategic and tactical marketing decisions. We provide an overview of the ten-step process in market segmentation analysis. In Step 1, we explain the requirements for market segmentation, helping learners decide whether their organisation is ready to segment. In Step 2 we specify the ideal target segment, including segment evaluation criteria. 
Module 2: Steps 3 and 4
In Step 3,we describe collecting data and define the segmentation variables and criteria, and discuss different sources of data. In Step 4 we explore the data and discuss data cleaning and how to pre-process categorical and numeric variables. We also demonstrate how to use R, to assist you with exploring the data. 
Module 3: Step 5
In Step 5,we extract market segments and group consumers using distance-based, hierarchical, and partitioning methods; hybrid approaches; and model-based methods. We also explain data structure analysis. 
Module 4: Steps 6 and 7
In Steps 6 and 7, we profile and describe segments. We use traditional approaches as well as visualisation techniques to identify key characteristics of market segments. In Step 7 we develop and visualise a complete picture of market segments; this includes testing and predicting segment differences in descriptor variables. 
Module 5: Steps 8, 9 and 10
In Step 8, we select the target segments including the tasks targeting decision and market segment evaluation. In Step 9 we customise the marketing mix. We also discuss the implications of market segmentation for marketing mix decisions concerning product, price, place,and promotion. Finally, in Step 10, we evaluate the success of the segmentation strategy, and stability of segment membership. We conclude with a discussion of segment hopping and segment evolution.",Market Segmentation Analysis
https://www.classcentral.com/course/france-universite-numerique-from-data-base-to-big-data-16958,"Many data systems exist today. The primary objective of the course is to have a conceptual grid of the different data systems by deepening the main standards.
A multidisciplinary introduction allows learners to have a strategic vision of the future of information systems around the concepts of ""mobiquity and BIG DATA"". Then, we present the fundamental concepts of databases and BIG DATA with their paradigms and properties in support: TIPS / ACID, RICE, WHAT / BASE and Google CABS. The Top Down and Bottom Up approaches to data integration then make it possible to explore the different paradigms of data systems.
This course is a fundamental prerequisite for all computer science students (Bachelor and master) wishing to do a Master in computer science in the Data economy like the MBDS (Mobiquity, Big Data and Systems Integration) from University Côte d’Azur (formerly University of Nice Sophia Antipolis). It is also intended for IT professionals who want a clarification of the concepts of databases and Big Data.
This is a weekly course over 7 weeks. Each week, 4 to 9 short video sequences will be offered to participants. These sequences will be accompanied by questions and practical work, as well as discussion forums. MCQs will evaluate the knowledge at the end of each week. The teaching team will speak once a week to answer the most frequent questions of the forum through an online conference.
The weekly MCQs and the peer-reviewed practical work will be used to successfully issue the follow-up certificate.
 
 
To follow this course, you have the choice between two packages :.
the DISCOVERY package and the CERTIFYING package.



            Read more
          



Week 1 : « Spiralist innovation on Big Data systems » This module is a strategic multidisciplinary introduction around big data systems with definitions of key concepts (data paradigm, data lake, etc.) and disruptive supporting technologies which will be useful during this course.
Week 2 : « Data paradigms and Codd’s relational data model » There exists a plethora of big data management systems. In the first part of the course, we propose a classification of these systems using data paradigms we illustrate with SQL standard (TIPS, ACID and RICE properties). The second part concerns Codd’s relational data model which represents a formal unifying foundation anfor big data management systems.
Week 3 : « SQL2 introduction » This course is devoted to SQL standard presentation (including the Transaction concept) which will be the Esperanto for big data systems with a focus here on relational structured data model
Week 4 : « Third Date’s manifesto (underlying object-relational data models) » Date’s manifesto is the neutral symmetric of Codd’s model for SQL2 for hybrid object-orient data bases. We clarify the concepts of objects (OID, VALUE) which will be useful for N.O.SQL systems.
Week 5 « Introduction to ODMG » Object-oriented data models based upon Bancilhon’s manifesto was proposed for object programmers. ODMG is a data base extension of OMG (Object Management Group) proposed on top of Java, C++ and Smalltalk
Week 6 : « Introduction to SQL3 » SQL3 is the fusion of Date’s and Stonebraker’s manifestos whose salient features are presented and discussed in this module.
Week 7 : « Overview of N.O. SQL and NEWS SQL » In this module we introduce N.O.SQL systems around KEY-VALUE (Hadoop, BLOB, Json Document, attributes) and GRAPHS and NEW SQL systems and identify the expected functionalitie of SQL for polystores systems with “the category theory” being a unifying formal framework.L.",From data base to big data
https://www.classcentral.com/course/columbiax-artificial-intelligence-18306,"Gain expertise in one of the most fascinating and fastest growing areas of computer science through an innovative online program that covers fascinating and compelling topics in the field of Artificial Intelligence and its applications. This MicroMasters program from Columbia University will give you a rigorous, advanced, professional, graduate-level foundation in Artificial Intelligence. The program represents 25% of the coursework toward a Master's degree in Computer Science at Columbia.



Courses under this program:Course 1: Artificial Intelligence (AI)
Learn the fundamentals of Artificial Intelligence (AI), and apply them. Design intelligent agents to solve real-world problems including, search, games, machine learning, logic, and constraint satisfaction problems.
Course 2: Machine Learning
Master the essentials of machine learning and algorithms to help improve learning from data without human intervention.
Course 3: Robotics
Learn the core techniques for representing robots that perform physical tasks in the real world.
Course 4: Animation and CGI Motion
Learn the science behind movie animation from the Director of Columbia’s Computer Graphics Group.",Artificial Intelligence
https://www.classcentral.com/course/matlab-capstone-17126,"Like most subjects, practice makes perfect in Data Science.   In the capstone project, you will apply the skills learned across courses in the Practical Data Science with MATLAB specialization to explore, process, analyze, and model data.   You will choose your own pathway to answer key questions with the provided data.

To complete the project, you must have mastery of the skills covered in other courses in the specialization.  The project will test your ability to import and explore your data, prepare the data for analysis, train a predictive model, evaluate and improve your model, and communicate your results.",Data Science Project: MATLAB for the Real World
https://www.classcentral.com/course/edx-uml-class-diagrams-for-software-engineering-7837,"Have you ever wondered how software architects, requirements engineers and business analysts sketch and draw out their plans for a software system?
In this computer science course, you will gain an in-depth understanding of Unified Modeling Language (UML) class diagrams, which are used to visually represent the conceptual design of a system. You will learn about UML class diagrams and how they are used to map out the structure of a business domain by showing business objects, their attributes, and associations.
Taught by an instructor with decades of experience in requirements engineering and domain modelling, this course will equip you with the skill of in-depth understanding of a UML class diagram and will enable you to judge the functional fit of a UML class diagram as blueprint for the development of an enterprise information system.
The Unified Modeling Language (UML) has become an in-demand skill in software development and engineering. In fact, some of today’s top jobs, i.e. business analysts, enterprise architects, but also developers, technical consultants and solutions architects, require UML knowledge. Enroll today and gain knowledge in an in-demand skill that will help set you apart from the competition.



Week 1: Introduction and UML Class Diagram Basics (part1)
Introduction as to what a data model is, why data modelling matters, and the concepts of modelling languages and notations. Introduction to the notions of ""Class"" and ""Attribute."" 
Week 2: UML Class Diagram Basics (parts 2 and 3)
Introduction to the concept of ""Association"" and its different variants: ""unary"" and ""ternary associations,"" and ""aggregation."" Learning to navigate a larger UML diagram. 
Week 3: UML Class Diagrams Advanced Topics
Introduction to the concept of ""inheritance"" and learning to read a model with inheritance. Introduction to the concept of ""AssociationClass"" and learning to reify an association.",UML Class Diagrams for Software Engineering
https://www.classcentral.com/course/edx-metabolomics-in-life-sciences-9254,"This course is an introduction to metabolomics principles and their applications in various fields of life sciences. We will provide a summary of all steps in metabolomics research; from experimental design, sample preparation, analytical procedures, to data analysis. The course also provides case studies of various kinds of research samples to attract students that are not familiar with metabolomics, providing them enough explanation to utilize metabolomics technology for their respective research fields. Several examples of metabolomics applications will be introduced throughout the lectures. These include examples within food science and technology, metabolic engineering, basic biology, introduction to imaging mass spectrometry, and application in medical science.No previous knowledge on metabolomics is needed but we recommend that students have an undergraduate-level understanding of Biochemistry, Analytical Chemistry, and Biostatistics, and that they learn about basic principles of multivariable analysis prior to taking this course.
      


          Week 1:  What is Metabolomics?Week 2:  Application of Metabolic Fingerprinting for Food Quality AssessmentsWeek 3:  Metabolomics: A Powerful Tool for Phenotype ImprovementWeek 4:  Basics of Mass Spectrometry and Imaging Mass Spectrometry",Metabolomics in Life Sciences
https://www.classcentral.com/course/advanced-seo-strategies-5608,"This course focuses on technical, mobile and social strategies for increasing site traffic. Learn how to build SEO for international audiences through content localization, global team alignment and optimizing for local search engines. Discover techniques to optimize mobile-friendly websites, get mobile apps discovered, and leverage social media to drive organic SEO traffic.  You will also learn how to identify key SEO metrics and collect, interpret, validate, and report success to your clients and stakeholders.
      


          Introduction
    -Welcome to this first module where you will discover how technical search engine optimization (SEO) can improve your website. You will discuss and use web metrics as you compare performance analysis tools and plug-ins. You will be able to find and fix problems, heighten visibility, improve site architecture, and accelerate page load speed for your own website.  You will be able to take the steps necessary to conduct a website audit and finally, you’ll discover strategies to achieve positive change by working well with teams and stakeholders.

Take Your Website Global
    -In this module, you will examine what you need to take your website global. You will prepare for global expansion and grasp tremendous opportunities to reach the world. You will be introduced to tested principles and best practices to optimize your website for global expansion. You will align your site with international audiences following guidance from search engines. You will explore how to structure URLs and employ localization to serve global customers, as well as develop engaging strategies to launch a global web marketing campaign. You will work with a budget for external or in-house localization teams and empower stakeholders to fulfill their roles in a global marketplace. 

Make the Most of Mobile and App SEO
    -This module will provide you knowledge necessary to take advantage of innovations and future trends in the mobile marketplace. You will be able to use a clear process to make your mobile apps easier to find. Identify Key Performance Indicators (KPIs) needed for successful App Store Optimization (ASO) and receive a checklist of best practices. You will use tools that provide insightful data to evaluate and beat your competition. Become mobile-friendly by examining the factors that improve app rankings in Apple iTunes or Google Play app stores, and optimize for social search engines. Gain insight into using and interpreting app data to competitive benefit. You’ll also review case studies illustrating how to generate business results, employ real-world experience, and take advantage of unparalleled opportunities with Mobile and Apps. 

Identify Metrics to Drive Performance
    -Welcome to the final module in this course. In this module, you will discuss the concepts to measure key metrics and conduct data analysis to bring value to stakeholders. You will recognize and use practical tips to quantify success, overcome common mistakes, and resolve data analysis errors. You will explore various tools and analytic packages, then use these to measure what matters. You will begin to use advanced analytics to drive business, and be shown how to analyze data reports to increase revenue. You will also discover enterprise-level platforms that enhance performance. All of this comes together to help you make sense of today’s data to provide future insights for yourself and your stakeholders.",Advanced Search Engine Optimization Strategies
https://www.classcentral.com/course/mooc-ed-teaching-statistics-through-data-investigations-3274,"Our world is rich with data sources, and technology makes data more accessible than ever before! To help ensure students are future ready to use data for making informed decisions, many countries around the world have increased the emphasis on statistics and data analysis in school curriculum–from elementary/primary grades through college. This course allows you to learn, along with colleagues from other schools,  an investigation cycle  to teach statistics and to help students explore data to make evidence-based claims.
Who should take this course? This MOOC-Ed  is applicable to anyone interested in strengthening their approaches to teaching statistics through data investigations. The statistical concepts included are those often introduced to middle school through early college learners. Thus, teachers of statistics in grades 6-12 and in post-secondary contexts are the primary audience. This course may also be of interest to elementary teachers, teacher educators, and teachers of other disciplines that use data-based explorations extensively to make claims and inferences (e.g., science, social science).



Unit 1: Course introduction-Considering the possibilities of teaching statistics with data (March 9 - March 15), considers what statistics is and why it is taught in schools. This unit explores the possibilities of students playing with real data and cool tools and of teaching statistics with data. You will have opportunities to set your goals for the course when playing with self-efficacy to teaching statistics and common content items related to statistics. We will offer some tools for data exploration, exciting readings, and sites where datasets are publicly available.
Unit 2: What is a statistical investigation? (March 16 - March 22), examines the difference between mathematics and statistics, introduces the statistics investigation cycle, and begins to consider habits of mind when working with statistics. You will have opportunities to analyze mathematical and statistical tasks and examine student reasoning as they engage in statistical investigations. We will offer some additional tools for data exploration and resources for lesson plans.
Unit 3: Introducing levels of statistical sophistication (March 23 - March 29), explores a framework for supporting growth in students’ statistical sophistication and digs deeper into statistical habits of mind. You will apply a statistical task framework to design/adapt and analyze instructional tasks and explore students' levels of statistical sophistication. We will offer some additional tools and resources assisting the teaching of statistics.
Unit 4: Starting a statistical investigation –Posing questions and collecting data (March 30 - April 12) , digs deeply into what it is important for students to consider during the pose and collect phases of statistical investigations and zooms in the concept of comparing distributions. You will play with the Census of School data set to try posing rich statistical questions and examining issues of survey questions for collecting data. We will offer some additional tools and resources assisting the teaching of statistics.
Unit 5: Investigating further — What can we say about the data? (April 13 - April 26), digs deeply into the analyze and interpret phases of the statistical investigation cycle and the concept of informal inferences. You will play with the Census of School data set to analyze and interpret results for the questions you pose in Unit 4. We will offer some additional tools and resources assisting the teaching of statistics.
Unit 6:Course wrap up and next steps (April 27 - May 3), allows participants to reflect on, assess, and share the knowledge gained throughout the course, provide feedback for the work posted by colleagues and share what they have learned and their ideas for improving the MOOC-Ed.",Teaching Statistics Through Data Investigations
https://www.classcentral.com/course/stanford-openedx-crisis-code-teaching-crisis-management-skills-to-enhance-management-of-advanced-cardiac-life-support-5706,"Healthcare professionals are required to handle medical emergencies and crises. These situations require teamwork and evidence-based techniques. This course will teach physicians crisis resource management principles and the provision of Advanced Cardiac Life Support (ACLS) during cardiac arrest.
 



Introduction to Crisis Resource Management (47 minutes)The Science of ACLS (50 minutes)Ventricular Tachycardia/Ventricular Fibrillation (73 Minutes)Pulseless Electrical Activity (PEA)/Asytole (80 Minutes)Airway Management and Vascular Access (30 Minutes)Symptomatic Bradycardia (42 Minutes)Unstable Supraventricular Tachycardia (78 Minutes)Post-resuscitation Management (28 Minutes)",Crisis Code: Teaching Crisis Management Skills to Enhance Management of Advanced Cardiac Life Support
https://www.classcentral.com/course/futurelearn-earth-observation-from-space-the-optical-view-6263,"##
Earth observation (EO) encompasses a series of techniques that use remote sensing to monitor changes to our climate, and natural and built environment.
Get an introduction to optical Earth observation
This free online course will provide an introduction to optical Earth observation - monitoring our planet from satellites, using photography, imaging in various wavelengths, lidar and other optical sensing technologies.
You’ll find out how satellite data is acquired and used, the range of data types available, and the terminology and techniques involved. The course will also provide detailed case studies of how this data is used in diverse fields, from climate science to humanitarian relief, monitoring of urban change to agriculture, and many other areas.
Learn with ESA - Europe’s Earth observation leader
The course has been developed by the European Space Agency (ESA) - the leading enabler of satellite Earth observation science and technology in Europe.
It will use case studies, real-world applications, and data from ESA and other Earth observation programmes, to help you discover:

how we observe and measure the Earth with optical sensors
how satellite data is used alongside other forms of measurement
the main types of data acquired through Copernicus and other satellites
how to conduct simple analysis using a range of different types of optical Earth observation data
how optical EO data is used in a range of scientific, policy and decision-making areas, in conjunction with models

Alongside articles and videos, interactive visualisation tools, additional resources and discussions with other learners will provide you with the opportunity to understand Earth observation in depth.
(Animations, data visualisations and imagery from ESA and NASA are provided courtesy of ESA and NASA. This course is produced for ESA by Imperative Space).
This course is designed both for people with some existing knowledge of Earth observation, as well as newcomers to the field. It will demystify the data, and make it easier for non-technical users to interpret and use it in their professional or day-to-day life, and in discourse and debate.
In case you are interested, new enrolments for the ESA Monitoring the Greenland Ice Sheet from Space course will remain open until 11th November 2017, so if you or your friends and colleagues would like to continue your exploration of satellite observation you can sign up here.



            Read more",Earth Observation from Space: the Optical View
https://www.classcentral.com/course/serverless-machine-learning-gcp-8696,"This one-week accelerated on-demand course provides participants a a hands-on introduction to designing and building machine learning models on Google Cloud Platform. Through a combination of presentations, demos, and hand-on labs, participants will learn machine learning (ML) and TensorFlow concepts, and develop hands-on skills in developing, evaluating, and productionizing ML models.

OBJECTIVES

This course teaches participants the following skills:

  ● Identify use cases for machine learning

  ● Build an ML model using TensorFlow

  ● Build scalable, deployable ML models using Cloud ML

  ● Know the importance of preprocessing and combining features

  ● Incorporate advanced ML concepts into their models

  ● Productionize trained ML models


PREREQUISITES

To get the most of out of this course, participants should have:

  ● Completed Google Cloud Fundamentals- Big Data and Machine Learning course OR have equivalent experience

  ● Basic proficiency with common query language such as SQL

  ● Experience with data modeling, extract, transform, load activities

  ● Developing applications using a common programming language such Python

  ● Familiarity with Machine Learning and/or statistics

Google Account Notes:
• Google services are currently unavailable in China.
      


          Welcome to Serverless Machine Learning on Google Cloud Platform

Module 1: Getting Started with Machine Learning

Module 2: Building ML models with Tensorflow

Module 3: Scaling ML models with Cloud ML Engine

Module 4: Feature Engineering",Serverless Machine Learning with Tensorflow on Google Cloud Platform
https://www.classcentral.com/course/climateadaptation-16880,"The world’s climate is changing, and among the most significant negative consequences is to human health. While climate change is a global health issue, its health impacts vary across geographies and populations. In this course, you will learn why taking action to plan for and adapt to climate change is necessary for protecting human health, as well as what kinds of actions are most appropriate for a particular location and population. You also will learn tools and strategies to effectively plan for and enact adaptation actions that build resilience to climate change’s negative effects.
      


          Welcome to Climate Adaptation for Human Health! 
    -This course discusses how adaptation is formally and informally defined, with detailed examples representing numerous spatial and temporal scales. The course also addresses how to use a range of vulnerability assessments to identify and prioritize opportunities for adaptation, illustrated through methodological and practical examples. The course then delves into the iterative process of adaptation activities, by focusing on the planning, implementing, and improving stages necessary for successful adaptation actions. Finally, successful strategies for adaptation practitioners are identified, focusing on explicit ways to maximize professional networks to create and sustain collaborative adaptation efforts. Throughout, the course focuses on practical examples of adaptation tools and activities that practitioners can implement in their communities.

 Introduction to Adaptation: What is Climate Adaptation? 
    -What does climate adaptation look like at the individual, local, regional, and national scale? Why is intentional adaptation to climate change necessary for protecting human health?  

Informing Adaptation: Collecting Data for Adaptation
    -What data is available to inform actions to adapt to climate change? How can data help us understand who is most vulnerable to climate change? 

Informing Adaptation: Assessing Adaptation Readiness
    -What adaptation actions are most appropriate for a particular population, and how is this assessed? Why is it important to measure “readiness” when planning for an adaptation action?

Planning for Adaptation: Adaptation Action Plans
    -Hows does the Adaptation Action Planning framework move adaptation planning ideas into action? What tools, networks, and resources are available after this course to continue engagement with the climate change and health community? 

Course Conclusion",Climate Adaptation for Human Health
https://www.classcentral.com/course/edx-introduction-to-fintech-11371,"Over the past decade emerging technologies, paired with massive changes in regulations, have driven an unprecedented transformation of finance around the world. This process is happening more rapidly in China and Asia than anywhere else. This course is designed to explore FinTech fundamentals and help make sense of this wave of change as it happens. 
New players such as start-ups and technology firms are challenging traditional players in finance, bringing democratization, inclusion and disruption. Companies engaged in social media, e-commerce, and telecommunications, as well as, companies and start-ups with large customer data pools, creative energies, and technical capacities, have brought competition to the existing financial infrastructure and are remaking the industry. 
These transformations have not only created challenges but also unprecedented opportunities, building synergies with new business and regulatory models, particularly in emerging markets and developing countries. To meet these changes, 21st-century professionals and students must be equipped with up-to-date knowledge of the industry and its incredible evolution. This course - designed by HKU with the support of SuperCharger and the Centre for Finance, Technology and Education - is designed to enable learners with the necessary tools to understand the complex interaction of finance, technology and regulation. 
In this course, through a series of video lectures, case studies, and assessments you will explore the major areas of FinTech including, beginning with What is FinTech before turning to Money, Payment and Emerging Technologies, Digital Finance and Alternative Finance, FinTech Regulation and RegTech, Data and Security, and the Future of Data Driven Finance, as well as, the core technologies driving FinTech including Blockchain, AI and Big Data. These will set the stage for understanding the FinTech landscape and ecosystem and grappling with the potential direction of future change.



            Read more
          



Module 1 What is FinTech?

FinTech Transformation
FinTech Evolution 1.0: Infrastructure
FinTech Evolution 2.0: Banks
FinTech Evolution 3.0 & 3.5: Startups and Emerging Markets
Industry Showcase: Collaboration between Financial Institutions and Startups
FinTech Typology
Emerging Economics: Opportunities and Challenges
From too-Small-To-Care to Too-Big-To-Fail
Introduction to Regulation
Industry Showcase: The Future of RegTech and 6 Technologies Impacting It

Module 2 Payments, Cryptocurrencies and Blockchain

Individual Payments
Developing Countries and DFS: The Story of Mobile Money
Developing Countries and DFS: Regulation of Mobile Money
RTGS Systems
The ABCDs of Alternative Finance
Building a New stack
Cryptocurrencies
Industry Showcase : Legal and Regulatory Implications of Cryptocurrencies
What is Blockchain?
Industry Showcase: The Benefits from New Payment Stacks (Applications of Ripple)

Module 3 Digital Finance and Alternative Finance

A Brief History of Financial Innovation
Digitization of Financial Services
FinTech & Funds
Industry Showcase: How AI is Transforming the Future of FinTech
Industry Showcase: Ensuring Compliance from the Start: Suitability and Funds
Crowdfunding - Regards, Charity and Equity
P2P and Marketplace Lending
The Rise of Chinese TechFins - New Models and New Products
What is an ICO?

Module 4 FinTech Regulation and RegTech

FinTech Regulations
Evolution of RegTech
RegTech Ecosystem: Financial Institutions
RegTech Ecosystem: Startups
RegTech Startups: Challenges
RegTech Ecosystem: Regulators
Industry Showcase: Use Case of AI in Smart Regulation and Fraud Detection
Regulatory Sandboxes
Smart Regulation
Redesigning Better Financial Infrastructure

Module 5 Data & TechFin

History of Data Regulation
Data in Financial Services
Industry Showcase : Application of Data Analytics in Finance
European Big-Bang: PSD2 / GDPR / Mifid2
Industry Showcase : PSD2: Open Banking API Will Help Startups
Industry Showcase : Methods of Data Protection: GDPR Compliance and Personal Privacy
Digital Identity
Change in mindset: Regulation 1.0 to 2.0 (KYC to KYD)
AI & Governance
New Challenges of AI and Machine Learning
Data, Metadata and Differential Privacy
Data is the New Oil: Risk of Breach
Industry Showcase : Cybersecurity Industry Update

Module 6 The Future of Data-Driven Finance


Case Study 1: Revolut
Case Study 2: Alibaba
Case Study 3: Aadhaar
Case Study 4: Credit Karma
Case Study 5: Digibank
Conclusion to Case Studies
FinTech Big Trends - Looking Forward",Introduction to FinTech
https://www.classcentral.com/course/stanford-openedx-algorithms-design-and-analysis-part-2-9250,"Welcome to the self paced course, Algorithms: Design and Analysis, Part 2! Algorithms are the heart of computer science, and the subject has countless practical applications as well as intellectual depth. This course is an introduction to algorithms for learners with at least a little programming experience. The course is rigorous but emphasizes the big picture and conceptual understanding over low-level implementation and mathematical details. After completing this course, you will have a greater mastery of algorithms than almost anyone without a graduate degree in the subject.

Specific topics in Part 2 include: greedy algorithms (scheduling, minimum spanning trees, clustering, Huffman codes), dynamic programming (knapsack, sequence alignment, optimal search trees, shortest paths), NP-completeness and what it means for the algorithm designer, analysis of heuristics, local search.

Learners will practice and master the fundamentals of algorithms through several types of assessments. There are 6 multiple-choice problem sets to test your understanding of the most important concepts. There are also 6 programming assignments, where you implement one of the algorithms covered in lecture in a programming language of your choosing. The course concludes with a multiple-choice final.

There are no assignment due dates and you can work through the course materials and assignments at your own pace.","Algorithms: Design and Analysis, Part 2"
https://www.classcentral.com/course/data-analytics-for-lean-six-sigma-8092,"Welcome to this course on Data Analytics for Lean Six Sigma. 

In this course you will learn data analytics techniques that are typically useful within Lean Six Sigma improvement projects. At the end of this course you are able to analyse and interpret data gathered within such a project. You will be able to use Minitab to analyse the data. I will also briefly explain what Lean Six Sigma is.

I will emphasize on use of data analytics tools and the interpretation of the outcome. I will use many different examples from actual Lean Six Sigma projects to illustrate all tools. I will not discuss any mathematical background. 

The setting we chose for our data example is a Lean Six Sigma improvement project. However data analytics tools are very widely applicable. So you will find that you will learn techniques that you can use in a broader setting apart from improvement projects. 

I hope that you enjoy this course and good luck!
Dr. Inez Zwetsloot & the IBIS UvA team
      


          Data and Lean Six Sigma
    -This module introduces Lean Six Sigma and shows you where data and data analytics have their place within the DMAIC framework.  It also introduces the software package Minitab. This package is used throughout the videos for data analytics. It is not mandatory to use this package. I just really like it!

Understanding and visualizing data
    -This module explains how to visualize data. It discusses visualizing single variables as well as visualizing two variables. You will learn to select the appropriate graph. For this it is essential to first learn the distinction between numerical and categorical data. 

Using probability distributions
    -In  this module on using probability distributions, you will learn how to quantify uncertainty. Furthermore you will learn to answer an important business question:  “what percentage of products or cases meet our specifications?"".

Introduction to testing
    -You will learn to model your CTQ and influence factor(s) and to use a decision tree to select the appropriate tool for data based testing of this model. Furthermore, causality is introduced.

Testing: numerical Y and categorical X
    -In this module on statistical testing, you will learn how to establish relationship between a numerical Y variable (the CTQ) and categorical influence factors (the X variables). 

Testing: numerical Y and numerical Y
    -What is the relation between the length of stay and the age of a patient? In this module you will learn to answers these types of questions using statistical tests to relate a numerical CTQ (the Y variable) to a numerical influence factor (the X variable).

Testing: categorical Y
    -Finally you will learn how to test a relationship between a Y and a X variable whenever your Y variable (the CTQ) is a categorical variable.",Data Analytics for Lean Six Sigma
https://www.classcentral.com/course/swayam-introductory-course-in-real-analysis-7941,"This is a basic course in Real Analysis which is a back bone of  any course on pure &  applied Mathematics and Statistics. This is a very useful course for any branch of science and engineering. The present course has been designed to introduce the subject to undergraduate/postgraduate students in science and engineering. The course contains a good introduction to each topic and an advance treatment of theory at a fairly understandable level to the students at this stage. Each concept has been explained through examples and application oriented problems.



Week 1: countable & uncountable sets (3 lectures)
Concepts of Metric Space (1 lectures)
Open ball, closed ball, limit point of a set (1 lectures)
 
Week 2: Some theorems  on Open &  closed  set (1 lectures)
Ordered set, least upper bound, greatest lower bound (2 lectures)
Compact set & some properties of Compact set (2 lectures)
 
Week 3: Heine Borel Theorem (1 lecture)
Weierstrass Theorem, connected set (1 lecture)
Cantor Set & its properties (1 lecture)
Dense set & derived set (1 lecture)
Limit of sequences of real numbers & Monotone sequence (1 lecture)
 
Week 4: Some important limits of sequences (1 lecture)
Ratio tests, Cauchy theorems on limits of sequence of real numbers (1 lectures)
Fundamental theorems on limit (1 lecture)
Some results on limit & Bolzano-Weierstrass Theorem (1 lecture)
Criteria for convergent sequence (1 lecture)
 
Week 5: Criteria for Divergent sequence (1 lecture)
 Cauchy sequence (1 lecture)
Cauchy convergence criteria for sequences (1 lecture)
Infinite series of Real numbers (1 lecture)
Convergence Criteria for series of positive real no. (1 lecture)
 
Week 6: Comparison test for series (1 lecture)
Absolutely and Conditional convergent series and Tests (2 lectures)
Ratio & Integral Tests for convergence of series (1 lecture)
Raabe’s test for convergence of series (1 lecture)
 
Week 7: Limit of functions & cluster point (2 lectures
Divergence criteria for limit (1 lecture)
Various properties of limit of functions (1 lecture)
Left & Right hand limits for functions (1 lecture)
 
Week 8: Limit of functions at infinity (1 lecture)
Continuity functions (Cauchy‘s definition) (1 lecture)
Continuity functions (Heine‘s definition) (1 lecture)
Properties of continuous functions (2 lectures)
 
Week 9: Boundedness Theorem and Max-Min theorem (1 lecture)
Location of root and Bolzano’s theorem (1 lecture)
Uniform continuity & related theorems (1 lecture)
Absolute continuity& related theorems (1 lecture)
Types of discontinuities & Continuity in a Metric Space (1 lectures)
 
Week 10: Types of discontinuities & Continuity in a Metric Space (1 lectures)
Relation between continuity & compact sets (1 lecture)
Differentiability of real valued functions (1 lecture)
Local Max. – Min. Cauchy’s and Lagrange’s Mean value theorem (1 lecture)
Rolle’s Mean value theorems & Applications (1 lecture)
 
Week 11: Applications of Derivatives (1 lecture)
Application of MVT & Darboux’s theorem (1 lecture)
L’Hospital Rule (1 lecture)
Taylor’s Theorem (1 lecture)
Riemann/Riemann Steiltjes Integral (1lecture)
 
Week 12: Riemann/Riemann Steiltjes Integral (1lecture)
Existence of Riemann Stieltjes Integral (1 lecture)
Riemann Stieltjes Integrable functions (1 lecture)
Properties of Riemann Stieltjes Integral (1 lecture)
Various results of Riemann Stieltjes Integral using step function (1 lecture)
Some more Results on Riemann Stieltjes Integral (1 lecture)",Introductory Course in Real Analysis
https://www.classcentral.com/course/global-disease-distribution-19044,"The Global Diseases Masterclass is part of the full-degree Masters of Public Health that the School of Public Health. By the end of this specialisation, our aim is that students will be able to critically apply epidemiological concepts to major global diseases and be able to appraise and recommend policy options to combat them.

Global Diseases Masterclass: Global Disease Distribution
In this course, we will introduce students to the most important trends and pattern in health and disease on a global scale. We will look at how health has improved over time, examine the trends for the future and look at between and within-country inequality in health. We will look at the methods that lie behind those statistics and think about different ways in which health can be conceptualised and measured. The course ends by considering the reason that might lie behind the patterns that we’ve pointed out and introducing the distinction between direct and structural interventions.The course ends by considering the reasons that might lie behind the patterns that we’ve described and introducing the concept of structural interventions.
      


          Introduction to Disease Masterclass: Disease Distributions and Trends
    -This module will look at the most important trends and patterns in health and disease around the world. You will see that health has improved enormously over time overall, but that these gains have been unequally distributed both between and within countries.

Disease Estimates
    -This module will look at exploring different health data sources and how we estimate statistics for specific diseases. You will also learn how disease estimates are generated.

Measuring disease
    -This module will consider the different metrics for evaluating health. You will also learn what DALYs are and why they are a useful metric for measuring diseases.

Disease Frameworks
    -This final module will step back and consider what factors may underpin the patterns of health and disease that have been examined in this course. As well as things that directly affect the risk of diseases, there are deeper factors that make some people more likely than others to be exposed to those risk factors. This leads to an introduction to the distinction between direct and structural interventions – a theme that is returned to in other courses in this specialisation.",Global Disease Masterclass: Global Disease Distribution
https://www.classcentral.com/course/wharton-business-financial-modeling-18841,"Wharton's Business and Financial Modeling Specialization is designed to help you make informed business and financial decisions. These foundational courses will introduce you to spreadsheet models, modeling techniques, and common applications for investment analysis, company valuation, forecasting, and more. When you complete the Specialization, you'll be ready to use your own data to describe realities, build scenarios, and predict performance.



          Course 1: Fundamentals of Quantitative Modeling- How can you put data to work for you? Specifically, how can numbers in a spreadsheet tell us about present and past business activities, and how can we use them to forecast the future? The answer is in building quantitative models, and this course is designed to help you understand the fundamentals of this critical, foundational, business skill. Through a series of short lectures, demonstrations, and assignments, you’ll learn the key ideas and process of quantitative modeling so that you can begin to create your own models for your own business or enterprise. By the end of this course, you will have seen a variety of practical commonly used quantitative models as well as the building blocks that will allow you to start structuring your own models. These building blocks will be put to use in the other courses in this Specialization.Course 2: Introduction to Spreadsheets and Models- The simple spreadsheet is one of the most powerful data analysis tools that exists, and it’s available to almost anyone. Major corporations and small businesses alike use spreadsheet models to determine where key measures of their success are now, and where they are likely to be in the future. But in order to get the most out of a spreadsheet, you have the know-how to use it. This course is designed to give you an introduction to basic spreadsheet tools and formulas so that you can begin harness the power of spreadsheets to map the data you have now and to predict the data you may have in the future. Through short, easy-to-follow demonstrations, you’ll learn how to use Excel or Sheets so that you can begin to build models and decision trees in future courses in this Specialization. Basic familiarity with, and access to, Excel or Sheets is required.Course 3: Modeling Risk and Realities- Useful quantitative models help you to make informed decisions both in situations in which the factors affecting your decision are clear, as well as in situations in which some important factors are not clear at all. In this course, you can learn how to create quantitative models to reflect complex realities, and how to include in your model elements of risk and uncertainty. You’ll also learn the methods for creating predictive models for identifying optimal choices; and how those choices change in response to changes in the model’s assumptions. You’ll also learn the basics of the measurement and management of risk. By the end of this course, you’ll be able to build your own models with your own data, so that you can begin making data-informed decisions. You’ll also be prepared for the next course in the Specialization.Course 4: Decision-Making and Scenarios- This course is designed to show you how use quantitative models to transform data into better business decisions. You’ll learn both how to use models to facilitate decision-making and also how to structure decision-making for optimum results. Two of Wharton’s most acclaimed professors will show you the step-by-step processes of modeling common business and financial scenarios, so you can significantly improve your ability to structure complex problems and derive useful insights about alternatives. Once you’ve created models of existing realities, possible risks, and alternative scenarios, you can determine the best solution for your business or enterprise, using the decision-making tools and techniques you’ve learned in this course.Course 5: Wharton Business and Financial Modeling Capstone- In this Capstone you will recommend a business strategy based on a data model you’ve constructed. Using a data set designed by Wharton Research Data Services (WRDS), you will implement quantitative models in spreadsheets to identify the best opportunities for success and minimizing risk. Using your newly acquired decision-making skills, you will structure a decision and present this course of action in a professional quality PowerPoint presentation which includes both data and data analysis from your quantitative models. Wharton Research Data Services (WRDS) is the leading data research platform and business intelligence tool for over 30,000 corporate, academic, government and nonprofit clients in 33 countries. WRDS provides the user with one location to access over 200 terabytes of data across multiple disciplines including Accounting, Banking, Economics, ESG, Finance, Insurance, Marketing, and Statistics.",Business and Financial Modeling
https://www.classcentral.com/course/edx-business-analytics-for-data-driven-decision-making-8215,"Virtually all managerial and leadership positions in the digital economy increasingly rely on data-driven decision making. Recent studies have shown companies who adopt ""Data-Driven Decision Management"" achieve significant productivity gains over other firms.
Having a solid grasp of the end-to-end process of making effective decisions with data will give you an edge, both in performing such analyses yourself, as well as in effectively managing teams of business analysts and data scientists.
In this course, part of both the Digital Leadership and Digital Product Management MicroMasters programs, you will learn the tools and techniques to become a data-driven or ""evidence-based"" manager.
You will learn the process of reframing a business question as a data question, reasoning about what data might be of assistance and how to obtain it, integrating and cleaning the data, performing the analysis, deriving and communicating insights from the analysis, and building the managerial culture to operate in this way and create competitive advantages from enterprise data.
This course is unique in the sense that it aims squarely at the needs of a manager in an analytically focused enterprise by providing both a hands-on introduction to the concepts, methods and processes of business analytics as well as an introduction to the use of analytics as the basis for creating a competitive advantage. 
Software Requirements
Completion of this course requires the use of Microsoft Power BI Desktop. Unfortunately, there is currently no version of Power BI Desktop for macOS or Linux operating systems. We encourage learners to secure access to a Windows environment, but if that is not possible, macOS and Linux users can run Power BI Desktop in a virtual Windows environment. The course provides steps for installing such an environment.



            Read more
          



None",Business Analytics for Data-Driven Decision Making
https://www.classcentral.com/course/swayam-biostatistics-and-design-of-experiments-5336,"Biostatistics is the application of statistics to different topics in biology including medicine, pharmacy, public health science, agriculture and fishery. It involves the analysis of data from experiments; its interpretation and drawing conclusion from the results. It is very relevant to all UG and PG level degree programmes majoring in Biotechnology and allied fields as well as practicing scientists. It involves the application of statistical theory to real-world problems, the practice of designing and conducting biomedical experiments and clinical trials. Design of experiments is planning experimental strategy, screening a large number of parameters and selecting the important ones, determining the minimum number of experiments and deciding on the mode and manner in which experiment have to be conducted. The course encompasses topics such as distribution of data, sample size, tests of significance, data reduction, regression analysis, comparison of performance of drugs in clinical trials, design of experiments, screening and second order designs.INTENDED AUDIENCE :UG/PG Biotech programmes (core or elective) and research scientists in biotechnology, clinical trials, agriculture etc and allied fieldsPREREQUISITES  :Basics of probability and statisticsINDUSTRY SUPPORT  :Biopharma, Agriculture, fisheries and Biotechnology companies.



COURSE LAYOUT Module 1 Introduction Experimental design strategy Data types/Binomial Distribution Poisson Distribution Normal Distribution Module 2 Standardized Normal Distribution/ t distribution t distribution/confidence interval Statistical tests t- tests t- tests – continued Module 3 t- tests – continued F- tests F- tests –continued ANOVA ANOVA-continued Module 4 ANOVA-continued ANOVA-continued ANOVA-continued ANOVA-continued ANOVA-continued Module 5 NORMALITY TEST/ODDS RATIO c2 distribution/test c2 distribution/test –continued c2 test Weibull distribution Module 6 Weibull distribution-contniued Weibull distribution-continued Nonparametric tests Nonparametric tests/Homogeneity of variance/Beta distribution Exponential / Hypergeometric distributions Module 7 Hypergeometric/Log normal distributions Design of Experiments (DOE) – Introduction Factorial design Full Factorial design Fractional Factorial design Module 8 Other designs Second order designs Second order designs-continued Regression Analysis Control Charts",Biostatistics and Design of experiments
https://www.classcentral.com/course/teach-impacts-technology-data-11234,"In this course you’ll focus on how constant data collection and big data analysis have impacted us, exploring the interplay between using your data and protecting it, as well as thinking about what it could do for you in the future. This will be done through a series of paired teaching sections, exploring a specific “Impact of Computing” in your typical day and the “Technologies and Computing Concepts” that enable that impact, all at a K12-appropriate level. 

This course is part of a larger Specialization through which you’ll learn impacts of computing concepts you need to know, organized into 5 distinct digital “worlds”, as well as learn pedagogical techniques and evaluate lesson plans and resources to utilize in your classroom. By the end, you’ll be prepared to teach pre-college learners to be both savvy and effective participants in their digital world.

In this particular digital world (personal data), you’ll explore the following Impacts & Technology pairs --

Impacts (Show me what I want to see!): Internet Privacy, Custom Ads, Personalization of web pages
Technologies and Computing Concepts: Cookies, Web vs Internet, https, Web Servers

Impacts (Use my data…. But protect it!): Common Cybersecurity knowledge levels, ISP data collection, Internet design, finding out what is known about you online, software terms and services
Technology and Computing Concepts: DNS, Cryptography (ciphers, hashing, encryption, SSL), Deep and Dark Web

Impacts (What could my data do for me in the future?): What is Big Data, Machine Learning finds new music, Wearable technologies.
Technology and Computing Concepts: AI vs ML, Supervised vs Unsupervised learning, Neural Networks, Recommender systems, Speech recognition

In the pedagogy section for this course, in which best practices for teaching computing concepts are explored, you’ll learn how to apply Bloom’s taxonomy to create meaningful CS learning objectives, the importance of retrieval-based learning, to build learning activities with online simulators, and how to use “fun” books to teach computing.

In terms of CSTA K-12 computer science standards, we’ll primarily cover learning objectives within the “impacts of computing” concept, while also including some within the “networks and the Internet” concepts and the “data and analysis” concept.  Practices we cover include “fostering and inclusive computing culture”, “recognizing and defining computational problems”, and “communicating about computing”.
      


            Read more
          



          Course Orientation
    -Welcome!  Are you interested in teaching about the impacts of your personal data in the digital world?   To learn more about the computation and computing concepts that underlie the technologies using that data?  We'll be using a problem-based approach to explore interesting ways to teach concepts of networks and the internet, data and analysis, and even algorithms and data representation.  Finally, we'll read a chapter from a children's fiction book -- ""The Secret Code Menace"" and identify some computer science learning outcomes for that chapter.

Data Collection
    -Why is it that when you are shopping for an item on one website, you start seeing ads for it other in other places? How do websites know (and quite well) what products and services to recommend their customers and users? We'll look at how the internet has evolved to personalize people's experiences while online.  Then to finish up this week, we will learn about how cookies and web servers work, as well as how HTTPS keeps connections secure.

Data Privacy
    -This week we'll look at aspects of our personal data such as -- when we we do not want it used, how we can keep it safe, and what control we have.  In this Technology Exploration, we'll learn about ciphers, hashing, cryptography, and encryption.  Also, do you know the difference between the ""deep"" web and the ""dark"" web? (You will know by the end of this week!)

Data Use
    -So far we have learned about data collection and privacy. Now we will spend the week covering some ways that data is used, so we must introduce big data. Along with our exploration of this progressive concept, we will help you connect the use of big data to machine learning though an activity designed to guide your understanding in a fun way!

Impacts of Computing and Pedagogy
    -Next we'll let you choose what you want to explore around  ""impacts of computing"" for the technologies we've explored in this world.  Along with that, we'll introduce another ""Formative Classroom Assessment Technique"" (FACT) and have you practice how you would use this in the classroom.  For our pedagogical focus, we'll look at how retrieval practice helps you learn far more effectively than ""re-studying"" and how to define the learning objectives for a given learning activity using Bloom's taxonomy.  Finally, you'll get to read a short chapter from a children's fiction book ""The Secret Code Menace"" and identify for yourself what kids can learn from reading it!","Teaching Impacts of Technology: Data Collection, Use, and Privacy"
https://www.classcentral.com/course/edx-essential-math-for-data-analysis-using-excel-online-12164,"Starting with the absolute basics of math and data, this course builds up your analyst skills while removing the mathematical hurdles and barriers that often come with beginning to learn how to analyze data. This course is intended for anyone with the desire to do data analysis and who would like to learn the math behind it all in a simplified way, as well as for anyone who would like a thorough refresher on the essentials. Learn how to handle different data types, understand mathematical notation, become proficient in handling data sets and summary statistics, and even get a sneak peek into how to be effective at making stctistical inferences and predictions, all told in a way to maximize your understanding—so that afterward, you can be well on your way toward analyzing data in any field or discipline.
      


          Module 1: Introduction to Data and VariablesModule 2: Summarizing Data with Distributions and GraphsModule 3: Summary StatisticsModule 4: Business Statistics Module 5: Introduction to Inferential Math and Forecasting",Essential Math for Data Analysis using Excel Online
https://www.classcentral.com/course/edx-business-intelligence-for-iot-solutions-12661,"Are you ready to create data visualization reports that help you to discover hidden trends in your business data? Do you want to get up-to-speed on the latest tools?  This course guides students through a series of lab activities that provide hands-on experience querying and visualizing data. After completing this course, students will be able to construct IoT data visualizations that allow a business to gain insights related to its operations. The first module examines the characteristics of time series data – how it can be used for analysis and prediction. It specifically walks the student through how IoT telemetry data is typically generated as time series data and techniques for managing and analyzing it with Azure Time Series Insights.Module two takes a closer look at specific features of Azure Time Series Insights – how it can be used to store, analyze and instantly query massive amounts of time series data.In the third module, students get a general introduction to using Power BI, with specific emphasis on how Power BI can load, transform and visualize IoT data sets.In the final module, students will move from using BI with static IoT data sets to working with real time streaming IoT data.  Students use Azure Stream Analytics as a data source for Power BI and explore the unique capabilities and insights that provides.
      


          This course is completely lab-based. There are no lectures or required reading sections. All of the learning content that you will need is embedded directly into the labs, right where and when you need it. Introductions to tools and technologies, references to additional content, video demonstrations, and code explanations are all built into the labs.Some assessment questions will be presented during the labs. These questions will help you to prepare for the final assessment.The course includes four modules, each of which contains two or more lab activities. The lab outline is provided below.Module 1: Time Series Data

Lab 1: Introducing Time Series Insights
Lab 2: Producing Simulated Data
Lab 3: Provisioning Time Series Insights
Lab 4: Analysis with Time Series Insights

Module 2: Visualizing and Querying Data

Lab 1: Setting Up Data Generation
Lab 2: Using Time Series Analysis Patterns
Lab 3: Using Advanced TSI Features
Lab 4: Managing Time Series Insights

Module 3: Power BI and IoT

Lab 1: Introducing Power BI
Lab 2: Transforming Data
Lab 3: Modeling Data
Lab 4: Visualizing Data

Module 4: Streaming with Power BI

Lab 1: Using Power BI with Streaming Data
Lab 2: Configuring Power BI
Lab 3: Using Power BI in an IoT architecture
Lab 4: Sharing Power BI Dashboards",Business Intelligence for IoT Solutions
https://www.classcentral.com/course/persuasive-writing-5729,"This course is available for a limited time only. Enrollments will close on the 27th of June 2019. In this project-centered course, you will learn everything you need to research and present an effective and persuasive position paper or policy advice. We recommend you sign up for a certificate as this course is on premium grading and you will only enjoy the full benefit of the project if you can join in with the assignments. In addition this course contains the exciting opportunity to research and analyze historical decisionmaking, international relations, business cases and battles  in an effort to truly understand constructing a convincing argument.

Most important decisions in life, and many unimportant ones, are taken after some degree of reflection. If those decisions affect other people, we may take some advice and we might even follow it. The larger the issue and the greater number of people involved, the more likely that advice process will be institutionalised. Most of us tend to think of policy advice in the context of things as counsel to politicians in matters of national security or policy-making by governments. Of course, we also know that it takes place on a regular basis within businesses and other organisations. But it also happens in local politics and in local campaigns and in everyday life. Every time you try to influence someone’s decision, you are offering policy advice. Even if you are not planning to be an active advisor, the discipline of collecting and arranging the necessary materials is useful in all kinds of research and writing exercises. Writing a policy advice is what we call a ‘transferrable skill’.

The course requires an academic approach, but no previous experience. The projects can be completed by both novices and advanced learners. One thing is certain. Both groups will learn a lot from the experience. 

What is a policy advice?
In its simplest form, a policy advice is a short paper that argues your position on a particular issue and the course of action you propose. It also tries to convince the audience to adopt your position and to take action on your advice. 

What advice can I give?
You may well have a topic already, based on your work or your social situation. This could be a piece of equipment your firm might want to buy or a new market it might wish to enter. It could be a campaign for a local play area or against pollution in local ground-water. In this case it is a question of arranging and presenting your position, and discussing it with others in a similar position.

 On the other hand, you might be open for suggestions. In this case, we have prepared some topics covering business case studies, issues of current affairs, and historical examples. For example, you could look into the archives advise Harry Truman to adopt a different policy towards the Soviet Union at the start of the Cold War. Alternatively you could suggest advise the Incas in 1532 not to be so trusting in their dealings with the Spanish. After all, you will know the outcome. So the course should appeal to everyone interested in practical policy-making as well as amateur historians, strategy gamers. Everyone can have fun applying these techniques to their favourite topics.

What will I learn?
The project-based course is designed so that you learn by doing rather than by listening. The assignments that you complete, the feedback that you receive and the assignments of others that you read and upon which you comment are all intrinsic parts of the course. The lectures are designed to act as signposts along the way and the readings allow you to explore some of the issues in greater depth. During the whole course experience you will learn to:
•	Frame a starting position for your own research
•	Use search engines to locate materials required for your advice
•	Explore ‘academic’ data-bases
•	Annotate your sources correctly
•	Target your research for statistical data
•	Choose a visualisation for your statistical data 
•	Construct an argument in a logical manner
•	Build up the logic in each paragraph 
•	Conduct a SWOT analysis
•	Conduct a Risk Analysis
•	Present the materials in a position paper
•	Convert the position paper to a policy advice
•	Recognise the policy-making hierarchy and shaping the advice accordingly 
•	Write a powerful and effective PowerPoint presentation
•	Place your project in the ‘real world’ context of the policy-cycle
•	And ... Discover a great, great deal about your chosen topic.

How much time will the course take?
The lecture materials in each module will themselves take no more than 30 minutes to view and review. Each module is accompanied by selected reading materials, but these are not compulsory. There is also a Skills Lab with extra literature and videos to assist you to improve your writing, computer and presentation skills. Combining these parts of the course, and assuming that you make some use of all the facilities offered, the ‘on-platform’ time should take no more than an one hour for each module. 
The project-time depends on the degree of advancement in the project choice. If you come with a ready prepared idea and knowledge of the area, then the project-time should in total be approximately four to five hours. If you decide to use the suggestions in our collections, then you should add another three to four hours to familiarise yourself with the subject and the necessary materials. If you should decide to start a completely new project from scratch, the you would need to add another three hours or so to orient yourself in the problem and then locating the required materials.

About Project-Centered Courses: Project-centered courses are designed to help you complete a personally meaningful real-world project, with your instructor and a community of learners with similar goals providing guidance and suggestions along the way. By actively applying new concepts as you learn, you’ll master the course content more efficiently; you’ll also get a head start on using the skills you gain to make positive changes in your life and career. When you complete the course, you’ll have a finished project that you’ll be proud to use and share
      


            Read more
          



Getting StartedIn this module, after a brief introduction, we will start our policy advice by defining the issue and finding sources. Check out our Resource section if you have not yet decided on an issue for your project. Perhaps you would like to use one of our cases and engage in a simulation?Writing the Position PaperIn this module we will learn how to construct an argument, which will form the backbone of your position paper or policy advice, and think about how to visualise the data supporting the argument. This is the second stage towards your policy advice. Writing the Policy AdviceIn this module you will turn your position paper into a policy advice, but first, we will teach you to apply a SWOT Analysis and Risk Assessment. Do not forget to use the Skills Lab from module 2.Presentation and ReflectionIn this module you will create a presentation to present your policy advice to your target audience, and we will reflect on the course.",Be Persuasive: Write a Convincing Position Paper or Policy Advice (Project-Centered Course)
https://www.classcentral.com/course/edx-implementing-dhcp-in-microsoft-windows-server-5341,"Interested in gaining the basic skills needed to go beyond simple IP address management? It may be time to consider management tools like DHCP and DNS in your quest to optimize your network infrastructure management.
This self-paced computer science course is an introduction to working with Dynamic Host Configuration Protocol (DHCP) in a Windows Server networked environment where you’ll have an opportunity to learn the basics of IP address management, DHCP scope creation and configuration and how to manage and maintain a DHCP infrastructure.
This fundamentals course will prepare you for more advanced courses in Windows Server administration.
You can take this course before or after course Implementing DNS in Microsoft Windows Server. Both courses provide essential skills for working with networks.",Implementing DHCP in Microsoft Windows Server
https://www.classcentral.com/course/udacity-developing-android-apps-7755,"As the first course in the Android Developer Nanodegree,  Developing Android Apps is the foundation of our advanced Android curriculum. This course blends theory and practice to help you build great apps the right way. In this course, you'll work with instructors step-by-step to build a cloud-connected Android app, and learn best practices of mobile development, and Android development in particular.Why Take This Course?With over 1 billion Android devices already activated, Android represents an incredible opportunity for developers.As Android continues to grow beyond smartphones, it will become the brains behind invisible, ubiquitous cloud-connected computing. The skills you learn in this course will help you build awesome apps for smartphones and tablets today, and propel you towards exciting opportunities in Android's future.By the end of this course, you’ll build a cloud-connected Android app, and understand the tools, principles, and patterns that underlie all Android development. You’ll understand the challenges associated with developing for the mobile environment (and how to overcome them), learn how to build a great user experience for Android devices, and apply this knowledge to your own projects.



Creating Project SunshineLearn how to create and run a simple Android appCreate simple layouts for Android Learn about the Android Studio IDELoading Data from the InternetConnect to the Internet and communicate with web APIs Learn about threading and how to make requests without slowing down your appLearn how to add menus to your appRecyclerViewLearn about the components that convert a list of data into visual UI elementsIntentsLearn the difference between Explicit and Implicit Intents.Learn how to navigate inside your apps using intents.Learn how to create Intents that apps outside your control can respond to. The Application LifecycleUnderstand the phases of the Android application lifecycle.Learn how to persist data between orientation and other changes.PreferencesAllow users to customize some aspects of your appConsider when to omit or add a preferenceCreating SQLite DatabasesImplement a SQLite databaseMake queries to and modify that database in your appIntroduction to Content ProvidersLearn how Content Providers provide an interface to share dataConsume data from an already existing ContentProviderBuilding a Content ProviderLearn to build a Content ProviderBackground TasksComing soon!Completing the UIComing soon!Polishing the UIComing soon!",Developing Android Apps
https://www.classcentral.com/course/mathematical-foundations-cryptography-9535,"Welcome to Course 2 of Introduction to Applied Cryptography. In this course, you will be introduced to basic mathematical principles and functions that form the foundation for cryptographic and cryptanalysis methods. These principles and functions will be helpful in understanding symmetric and asymmetric cryptographic methods examined in Course 3 and Course 4. These topics should prove especially useful to you if you are new to cybersecurity. It is recommended that you have a basic knowledge of computer science and basic math skills such as algebra and probability.
      


          Integer Foundations
    -Building upon the foundation of cryptography, this module focuses on the mathematical foundation including the use of prime numbers, modular arithmetic, understanding multiplicative inverses, and extending the Euclidean Algorithm. After completing this module you will be able to understand some of the fundamental math requirement used in cryptographic algorithms. You will also have a working knowledge of some of their applications.

Modular Exponentiation
    -A more in-depth understanding of modular exponentiation is crucial to understanding cryptographic mathematics.  In this module, we will cover the square-and-multiply method, Eulier's Totient Theorem and Function, and demonstrate the use of discrete logarithms. After completing this module you will be able to understand some of the fundamental math requirement for cryptographic algorithms. You will also have a working knowledge of some of their applications.

Chinese Remainder Theorem
    -The modules builds upon the prior mathematical foundations to explore the conversion of integers and Chinese Remainder Theorem expression, as well as the capabilities and limitation of these expressions. After completing this module, you will be able to understand the concepts of Chinese Remainder Theorem and its usage in cryptography.

Primality Testing
    -Finally we will close out this course with a module on Trial Division, Fermat Theorem, and the Miller-Rabin Algorithm.  After completing this module, you will understand how to test for an equality or set of equalities that hold true for prime values, then check whether or not they hold for a number that we want to test for primality.",Mathematical Foundations for Cryptography
https://www.classcentral.com/course/columbiax-data-science-for-executives-18406,"Data science is making us smarter and more innovative in so many ways. How does it all work? In this Data Science and Analytics Professional Certificate program you will gain insight into the latest data science tools and their application in finance, health care, product development, sales and more. With real world examples, we will demonstrate how data science can improve corporate decision-making and performance, personalize medicine and advance your career goals.
Taught by a distinguished team of professors at Columbia University’s Data Science Institute, this program is perfect for anyone who wants to understand basic concepts in data science without getting into the weeds of programming. Aimed at organization leaders, business managers, health care professionals and anyone considering a career in data science, this program will steep learners in the fundamentals of statistics, machine learning and algorithms. It will also introduce emerging technologies such as the Internet of Things (IoT) , or wirelessly connected products, and techniques that allow computers to summarize mountains of text, audio and video. Concrete examples provided throughout the program will ensure that learners fully grasp and master key concepts.



Courses under this program:Course 1: Statistical Thinking for Data Science and Analytics
Learn how statistics plays a central role in the data science approach.
Course 2: Machine Learning for Data Science and Analytics
Learn the principles of machine learning and the importance of algorithms.
Course 3: Enabling Technologies for Data Science and Analytics: The Internet of Things
Discover the relationship between Big Data and the Internet of Things (IoT).",Data Science for Executives
https://www.classcentral.com/course/grand-challenges-6383,"The purpose of this course is to introduce you to current global challenges in conservation and development, including changes in both sectors.  This course will inspire you to rethink assumptions to address global challenges in conservation and development, and introduce you to new models and approaches that harness technological, behavioral, and financial innovation. This course will equip you with the insights, skills and approaches necessary to successfully overcome these obstacles.  In addition, this course will provide participants with the tools, models, and approaches to address global grand challenges in conservation and development, to question fundamental assumptions, and to create and execute new solutions. Course participants will be trained in the processes around innovation and design to address global grand challenges.  This includes content focused on constructing innovation pipelines, principals of design and engineering unique to the developing world and to conservation (Design for the Other 90%), on harnessing and developing disruptive technologies, principles of behavior and marketing, and on overcoming the challenges with setting up social ventures.

The course format will facilitate the development of a global community of innovators who will help solve the current and future grand challenges our planet faces in conservation and development, and will encourage thinking about how to do so that rethinks traditional assumptions and approaches within both conservation and development.  This course will leverage the incredible idealism and interest in social entrepreneurship, design, and innovation among the millennials, in the US and abroad, and is intended to appeal to those interested in the maker movement.   It also seeks to engage individuals in the developing world who are closest to the problems of conservation and development,  who would benefit from the approaches taught in the course, and who can leverage their own knowledge of local culture.
      


            Read more
          



Welcome and Course OverviewThis course will focus on new approaches to development problems that harness technological and financial innovations, coupled with entrepreneurship, to improve the scale, sustainability, and efficacy of development and conservation approaches. Specifically, the course will seek to ask: How can the next generation of technologies, coupled with new financial innovations and approaches, help address conservation and development challenges and rethink assumptions? How can science and technology help us deliver more services with less costly infrastructure?  To achieve these goals, the course will be split into four segments: 1) Review of the major challenges, current approaches, and criticisms of those approaches for development, including what development has been effective; 2) Review of the major challenges for conservation and the current debate in the field of how we may transform conservation; 3) Rethinking assumptions to solving the grand challenges in conservation and development, including review of new technologies and innovations; and 4) Design, marketing, and entrepreneurship for addressing global grand challenges.  To get started,  begin by watching the Welcome Video, view the Course Overview document, and review the Course Resources information I provided. I hope you enjoy the course!Grand Challenges of DevelopmentMost stereotypes of the developing world paint a simple picture of a subsistence farmer with impoverished children. However, when we dig deeper into the data, we find the developing world exhibits substantial complexity that belies traditional stereotypes. In fact, many of our assumptions about the developing world and how to address its problems may be wrong. In this module we will review, with lectures and interviews with some of the world’s best experts on the subject, many of the Grand Challenges of Development—food security, global heath, governance & the rule of law, and response to humanitarian disasters. We will also review the global development-industrial complex, and how it both benefits and undermines the development aspirations of nation-states. Finally, this module engages deeply with two important development case studies: the 2010 earthquake in Haiti and the 2014–2015 Ebola outbreak in West Africa, from those who have been at the front lines of the humanitarian response to these tragedies. To get started, begin by watching the video ""Paradoxes in Development."" Grand Challenges in ConservationWe are in the middle of a period of extraordinary change on the planet, a sixth great mass extinction. Unlike the previous mass extinction events, this is the first extinction in Earth’s history that is driven by the actions of a single species. During this period, the earth has been fundamentally changing physically, chemically, biologically, and ecologically. The problems of extinction and habitat destruction are increasing exponentially, while our solutions are incremental. Conservation remains at times technophobic, risk-averse, reactionary, intransigent, and uninspiring, but it is changing. Much as humans have caused these problems, we have the ability to solve them. This module will present the Grand Challenges in Conservation, from wildlife trade, to energy, to climate change, to addressing the underlying drivers of global extinction. You will hear from leaders of some of the world’s most important conservation organizations working on these topics. We will examine the current debate underway in the future of conservation.  This week's module will demonstrate ways to: (1) apply our unparalleled innovation capacity and harness our technological advances to engineer resilience to global environmental changes; and (2) change demand and incentive structures to alter our behavior, and improve our ability to monitor and protect species around the world. Finally, this module looks in-depth at one of the world’s most important biodiversity hotspots, Madagascar, an 8th continent that has served as a laboratory for evolution. To get started, begin by watching the video ""Conservation Grand Challenges.""Exponential Technology and Open Source InnovationThe democratization of science and technology has given us powerful new tools to apply to the grand challenges identified in previous modules. Technology has gained exponentially in processing power, memory capacity, sensor density and number, pixel capacity, and storage. Current advances in molecular biology are rivaling (and in some cases overtaking) the rate of change that we have seen in computing and information technology. The democratization of information technology, coupled with the global spread of mobile platforms, particularly smartphones, allows for revolutionary new approaches in conservation and development that were impossible a decade ago. We have new ways of monitoring the planet from low cost sensors on artisanal fishing boats, to drones and to nanosatellites, that allow us to monitor the planet at multiple scales with unprecedented resolution and cadence. 3D Printing allows for faster prototyping and decentralization of manufacturing. Greater degrees of global connectivity allow us to crowd source the world for new ideas through open innovation. Open source approaches can help develop and/or source new ideas or products, distribute the burden for collecting and analyzing data, co-design new solutions, and share in the burdens of research, publication, and funding, while simultaneously engaging the public. This module is an introduction to these new tools and technologies for conservation and development through lectures, technology demos, and interviews with leading engineers, innovators, and entrepreneurs who are at the cutting edge of some of these areas. These interviews include leaders at Indiegogo, XPRIZE, Planet Labs, and USAID. You will receive an in-depth look at open source innovation, including how to run a crowdfunding campaign. You will closely examine the internal mechanics of two of the Grand Challenges for Development programs: maternal and child health, and using innovation to design a better protective suit for Ebola.  To get started, view the video ""Emerging Technologies for Conservation and Development, Part 1.""Behavioral Innovation, Financial Innovation, and DesignBehavior is the cutting edge of adaptation. It can be the fastest way to meaningful change and also the biggest barrier against it. Behavioral innovations such as incentives and rewards, harnessing competition and gamification, knowledge gaps, social pressure and networks, fear, self-identity and self-worth, and altruism provide powerful new tools to accelerate change and break down barriers. Financial innovations are a subset of behavior change. They include pay-for-performance mechanisms such as direct payments for conservation, advance market commitments, social impact bonds, conservation finance, conservation credit trading platforms, as well as harnessing new tools and platforms such as crowdfunding, microinsurance, microcredits, peer-to-peer lending, pay-as-you-go mechanisms, and franchise schemes. Finally, design is the application of behavioral science and anthropology to products and systems. When done well, design can integrate the needs of people and species; the possibilities of technology; and the demand for impact, sustainability, and scalability.  This week's content is an introduction to new models of behavioral and financial innovation, and design theory. This module features lectures and interviews with Asher Jay, a creative conservationist who uses art and marketing to end wildlife trafficking, Krista Donaldson, the CEO of Design Revolution (D-Rev), and Ron Gonen, the cofounder of Recyclebank, a model of how behavior change, technology, and entrepreneurship can solve environmental challenges. To get started, view the video Design for Impact.""EntrepreneurshipOnce you have your idea or innovation, how do you translate it into an enterprise (entrepreneurship) or a startup within a company or institution (intrapreneurship)? How do you influence other companies to adopt your novel approach (extrapreneurship)? How do you create a social enterprise, a value-driven organization that borrows heavily from tools of the private sector, or a new for-profit venture that has a double bottom line – the twin aims of both profit and impact? This module is an introduction to the art of the start – from understanding how to think about your business model, to putting together a team, to pitching for funding, and getting to scale.  To get started, view the video ""Introduction to Social Entrepreneurship.""",Innovation and Design for Global Grand Challenges
https://www.classcentral.com/course/miriadax-excel-avanzado-2347,"Data management and graphics, databases, pivot tables, and advanced array formulas, Solver, sensitivity analysis and scenario management, forms and templates, automate processes by creating macros, introduction to programming in Visual Basic for Applications ( VBA).
Knowledge required:
Initial knowledge of Excel. No previous knowledge required of Macros.



Module 0: Introduction
Module 1: Previous concepts
Module 2: Data management and graphics
Module 3: Customizing Excel
Module 4: Databases
Module 5: Advanced Formulae 1
Module 6: Advanced Formulae 2
Module 7: Data Analysis
Module 8: Dynamic Tables 1
Module 9: Dynamic Tables 2
Module 10: Creating Macros
Module 11: VBA Programming 1
Module 12: VBA Programming 2
Closing the course",Excel Avanzado
https://www.classcentral.com/course/pennx-computer-science-essentials-for-software-de-18407,"Gain the systematic knowledge required to be a software developer.
In this professional certificate program, you will learn essential computer science concepts for software development ranging from the fundamentals of object-oriented programming to using efficient algorithms to design high-quality software.
This program begins with the basic concepts of Java, one of the industry’s most commonly used programming languages, and progresses into best practices in modern software development to developing efficient algorithms using sophisticated data structures for complex computational tasks. Finally, you will develop interactive and data-driven web apps using JavaScript.
This program will give you a thorough understanding of core principles of professional software development.



Courses under this program:Course 1: Software Development FundamentalsLearn the fundamentals of object-oriented programming in Java, as well as best practices of modern software development.Course 2: Data Structures and Software DesignLearn how to select, apply, and analyze the most appropriate data representations in your code and design high quality software that is easy to understand and modify.Course 3: Algorithm Design and AnalysisLearn about the core principles of computer science: algorithmic thinking and computational problem solving.Course 4: Programming for the Web with JavaScriptLearn how to develop dynamic, interactive, and data-driven web apps using JavaScript.",Computer Science Essentials for Software Development
https://www.classcentral.com/course/diabetes-genomic-medicine-5048,"##
There have been huge advances in the field of genetics in the last 10 years since the sequencing of the first human genome in 2003. It is now possible to analyse all 20,000 human genes in a single experiment, rather than focussing on one gene at a time. We are in the genomics era.
This free online course will introduce the topic of genomics, using the University of Exeter’s research expertise in diabetes, to illustrate the clinical application of current genomics knowledge.
Explore the impact of genomic testing
We will use patient experiences to discuss the impact and value of a genetic diagnosis for diabetes for patients, their families and the clinicians responsible for their care. You will learn about the value of understanding the underlying pathological mechanism of a disease, to enable the progression from genomic testing to improvements in clinical care.
Find out how genomics can inform us about disease risks
You will learn about: the different modes of inheritance for diabetes, including polygenic, monogenic, mitochondrial and epigenetic; the molecular basis of these inheritance patterns; and how this relates to risk for individuals, families and populations.
Understand the strategies for genomic testing
You will be taken through the process of discovering novel genetic mutations in the genome, including intergenic regions, previously thought to play a minor role in gene function. This will include thinking about the pattern of inheritance, to design a strategy for gene discovery, through to the latest laboratory techniques used for genomic sequencing.
There will also be an introduction to the bioinformatics resources and techniques used to interpret the wealth of genomic data generated by the techniques described.
We won’t be able to join the discussions ourselves, so we hope that the course will be one that develops a strong learning community. We encourage you to participate fully in discussions, to support other learners and to share knowledge where possible, and hope that you will enjoy interacting with and learning from each other in this way.
This course is designed for anyone who wants to learn about how the genomic era is changing medical science, including healthcare professionals, science undergraduates and non-specialists. There are complex scientific elements within the course which non-specialists might not feel the need to engage with in as much depth as others, but there are still benefits from covering the overall subject matter.
Healthcare professionals might find the Certificate of Achievement for this course useful for providing evidence of Continuing Professional Development (CPD), or commitment to their career.



            Read more",Genomic Medicine: Transforming Patient Care in Diabetes
https://www.classcentral.com/course/edx-modeling-climate-change-2814,"Bringing together insights from physics, chemistry, biology, earth and atmospheric sciences -- and even some economics -- this course is geared to curious enthusiasts, allowing them to work with real climate data and simulations of the earth’s changing climate.
 
This eight-week class takes a quantitative approach to the science of global warming and will enable students to understand the greenhouse effect, the planet's carbon cycle, and how burning fossil fuel affects that cycle; and to evaluate the potential severity of humans’ impact on Earth’s climate.",Modeling Climate Change
https://www.classcentral.com/course/edx-deep-learning-with-python-and-pytorch-11733,"The course will teach you how to develop Deep Learning models using Pytorch while providing the necessary deep-learning background.We'll start off with PyTorch's tensors and its Automatic Differentiation package. Then we'll cover different Deep Learning models in each section, beginning with fundamentals such as Linear Regression and logistic/softmax regression.We'll then move on to Feedforward deep neural networks, the role of different activation functions, normalization and dropout layers.In the final part of the course, we'll focus on Convolutional Neural Networks and Transfer Learning (pre-trained models). Several other Deep Learning methods will also be covered.
      


          Module 1 – Introduction to Pytorch 

What’s Deep Learning and why Pytorch
1-D Tensors and useful Pytoch Functions
2-D Tensors and useful functions
Derivatives and Graphs in Pytorch
Data Loader

 Module 2 – Linear Regression

Prediction 1D regression
Training 1D regression
Stochastic gradient descent, mini-batch gradient descent
Train, test, split and early stopping
Pytorch way
Multiple Linear Regression

Module 3 - Classification 

Logistic Regression
Training Logistic Regressions Part 1
Training Logistic Regressions Part 2
Softmax Regression

 Module 4 - Neural Networks 

Introduction to Networks
Network Shape Depth vs Width
Back Propagation
Activation functions

Module 5 - Deep Networks 

Dropout
Initialization
Batch normalization
Other optimization methods

Module 6 - Computer Vision Networks 

Convolution
Max Polling
Convolutional Networks
Pre-trained Networks",Deep Learning with Python and PyTorch
https://www.classcentral.com/course/edx-amazon-sagemaker-simplifying-machine-learning-application-development-12511,"Machine learning is one of the fastest growing areas in technology and a highly sought after skillset in today’s job market.  
This course will teach you, an application developer, how to use Amazon SageMaker to simplify the integration of Machine Learning into your applications. Key topics include: an overview of Machine Learning and problems it can help solve, using a Jupyter Notebook to train a model based on SageMaker’s built-in algorithms and, using SageMaker to publish the validated model. You will finish the class by building a serverless application that integrates with the SageMaker published endpoint.  
Learn from AWS Training and Certification expert instructors through lectures, demonstrations, discussions and hands-on exercises* as we explore this complex topic from the lens of the application developer.
Added Bonus: Students who enroll in this course as a verified learner and complete this course by May 31, 2020 become eligible to earn a voucher for the AWS Certified Machine Learning - Specialty practice exam. This practice exam voucher will allow you to test your Machine Learning skills in an online exam environment and will review some of the subjects covered in this course. At a $40 value, the practice exam voucher is available only to students who earn a Verified Certificate through edX.  
*Note that there may be a cost associated with some exercises. If you do not wish to incur additional expenses, you may view demonstrations instead.



            Read more
          



Welcome to Machine Learning with Amazon SageMaker

Course Introduction 
Welcome to Machine Learning with SageMaker on AWS
Course Welcome and Student Information
Meet the Instructors
Introduce Yourself



Week 1


Introduction to Machine Learning with SageMaker on AWS 
Introduction to Week 1
What we we use ML for?
Diving Right In
What is Amazon SageMaker


WeeklyQuiz, Readings, Resources, Discussion 
Week 1 Notes and Resources
Week 1 Quiz
Week 1 Discussion



Week 2


Amazon SageMaker Notebooks and SDK 

Introduction to Week 2


Amazon SageMaker Notebooks 
Introduction to Jupyter Notebooks
Notebooks and Libraries: Cleaning and Preparing Data
Exercise 2.1 Walkthrough
Exercise 2.1: Create Your Notebook Instance (Optional)


Weekly Quiz, Readings, Resources, Discussion 
Week 2 Notes and Resources
Week 2 Quiz
Week 2 Discussion



Week 3


Amazon SageMaker Algorithms 
Introduction to Week 3


ML and Amazon SageMaker Terminology 
SageMaker/ML Terminology and Algorithms
Hyperparameter Tuning


Amazon SageMaker Algorithms 
k-means Algorithm Walkthrough
Introduction to Exercise 3.1
Exercise 3.1: Using the k-means Algorithm (Optional)
XGBoost Algorithm Walkthrough (Part 1)
XGBoost Algorithm Walkthrough (Part 2)
XGBoost Algorithm Walkthrough (Part 3)
Introduction to Exercise 3.2
Exercise 3.2: Using the XGBoost Algorithm (Optional)


Weekly Quiz, Readings, Resources, Discussion 
Week 3 Notes and Resources
Week 3 Quiz
Week 3 Discussion



Week 4

Application Integration 
Introduction to Week 4


Integrating Amazon SageMaker with your Applications 
Serverless Recap
Exercise 4.1 Walkthrough
Exercise 4.1: Python Movie Recommender (Optional)
Bring Your Own Models
Bringing Your Own Models: MXNet and TensorFlow


Weekly Quiz, Readings, Resources, Discussion 
Week 4 Notes and Resources
Week 4 Quiz
Class Wrap Up
Course Survey
Week 4 Discussion


End of Course Assessment (Verified Certificate Track Only)",Amazon SageMaker: Simplifying Machine Learning Application Development
https://www.classcentral.com/course/edx-learning-analytics-fundamentals-9283,"The demand for data science and learning science skills has continued to increase as classrooms, labs, and organizations look to optimize their data and improve learning environments for students and employees. The UTArlingtonX Learning Analytics courses will give you the opportunity to gain invaluable knowledge and expertise in this growing field.
In this introductory course, you will develop a solid understanding of fundamental learning analytics theories and processes, and explore different types of educational data. You will gain experience working with educational data sets and the R programming language, and hear from a diverse set of voices in the field. Finally, you will also consider ethics and privacy issues, as well explore how to work as part of a team in a domain that is becoming increasingly cross-disciplinary.
By grasping these fundamental areas, you will have a better understanding of the field of learning analytics and be able to apply skills to any occupation that utilizes educational data.



Week 1: What are learning analytics?
Week 2: What types of data will you work with?
Week 3: What types of things will you do?
Week 4: How do you work as part of a team or within an organization?",Learning Analytics Fundamentals
https://www.classcentral.com/course/edx-the-science-and-practice-of-sustainable-development-7269,"This course is part of the Leadership in Global Development MicroMasters program. In order to get the most out of this course, we recommend that you have experience working in the development sector or a strong interest in this area. We also recommend that you complete the other three coursesthat make up the Leadership in Global Development MicroMasters program: Leaders in Global Development, Adaptive Leadership in Development, and Critical Development Perspectives. 
This course introduces the origin and key concepts of sustainability and how to apply those to sustainable development practice.
Sustainable development will be explored through theories and case studies from a range of disciplines, and a particular focus will be on how the Sustainable Development Goals (SDG) interrelate in practice. You also will learn about planetary boundaries, urbanisation and growing inequality, to show how integral sustainable development is to our everyday existence.
This course will attempt to provide key content knowledge to bridge the science and the practice of the application and enhancement of sustainable development. The course draws on contemporary examples to address the world's most urgent challenges, with emphasis on the linkages between science and policy.



Module 1 - The History and Politics of Sustainable Development 
Module 2 - The Science of Sustainable Development 
Module 3 - Introduction to the SDG agenda 
Module 4 - Critical Perspectives, Complexity and Indigenous Knowledges 
Module 5 - Sustainable Development Goals 17 16: Partnerships, finance, technologies and institutions, the frameworks for enabling the SDGs 
Module 6 - Sustainable Development Goals 13 7: Climate action, affordable and clean energy and the interconnections 
Module 7 - Sustainable Development Goals 3, 5 6: Health, wellbeing, gender equality and clean water and sanitation 
Module 8 - Sustainable Development Goals 1, 2 10: No Poverty, zero hunger and reduced inequalities 
Module 9 - Sustainable Development Goals 12, 14 15: Responsible consumption and production, life below water and life on land 
Module 10 - Sustainable Development Goals 8, 9, 4 11: Decent work and economic growth, Industry Innovation and Infrastructure, Quality Education and Sustainable Cities and Communities",The Science and Practice of Sustainable Development
https://www.classcentral.com/course/teach-impacts-technology-relationships-11237,"In this course you’ll focus on how “smart” devices have changed how we interact with others in personal ways, impacting how we stay connected in our increasingly mobile society. This will be done through a series of paired teaching sections, exploring a specific “Impact of Computing” in your typical day and the “Technologies and Computing Concepts” that enable that impact, all at a K12-appropriate level. 

This course is part of a larger Specialization through which you’ll learn impacts of computing concepts you need to know, organized into 5 distinct digital “worlds”, as well as learn pedagogical techniques and evaluate lesson plans and resources to utilize in your classroom. By the end, you’ll be prepared to teach pre-college learners to be both savvy and effective participants in their digital world.

In this particular digital world (relationships), you’ll explore the following Impacts & Technology pairs --

Impacts (Keep me connected in a mobile society):, personal relationships, facebook, circle of friends  
Technology and Computing Concepts: algorithms, software engineering evolution, heuristics, computer runtime, big O notation, P vs NP

Impacts (Making geography-based connections): findings friends, maps, geolocation
Technology and Computing Concepts: data and binary,  image encoding, pixels, how color pickers work, filters, blurs 

In the pedagogy section for this course, in which best practices for teaching computing concepts are explored, you’ll learn about the current CSTA K-12 CS Standards and practice using them to review and apply to lesson plans, as well as how to apply the ICAP framework to connect your students’ engagement to active learning outcomes, such as through peer instruction. 

In terms of CSTA K-12 computer science standards, we’ll primarily cover learning objectives within the “impacts of computing” concept, while also including some within the “networks and the Internet” concepts and the “data and analysis” concept.  Practices we cover include “fostering and inclusive computing culture”, “recognizing and defining computational problems”, and “communicating about computing”.
      


            Read more
          



          Course Orientation
    -Welcome!  Are you interested in teaching about the impacts technology has on our relationships?  To learn more about the computation and computing concepts that underlie those technologies?  We'll be using a problem-based approach to explore interesting ways to teach concepts of networks and the internet, data and analysis, and even algorithms and data representation.  Finally, we'll evaluate, critique and improve/personalize two lesson plans -- one of your choice and one on pixels.  Specifically, we'll be looking to improve these lesson plans by increasing the amount of interactive learning time for students.  

Keeping Connected in a Global Society
    -How has your ability to connect with friends and family changed since social media has become so ubiquitous?  What different groups of people are you connected to?  Besides looking at the impact of social media on our lives and society, we'll also take a detailed look at the history and development of the Facebook newsfeed algorithm -- learning a bit about software engineering , user experience, and heuristics.  From interacting with a Facebook visualization tool we'll be curious to investigate what causes programs to take a long time to run and how computer scientists categorize how long it will take for programs to run.

Making Geography-based Connections
    -With so much more knowledge being collected about our physical location, we have new ways we can find friends and support relationships among those ""close"" to us.  We'll look at several apps that leverage this and dive into digital image representations needed to support filters like those found in Snapchat.

Impacts of Computing and Supporting Interactive Learning
    -This week we'll introduce the Computer Science K-12 Framework and the Computer Science Teachers Association K-12 Computer Science Standards which are starting to frame state K-12 Computer Science standards in the US.  We'll guide you in finding and developing a lesson plan for a particular grade band around a resource for learning about the impact of technology on culture.   Next we'll learn a bit about further differentiating and defining ""active learning"" using the ICAP (interactive, constructive, active, passive) learning framework and see how Peer Instruction can be used to scaffold interactive learning experiences.

More lesson plans for interactivity:  Impacts and Encoding Images
    -This week is all about giving you the time and excuse to develop lesson plans you can use (and/or share with colleagues!)  We'll be improving lesson plans (including the one you created last week) to increase the amount of ""interactive"" learning in them.  Additionally, we'll try to align these lessons with CSTA standards -- recognizing that these may have been produced before the CSTA standards existed.  However, the process of seeing how they fit (or don't fit) with the standards may help give us ideas on how these lessons could be modified.",Teaching Impacts of Technology: Relationships
https://www.classcentral.com/course/genomic-data-science-18700,"With genomics sparks a revolution in medical discoveries, it becomes imperative to be able to better understand the genome, and be able to leverage the data and information from genomic datasets. Genomic Data Science is the field that applies statistics and data science to the genome. This Specialization covers the concepts and tools to understand, analyze, and interpret data from next generation sequencing experiments. It teaches the most common tools used in genomic data science including how to use the command line, along with a variety of software implementation tools like Python, R, Bioconductor, and Galaxy. This Specialization is designed to serve as both a standalone introduction to genomic data science or as a perfect compliment to a primary degree or postdoc in biology, molecular biology, or genetics, for scientists in these fields seeking to gain familiarity in data science and statistical tools to better interact with the data in their everyday work. To audit Genomic Data Science courses for free, visit https://www.coursera.org/jhu, click the course, click Enroll, and select Audit. Please note that you will not receive a Certificate of Completion if you choose to Audit.



          Course 1: Introduction to Genomic Technologies- This course introduces you to the basic biology of modern genomics and the experimental tools that we use to measure it. We'll introduce the Central Dogma of Molecular Biology and cover how next-generation sequencing can be used to measure DNA, RNA, and epigenetic patterns. You'll also get an introduction to the key concepts in computing and data science that you'll need to understand how data from next-generation sequencing experiments are generated and analyzed. This is the first course in the Genomic Data Science Specialization.Course 2: Genomic Data Science with Galaxy- Learn to use the tools that are available from the Galaxy Project. This is the second course in the Genomic Big Data Science Specialization.Course 3: Python for Genomic Data Science- This class provides an introduction to the Python programming language and the iPython notebook. This is the third course in the Genomic Big Data Science Specialization from Johns Hopkins University.Course 4: Algorithms for DNA Sequencing- We will learn computational methods -- algorithms and data structures -- for analyzing DNA sequencing data. We will learn a little about DNA, genomics, and how DNA sequencing is used. We will use Python to implement key algorithms and data structures and to analyze real genomes and DNA sequencing datasets.Course 5: Command Line Tools for Genomic Data Science- Introduces to the commands that you need to manage and analyze directories, files, and large sets of genomic data. This is the fourth course in the Genomic Big Data Science Specialization from Johns Hopkins University.Course 6: Bioconductor for Genomic Data Science- Learn to use tools from the Bioconductor project to perform analysis of genomic data. This is the fifth course in the Genomic Big Data Specialization from Johns Hopkins University.Course 7: Statistics for Genomic Data Science- An introduction to the statistics behind the most popular genomic data science projects. This is the sixth course in the Genomic Big Data Science Specialization from Johns Hopkins University.Course 8: Genomic Data Science Capstone- In this culminating project, you will deploy the tools and techniques that you've mastered over the course of the specialization. You'll work with a real data set to perform analyses and prepare a report of your findings.",Genomic Data Science
https://www.classcentral.com/course/entrepreneurs-blockchain-technology-13078,"In this course, you will gain a thorough understanding of the blockchain and distributed ledger technologies, including an introduction to the necessary foundations in cryptography. The course will discuss blockchain as a distributed ledger and introduce distributed consensus as a mechanism to maintain the integrity of the blockchain. The other revolutionary technologies that are changing the world as we speak are artificial intelligence and machine learning. You will learn about the three major types of AI algorithms: supervised and unsupervised machine learning, as well as reinforcement learning. 

You will learn about the application of blockchain outside of finance. In particular, how blockchain fundamentally changes the way we deal with our personal data. You will see how the web 2.0 model--where big companies like facebook and google collect as much of your personal data as possible to sell it to third parties--is coming to an end. The new web 3.0 is decentralized and uses the power of the blockchain to put users in full control over their own data. Finally, we will look at the benefits and considerations of blockchain and whether blockchain is the right solution for your problem.

#UCTFintech
      


          Cryptographic foundations of the blockchain
    -This week looks at the plumbing of current and future financial systems. Firstly we will look at our current financial infrastructure and how it facilitates the safe and efficient functioning of the financial system. We will also look at how our current infrastructure falls short and why this is an opportunity for fintech companies. We start with what banks and other financial intermediaries are, and why we regulate them. Then we will talk about how our financial infrastructure connects financial intermediaries and ensures that they can trade with one another. Secondly this week, we turn to the plumbing of the financial system of the future, which can be summarized in one word really, blockchain. Before going into details about how exactly the blockchain works, it makes sense to talk about how blockchain will disrupt our existing financial system. It's then time to take a deep dive into the cryptographic foundations of the blockchain. We will talk about public private key cryptography and explain exactly why cryptography makes the blockchain so secure. We end off the week with a complete overview of the data structures used in almost all blockchains. This will give you a thorough understanding of the innermost workings of the blockchain. Equipped with these tools, we can then take on the remainder of the course. 

Mastering the blockchain technology
    -Welcome to the second week of our course. This is the week where it gets real. We will finally have all the ingredients we need to fully grasp what the blockchain is. We start the week off by explaining single and double entry bookkeeping. It's important to understand why double entry bookkeeping improved the integrity of ledges in Italy in the 14th century, to truly appreciate how novel and revolutionary the blockchain is. For hundreds of years, double-entry bookkeeping was the method of choice when it comes to financial accounting. In double-entry bookkeeping, the two parties in a transaction each update their books, which provides some security against fraudulent actors. With the emergence of the distributed ledger technology and the blockchain however, we have seen a fundamental paradigm shift in accounting. The accounting perspective is very useful when we want to understand the blockchain as a distributed ledger. Distributed ledger is shared among a number of counterparties who want to transact with one another. A blockchain collects a number of transactions in the block, and through clever combination of cryptography and incentive schemes, ensures that these blocks cannot be altered. Each block contains a reference to the previous block, which is how a chain of blocks turns into a blockchain. We will discuss the different consensus mechanisms and cover both proof of work and proof-of-stake in detail. You will understand both the theory behind them and how they are applied in different block chains. This is an exciting week so let's get started.

How Artificial Intelligence Changes Data Analytics
    -Welcome to the third week of our course. This week we will explore more technology that is also disrupting the financial services industry, specifically artificial intelligence or AI. We will actually get our hands dirty and cover the three streams of AI, supervised and unsupervised machine learning, as well as reinforcement learning. All three methods are widely used in the financial services industry already, and we kick the week off by giving you a bird's-eye view of the possible applications of AI in finance. Then we turn to unsupervised machine learning, which is mainly used to cluster large amounts of high dimensional and unstructured data. This has many applications in the financial services industry. Once we have covered unsupervised learning, we then dive into supervised machine learning, which is a brilliant way to classify large amounts of data. A supervised machine learning algorithm must be trained on the training data set, which is often historical data. Once properly trained, the algorithm can then correctly classify patterns in new data, which is why supervised machine learning is so powerful. The idea of training data is then taken one step further in reinforcement learning, where algorithms learn from their interactions with the environment just like a human would. Reinforcement learning is an immensely powerful tool, and many big Wall Street firms are heavily investing into AI trading algorithms that really use reinforcement learning at their heart. Once we have all this heavy material covered, it's time to treat ourselves. So, at the end of this week, you will meet a number of guest lecturers from the financial services industry who will explain to you how their companies are successfully using AI in their business. This is a big week, where we look beyond the blockchain and to the second big pillar of the Fintech revolution, AI and machine learning.

Preparing your company for the fintech revolution
    -Welcome to the fourth week of our course. So, this week, we turn to applications of the blockchain outside of the traditional financial services industry. Since this is a course on FinTech, we will still focus on applications that have ties either with payment services or other financial services. But the main applications are really outside of finance. The first such application is the new architecture of the Internet, the Web 3.0. The current Internet paradigm, the Web 2.0 is built on uses handing that data to large corporations like Facebook or Twitter, and exchange for free services. But as we've seen with a fake news scandal around the 2016 US presidential election and the Brexit referendum, this business model comes with its disadvantages. The biggest disadvantage is privacy. Once a user post his personal data to for example a social media website, he has no longer control over the data. This is where the blockchain comes in. With a blockchain, is possible to give uses ownership of their data to ensure that they have full control over their personal sensitive information. So, this week, you will learn how the blockchain changes at prevailing Web 2.0 business model, and provides endless possibilities for truly decentralized Internet. We will then talk about possible drawbacks to blockchains, and when it is appropriate to use a blockchain and when it is not. There is as much to do for us this week. So, let's dive right in.",How Entrepreneurs in Emerging Markets can master the Blockchain Technology
https://www.classcentral.com/course/swayam-big-data-computing-12942,"In today's fast-paced digital world , the incredible amount of data being generated every minute has grown tremendously from sensors used to gather climate information, posts to social media sites, digital pictures and videos, purchase transaction records, and GPS signals from cell phone to name a few. This amount of large data with different velocities and varieties is termed as big data and its analytics enables professionals to convert extensive data through statistical and quantitative analysis into powerful insights that can drive efficient decisions. This course provides an in-depth understanding of terminologies and the core concepts behind big data problems, applications, systems and the techniques, that underlie today's big data computing technologies. It provides an introduction to some of the most common frameworks such as Apache Spark, Hadoop, MapReduce, Large scale data storage technologies such as in-memory key/value storage systems, NoSQL distributed databases, Apache Cassandra, HBase and Big Data Streaming Platforms such as Apache Spark Streaming, Apache Kafka Streams that has made big data analysis easier and more accessible. And while discussing the concepts and techniques, we will also look at various applications of Big Data Analytics using Machine Learning, Deep Learning, Graph Processing and many others. The course is suitable for all UG/PG students and practicing engineers/ scientists from the diverse fields and interested in learning about the novel cutting edge techniques and applications of Big Data Computing.



            Read more
          



Week 1  :  Introduction to Big DataWeek 2  :  Introduction to Enabling Technologies for Big DataWeek 3  :  Introduction to Big Data PlatformsWeek 4  :  Introduction to Big Data Storage Platforms for Large Scale Data StorageWeek 5  :  Introduction to Big Data Streaming Platforms for Fast DataWeek 6  :  Introduction to Big Data Applications (Machine Learning)Week 7  :  Introduction of Big data Machine learning with SparkWeek 8  :  Introduction to Big Data Applications (Graph Processing)",Big Data Computing
https://www.classcentral.com/course/futurelearn-data-science-for-healthcare-using-real-world-evidence-11725,"Understand real world evidence (RWE) and learn how to use it
Real world data (RWD) is the huge quantity of data that falls outside the boundaries of controlled clinical trials, data that is increasingly used to inform decisions in healthcare. Real world evidence (RWE), is the conclusions drawn from this data.
On this course you will learn how real world evidence can be used in healthcare, exploring current trends and existing methodologies for using it. You will consider ethics, design thinking, commercial applications, and the limitations of RWE.
You will also practice using RWE, applying a user-friendly business intelligence tool to examine RWD.
This course is for anyone with an interest in the relationship between ICT and healthcare, especially those interesting in data analysis. You might be an undergraduate student in data science, an analyst or commercial manager working in life sciences pharmaceuticals, healthcare regulation, biotech and medical devices. This course focuses on UK health data, however the course is relevant to learners in other countries.
To take part in this course, you will need a computer with high-speed access to the internet.",Data Science for Healthcare: Using Real World Evidence
https://www.classcentral.com/course/datasci3-4247,"Producing numbers is not enough; effective data scientists know how to interpret the numbers and communicate findings accurately to stakeholders to inform business decisions.  Visualization is a relatively recent field of research in computer science that links perception, cognition, and algorithms to exploit the enormous bandwidth of the human visual cortex.  In this course you will design effective visualizations and develop skills in  recognizing and avoiding poor visualizations.  

Just because you can get the answer using big data doesn’t mean you should.  In this course you will have the opportunity to explore the ethical considerations around big data and how these considerations are beginning to influence policy and practice.  

Learning Goals: After completing this course, you will be able to:
1. Design and critique visualizations
2. Explain the state-of-the-art in privacy, ethics, governance around big data and data science
3. Explain the role of open data and reproducibility in data science","Communicating Results: Visualization, Ethics, Reproducibility"
https://www.classcentral.com/course/edx-introduction-to-urban-geo-informatics-10080,"“Where does geographical data come from?”“How do we monitor our environment?”“How do we navigate with our phones?”“What is happening beneath our feet?”These are just some of the questions that crop up every so often as we wander around the streets of our urban metropolises. Many of the technologies we used, many of the decisions we made are based on spatial data, most of which are acquired from Geospatial Technologies. This data and the interpretation of the data is known as “Geo-Informatics”.In this course, you will explore various technologies involved in Geo-Informatics, how the technologies help us to retrieve spatial data, and more importantly how the geographical data becomes the information used in decision making. You will explore the fields of Remote Sensing, Geographic Information Systems (GIS), Global Navigation Satellite Systems (GNSS) such as GPS, and Underground Mapping. Additionally, the concept of Smart City and the Urban Environment will be introduced to you. From this, you will gain an understanding of how these technologies help us to shape and understand the world that we are living in.
      


Week 1: The Urban EnvironmentIntroduction to the Urban Environment and its issues.Week 2: GISIntroduction to Geographic Information Systems (GIS); its role and how data are analysed inside a GIS, the applications of GIS, and how it is integrated into our lives.Week 3: Remote SensingIntroduction to Remote Sensing; its history and techniques, how data are acquired through Remote Sensing technologies, and how they are processed.Week 4: Underground Survey & MappingIntroduction to methods for Underground Mapping and how to see the unseen.Week 5: Navigational SystemsIntroduction to how we position ourselves on Earth, how we navigate through our surroundings, and the different Systems.Week 6: Smart CitiesIntroduction to what is a Smart City, where Big Data come from, and how we can use Big Data to shape our world.",Introduction to Urban Geo-Informatics
https://www.classcentral.com/course/swayam-plastic-waste-management-12920,"This course will focus on:1. Introduction of Plastic pollution as a global problem today.2. What is Plastic Waste? The Magnitude of the problem on global scale and in Indian context. Plastic in Ocean and impact on sea life and economy.3. What is the nature and complexity of this problem and what could be the best way to manage the plastic waste and how to mitigate the risk from plastic waste.4. Plastic Waste Management Rules 2016, Recent Plastic Bans and the use of Extended Producer Responsibilities (EPR) concepts in managing Plastic waste in India.5. Best Practices of Managing Plastic Waste from around the World including use of Plastic waste in road (experience from Indian context and other countries)6. Way forward – how to manage this waste stream applying state of the art technologiesINTENDED AUDIENCE :Civil and Chemical Engineering BTech programs, Environmental Engineering and Environmental Science Masters and Doctoral ProgramsPREREQUISITES :Basic Environmental Science, Basic Differential Equations, Basic ChemistryINDUSTRY SUPPORT :AECOM, Ramky, Environmental Resource Management (ERM),SENES/ARCADIS. Waste Management related companies, Govt. Agencies



COURSE LAYOUT Week 1: Plastics – What it is? Types, Uses and Global StatisticsWeek 2:  Plastic Waste – Sources, Production, Global and Indian ContextWeek 3:Plastic Waste Management Rules 2016 (India) and Global Rules and RegulationsWeek 4: Plastic Bans including China Sword Policy implication on global plastic waste managementWeek 5: Impact of Plastics on Marine Life, Effect on Wildlife, Human Health and EnvironmentWeek 6: Plastic Waste Management Practices – Use of Plastic waste in roads, issues and challengesWeek 7: Possible Alternate Materials to Plastics –Greener AlternativesWeek 8: Plastics Resource Recovery and Circular Economy.",Plastic Waste Management
https://www.classcentral.com/course/pointers-arrays-recursion-10326,"The third course in the specialization Introduction to Programming in C introduces the programming constructs pointers, arrays, and recursion. Pointers provide control and flexibility when programming in C by giving you a way to refer to the location of other data. Arrays provide a way to bundle data by guaranteeing sequences of data are grouped together. Finally, recursive functions—functions that call themselves—provide an alternative to iteration that are very useful for implementing certain algorithms.
      


          Pointers
    -Pointers are one of the most important and powerful aspects of the C language.  Pointers are critical to understanding arrays, which let you manipulate sequences of data.  They also give a programmer control and flexibility when programming, enabling solutions that are clean and efficient. Some other languages use pointers implicitly—or pointer-like constructs—so understanding their use will make you a better programmer in any language.

Arrays
    -Arrays are sequences of memory of the same type that are guaranteed to be one after another. This is an incredibly useful data format, enabling you to store many things together under one variable name. In this module, you will learn how to use arrays to solve more complex problems and lay the groundwork for more complex data types.

Uses of Pointers
    -Now that you have mastered the basics of pointers and arrays, it is time to see some important uses of them.  In this module, you will learn about how to manipulate strings and multi-dimensional arrays.  You will also learn about function pointers, which allow you to pass ""which function to call"" as the parameter of another function.

Recursion
    -By now you are familiar with iteration, in which repetition is expressed in terms of loops.  Another programming technique to accomplish similar ideas is ""recursion"" in which a more complex instance of a problem is expressed in terms of solutions to simpler instances of the problem.  In this module, you will learn how to read and write recursive code, giving you another powerful option for how to approach programming problems.


Project
    -Now that you have learned about pointers and arrays, you will build on the code you wrote in Course 2 to build a deck of cards and evaluate a poker hand. In the next course, you will complete the program to calculate poker odds with a Monte Carlo simulation.","Pointers, Arrays, and Recursion"
https://www.classcentral.com/course/independent-data-warehousing-on-aws-digital-12674,"In this course, you will learn concepts, strategies, and best practices for designing a cloud-based data warehousing solution using Amazon Redshift, the petabyte-scale data warehouse in AWS. We will demonstrate how to collect, store, and prepare data for the data warehouse by using other AWS services, such as Amazon DynamoDB, Amazon EMR, Amazon Kinesis Firehose, and Amazon Simple Storage Service (Amazon S3). We will also explore how to use business intelligence (BI) tools to perform analysis on your data.
Intended Audience
This course is intended for:

Database architects
Database administrators
Database developers
Data analysts
Data scientists

Course Objectives
This course teaches you how to:

Evaluate the relationship between Amazon Redshift and other Big Data systems
Evaluate use cases for data warehousing workloads and review real-world implementation of AWS data and analytic services as part of a data warehousing solution
Evaluate approaches and methodologies for designing data warehouses
Design the data warehouse to make effective use of compression, data distribution, and sort methods
Understand which security features are appropriate for Amazon Redshift, such as encryption, IAM permissions, and database permissions
Launch an Amazon Redshift cluster and use the components, features, and functionality to implement a data warehouse in the cloud
Use other AWS data and analytic services, such as Amazon DynamoDB, Amazon EMR, Amazon Kinesis Firehose, and Amazon S3, to contribute to the data warehousing solution
Identify data sources and assess requirements that affect the data warehouse design
Load and unload data and perform data maintenance tasks
Write queries and evaluate query plans to optimize query performance
Configure the database to allocate resources such as memory to query queues and define criteria to route certain types of queries to your configured query queues for improved processing
Audit, monitor, and receive event notifications about activities in the data warehouse by using features and services such as Amazon Redshift database audit logging, Amazon CloudTrail, Amazon CloudWatch, and Amazon Simple Notification Service (Amazon SNS)
Prepare for operational tasks such as resizing Amazon Redshift clusters and using snapshots to back up and restore clusters
Use a BI application to perform data analysis and visualization tasks against your data

Prerequisites
We recommend that attendees of this course have the following prerequisites:

Completion of the AWS Technical Essentials course or have equivalent experience
Familiarity with relational databases and database design concepts

 



            Read more
          




Introduction to Data Warehousing
Introduction to Amazon Redshift
Launching Clusters
Designing the Database Schema
Identifying Data Sources
Loading Data
Writing Queries and Tuning for Performance
Amazon Redshift Spectrum
Maintaining Clusters
Analyzing and Visualizing Data",Data Warehousing on AWS (Digital)
https://www.classcentral.com/course/france-universite-numerique-internet-of-things-with-microcontrollers-a-hands-on-course-l-internet-des-objets-sur-microcontroleurs-par-la-pratique-17928,"About this course / À propos du cours   This course is an introduction to microcontroller programming for Internet of Things applications. It does not address the domestic or general uses of connected objects, nor their societal issues.   Considered as the third revolution of the Internet, the Internet of Things (IoT) is a natural evolution of technology, a link between the physical world and the digital world whose goal is to make our life easier. With already billions of connected objects, the Internet of Things has a very wide range of applications including for instance home automation, agriculture, but also healthcare and industry... The Internet of Things is a revolutionary paradigm enabling many new applications. For this revolution to be a success, it has to meet a lot of challenges among which:  Energy efficiency of the IoT devices for a long autonomy and energy saving  Interoperability between all the connected objects  Updates of the devices for a long-term use  Security of the IoT devices to prevent them from being hacked Data privacy of the users You are a developer, a computer science student, an engineer or just a maker fond of technology?Be an IoT active player: don’t just consume things, create things! This MOOC will help you understand the specificities of connected object programming through a mix of theoretical contents and hands-on activities. At the end of the course, you will be able to develop an IoT application from the object to the cloud. No need to possess specific hardware to take this course: you will be able to program and test your firmware using the FIT IoT-Lab testbed. Most of the software and coding in the hands-on activities is based on the open source IoT operating system RIOT: this enables re-use of this code on a large variety of IoT devices, beyond hardware available through the FIT IoT-Lab testbed.   Ce cours est une initiation à la programmation sur microcontrôleurs pour les applications de l'Internet des objets. Il n'aborde pas les usages généraux ou domestiques des objets connectés, ni leurs enjeux sociétaux.   Considéré comme la troisième révolution de l'Internet, l'Internet des objets (Internet of Things ou IoT en anglais) est une évolution naturelle de la technologie, un lien entre le monde physique et le monde numérique dont l'objectif est de nous faciliter la vie. Avec déjà des milliards d'objets connectés, l'Internet des objets a un très large éventail d'applications, notamment dans les domaines de la domotique, de l'agriculture mais aussi la santé ou l'industrie... L'Internet des objets constitue un paradigme révolutionnaire qui offre une multitude de nouvelles applications. Pour que cette révolution soit un succès, elle doit relever de nombreux défis parmi lesquels :  L'efficacité énergétique des appareils IoT pour une plus grande autonomie et des économies d'énergie   L'intéropérabilité entre tous les objets connectés  La mise à jour des dispositifs pour un usage long terme  La sécurité des appareils IoT pour empêcher leur piratage   La protection des données des utilisateurs Vous êtes un·e développeur·se, un·e étudiant·e en informatique, un·e ingénieur·e ou tout simplement un·e maker fan de technologie ?Devenez acteur·rice de l'IoT : ne soyez pas uniquement consommateur·rice·s, devenez créateur·rice·s d'objets !  Ce MOOC vous aidera à comprendre les spécificités de la programmation d'objets connectés à travers une alliance de contenus théoriques et d'activités pratiques.  A la fin de ce cours vous serez capable de développer une application IoT de l'objet au cloud.  Pas besoin de posséder de matériel spécifique pour suivre ce cours : vous pourrez programmer et tester votre logiciel en utilisant la plateforme d'expérimentation FIT IoT-Lab. La plupart du code et des exercices pratiques de programmation sont basés sur le système d'exploitation open source RIOT : ceci permet la réutilisation de ce code sur une large gamme de matériel IoT, au delà du matériel disponible sur la plateforme d'experimentation FIT IoT-Lab. Format  This MOOC is composed of 5 modules combining:  textual course contents,  course videos,  tutorials  quizzes  hands-on activities with the use of Jupyter notebooks, the FIT IoT-Lab platform and the RIOT operating system. The course is bilingual english / french: all the material is proposed in english and french, the videos are in english with english and french subtitles.  Ce MOOC est composé de 5 modules associant : des contenus de cours textuels,  des vidéos,  des tutoriels,  des quiz  des activités pratiques avec l'utilisation de notebooks Jupyter, de la plateforme FIT IoT-Lab et du système d'exploitation RIOT. Le cours est bilingue anglais / français : tous les contenus textuels sont proposés en anglais et français, les vidéos sont en anglais avec des sous-titres anglais et français.  Prerequisites / Prérequis  Following this course assumes the following prior knowledge: Programming notions of C and/or Python or Bash Linux systems (use of command lines)   Pour suivre ce cours il est nécessaire de possèder les pré-requis suivants :  Notions de programmation en C et/ou Python ou Bash   Connaissance des systèmes Linux (lignes de commandes)   Course Syllabus / Plan du cours  Module 1: Internet of Things: General Presentation  At the end of this module you will be able to provide a description of the IoT system from the device to the cloud. Module 2: Focus on Hardware Aspects At the end of this module you will be able to explain the hardware architecture of a connected device with the energy constraints associated. You will also be able to classify IoT devices according to their role or application. Module 3: Focus on Embedded Softwares  At the end of this module you will be able to apply the specific programming principles for a connected object. You will also be able to describe the characteristics of the RIOT operating system. Module 4: Focus on Low-Power Wireless Networks At the end of this module you will be able to describe IoT communication protocols with the various networks layers. You will also be able to write your first IoT application using the Internet protocol CoAP in order to retrieve the values from a temperature sensor. Module 5: Securing Connected Objects At the end of this module you will be able to identify the security problems of connected objects and the existing solutions to overcome them.  Module 1 : Présentation générale de l'Internet des Objets A la fin de ce module, vous obtiendrez une vision d'ensemble de la chaîne IoT, de l'objet au cloud. Module 2 : Zoom sur les aspects matériels A la fin de ce module, vous serez capable d'expliquer l'architecture matérielle d'un objet connecté avec les contraintes énergétiques liées. Vous serez également en mesure de classer les objets IoT par rôle ou application. Module 3 : Zoom sur les logiciels embarqués A la fin de ce module, vous serez capable d'appliquer les principes spécifiques de programmation d'un objet connecté et de décrire les caractéristiques du système d'exploitation RIOT. Module 4 : Zoom sur les réseaux basse consommation sans-fil A la fin de ce module, vous serez capable de décrire les protocoles de communication IoT avec les différentes couches réseaux. Vous serez également en mesure d'écrire votre première application IoT avec l'utilisation du protocole Internet CoAP pour récupérer les valeurs d'un capteur de température. Module 5 : Sécurisation des objets connectés A la fin de ce module, vous serez capable d'identifier les problèmes de sécurité des objets connectés et les solutions existantes pour les contourner. Teachers / Enseignants  Alexandre Abadie Alexandre Abadie is a research engineer at Inria Saclay - Île-de-France. He is a contributor and maintainer of RIOT, an operating system for the Internet of things and core team member of the FIT-IoT-LAB platform.Alexandre Abadie est ingénieur de recherche chez Inria Saclay - Île-de-France. Il est contributeur et responsable de RIOT, un système d'exploitation pour l'Internet des objets. Il est l'un des membres de l'équipe FIT-IoT-LAB, plateforme d’expérimentation de l'IoT. Emmanuel Baccelli Emmanuel Baccelli is research scientist at Inria and Professor at Freie Universität Berlin. His research topics are computer networks, protocol design and performance evaluation, and embedded software. Emmanuel Baccelli is a co-founder and coordinator of RIOT. Emmanuel Baccelli est chercheur en informatique chez Inria et Professeur à Freie Universität Berlin. Ses sujets de recherche sont les réseaux informatiques, la conception de protocoles et l'évaluation de performance, et le logiciel embarqué. Emmanuel Baccelli est cofondateur et coordinateur de RIOT.  Antoine Gallais Antoine Gallais is a Professor at the Université Polytechnique Hauts-de-France, Valenciennes. His research topics include routing and MAC protocols for the Internet of Things, fault-tolerance and cybersecurity. Antoine Gallais est Professeur à l'Université Polytechnique Hauts-de-France, Valenciennes. Sa recherche porte sur les protocoles de contrôle d'accès au medium et de routage pour l'Internet des objets, la tolérance aux pannes et la cybersécurité. Olivier Gladin Olivier Gladin worked for ten years in the video game industry and is now a research engineer in the experimentation and development team at Inria Saclay - Île-de-France where he works on very high-resolution wall-sized displays. He is also an IoT enthusiast.Olivier Gladin a travaillé pendant dix dans l'industrie du jeu video et il est maintenant ingénieur de recherche dans l'équipe expérimentation et développement du centre Inria Saclay - Île-de-France où il s'occupe de murs d'écrans très haute résolution. C'est également un passionné d'IoT.  Nathalie Mitton Nathalie Mitton is a research scientist at Inria (Lille Nord Europe). Her research interests focus on self-organization from PHY to routing for wireless networks composed of hardware constrained devices (battery-powered, low memory and CPU capacities) . Nathalie Mitton est chercheur en informatique chez Inria (Lille Nord Europe). Sa recherche porte sur les mécanismes d’auto-organisation dans les réseaux de capteurs et de robots sans fil et systèmes RFID, de la couche physique à la couche réseau (réseaux composés d'objets contraints matériellement en termes de mémoire, énergie et CPU).  Frédéric Saint-Marcel Frédéric Saint-Marcel is a research engineer at Inria Grenoble - Rhône-Alpes. Since 2012 he is the technical leader of FIT IoT-LAB development team focusing on Internet of Things and in charge of the testbed exploitation. Frédéric Saint-Marcel est ingénieur de recherche chez Inria Grenoble -Rhône-Alpes. Depuis 2012 il est directeur technique de l'équipe de développement FIT IoT-LAB qui travaille sur l'Internet des objets et qui gère l'exploitation du testbed.  Guillaume Schreiner Guillaume Schreiner is an engineer working for CNRS at ICube laboratory (UMR 7357) - Strasbourg. Since 2008, he's involved in SensLab and FIT IoT-LAB development, french research projects dealing with IoT. In 2015, he became technical head of ICube Inetlab testbed.Guillaume Schreiner est ingénieur d'études au CNRS et travaille au laboratoire ICube (UMR 7357) à Strasbourg. Depuis 2008, il est impliqué dans les développements des projets ANR SenLab et Equipex FIT IoT-LAB liés au monde de l'Internet des Objets. En 2015, il devient responsable de la plateforme Inetlab de ICube.  Julien Vandaële Julien Vandaële is a research engineer at Inria Lille - North Europe. Since 2008, he has been working in Nathalie Mitton's research team, being part of the developers team of the FIT IoT-LAB platform since its inception. He likes to get involved in innovative projects mixing IoT and embedded electronics, with scientific mediation as a background.Julien Vandaële est ingénieur de recherche chez Inria Lille - Nord Europe. Il travaille depuis 2008 dans l'équipe de recherche de Nathalie Mitton, faisant partie de l'équipe des développeurs de la plateforme FIT IoT-LAB depuis ses débuts. Il aime s'impliquer dans des projets innovants mêlant IoT et électronique embarquée, sur fond de médiation scientifique.  Evaluation At the end of the course, an attestation of achievement will be delivered to the participants who will have obtained the minimal score required. The evaluation is based on quizzes and peer assessment of hands-on activities.  A l'issue du cours, une attestation de suivi avec succès sera délivrée aux participants ayant obtenu la note minimale requise. L’évaluation est basée sur des quiz et sur une évaluation par les pairs d'activités pratiques. Terms of use / Conditions d'utilisations Terms of use of the course content The videos are shared under Creative Commons License  BY-NC-ND: the name of the author should always be mentioned ; the user can exploit the work except in a commercial context and he cannot make changes to the original work. The other course contents are shared under Creative Commons License  BY-NC: the name of the author should always be mentioned ; the user is free to share (copy and redistribute the material in any medium or format) except in a commercial context ; the user can adapt (remix, transform, and build upon) the material. Conditions d’utilisation du contenu du cours Les vidéos sont diffusées sous licence Creative Commons License  BY-NC-ND: l’utilisateur doit mentionner le nom de l’auteur, il peut exploiter l’œuvre sauf dans un contexte commercial et il ne peut apporter de modifications à l’œuvre originale. Les autres ressources du cours sont diffusées sous Licence Creative Commons  BY-NC : l’utilisateur doit mentionner le nom de l’auteur, il peut exploiter l’œuvre sauf dans un contexte commercial et il peut apporter des modifications à l’œuvre originale. Terms of use of the contents produced by users The contents produced by users are shared under Creative Commons License  BY-NC-ND: the name of the author should always be mentioned ; the user can exploit the work except in a commercial context and he cannot make changes to the original work. Conditions d’utilisation des contenus produits par les participants Les contenus produits par les participants sont, sauf mention contraire, sous Licence Creative Commons  BY-NC-ND : l’utilisateur doit mentionner le nom de l’auteur, il peut exploiter l’œuvre sauf dans un contexte commercial et il ne peut apporter de modifications à l’œuvre originale.  Follow us on twitter @InriaLearnLab #MoocIoT   https://twitter.com/InriaLearnLab #MoocIoT    
      


            Read more
          



Course Syllabus / Plan du cours  Module 1: Internet of Things: General Presentation  At the end of this module you will be able to provide a description of the IoT system from the device to the cloud. Module 2: Focus on Hardware Aspects At the end of this module you will be able to explain the hardware architecture of a connected device with the energy constraints associated. You will also be able to classify IoT devices according to their role or application. Module 3: Focus on Embedded Softwares  At the end of this module you will be able to apply the specific programming principles for a connected object. You will also be able to describe the characteristics of the RIOT operating system. Module 4: Focus on Low-Power Wireless Networks At the end of this module you will be able to describe IoT communication protocols with the various networks layers. You will also be able to write your first IoT application using the Internet protocol CoAP in order to retrieve the values from a temperature sensor. Module 5: Securing Connected Objects At the end of this module you will be able to identify the security problems of connected objects and the existing solutions to overcome them.  Module 1 : Présentation générale de l'Internet des Objets A la fin de ce module, vous obtiendrez une vision d'ensemble de la chaîne IoT, de l'objet au cloud. Module 2 : Zoom sur les aspects matériels A la fin de ce module, vous serez capable d'expliquer l'architecture matérielle d'un objet connecté avec les contraintes énergétiques liées. Vous serez également en mesure de classer les objets IoT par rôle ou application. Module 3 : Zoom sur les logiciels embarqués A la fin de ce module, vous serez capable d'appliquer les principes spécifiques de programmation d'un objet connecté et de décrire les caractéristiques du système d'exploitation RIOT. Module 4 : Zoom sur les réseaux basse consommation sans-fil A la fin de ce module, vous serez capable de décrire les protocoles de communication IoT avec les différentes couches réseaux. Vous serez également en mesure d'écrire votre première application IoT avec l'utilisation du protocole Internet CoAP pour récupérer les valeurs d'un capteur de température. Module 5 : Sécurisation des objets connectés A la fin de ce module, vous serez capable d'identifier les problèmes de sécurité des objets connectés et les solutions existantes pour les contourner.",Internet of Things with Microcontrollers: a hands-on course / L'Internet des Objets sur microcontrôleurs par la pratique
https://www.classcentral.com/course/introduction-iot-boards-12535,"Internet of Things (IoT) is an emerging area of information and communications technology (ICT) involving many disciplines of computer science and engineering including sensors/actuators, communications networking, server platforms, data analytics and smart applications. IoT is considered to be an essential part of the 4th Industrial Revolution along with AI and Big Data. This course will be very useful to senior undergraduate and graduate students as well as engineers who are working in the industry. This course aims at introducing the general concepts and architecture of IoT applications, networking technologies involved, IoT development kits including Arduino, Raspberry Pi, Samsung ARTIK, and how to program them. This course will be offered in English. Subtitles/captions in both of English and Korean will be also provided. 

IoT (Internet of Things, 사물인터넷)는 최근 중요한 정보통신기술로 주목 받고 있으며 센서/ 제어기, 통신 네트워크, 서버 플랫폼, 데이터 분석, 스마트 앱 등의 컴퓨터공학 기술들이 융합된 기술입니다. IoT는 인공지능, 빅데이터와 함께, 4차산업혁명의 3대 핵심 기술 중 하나로 손꼽히고 있습니다. 본 강좌는 현재 대학에서 공부를 하고 있는 학부 3-4학년 및 대학원생들에게 뿐만 아니라 현장의 개발자, 엔지니어들에게도 도움이 될 거라 믿습니다. IoT의 개념부터 아키텍처, 네트워크기술들을 소개하고 IoT 앱들을 개발할 때 많이 사용되는 Arduino, Raspberry Pi와 삼성전자의 ARTIK 플랫폼을 소개합니다. 
본 과목은 영어로 진행되며, 영문과 한글 자막을 제공합니다.
      


          Introduction to IoT

Networking Technologies for IoT

IoT Programming with Arduino

IoT Programming with Raspberry Pi

IoT Programming with ARTIK Board",Introduction and Programming with IoT Boards
https://www.classcentral.com/course/edx-ap-computer-science-a-java-programming-loops-and-data-structures-7212,"In this computer science course, you will learn the basics of programming in the Java language, and cover topics relevant to the AP Computer Science A course and exam.
This course will cover repetition statements (for, while, do-while and for-each), the array data structure, methods and recursion.
This course is for anyone interested in taking a first-level computer-programming course, particularly those who attend a school that does not provide a similar class.
No previous programming knowledge is needed, although it is recommended that learners be comfortable with the topics addressed in AP Computer Science A: Java Programming.
We are looking forward to helping you explore this exciting new world!



Unit Name or Timeframe: Repetition (2 weeks)
Loops (for-loop, while-loop, do-while-loop)
Nested loops
Fencepost errors
Infinite loops
IndexOutOfBounds exception
Unit Name or Timeframe: Data Structures (2 weeks)
Arrays and indexing
Memory management of data structures
Homogeneity
Array length property
Looping though arrays using for and for-each loops
Generalization
Two-dimensional arrays
Unit Name or Timeframe: Recursion (2 weeks)
Recursive functions and induction
Exit conditions
Call stack",AP Computer Science A: Java Programming Loops and Data Structures
https://www.classcentral.com/course/iversity-governance-and-policy-advice-how-political-decisions-come-to-life-2491,"Political decisions are of course made by governments and/or parliaments. But who provides these bodies with the information they need and shows them the strategic options they have? Who frames political action before the wider public even takes notice of the issue? How does political agenda setting work and what do certain policy outcomes tell us about the future of the issue at stake?This course is designed to outline key features of policy advice and political consulting and their impact on governance.We will observe the key players on the spot as well as those behind the scenes and we will analyze their patterns of interaction. Moreover, we will provide insights regarding essential questions to which there are no single right answers: What role does policy advice play in different democracies? What is good policy advice? What makes an expert? In sum: Whom do (and should) politicians and society listen to, and what do (and should) they make of the advice they receive?
What do I learn?
By the end of the course, students will know the key concepts of policy advice as well as the main actors in the field and their patterns of interaction. They will understand how and by whom a certain political decision is framed, shaped and implemented. And they will be able to apply this knowledge to a given political event which may affect their own professional or personal life. So, first and foremost, they will be able to ask the right questions.
What do I need to know
The course is designed to cater for students and professionals who are interested in decision making, political communication, policy advice, and consulting. Course participants are expected to follow current politics and to be keen on looking at the matter from different (and sometimes unusual) perspectives. Basic knowledge in political science would be an asset.



            Read more
          



Chapter 1        Introduction and Course OverviewConvener: Prof. Dr. Andrea Römmele, Professor for Communication in Politics & Civil Society, Hertie School of Governance
Chapter 2        Truth to Power? Scientific Advisers Seeking Truth, Decision-Makers Seeking Power?Convener: PD Dr. Martin Thunert, Senior Lecturer, Heidelberg Center for American Studies, University of Heidelberg
Chapter 3        Political Communication and Political ConsultingConvener: Prof. Dr. Andrea Römmele, Professor for Communication in Politics & Civil Society, Hertie School of Governance
Chapter 4        Economic and Financial PolicyConvener: Prof. Dr. Thomas König, Chair of Political Science, University of Mannheim
Chapter 5        Social PolicyConvener: Prof. Dr. Kent Weaver, Senior Fellow at the Brookings Institution and Professor of Public Policy and Government at Georgetown University
Chapter 6        Foreign and Security PolicyConvener: Dr. Nicole Renvert, Postdoc Fellow, Käte Hamburger Kolleg / Centre for Global Cooperation Research, Duisburg
Chapter 7        Energy and EnvironmentConvener: Prof. Dr. Karen Smith Stegen, KAEFER Professor of Renewable Energy and Environmental Politics, Jacobs University, Bremen
Chapter 8        Policy Advice in International CooperationConvener: Katharina Hübner, Senior Manager, Division Good Governance and Human Rights, Deutsche Gesellschaft für Internationale Zusammenarbeit (GIZ)
Chapter 9        Citizens’ Involvement in Policy AdviceConvener: Henrik Schober, Head Editor, Zeitschrift für Politikberatung (Journal for Political Consulting and Policy Advice), Hertie School of Governance
Chapter 10        Best Practices: Guidelines for Policy Advice?Convener: Prof. Dr. Andrea Römmele, Professor for Communication in Politics & Civil Society, Hertie School of Governance",Governance and Policy Advice: How political decisions come to life
https://www.classcentral.com/course/independent-introduction-to-enterprise-computing-1007,"This course provides an overview of Enterprise Computing and in particular, the role of System z hardware and its primary operating system (z/OS) in an Enterprise Computing environment. The emphasis is on commercial computing.  The introductory topic provides an overview of Enterprise Computing in general. This is followed with an introduction to the System z enterprise server hardware and its operating system, z/OS. Enterprise computing involves many different types of workloads; for example, transaction processing, business intelligence, end user interactive computing, web serving, data serving, batch, and many others. This short course will provide an overview of two very important Enterprise Computing workloads: end user interactive computing (TSO/ISPF and USS) and batch processing and their related technologies.
Prerequisites:

Some familiarity with an existing operating system (e.g. UNIX, Windows, etc. ) and associated terminology and concepts.
A high speed internet connection for access to course materials.
A current version of Internet Explorer or another browser to view the web pages associated with the course materials. Adobe acrobat reader (current version).
Word processing software or the ability to read current word processing documents.

 
Course Learning Objectives:
Upon successful completion of this course, the student will be able to do the following:
 

List the characteristics of Enterprise Computing
Describe the role of Enterprise Server in an Enterprise Computing environment and list some of its characteristics.
List the distinguishing characteristics of the System z architecture and hardware.
List some of the characteristics of the z/OS operating system and why these characteristics are of value to an Enterprise Computing configuration.
Describe some commonly used z/OS data sets, their characteristics and use.
Be familiar with basic functions and usage of TSO, ISPF, and JCL
Describe the characteristics of batch workloads and their importance to Enterprise Computing.
Discuss, at a high level, the functions and processing of batch jobs by JES2
Explain the flow of a job
Be familiar with and able to use System z and z/OS terminology and acronyms.
Be familiar with the System z hardware and software history and evolution.

Required Reading
The IBM text, “Introduction to the New Mainframe: z/OS Basics” will be the base text for the course. The IBM publication number is: SG24-6366. A softcopy of this book is available for download at http://www.redbooks.ibm.com/abstracts/sg246366.html as well as a means to order a hardcopy. In addition, topic lecture material and notes will be provided to complement/augment the reading. Additional supplementary reading will be noted and may be used in some of the assignments or discussions. Other relevant PDF extracts, papers, articles, etc. will also be provided as well as URLs to relevant web resources.
 
Course Grading
A passing grade for all the course quizzes is 70%. Students can re-take a quiz if they want to improve their grade. You do not have to pass a quiz in order to move on to the next topic. If a student passes all quizzes with a passing grade, the student has successfully completed the class.



            Read more
          



Week 1Course WelcomeIntroduction to Enterprise Computing
Week 2Introduction to Enterprise Servers
Week 3Introduction to z/OS
Week 4Introduction to Data Sets and Related Concepts
Week 5Introduction to TSO, ISPF, and USS
Week 6 Introduction to Batch
Week 7Introduction to JCL
Week 8Introduction to the Job Entry SubsystemCourse Closing",Introduction to Enterprise Computing
https://www.classcentral.com/course/edx-open-and-smart-government-5020,"How can governments become more open and transparent, while simultaneously dealing with various challenges, such as data sensitivity? How can open government data be used to improve policy making? Which technologies are available to make governments more open and to use open government data? How can data be turned into smartness?
Governments all over the world aim to become more open and transparent in order to establish closer ties with their constituents. However, opening government involves complex challenges and poses two major areas of concerns. First, many different stakeholders are involved and there are various dependencies between them, and second, the technologies that support open government are fragmented. In addition, it is unclear how different contexts should alter the best practices for open government.
This course explores the foundations and objectives of Open Government and examines current developments, including the opening and reuse of governmental data such as the release of data by governments in America and Europe.
This course will empower you, by helping you grasp the key principles surrounding open government. The topics of the course are applied to concrete cases, which you will be asked to analyze and discuss with your peers.
This course may be of interest to the following:

Students interested in the basics of open government, in smart government, in data-driven governance and data-driven research;
Professionals and researchers working on open government research and interested in strategies and challenges for opening governments
Professionals and researchers working on open data research or open data initiatives
Professionals and researchers working on topics related to public values, use of algorithms, including transparency and privacy, in a governmental context
Senior administrators, policy advisors, government officials or agency members, who are interested in how ICTs change governments and how ICTs can be used in public administrations




            Read more
          



          Week 1: Introduction to Open Government Introduction to the foundations and objectives of Open Government, including its meaning, ICT-developments that influence(d) Open Government and stakeholders of Open Government.  Week 2. Opening and reusing government data An introduction to concepts related to Open Government Data (e.g. a definition of Open Government Data, using open data for policy making, and open data portals and infrastructures) and to benefits, barriers and potential negative effects of open government data cases.  Week 3. Technical and judicial aspects of governmental information sharing A discussion of real open government cases and an analysis and discussion of benefits, barriers and potential negative effects of open government cases, including technological and judicial aspects (e.g. metadata and technologies for linking big and open data).  Week 4. Open government and public values and conclusions An analysis and discussion of public values and best practices related to open government. In this week we also discuss transparency and privacy in the context of open government.  Week 5. Exam In this week, students complete their final assignment and exam.",Open and Smart Government
https://www.classcentral.com/course/edx-introduction-to-probability-part-2-inference-and-processes-10017,"The world is full of uncertainty: accidents, storms, unruly financial markets, noisy communications. The world is also full of data. Probabilistic modeling and the related field of statistical inference are the keys to analyzing data and making scientifically sound predictions.This course is part of a 2-part sequence on the basic tools of probabilistic modeling. Topics covered in this course include:  

laws of large numbers
the main tools of Bayesian inference methods
an introduction to classical statistical methods
an introduction to random processes (Poisson processes and Markov chains)

This course is a follow-up to Introduction to Probability: Part I - The Fundamentals, which introduced the general framework of probability models, multiple discrete or continuous random variables, expectations, conditional distributions, and various powerful tools of general applicability. The contents of the two parts of the course are essentially the same as those of the corresponding MIT class, which has been offered and continuously refined over more than 50 years. It is a challenging class, but will enable you to apply the tools of probability theory to real-world applications or your research.Probabilistic models use the language of mathematics. But instead of relying on the traditional ""theorem - proof"" format, we develop the material in an intuitive - but still rigorous and mathematically precise - manner. Furthermore, while the applications are multiple and evident, we emphasize the basic concepts and methodologies that are universally applicable.Photo by Pablo Ruiz Múzquiz on Flickr. (CC BY-NC-SA 2.0)



            Read more
          




Bayesian inference: basic concepts and methods
Inference in linear normal models
General and linear least mean squares estimation
Limit theorems (weak law of large numbers, and the central limit theorem)
An introduction to classical statistics
The Bernoulli and Poisson processes
Markov chains",Introduction to Probability: Part 2 - Inference and Processes
https://www.classcentral.com/course/udacity-firebase-essentials-for-android-5055,"In this course, you’ll learn how to use Firebase. Firebase is a cloud backend, and one of the leading choices for Backend as a Service. It enables you to quickly get synchronized data up and running for multi-user apps. This is important because nearly every mobile app these days requires authentication and real-time data updates.  

We’ll begin by showing you how easy it is to read and write almost any data to Firebase. After that, we’ll teach you how to allow users to login and have data associated with them. We’ll then cover how to write queries and filters for your data. You’ll discover how to take advantage of Firebase's offline capabilities, and master efficient database design for lightning-fast data retrieval. Lastly, you’ll learn how to use Firebase’s Security and Rules language to secure and add permissions to your data. 

By the end of this course you will have an Android application that can store and share data between different users in real time as well as authenticate and authorize those users.Why Take This Course?If you are an Android developer and your app needs any of the following features:

- Online data storage
- Real-time synchronization between many users
- Authentication for Email/Password as well as OAuth providers
- Data permissions and security
- Offline access to data

This is the course for you!

Firebase is a gentle but very powerful introduction to storing and managing data. With just a few lines of code, you can read and write almost any data you could dream up from your own custom Firebase backend. 

Furthermore, Firebase has a generous free plan that lets you start making hosted apps with multiple users immediately.
      


            Read more
          



          ### Lesson 1
In this lesson you'll set up Firebase and read and write your first data. 

**Topics include:**

* Course Description and Prerequisites
* Getting Setup With Firebase
* Writing your first Firebase Data
* How Data Works in Firebase
* Reading your first Firebase Data
* Plain Old Java Objects in Firebase
* When to Choose Firebase as part of your stack

### Lesson 2
In this lesson you'll learn all the ins and outs of reading and writing data, including displaying lists of data that are synced with your Firebase database. 

**Topics include:**

* Writing
* Reading
* Debugging
* Lists in Firebase and FirebaseUI
* Best Practices for Reading and Writing Data

###Lesson 3
In this lesson you'll how to create user accounts using both the an email and password login flow, as well as Google login. You’ll then use this user data to display different information to the user depending on who they are signed in as. 

**Topics include:**

* Creating and Logging in Users via Email and Password
* Logging in Users with Google
* Logging out Users
* How to Store App Specific User Data
* How to Use User Data 
* Basic Login Security and Resetting User Passwords

###Lesson 4 (COMING SOON)
In this lesson you'll learn how to structure your database schema for lightning fast queries and sorting. You’ll use your new data structure to implement sharing functionality. You’ll also learn about Firebase’s filtering and sorting capabilities by adding sorting and basic autocomplete to ShoppingList++. 

**Topics include:**

* Sorting in Firebase with orderBy
* How and why to de-normalize data
* Dealing with Many to Many relationships in Firebase
* Using IndexOn and OrderByValue for faster searches
* Range, Start At, End At and Limit queries
* Basic Searching in Firebase

### Lesson 5 (COMING SOON)
In this lesson you'll learn about how Firebase deals with offline access and how to secure your data using Firebase’s built in security and permission rules. 

**Topics include:**

* Firebase Offline Access
* Security Rules
* Expression in Security Rules
* Authentication Checking in Security Rules
* Data Validation in Firebase",Firebase Essentials For Android
https://www.classcentral.com/course/independent-take-off-with-stats-in-python-12377,"This learning module in engineering computations (EngComp2) builds from a foundation in Python programming to develop data practices and computational problem-solving. You learn to handle data programmatically, reading data from files, cleaning and organizing data, and performing exploratory data analysis. You will use real data, learn to make pretty data visualizations, and gain insight from data.
The target audience is first- or second-year science and engineering students, but only high-school-level mathematics background is assumed.
What You'll Learn

Exploratory data analysis with real data (canned craft beers in the US, lead exposure from cosmetics, life expectancy and wealth).
Handling labeled data with the pandas library: data frames and series.
Visualizing quantitative and categorical data.
Getting insights from data using data-frame and series methods, various plots and interactive widgets.

 




Cheers! Stats with beers
Seeing stats in a new light
Lead in lipstick (a full worked-out example)
Life expectancy and wealth",Take off with Stats in Python
https://www.classcentral.com/course/machine-learning-big-data-apache-spark-15208,"This course will empower you with the skills to scale data science and machine learning (ML) tasks on Big Data sets using Apache Spark. Most real world machine learning work involves very large data sets that go beyond the CPU, memory and storage limitations of a single computer. 

Apache Spark is an open source framework that leverages cluster computing and distributed storage to process extremely large data sets in an efficient and cost effective manner. Therefore an applied knowledge of working with Apache Spark is a great asset and potential differentiator for a Machine Learning engineer.

After completing this course, you will be able to:
- gain a practical understanding of Apache Spark, and apply it to solve machine learning problems involving both small and big data
- understand how parallel code is written, capable of running on thousands of CPUs. 
- make use of large scale compute clusters to apply machine learning algorithms on Petabytes of data using Apache SparkML Pipelines. 
- eliminate out-of-memory errors generated by traditional machine learning frameworks when data doesn’t fit in a computer's main memory
- test thousands of different ML models in parallel to find the best performing one – a technique used by many successful Kagglers
- (Optional) run SQL statements on very large data sets using Apache SparkSQL and the Apache Spark DataFrame API.

Enrol now to learn the machine learning techniques for working with Big Data that have been successfully applied by companies like Alibaba, Apple, Amazon, Baidu, eBay, IBM, NASA, Samsung, SAP, TripAdvisor, Yahoo!, Zalando and many others.

NOTE: You will practice running machine learning tasks hands-on on an Apache Spark cluster provided by IBM at no charge during the course which you can continue to use afterwards.

Prerequisites:
- basic python programming
- basic machine learning (optional introduction videos are provided in this course as well)
- basic SQL skills for optional content

The following courses are recommended before taking this class (unless you already have the skills)
https://www.coursera.org/learn/python-for-applied-data-science or similar
https://www.coursera.org/learn/machine-learning-with-python or similar
https://www.coursera.org/learn/sql-data-science for optional lectures
      


            Read more
          



          Week 1: Introduction
    -This is an introduction to Apache Spark. You'll learn how Apache Spark internally works and how to use it for data processing. RDD, the low level API is introduced in conjunction with parallel programming / functional programming. Then, different types of data storage solutions are contrasted. Finally, Apache Spark SQL and the optimizer Tungsten and Catalyst are explained. 

Week 2: Scaling Math for Statistics on Apache Spark
    -Applying basic statistical calculations using the Apache Spark RDD API in order to experience how parallelization in Apache Spark works

Week 3: Introduction to Apache SparkML
    -Understand the concept of machine learning pipelines in order to understand how Apache SparkML works programmatically

Week 4: Supervised and Unsupervised learning with SparkML
    -Apply Supervised and Unsupervised Machine Learning tasks using SparkML",Scalable Machine Learning on Big Data using Apache Spark
https://www.classcentral.com/course/edx-question-everything-scientific-thinking-in-real-life-6023,"Have you ever wondered how you can apply math and science skills to real life? Do you wish you could go beyond what you've learned in the classroom? This science course will advance your knowledge as we unpack some important scientific thinking skills using real-world examples. By completing this course, you will be better prepared to continue studying math and science at the high school level and beyond.
In this course, a collaboration between The University of Queensland and Brisbane Grammar School, we will cover key scientific concepts related to:

Measurement
Estimation
The validity of evidence
The difference between logic and opinion
Misconceptions
Modeling
Prediction
Extrapolation

Each concept will be explored through real world examples and problems that will help you visualize how math and science work in your life.
This course is ideal for high school students looking to challenge themselves and further develop an interest in math and science. It is also applicable to high school science teachers looking for additional materials for teaching.



MODULE 1: Data and Measurement
Meet the course team and an introduction to the course content and navigation. We look at how speed is calculated using a LiDAR (Light Detection and Ranging). 
MODULE 2: Estimation and Measurement
We investigate the different ways in which we might perform an estimation and then use estimation to solve a variety of problems. 
MODULE 3: Validity of Evidence
We explore the difference between quantitative and qualitative evidence and develop our understanding of validity as it relates to evidence. 
MODULE 4: Evidence and Opinion
Learn the important difference between evidence and opinion, and test that understanding by conducting an experiment. 
MODULE 5: Misconceptions
Through a series of investigations and experiments we look at how misconceptions are formed and how to construct a better understanding of the facts surrounding a common misconception. 
MODULE 6: Modelling
We use data from a number of Olympic and World records to develop models and feature a graphing tool to better understand data modelling. 
MODULE 7: Prediction and Extrapolation
We continue to use Olympic and World records to move beyond modelling in order to extrapolate information and make predictions. 
MODULE 8: Synthesis and Application
Finally, we synthesise the concepts covered in all 7 modules to perform an experiment related to the calculation of gravity.",Question Everything: Scientific Thinking in Real Life
https://www.classcentral.com/course/edx-population-health-disease-prevention-and-management-11561,"This course is part of the Certified Lifestyle Medicine Executive MicroMasters program which consists of 9 courses and a capstone exam. After completing the program, you can also apply to Doane University to complete your MBA online for approximately $10,500 (learn more about the program here).________________________________________________________________The connections between prevention, wellness and behavioral health science with healthcare delivery, quality and safety, lifestyle medicine-based disease management and economic issues of value and risk—all in the service of specific populations and subpopulations - need to be made in order that disease can be prevented and managed within these populations. Learners who take this course will come away with the knowledge to be able to identify key socio-economic and cultural determinants of population health outcomes, analyze the impact of socio-cultural factors on access to health care and adjust health promotions and interventions accordingly.This course is part of the Certified Lifestyle Medicine MicroMasters program. For an introduction to lifestyle medicine, see the Lifestyle Medicine Competencies Professional Certificate program.",Population Health: Disease Prevention and Management
https://www.classcentral.com/course/edx-ap-computer-science-a-java-programming-classes-and-objects-7211,"In this computer science course, you will learn the basics of programming in the Java language, and cover topics relevant to the AP Computer Science A course and exam.
This course will cover:

classes
objects and object-oriented design
fields and visibility
constructors, mutators and accessor methods
encapsulation
interfaces
the List interface
method overriding

This course is for anyone interested in taking a first-level computer-programming course, particularly those who attend a school that does not provide a similar class.
No previous programming knowledge is needed, but it is recommended that learners be comfortable with the topics addressed in AP Computer Science A: Java Programming and AP Computer Science A: Java Programming Data Structures and Loops.
We are looking forward to helping you explore this exciting new world!



Unit Name or Timeframe: Methods and Classes (3 weeks)
Object-oriented design and encapsulation
Top-down development and functional decomposition
State and behavior
Fields and visibility
Methods and parameters
Calling methods and passing parameters by-value and by-reference
Constructors and instantiation
The static keyword
Scope
Method overloading
Encapsulation
Accessors and mutators
Immutable objects
Unit Name or Timeframe: Interfaces (1 week)
Interfaces and abstraction
Interface implementation
Reference types
List interface and iterators
Comparable interface
Unit Name or Timeframe: Inheritance (2 weeks)
Inheritance and the Object class
Public and private data and methods
The super, this and null references
Encapsulation and information hiding
Inheritance using extends, recognizing single-inheritance
Equality vs identity
has-a vs is-a relationships involving inheritance and aggregation
Method overriding
The instanceof operator",AP Computer Science A: Java Programming Classes and Objects
https://www.classcentral.com/course/edx-capstone-exam-for-statistics-and-data-science-11484,This capstone exam is the final part of the MITx MicroMasters Program in Statistics and Data Science. Complete the four courses in this program and take this virtually-proctored exam to earn your MicroMasters credential and demonstrate your proficiency in data science or accelerate your path towards an MIT PhD or a Master's at other universities.,Capstone Exam for Statistics and Data Science
https://www.classcentral.com/course/openhpi-code-of-life-when-computer-science-meets-genetics-5151,"Welcome to the class: we are very excited that you are interested in learning more about the foundations of life. In this openHPI course, we will give an introduction about components of human cells and their functions. We dive into the cell core to explore the Deoxyribonucleic Acid (DNA), its structure, and how it stores the code of life. Furthermore, we will explore how to discover genetic variants and mutations and how to assess their impact on the cell functions and the whole human body. Ultimately, we will outline how individual genetic variants can be connected to complex diseases, such as cancer. Just two decades ago, all these tasks would have been impossible due to missing knowledge about the DNA and a lack of computational power. As a result, you will learn basic concepts about how to incorporate latest computer science aspects to explore the code of life interactively.",Code of Life – When Computer Science Meets Genetics
https://www.classcentral.com/course/edx-data-structures-fundamentals-10246,"A good algorithm usually comes together with a set of good data structures that allow the algorithm to manipulate the data efficiently. In this course, part of the Algorithms and Data Structures MicroMasters program, we consider the common data structures that are used in various computational problems. You will learn how these data structures are implemented in different programming languages and will practice implementing them in our programming assignments. This will help you to understand what is going on inside a particular built-in implementation of a data structure and what to expect from it. You will also learn typical use cases for these data structures.
A few examples of questions that we are going to cover in this course are:

What is a good strategy of resizing a dynamic array?
How priority queues are implemented in C++, Java, and Python?
How to implement a hash table so that the amortized running time of all operations is O(1) on average?
What are good strategies to keep a binary tree balanced?

We look forward to seeing you in this course! We know it will make you a better programmer.



Module 1: Basic Data Structures In this module, you will learn about the basic data structures used throughout the rest of this course. We start this module by looking in detail at the fundamental building blocks: arrays and linked lists. From there, we build up two important data structures: stacks and queues. Next, we look at trees: examples of how they’re used in Computer Science, how they’re implemented, and the various ways they can be traversed. Once you’ve completed this module, you will be able to implement any of these data structures, as well as have a solid understanding of the costs of the operations, as well as the tradeoffs involved in using each data structure.
Module 2: Dynamic Arrays and Amortized Analysis In this module, we discuss Dynamic Arrays: a way of using arrays when it is unknown ahead-of-time how many elements will be needed. Here, we also discuss amortized analysis: a method of determining the amortized cost of an operation over a sequence of operations. Amortized analysis is very often used to analyse performance of algorithms when the straightforward analysis produces unsatisfactory results, but amortized analysis helps to show that the algorithm is actually efficient. It is used both for Dynamic Arrays analysis and will also be used in the end of this course to analyze Splay trees.
Module 3: Priority Queues and Disjoint Set Union We start this module by considering priority queues which are used to efficiently schedule jobs, either in the context of a computer operating system or in real life, to sort huge files, which is the most important building block for any Big Data processing algorithm, and to efficiently compute shortest paths in graphs, which is a topic we will cover in our next course. For this reason, priority queues have built-in implementations in many programming languages, including C++, Java, and Python. We will see that these implementations are based on a beautiful idea of storing a complete binary tree in an array that allows to implement all priority queue methods in just few lines of code. We will then switch to disjoint sets data structure that is used, for example, in dynamic graph connectivity and image processing. We will see again how simple and natural ideas lead to an implementation that is both easy to code and very efficient. By completing this module, you will be able to implement both these data structures efficiently from scratch.
Modules 4 and 5: Hash Tables In this module you will learn about very powerful and widely used technique called hashing. Its applications include implementation of programming languages, file systems, pattern search, distributed key-value storage and many more. You will learn how to implement data structures to store and modify sets of objects and mappings from one type of objects to another one. You will see that naive implementations either consume huge amount of memory or are slow, and then you will learn to implement hash tables that use linear memory and work in O(1) on average!
Module 6: Binary Search Trees In this module we study binary search trees, which are a data structure for doing searches on dynamically changing ordered sets. You will learn about many of the difficulties in accomplishing this task and the ways in which we can overcome them. In order to do this you will need to learn the basic structure of binary search trees, how to insert and delete without destroying this structure, and how to ensure that the tree remains balanced.",Data Structures Fundamentals
https://www.classcentral.com/course/edx-computation-structures-3-computer-organization-6245,"Digital systems are at the heart of the information age in which we live, allowing us to store, communicate and manipulate information quickly and reliably. This computer science course is a bottom-up exploration of the abstractions, principles, and techniques used in the design of digital and computer systems. If you have a rudimentary knowledge of electricity and some exposure to programming, roll up your sleeves, join in and design a computer system!
This is Part 3 of a 3-part series on digital systems, providing an introduction to the hardware/software interface and is based on a course offered by the MIT Department of Electrical Engineering and Computer Science. Topics include pipelined computers, virtual memories, implementation of a simple time-sharing operating system, interrupts and real-time, and techniques for parallel processing.
Using your browser for design entry and simulation, you’ll optimize your processor design from Part 2 for size and speed, and make additions to a simple time-sharing operating system.
 
Learner Testimonial
""Out of the many edX courses I have taken, the first two parts of 6.004x were clearly the best. I am looking forward to the third part.” -- Previous Student




Pipelined Beta: pipelined execution of instructions, data and control hazards, resolving hazards using bypassing, stalling and speculation.
Virtual Memory: extending the memory hierarchy, paging using hierarchical page maps and look-aside buffers, contexts and context switching, integrating virtual memories with caches.
Operating Systems: processes, interrupts, time sharing, supervisor calls.
Devices and Interrupts: device handlers asynchronous I/O, stalling supervisor calls, scheduling, interrupt latencies, weak and strong priority systems.
Processes, Synchronization and Deadlock: inter-process communication, bounded buffer problem, semaphores for precedence and mutual exclusion, semaphore implementation, dealing with deadlock.
Interconnect: the truth about wires, point-to-point vs. shared interconnect, communication topologies.
Parallel Processing: instruction-, data- and thread-level parallelism, Amdahl’s Law, cache coherency.
Labs: optimizing your Beta design for size and speed, emulating instructions, extending a simple time-sharing operating system.",Computation Structures 3: Computer Organization
https://www.classcentral.com/course/mitx-statistics-and-data-science-18342,"Demand for professionals skilled in data, analytics, and machine learning is exploding. A recent report by IBM and Burning Glass states that there will be 364K new job openings in data-driven professions by 2020 in the US. Data scientists bring value to organizations across industries because they are able to solve complex challenges with data and drive important decision-making processes. 39% of the most rigorous data science positions require a degree higher than a bachelor’s.
This MicroMasters program in Statistics and Data Science is comprised of four online courses and a virtually proctored exam that will provide you with the foundational knowledge essential to understanding the methods and tools used in data science, and hands-on training in data analysis and machine learning. You will dive into the fundamentals of probability and statistics, as well as learn, implement, and experiment with data analysis techniques and machine learning algorithms. This program will prepare you to become an informed and effective practitioner of data science who adds value to an organization. The program certificate can be applied, for admitted students, towards a PhD in Social and Engineering Systems (SES) through the MIT Institute for Data, Systems, and Society (IDSS) or may accelerate your path towards a Master’s degree at other universities around the world.
Anyone can enroll in this MicroMasters program. It is designed for learners that want to acquire sophisticated and rigorous training in data science without leaving their day job but without compromising quality. There is no application process but college-level calculus and comfort with mathematical reasoning and Python programming are highly recommended if you want to excel. All the courses are taught by MIT faculty at a similar pace and level of rigor as an on-campus course at MIT. This program brings MIT’s rigorous, high-quality curricula and hands-on learning approach to learners around the world – at scale.
For more detail on this program and credit pathways, please visit https://micromasters.mit.edu/ds/



            Read more
          



Courses under this program:Course 1: Probability - The Science of Uncertainty and Data
Build foundational knowledge of data science with this introduction to probabilistic models, including random processes and the basic elements of statistical inference -- Course 1 of 4 in the MITx MicroMasters program in Statistics and Data Science.
Course 2: Data Analysis in Social Science—Assessing Your KnowledgeLearn the methods for harnessing and analyzing data to answer questions of cultural, social, economic, and policy interest, and then assess that knowledge— Course 2 of 4 in the MITx MicroMasters program in Statistics and Data Science.Course 3: Fundamentals of Statistics
Develop a deep understanding of the principles that underpin statistical inference: estimation, hypothesis testing and prediction. -- Course 3 of 4 in the MITx MicroMasters program in Statistics and Data Science.
Course 4: Machine Learning with Python: from Linear Models to Deep Learning
An in-depth introduction to the field of machine learning, from linear models to deep learning and reinforcement learning, through hands-on Python projects. -- Course 4 of 4 in the MITx MicroMasters program in Statistics and Data Science.
Course 5: Capstone Exam in Statistics and Data Science
Solidify and demonstrate your knowledge and abilities in probability, data analysis, statistics, and machine learning in this culminating assessment. -- Final Requirement of the MITx MicroMasters Program in Statistics and Data Science.",Statistics and Data Science
https://www.classcentral.com/course/edx-performance-assessment-in-the-ngss-classroom-implications-for-practice-17140,"This course from the Stanford NGSS Assessment Project (SNAP) is designed to guide participants in exploring the role performance assessment can play in helping their students meet the goals of the Next Generation Science Standards. Participants will learn SNAP's strategies for analyzing what an assessment is evaluating, analyzing multidimensional student data, and making instructional decisions based on evidence of students' progress and additional needs. Participants will have opportunities throughout the course to practice using these strategies with sample short performance assessments (20 minute tasks) and student data. 
This course follows a hybrid format designed to support groups of colleagues learning together. Instruction is delivered through four video sessions and the assignments for those sessions are done in-person (face-to-face) with groups of colleagues. One member of the group should be designated a facilitator. Because this format is so unusual, we have created introductory videos to help you organize your groups and prepare for the face-to-face sessions. Note: SNAP is not present in these meetings -- we provide facilitation guides and all of the materials you will need for the assignments, but these meetings are run by you and your colleagues.",Performance Assessment in the NGSS Classroom: Implications for Practice
https://www.classcentral.com/course/edx-supply-chain-technology-and-systems-6366,"There are underlying fundamental principles and concepts that apply to all supply chains, which can be expressed in relatively straightforward models. However, to actually implement them across a real supply chain requires the use of technology across multiple systems. Supply chains have a long history of using technology to improve efficiency and effectiveness. The shear scale and scope of most supply chains require many distinct systems to interact with each other.
Unfortunately, technology is a moving target. It is constantly evolving and improving so that today's technology is outdated within a few years or months. Rather than focusing on a specific software system, this business and management course will focus on three aspects: fundamental concepts, core systems, and data analysis.
We will start with the introduction of fundamental concepts that are used in all software tools. We will cover IT fundamentals, including project management and software processes, data modeling, UML, relational databases and SQL. We will also introduce Internet technologies, such as XML, web services, and service-oriented architectures. No prior programming experience required.
We will then provide an overview of the main types of supply chain software including ERP, WMS, and TMS systems. We will describe their main functionality, how they work, how they are used, their architecture, data flows, and how they are organized into modules. We will also cover the software selection process and how software upgrade and implementation projects should be organized and managed.
Finally, we will dive into data analysis that is core to all large supply chains. We will introduce visualization and big data analysis techniques that are used in practice today.



            Read more",Supply Chain Technology and Systems
https://www.classcentral.com/course/edx-health-informatics-technology-in-population-healthcare-analytics-11563,"This course is part of the Certified Lifestyle Medicine Executive MicroMasters program which consists of 9 courses and a capstone exam. After completing the program, you can also apply to Doane University to complete your MBA online for approximately $10,500 (learn more about the program here).________________________________________________________________Health informatics technology (HIT) is the field of study that focuses on acquiring, storing, and retrieving healthcare data. In order to address the challenges of safety, quality, effectiveness, and efficiency in healthcare systems for population health, HIT is essential. Electronic healthcare records and data are dynamic and at a population level, HIT enables the use of aggregate data to refine and enhance our understanding of what interventions are most clinically and cost effective for subsets of patients within a population.While most health informatics texts take a hospital-centric approach, this course focuses on how to operationalize informatics solutions to address important public health challenges impacting individuals, families, communities, and the environment in which they live.This course is part of the Certified Lifestyle Medicine Executive MicroMasters program. For an introduction to lifestyle medicine, see the Lifestyle Medicine Competencies Professional Certificate program.",Health Informatics Technology in Population Healthcare Analytics
https://www.classcentral.com/course/edx-foundations-of-data-science-prediction-and-machine-learning-10320,"One of the principal responsibilities of a data scientist is to make reliable predictions based on data. When the amount of data available is enormous, it helps if some of the analysis can be automated. Machine learning is a way of identifying patterns in data and using them to automatically make predictions or decisions. In this data science course, you will learn basic concepts and elements of machine learning. 
The two main methods of machine learning you will focus on are regression and classification. Regression is used when you seek to predict a numerical quantity. Classification is used when you try to predict a category (e.g., given information about a financial transaction, predict whether it is fraudulent or legitimate). 
For regression, you will learn how to measure the correlation between two variables and compute a best-fit line for making predictions when the underlying relationship is linear. The course will also teach you how to quantify the uncertainty in your prediction using the bootstrap method. These techniques will be motivated by a wide range of examples. 
For classification, you will learn the k-nearest neighbor classification algorithm, learn how to measure the effectiveness of your classifier, and apply it to real-world tasks including medical diagnoses and predicting genres of movies. 
The course will highlight the assumptions underlying the techniques, and will provide ways to assess whether those assumptions are good. It will also point out pitfalls that lead to overly optimistic or inaccurate predictions.



            Read more",Foundations of Data Science: Prediction and Machine Learning
https://www.classcentral.com/course/edx-scientific-methods-and-research-9380,"What does it mean to conduct research? What are the distinct stages of the research process? What are the requirements of modern scientific research? How do you analyze a scientific article? 
This course will teach you to conduct research in accordance with scientific methodology. You'll learn to analyze scientific articles in engineering and science subjects, and how to conduct scientific experiments. 
The course will help to develop the core skill of a scientist, giving you the research tools to succeed. The course material is well-suited for anyone interested in the problems of uncovering knowledge and science; giving you a methodology for the achievement of educational and scientific activities. 
This course is for anyone who has ever said, “Science is interesting.” It will appeal to those who want to learn the processes behind modern scientific research.




Week 1: The philosophical aspects of scientific activity
Introduction to the Philosophy of Science. What is a ""scientific theory""? The structure of a scientific theory. The methodology used to obtain scientific knowledge. Requirements to achieve scientific results.
Week 2: Theory and practice of scientific research
What is research? Ph.D. requirements. Research planning. Research question. Modes inquiry. Induction and deduction in your research project.
Week 3: Philosophical principles of research
Ontology and epistemology. Objectivity and subjectivity. Causation and correlation in your research project.
Week 4: Research process
Literature review. Research questions and hypothesis. The structure of paper and plan investigation. Research impact.
Week 5: Methodology of experiment in engineering studies
The purpose and structure of the experiment. Planning. Analysis of the results.",Scientific Methods and Research
https://www.classcentral.com/course/metabolomics-3896,"##
Metabolomics is an emerging field that aims to measure the complement of metabolites (the metabolome) in living organisms. The metabolome represents the downstream effect of an organism’s genome and its interaction with the environment. Metabolomics has a wide application area across the medical and biological sciences. The course provides an introduction to metabolomics, describes the tools and techniques we use to study the metabolome and explains why we want to study it. By the end of the course you will understand how metabolomics can revolutionise our understanding of metabolism.
The course is primarily aimed at final year undergraduate science students and research scientists who are interested in learning about the application of metabolomics to understand metabolism. However, metabolomics is a new tool to the scientific community and this course will provide a valuable introduction to scientists at any stage in their careers. It is not essential to have any previous knowledge of the subject area but a reasonable knowledge and understanding of science would be beneficial.",Metabolomics: Understanding Metabolism in the 21st Century
https://www.classcentral.com/course/edx-urban-design-for-the-public-good-dutch-urbanism-8020,"Are you an urban planner, designer, policy maker or involved or interested in the creation of good living environments?
This course will broaden your scope and diversify your take on the field of urban planning and design. We will focus on a unique Dutch approach and analyze how it can help those involved with urban planning and design to improve the physical environment in relation to the public good it serves, including safety, wellbeing, sustainability and even beauty.
You will learn some of the basic traits of Dutch Urbanism, including its:

contextual approach;
balance between research and design;
simultaneous working on multiple scale levels.

You will practice with basic techniques in spatial analysis and design pertaining to these points. You will also carry out these activities in your own domestic environment.
This course is taught by the Faculty of Architecture and the Built Environment at TU-Delft, ranked no. 4 in Architecture/Built Environment on the QS World University Rankings (2016).
All the material in this course is presented at entry level. But since the course has an integral perspective, combining planning and design aspects, it can still be relevant for trained professionals who feel they lack experience in either field.
 



          Week 1:The first module is a thematic and technical introduction of the basic concepts behind the course and its functionality.Week 2:We will focus on the concept of “public goods” and how these can be strengthened or created by design and planning actions.Week 3:This module is focused around the structural role of the natural landscape in any urban environment.Week 4:We will introduce you to the concept of Urban Metabolism and the way in which different urban “flows” interact.Week 5:We will look at how seemingly small interventions like the restructuring of an urban plaza can have a great impact on the usability and enjoyability of the city for all.Week 6:This module is an introduction to the realm of data driven design. What may someday result in “smart cities” must start from a basic understanding of the relation between data and design.Week 7:Another exercise in how to achieve big results with small interventions: In this module, we will look at how strategic changes in infrastructure have brought new life to a dilapidated area.Week 8:Rounding off this course, we will bring the concept of design for the public good to an new level, what have we learned? But more importantly, what are the roads ahead?",Urban Design for the Public Good: Dutch Urbanism
https://www.classcentral.com/course/edx-digital-networks-essentials-6719,"Every business today depends on connectivity, and now there is increasing demand for engineers who can design, develop and manage data networks – and keep them secure as well.
This applied computer science MOOC will give you the hands-on know-how to master the network technologies used every day to communicate and access information via the web and phones.
You’ll learn the vocabulary, concepts and mechanisms common to all digital networks, and explore the TCP, UDP and IP protocols that support all online communications.
You’ll also see how a global network is organized and how its components work together, and understand the importance of standards and protocols. This course is designed for students or professionals with a background in science or computing.
Practical coursework is carried out in a Unix virtual environment that can be installed on any modern computer.
Sign up now and sharpen up your network knowledge!",Digital Networks Essentials
https://www.classcentral.com/course/udacity-high-performance-computing-1028,"The goal of this course is to give you solid foundations for developing, analyzing, and implementing parallel and locality-efficient algorithms. This course focuses on theoretical underpinnings. To give a practical feeling for how algorithms map to and behave on real systems, we will supplement algorithmic theory with hands-on exercises on modern HPC systems, such as Cilk Plus or OpenMP on shared memory nodes, CUDA for graphics co-processors (GPUs), and MPI and PGAS models for distributed memory systems.This course is a graduate-level introduction to scalable parallel algorithms. ""Scale"" really refers to two things: efficient as the problem size grows, and efficient as the system size (measured in numbers of cores or compute nodes) grows. To really scale your algorithm in both of these senses, you need to be smart about reducing asymptotic complexity the way you’ve done for sequential algorithms since CS 101; but you also need to think about reducing communication and data movement. This course is about the basic algorithmic techniques you’ll need to do so.The techniques you’ll encounter covers the main algorithm design and analysis ideas for three major classes of machines: for multicore and many core shared memory machines, via the work-span model; for distributed memory machines like clusters and supercomputers, via network models; and for sequential or parallel machines with deep memory hierarchies (e.g., caches). You will see these techniques applied to fundamental problems, like sorting, search on trees and graphs, and linear algebra, among others. The practical aspect of this course is implementing the algorithms and techniques you’ll learn to run on real parallel and distributed systems, so you can check whether what appears to work well in theory also translates into practice. (Programming models you’ll use include Cilk Plus, OpenMP, and MPI, and possibly others.)Why Take This Course?



            Read more
          



The course topics are centered on three different ideas or extensions to the usual serial RAM model you encounter in CS 101. Recall that a serial RAM assumes a sequential or serial processor connected to a main memory.Unit 1: The work-span or dynamic multithreading modelIn this model, the idea is that there are multiple processors connected to the main memory. Since they can all ""see"" the same memory, the processors can coordinate and communicate via reads and writes to that ""shared"" memory.Sub-topics include:** Intro to the basic algorithmic model** Intro to OpenMP, a practical programming model** Comparison-based sorting algorithms** Scans and linked list algorithms** Tree algorithms** Graph algorithms, e.g., breadth-first searchUnit 2: Distributed memory or network modelsIn this model, the idea is that there is not one serial RAM, but many serial RAMs connected by a network. In this model, each serial RAM’s memory is private to the other RAMs; consequently, the processors must coordinate and communicate by sending and receiving messages.Sub-topics include:** The basic algorithmic model** Intro to the Message Passing Interface, a practical programming model** Reasoning about the effects of network topology** Dense linear algebra** Sorting** Sparse graph algorithms** Graph partitioningUnit 3: Two-level memory or I/O modelsIn this model, we return to a serial RAM, but instead of having only a processor connected to a main memory, there is a smaller but faster scratchpad memory in between the two. The algorithmic question here is how to use the scratchpad effectively, in order to minimize costly data transfers from main memory.Sub-topics include:** Basic models** Efficiency metrics, including ""emerging"" metrics like energy and power** I/O-aware algorithms** Cache-oblivious algorithms",High Performance Computing
https://www.classcentral.com/course/swayam-vlsi-physical-design-7894,"The course will introduce the participants to the basic design flow in VLSI physical design automation, the basic data structures and algorithms used for implementing the same. The course will also provide examples and assignments to help the participants to understand the concepts involved, and appreciate the main challenges therein.INTENDED AUDIENCE : Computer Science and Engineering / Electronics and Communication Engineering / Electrical EngineeringPREREQUISITES : Basic concepts in digital circuit designINDUSTRY SUPPORT : Intel, Cadence, Mentor Graphics, Synopsys, Xilinx



COURSE LAYOUT Week 1 : Introduction to physical design automationWeek 2 : Partitioning, Floorplanning and PlacementWeek 3 : Grid Routing and Global RoutingWeek 4 : Detailed Routing and Clock DesignWeek 5 : Clock Routing and Power/GroundWeek 6 : Static Timing Analysis and Timing ClosureWeek 7 : Physical Synthesis and Performance Driven Design FlowWeek 8 : Interconnect Modeling and Layout CompactionWeek 9 : Introduction to Testing, Fault Modeling and Simulation]]>Week 10 : Test Pattern Generation, DFT and BISTWeek 11 : Low Power Design TechniquesWeek 12 : Low Power Design Techniques (contd.)",VLSI Physical Design
https://www.classcentral.com/course/fitting-statistical-models-data-python-12633,"In this course, we will expand our exploration of statistical inference techniques by focusing on the science and art of fitting statistical models to data. We will build on the concepts presented in the Statistical Inference course (Course 2) to emphasize the importance of connecting research questions to our data analysis methods. We will also focus on various modeling objectives, including making inference about relationships between variables and generating predictions for future observations.

This course will introduce and explore various statistical modeling techniques, including linear regression, logistic regression, generalized linear models, hierarchical and mixed effects (or multilevel) models, and Bayesian inference techniques. All techniques will be illustrated using a variety of real data sets, and the course will emphasize different modeling approaches for different types of data sets, depending on the study design underlying the data (referring back to Course 1, Understanding and Visualizing Data with Python).

During these lab-based sessions, learners will work through tutorials focusing on specific case studies to help solidify the week’s statistical concepts, which will include further deep dives into Python libraries including Statsmodels, Pandas, and Seaborn. This course utilizes the Jupyter Notebook environment within Coursera.
      


          WEEK 1 - OVERVIEW & CONSIDERATIONS FOR STATISTICAL MODELING
    -We begin this third course of the Statistics with Python specialization with an overview of what is meant by “fitting statistical models to data.” In this first week, we will introduce key model fitting concepts, including the distinction between dependent and independent variables, how to account for study designs when fitting models, assessing the quality of model fit, exploring how different types of variables are handled in statistical modeling, and clearly defining the objectives of fitting models.

WEEK 2 - FITTING MODELS TO INDEPENDENT DATA
    -In this second week, we’ll introduce you to the basics of two types of regression: linear regression and logistic regression.  You’ll get the chance to think about how to fit models, how to assess how well those models fit, and to consider how to interpret those models in the context of the data.  You’ll also learn how to implement those models within Python.

WEEK 3 - FITTING MODELS TO DEPENDENT DATA
    -In the third week of this course, we will be building upon the modeling concepts discussed in Week 2. Multilevel and marginal models will be our main topic of discussion, as these models enable researchers to account for dependencies in variables of interest introduced by study designs. We’ll be covering why and when we fit these alternative models, likelihood ratio tests, as well as fixed effects and their interpretations. 

WEEK 4: Special Topics
    -In this final week, we introduce special topics that extend the curriculum from previous weeks and courses further. We will cover a broad range of topics such as various types of dependent variables, exploring sampling methods and whether or not to use survey weights when fitting models, and in-depth case studies utilizing Bayesian techniques to derive insights from data. You’ll also have the opportunity to apply Bayesian techniques in Python.",Fitting Statistical Models to Data with Python
https://www.classcentral.com/course/edx-javascript-introduction-8496,"This course is part of W3C's ""Front-End Web Developer"" Professional Certificate.

This computer science course is an initiation to JavaScript programming and has been designed to help Web developers have an understanding of the basic concepts of the language. This course was developed in partnership between W3C and University Côte d'Azur.
JavaScript lets you add interactive features to your Web sites, including dynamically updated content, controlled multimedia, animated images, and much more.
The main objective of this course is to master JavaScript best practices by means of many interactive examples, some of which are demonstrated in live coding videos.
We’ll use JavaScript within the Web browser. Why JavaScript is worth your time:

HTML5, CSS and JavaScript are the “classic three” for developers and designers;
It allows you to add interactivity to your Web sites;
You can use JavaScript and HTML5 APIs to create custom graphics and animation, and to master multimedia using audio and video players, music and sound effects;
It is powerful, easy to learn, and quick to write;
It has great tools (editors, runtimes, lint tools, browsers, and third party libraries) as well as great online support through plenty of active open source communities.

At the end of the course, we expect that you will be able to read the source code of any JavaScript example found on the Web, learn from it, tweak it, and even – why not? – start contributing to open-source JavaScript projects. This introductory course will make you think like a JavaScript developer.



            Read more
          



Module 1: Introduction to JavaScript

JavaScript, HTML and CSS
JavaScript overview
Your first HTML/CSS/JS page
Variables, values, functions, operators, and expressions
Simple JavaScript examples to play with

Module 2: Adding interactivity to HTML

Conditional statements, loops and logical operators
Functions and callbacks
Handling events
The DOM API
Let's write a small game

Module 3: Playing with HTML5

APIs Arrays and iterators
HTML5 multimedia and JavaScript API
Displaying a map with the Geolocation API
Playing sound samples and music

Module 4: Structuring data

Objects, properties and methods
Creating multiple objects
Organizing the code in separate files
Improving the game with ES6 classes

Module 5: Working with forms

Built-in JavaScript objects
HTML5 tables, forms and input fields
The JSON notation
Let's create a small application",JavaScript Introduction
https://www.classcentral.com/course/edx-energy-principles-and-renewable-energy-9792,"This course addresses the important global issue of transitioning to a sustainable energy future.
The course covers: basic energy concepts and terms; energy systems; the challenge of fossil-fuel greenhouse gas emissions from power generation; and describes and evaluates a range of renewable energy technologies. Renewable energy technologies analysed include: bioenergy, geothermal, solar, wind power, hydropower and ocean power.
This course is part of the Sustainable Energy MicroMasters series. You may take the course as a single course or complete all four courses in the series. 
There are two enrolment options: verified enrolment and audit enrolment.We recommend that you enrol in the Audit enrolment track first. If you wish to complete the assessment tasks with the aim to achieve at least 70% in the final grade and a course certificate, you must upgrade to the Verified enrolment track and pay the Verified enrolment fee within the first five weeks from when the course opened. If you miss the Verified enrolment upgraded deadline you can continue with the course as an Audit learner and enrol as a Verified learner in the next run of the course (and complete the assessment tasks then). you enrol as a verified learner and successfully complete all four courses you will qualify for the Sustainable Energy MicroMasters credential. 
A Sustainable Energy MicroMasters credential is worthwhile in itself, but, if you wish to continue your studies, the Sustainable Energy MicroMasters credential could be used towards studying the Master of Sustainable Energy at The University of Queensland in Brisbane, Australia. 
Learners who choose to enrol as verified and pay the enrolment fee, will be required to write an assignment, and achieve an overall passing grade of 70% or above in order to receive the downloadable verified certificate. 
The final examination is timed and has a weight of 30%. The written paper has a weight of 50%, is submitted to Turnitin, a text-matching software, and is instructor-marked. 
If you enrol in the audit track, you will have access to all the videos and other resources while the course is open, but you will not have access to the graded assessment tasks. In addition, audit participants will not be eligible to receive a course certificate upon completion of the course. 
Both enrolment tracks are valuable. However, if you decide to enrol in the Verified enrolment track, please ensure you will be able to write a Masters level paper. 
Plagiarism and cheating, including (i) copying and pasting text from other sources and (ii) using information from other sources without full and compliant referencing, will result in a grade of zero. 
This course runs multiple times throughout the year.



            Read more
          



Background:Energy Literacy
An introduction to the language of energy aimed at those without an engineering or science background, to allow learners to engage with the material that follows. 
Topic 1: The Challenge
This topic describes some of the challenges we face in creating sustainable energy systems given the world's increasing demand for energy and the threat posed by climate change. 
Topic 2: Energy systems
We will introduce learners to some of the fundamental science that governs energy systems and energy transformation. 
Topic 3: Bioenergy
This topic describes the uses of Bioenergy, carbon footprint, global uptake and future possibilities. 
Topic 4: Geothermal
This topic describes the uses of geothermal energy, carbon footprint, global uptake and future possibilities. 
Topic 5: Solar
This topic investigates the different types of solar energy and then describes how solar energy can be used, its carbon footprint, global uptake and future possibilities. 
Topic 6: Wind power
This topic describes how energy from the wind can be used, its carbon footprint, global uptake and future possibilities. 
Topic 7: Hydropower
This topic focuses on how hydropower is used to create energy, how this energy can be used, its carbon footprint, global uptake and future possibilities. 
Topic 8: Ocean power
This topic describes how energy can be extracted from the ocean's waves and tides, how this energy can be used, its carbon footprint, how much is used around the world and its future possibilities. 
Topic 9: Energy storage
This topic introduces learners to the ways energy can be stored, the characteristics of an energy storage system and the possible uses of an energy storage system. 
Topic 10: Electricity management
In electricity management learners will be introduced to how electricity markets work, transmission and distribution concepts and the requirement for balancing the grid.",Energy Principles and Renewable Energy
https://www.classcentral.com/course/opensap-sap-data-intelligence-for-enterprise-ai-17234,"With the recent breakthroughs in artificial intelligence (AI), many companies are pursuing the means to apply machine learning-based techniques to their business processes to transform and improve their usability and profitability and accelerate industry growth. SAP aspires to make all its enterprise solutions smart and help customers evolve to an intelligent enterprise.
This course offers an introduction to SAP Data Intelligence, SAP’s new AI/data science platform to manage complex data landscapes, build scalable data pipelines, and provision the entire data science process from proof of concept development to operationalization, continuous optimization, and adaptation. SAP Data Intelligence is a flexible solution that connects open source environments like JupyterLab with proven SAP technologies like SAP HANA and SAP Leonardo Machine Learning, while allowing you to work across them seamlessly. The features offered facilitate the building of smart applications for customers and business partners.
In this course, we’ll discuss use cases for enterprise machine learning applications. We’ll show you how to work with popular languages, such as Python and R, or your favorite libraries such as TensorFlow, in a development to production environment that supports you through the entire lifecycle management, from data access to continuous model retraining and deployment. You’ll also go through a variety of demos to learn how to build and consume your own machine learning/deep learning models.
The course is aimed mainly at data science enthusiasts but is also suitable for anyone interested in data science and innovation, focusing on the specific product capabilities for developing a data science scenario in an enterprise landscape. To learn more about the data management aspects of SAP Data Intelligence for data engineers, developers, and development operations, we highly recommend you also visit the course Freedom of Data with SAP Data Hub (HUB1) on openSAP.
 



            Read more
          



Unit 1: Enabling the Intelligent Enterprise with Machine Learning
Unit 2: Intelligent SAP Applications
Unit 3: Customer Use Cases
Unit 4: SAP Data Intelligence Capabilities for Data Scientists
Unit 5: SAP Data Intelligence Launchpad and Components
Unit 6: Machine Learning Scenario Manager
Unit 7: Data Science Experiments in Jupyter Notebook (PAL, APL, Python)
Unit 8: Working with the SAP Data Intelligence Pipeline Modeler
Unit 9: Operationalizing Python and R with the Pipeline Modeler
Unit 10: Intelligent Services
Unit 11: Summary and Outlook",SAP Data Intelligence for Enterprise AI
https://www.classcentral.com/course/edx-deep-learning-fundamentals-with-keras-11732,"Looking to kickstart a career in deep learning? Look no further. This course will introduce you to the field of deep learning and teach you the fundamentals. You will learn about some of the exciting applications of deep learning, the basics fo neural networks, different deep learning models, and how to build your first deep learning model using the easy yet powerful library Keras. This course will present simplified explanations to some of today's hottest topics in data science, including: 

What is deep learning?
How do neural networks learn and what are activation functions?
What are deep learning libraries and how do they compare to one another?
What are supervised and unsupervised deep learning models?
How to use Keras to build, train, and test deep learning models?

The demand for deep learning skills-- and the job salaries of deep learning practitioners -- are continuing to grow, as AI becomes more pervasive in our societies. This course will help you build the knowledge you need to future-proof your career.
      


Module 1 - Introduction to Deep Learning              - Introduction to Deep Learning     - Biological Neural Networks     - Artificial Neural Networks - Forward Propagation Module 2 - Artificial Neural Networks     - Gradient Descent     - Backpropagation     - Vanishing Gradient     - Activation FunctionsModule 3 - Deep Learning Libraries     - Introduction to Deep Learning Libraries     - Regression Models with Keras     - Classification Models with KerasModule 4 - Deep Learning Models     - Shallow and Deep Neural Networks     - Convolutional Neural Networks     - Recurrent Neural Networks     - Autoencoders",Deep Learning Fundamentals with Keras
https://www.classcentral.com/course/edx-web-app-development-with-the-power-of-node-js-10245,"JavaScript is the most trending programming language on the web today! Facebook, Google, Uber and countless so-called Unicorn startups have now made JavaScript a cornerstone of their technology stack.This online course requires no prior knowledge of the JavaScript language. In the first week of the course you will explore the language's basic concepts and fundamentals, and during the second week we will dive into advanced topics such as functions and objects.While JavaScript is recognized primarily for making web pages interactive within web browsers, this course covers the use of the Node.js library - a platform that enables running JavaScript code outside the browser and allows the development of an end-to-end applications in JavaScript. In week three, we will cover the basic architecture of a web application by getting an up-close view of the different parts that make up this application. You will see how data is being exchanged over an Application Programming Interface (API) and what are the different tools and libraries that will allow you to construct such an application. The course will then cover the basic steps required to set up a Node.js server that can process web requests and interact with various set of databases. In the process, you will also be introduced to the Model View Controller (MVC) pattern, a software architecture that organizes the JavaScript application into modules.Finally, in week four, you will also learn how incredibly easy it is to create beautiful data visualizations that your boss will be proud of. You will gain a basic understanding of the technologies used to present data on the web and will learn how to visualize interactive data using the popular Data Driven Documents (D3) data library.Whether you are considering a career as a full-stack web developer, pondering developing a mobile app for your next startup or just want to pad your toolbox with a highly sought out skill, this course is definitely for you!
      


            Read more
          



Week 1: Language basicsIntroduction to first steps of writing proper JavaScript code and the foundations of the language. Week 2: Functions and ObjectsThe principles of working with functions and the basics of Object-Oriented paradigms are explained.Week 3: Server-side JavaScriptIntroduction to working with Node.js and to writing your first JavaScript-based web application.Week 4: Data VisualizationIntroduction to the beautiful world of data visualization and to how simply and easily give useful insights from data to the world.",Web App Development with the Power of Node.js
https://www.classcentral.com/course/edx-introduction-to-open-source-networking-technologies-11389,"Explore open source networking projects, from The Linux Foundation and beyond, that are shaping the future of networking and telecoms. 
Designed for open source enthusiasts, university students,network architects and engineers, security architects and engineers, and systems engineers, this course offers a great introduction to open source networking. 
This course covers the open networking stack from top to bottom; starting from networking hardware disaggregation and modern 100G and 400G switches, through network operating systems, network controllers, virtualization,and orchestration. 
Develop an understanding of the use cases and technical options for modern open networking in enterprises, service providers, and cloud providers. Become familiar with the following open source networking projects and their use cases: 

Open Compute Project, ONIE, Akraino
FD.io, OVS, IO Visor, DPDK, Open Dataplane, P4
OpenSwitch , Open Network Linux , FRR, DANOS, SONIC, FBOSS
OpenDayLight, Tungsten Fabric (OpenContrail) , ONOS, CORD, Open Security Controller
ONAP, OPNFV
PNDA, SNAS.




Welcome and Introduction 
Chapter 1. Introduction to Open Source Networking 
Chapter 2. The Open Source and Software Defined Networking Landscape 
Chapter 3. Disaggregated Hardware 
Chapter 4. IO Abstraction and Data Path 
Chapter 5. Network Operating systems 
Chapter 6. Network Control 
Chapter 7. Cloud and Virtual Management 
Chapter 8. Network Virtualization 
Chapter 9. Network Function Virtualization 
Chapter 10. Orchestration, Management, Policy 
Chapter 11. Network Automation 
Chapter 12. Network Data Analytics 
Chapter 13. Summary 
Final Exam",Introduction to Open Source Networking Technologies
https://www.classcentral.com/course/edx-big-data-analytics-8158,"Gain essential skills in today’s digital age to store, process and analyse data to inform business decisions.
In this course, part of the Big Data MicroMasters program, you will develop your knowledge of big data analytics and enhance your programming and mathematical skills. You will learn to use essential analytic tools such as Apache Spark and R.
Topics covered in this course include:

cloud-based big data analysis;
predictive analytics, including probabilistic and statistical models;
application of large-scale data analysis;
analysis of problem space and data needs.

By the end of this course, you will be able to approach large-scale data science problems with creativity and initiative.



Section 1: Simple linear regression
Fit a simple linear regression between two variables in R;Interpret output from R;Use models to predict a response variable;Validate the assumptions of the model. 
Section 2: Modelling data
Adapt the simple linear regression model in R to deal with multiple variables;Incorporate continuous and categorical variables in their models;Select the best-fitting model by inspecting the R output. 
Section 3: Many models
Manipulate nested dataframes in R;Use R to apply simultaneous linear models to large data frames by stratifying the data;Interpret the output of learner models. 
Section 4: Classification
Adapt linear models to take into account when the response is a categorical variable;Implement Logistic regression (LR) in R;Implement Generalised linear models (GLMs) in R;Implement Linear discriminant analysis (LDA) in R. 
Section 5: Prediction using models
Implement the principles of building a model to do prediction using classification;Split data into training and test sets, perform cross validation and model evaluation metrics;Use model selection for explaining data with models;Analyse the overfitting and bias-variance trade-off in prediction problems. 
Section 6: Getting bigger
Set up and apply sparklyr;Use logical verbs in R by applying native sparklyr versions of the verbs. 
Section 7: Supervised machine learning with sparklyr
Apply sparklyr to machine learning regression and classification models;Use machine learning models for prediction;Illustrate how distributed computing techniques can be used for “bigger” problems. 
Section 8: Deep learning
Use massive amounts of data to train multi-layer networks for classification;Understand some of the guiding principles behind training deep networks, including the use of autoencoders, dropout, regularization, and early termination;Use sparklyr and H2O to train deep networks. 
Section 9: Deep learning applications and scaling up
Understand some of the ways in which massive amounts of unlabelled data, and partially labelled data, is used to train neural network models;Leverage existing trained networks for targeting new applications;Implement architectures for object classification and object detection and assess their effectiveness. 
Section 10: Bringing it all together
Consolidate your understanding of relationships between the methodologies presented in this course, theirrelative strengths, weaknesses and range of applicability of these methods.",Big Data Analytics
https://www.classcentral.com/course/data-science-python-18916,"The 5 courses in this University of Michigan specialization introduce learners to data science through the python programming language. This skills-based specialization is intended for learners who have a basic python or programming background, and want to apply statistical, machine learning, information visualization, text analysis, and social network analysis techniques through popular python toolkits such as pandas, matplotlib, scikit-learn, nltk, and networkx to gain insight into their data.

Introduction to Data Science in Python (course 1), Applied Plotting, Charting & Data Representation in Python (course 2), and Applied Machine Learning in Python (course 3) should be taken in order and prior to any other course in the specialization. After completing those, courses 4 and 5 can be taken in any order. All 5 are required to earn a certificate.
      


          Course 1: Introduction to Data Science in Python- This course will introduce the learner to the basics of the python programming environment, including fundamental python programming techniques such as lambdas, reading and manipulating csv files, and the numpy library. The course will introduce data manipulation and cleaning techniques using the popular python pandas data science library and introduce the abstraction of the Series and DataFrame as the central data structures for data analysis, along with tutorials on how to use functions such as groupby, merge, and pivot tables effectively. By the end of this course, students will be able to take tabular data, clean it, manipulate it, and run basic inferential statistical analyses. This course should be taken before any of the other Applied Data Science with Python courses: Applied Plotting, Charting & Data Representation in Python, Applied Machine Learning in Python, Applied Text Mining in Python, Applied Social Network Analysis in Python.Course 2: Applied Plotting, Charting & Data Representation in Python- This course will introduce the learner to information visualization basics, with a focus on reporting and charting using the matplotlib library. The course will start with a design and information literacy perspective, touching on what makes a good and bad visualization, and what statistical measures translate into in terms of visualizations. The second week will focus on the technology used to make visualizations in python, matplotlib, and introduce users to best practices when creating basic charts and how to realize design decisions in the framework. The third week will be a tutorial of functionality available in matplotlib, and demonstrate a variety of basic statistical charts helping learners to identify when a particular method is good for a particular problem. The course will end with a discussion of other forms of structuring and visualizing data. This course should be taken after Introduction to Data Science in Python and before the remainder of the Applied Data Science with Python courses: Applied Machine Learning in Python, Applied Text Mining in Python, and Applied Social Network Analysis in Python.Course 3: Applied Machine Learning in Python- This course will introduce the learner to applied machine learning, focusing more on the techniques and methods than on the statistics behind these methods. The course will start with a discussion of how machine learning is different than descriptive statistics, and introduce the scikit learn toolkit through a tutorial. The issue of dimensionality of data will be discussed, and the task of clustering data, as well as evaluating those clusters, will be tackled. Supervised approaches for creating predictive models will be described, and learners will be able to apply the scikit learn predictive modelling methods while understanding process issues related to data generalizability (e.g. cross validation, overfitting). The course will end with a look at more advanced techniques, such as building ensembles, and practical limitations of predictive models. By the end of this course, students will be able to identify the difference between a supervised (classification) and unsupervised (clustering) technique, identify which technique they need to apply for a particular dataset and need, engineer features to meet that need, and write python code to carry out an analysis. This course should be taken after Introduction to Data Science in Python and Applied Plotting, Charting & Data Representation in Python and before Applied Text Mining in Python and Applied Social Analysis in Python.Course 4: Applied Text Mining in Python- This course will introduce the learner to text mining and text manipulation basics. The course begins with an understanding of how text is handled by python, the structure of text both to the machine and to humans, and an overview of the nltk framework for manipulating text. The second week focuses on common manipulation needs, including regular expressions (searching for text), cleaning text, and preparing text for use by machine learning processes. The third week will apply basic natural language processing methods to text, and demonstrate how text classification is accomplished. The final week will explore more advanced methods for detecting the topics in documents and grouping them by similarity (topic modelling). This course should be taken after: Introduction to Data Science in Python, Applied Plotting, Charting & Data Representation in Python, and Applied Machine Learning in Python.Course 5: Applied Social Network Analysis in Python- This course will introduce the learner to network analysis through tutorials using the NetworkX library. The course begins with an understanding of what network analysis is and motivations for why we might model phenomena as networks. The second week introduces the concept of connectivity and network robustness. The third week will explore ways of measuring the importance or centrality of a node in a network. The final week will explore the evolution of networks over time and cover models of network generation and the link prediction problem. This course should be taken after: Introduction to Data Science in Python, Applied Plotting, Charting & Data Representation in Python, and Applied Machine Learning in Python.",Applied Data Science with Python
https://www.classcentral.com/course/applied-data-science-18818,"This is an action-packed specialization is for data science enthusiasts who want to acquire practical skills for real world data problems. It appeals to anyone interested in pursuing a career in Data Science, and already has foundational skills (or has completed the Introduction to Applied Data Science specialization). You will learn Python - no prior programming knowledge necessary. You will then learn data visualization and data analysis. Through our guided lectures, labs, and projects you’ll get hands-on experience tackling interesting data problems. Make sure to take this specialization to solidify your Python and data science skills before diving deeper into big data, AI, and deep learning.

Upon completing all courses in the specialization and receiving the Specialization certificate, you will also receive an IBM Badge recognizing you as a Specialist in Applied Data Science.

LIMITED TIME OFFER: Subscription is only $39 USD per month and gives you access to graded materials and a certificate.
      


          Course 1: Python for Data Science and AI- This introduction to Python will kickstart your learning of Python for data science, as well as programming in general. This beginner-friendly Python course will take you from zero to programming in Python in a matter of hours. Module 1 - Python Basics o Your first program o Types o Expressions and Variables o String Operations Module 2 - Python Data Structures o Lists and Tuples o Sets o Dictionaries Module 3 - PythonProgramming Fundamentals o Conditions and Branching o Loops o Functions o Objects and Classes Module 4 - Working with Data in Python o Reading files with open o Writing files with open o Loading data with Pandas o Numpy Finally, you will create a project to test your skills.Course 2: Data Analysis with Python- Learn how to analyze data using Python. This course will take you from the basics of Python to exploring many different types of data. You will learn how to prepare data for analysis, perform simple statistical analysis, create meaningful data visualizations, predict future trends from data, and more! Topics covered: 1) Importing Datasets 2) Cleaning the Data 3) Data frame manipulation 4) Summarizing the Data 5) Building machine learning Regression models 6) Building data pipelines Data Analysis with Python will be delivered through lecture, lab, and assignments. It includes following parts: Data Analysis libraries: will learn to use Pandas, Numpy and Scipy libraries to work with a sample dataset. We will introduce you to pandas, an open-source library, and we will use it to load, manipulate, analyze, and visualize cool datasets. Then we will introduce you to another open-source library, scikit-learn, and we will use some of its machine learning algorithms to build smart models and make cool predictions. If you choose to take this course and earn the Coursera course certificate, you will also earn an IBM digital badge. LIMITED TIME OFFER: Subscription is only $39 USD per month for access to graded materials and a certificate.Course 3: Data Visualization with Python- ""A picture is worth a thousand words"". We are all familiar with this expression. It especially applies when trying to explain the insight obtained from the analysis of increasingly large datasets. Data visualization plays an essential role in the representation of both small and large-scale data. One of the key skills of a data scientist is the ability to tell a compelling story, visualizing data and findings in an approachable and stimulating way. Learning how to leverage a software tool to visualize data will also enable you to extract information, better understand the data, and make more effective decisions. The main goal of this Data Visualization with Python course is to teach you how to take data that at first glance has little meaning and present that data in a form that makes sense to people. Various techniques have been developed for presenting data visually but in this course, we will be using several data visualization libraries in Python, namely Matplotlib, Seaborn, and Folium. LIMITED TIME OFFER: Subscription is only $39 USD per month for access to graded materials and a certificate.Course 4: Applied Data Science Capstone- This capstone project course will give you a taste of what data scientists go through in real life when working with data. You will learn about location data and different location data providers, such as Foursquare. You will learn how to make RESTful API calls to the Foursquare API to retrieve data about venues in different neighborhoods around the world. You will also learn how to be creative in situations where data are not readily available by scraping web data and parsing HTML code. You will utilize Python and its pandas library to manipulate data, which will help you refine your skills for exploring and analyzing data. Finally, you will be required to use the Folium library to great maps of geospatial data and to communicate your results and findings. If you choose to take this course and earn the Coursera course certificate, you will also earn an IBM digital badge upon successful completion of the course. LIMITED TIME OFFER: Subscription is only $39 USD per month for access to graded materials and a certificate.",Applied Data Science
https://www.classcentral.com/course/swayam-mass-spectrometry-based-proteomics-4443,"Mass spectrometry is an advanced analytical technique for accurate mass measurement. It does so by producing charged molecular species in vacuum followed by its separation in the magnetic and electric fields on the basis of their mass to charge (m/z) ratio. MALDI and ESI- coupled with mass analyzers are commonly used mass spectrometer configuration in proteomics. The human proteome draft was decoded by using high-resolution liquid chromatography coupled with mass spectrometry.
In this module, we will discuss the basics of mass spectrometry, sample preparations, liquid chromatography, hybrid mass spectrometers and quantitative proteomics techniques such as iTRAQ, SILAC and TMT using mass spectrometry. The course will also provide the basic knowledge about sample preparation, mass spectrometry workflow, different chromatography technologies and quantitative proteomics.



Week 1: Proteomics introduction and sample preparation
Lec 1: Introduction to proteomicsLec 2: Why proteomics and sample preparationLec 3: Protein extractionLec 4: In-gel & in-solution digestionLec 5: Fundamentals of mass spectrometry
Week 2: Basics of mass spectrometry
Lec 6: Chromatography technologiesLec 7: Liquid chromatographyLec 8: Mass spectrometry: Ionization sourcesLec 9: Mass spectrometry: Mass analyzersLec 10: MALDI sample preparation and analysis
Week 3: Quantitative proteomics
Lec 11: Introduction to quantitative proteomicsLec 12: Hybrid mass spectrometry configurationsLec 13: SILAC: In vivo labelingLec 14: iTRAQ: In vitro labelingLec 15: TMT: In vitro labeling
Week 4: Proteomics and systems biology
Lec 16: Quantitative proteomics data analysisLec 17: Proteomics and systems biology-I Lec 18: Proteomics and systems biology-IILec 19: Proteomics applicationsLec 20: Challenges in proteomics",Mass spectrometry based proteomics
https://www.classcentral.com/course/edx-nuclear-energy-science-systems-and-society-11884,"Nuclear Energy: Science, Systems and Society offers an introduction to the basic physics of nuclear energy and radiation, with an emphasis on the unique attributes and challenges of nuclear energy as a low-carbon solution. Peaceful applications of ionizing radiation to help humankind, such as reactors for materials science research, nuclear medicine, and security initiatives, will be introduced. 
The course will explore fission energy, establishing the scientific, engineering, and economic basis for fission reactors, and will describe the state of the art in nuclear reactor technology. 
We will also learn about magnetic fusion energy research, with lectures covering the scientific and engineering basis of tokamaks, the state of the art in world fusion experiments, and the MIT vision for high-magnetic field fusion reactor. 
In addition, the course also includes an optional hands-on section using guided exercises available on-line.
As a preview, please enjoy this virtual tour of the MIT Reactor!
----
Image Source: http://sciencestockphotos.com/free/electrical/slides/radioactive_smoke_detector.html, Image by http://sciencestockphotos.com



Module 1: Introduces the basics of ionizing radiation - what it is, where it comes from, and how it is used to benefit humanity. We specifically focus on the origins and energetics of ionizing radiation, and quantify what radiation dose is, where it comes from, and how much people can safely tolerate with no adverse effects. 
Module 2: Will articulate attributes and challenges of nuclear energy as a commercial source of electric power. Will focus on potential contribution of nuclear energy to decarbonization of the power sector, including discussion of nuclear power plant economics and safety. A few innovations in nuclear energy systems will be described. 
Module 3: Will cover the basics of nuclear fusion, including fundamental plasma physics concepts needed to understand the prospects for development of magnetic confinement fusion. Innovation and future directions will be described.","Nuclear Energy: Science, Systems and Society"
https://www.classcentral.com/course/edx-sustainable-urban-environments-8610,"How can we strengthen sustainability? By empowering individuals and communities to transform and balance dynamic natural resources, economic prosperity, and healthy populations.
In this course, you’ll explore productive and disruptive social, ecological, and economic intersections – the “triple bottom line.” You’ll investigate a spectrum of global, national, regional, municipal and personal relationships that are increasing resiliency. Most importantly, you’ll learn how to effectively locate your interests, and to leverage optimistic change within emerging 21st century urban environments.
This course will describe fundamental paradigm shifts that are shaping sustainability. These include connectivity, diversity, citizen engagement, collaboration source tracing, mapping, transportation, and integrative, regenerative design. We will take examples from cities around the globe; making particular use of the complex evolution of site-specific conditions within the Connecticut River watershed. In addition we will present tools and strategies that can be utilized by individuals, communities, and corporations to orchestrate effective and collective change.
Each week, lessons will highlight the significance of clean water as a key indication of ecosystem, community and human health. Learners will be asked to investigate and share information about their local environment.
Finally, we will note the impact of such disruptive forces as industrial pollution, changing governance, privatization of public services, mining of natural resources, public awareness, and climate change. A fundamental course goal will be to characterize indicators of economic prosperity and happiness that relate to environmental sustainability – and the capacity of individuals to create change.



            Read more
          



Week #1: Basic Concepts 
This week will offer an introduction to basic concepts of urban sustainability and key course points. Various sustainability rating systems will be reviewed, with respect to the capacity of metrics to leverage environmental change and indicate quality-of-life benefits.        
 
Week #2: Governance and Science
This week focuses on scientific and legal efforts to expand urban sustainability, as well as their impacts on human health, social and environmental justice, and both the management and stewardship of natural resources.
 
Week #3: Urban Planning for Everyday Routines
This week will emphasize the everyday world of urban sustainability, including tracing municipal services, urban parks and planning, as well as efforts to make cities more walkable. We will also explore links between sustainability and human happiness.
 
Week #4: Urgency and the Global Economy
We will look at the big picture to examine big corporations, development projects, and systems that can leverage climate change mitigation and adaptation, fair trade, food security, green finance – all at a planetary scale. The UN’s sustainable development goals (SDGs) will be reviewed along with international conservation and rapid urban development. We will analyze how our smart phones and computers are source of global information, and a physical trace of global resources and manufacturing.
 
Week #5: Adaptation and Individual Mitigation
This week, we will explore individual people’s strategies and capacities for addressing urban sustainability through consumption patterns, eating habits, health choices, energy usage, bicycling, recycling, and the new sharing economy.
 
Week #6:
The final week will focus on summarizing the course and completing all projects.",Sustainable Urban Environments
https://www.classcentral.com/course/wharton-cryptocurrency-blockchain-introd-13733,"What is Cryptocurrency and how is it an innovative and effective method of currency? This course was designed for individuals and organizations who want to learn how to navigate investment in cryptocurrencies. Professors Jessica Wachter and Sarah Hammer will guide you through developing a framework for understanding both Cryptocurrency and Blockchain. You’ll learn how to define a currency, analyze the foundations of digital signatures and blockchain technology in cryptocurrency, and accurately assess the risks of cryptocurrency in a modern investment portfolio. By the end of this course, you’ll have a deep understanding of the realities of Cryptocurrency, the intricacies of Blockchain technology, and an effective strategy for incorporating Cryptocurrency into your investment plans. No prerequisites are required, although ""Fintech: Foundations, Payments, and Regulations""  from Wharton's Fintech Specialization is recommended.
      


          Module 1: Introduction to Cryptocurrency
    -In this module, you’ll define Bitcoin and understand its popularity as a currency. You’ll discuss the methodology behind transacting with Bitcoin, and gain a deep understanding of the definition of currency and the critical importance of a shared common belief behind a unit of currency. You’ll also analyze the growth of centralized intermediaries that facilitate dollar transactions using cash-alternative methodologies and their role in currency. By the end of this module, you’ll have a more clearly defined understanding of why cryptocurrency and bitcoin is used as a cash-alternative method, and how Bitcoin derives its potential value in the current market. 

Module 2: Rules and Structure of Bitcoin
    -This module was designed to analyze the problems that a decentralized currency must solve in order to be successful, and how Bitcoin meets these challenges using cryptology and blockchain technology. After identifying the philosophy of identity behind the concept of property rights, you'll learn how Bitcoin utilizes digital signatures in their transactions to ensure privacy for individuals. Then, you’ll examine how blockchain technology employs Hash Functions to detect tampering attempts. Finally, you’ll explore the creation and concept of Distributed Consensus Protocol and how Proof of Work incentivizes honest trading and stable currency creation. By the end of this module, you’ll be able to identify the importance of digital signatures, Blockchain, and Proof of Work in the stability of Bitcoin as a currency.

Module 3: Cryptocurrency as an Asset Class
    -In this module, you’ll examine Cryptocurrency as an asset class, and delve deeper into whether Cryptocurrency has a place in individual investment portfolios. Through examining the theory and data perspective of traditional finance, you’ll understand the risks and returns on Bitcoin and its place in a more stable and predictable portfolio. You’ll also learn about the Capital Asset Pricing Model, and key concepts of Modern Portfolio Theory such as Tangency Portfolio and the Sharpe Ratio. Through calculating and specifying both Beta and Alpha of Bitcoins, you’ll be able to accurately measure the systematic risk the investor takes in creating a portfolio with Bitcoin. By the end of this module, you’ll be able to estimate and analyze the values of Beta and Alpha in Cryptocurrency, and effectively optimize utility in incorporating Cryptocurrency as an asset for your portfolio.

Module 4: The Blockchain Ecosystem
    -In this module, you’ll explore the Blockchain Ecosystem and the numerous use cases for Blockchain in different industries. Through examination of the key attributes of Blockchain, you’ll discover how Blockchain is built. You’ll also learn about the difference between Proof of Work and Proof of Stake, and the two interoperabilities of Blockchain. Through analyzing the different types of crypto finance, you’ll explore the different use cases of Blockchain in business, gaming, and investing. By the end of this module, you’ll have a deeper understanding of the fundamentals of Blockchain, be able to utilize Blockchain in many different contexts, and assess how Blockchain will affect both business and society in the future.",Cryptocurrency and Blockchain: An Introduction to Digital Currencies
https://www.classcentral.com/course/swayam-programming-data-structures-and-algorithms-using-python-14260,"This course is an introduction to programming and problem solving in Python. It does not assume any prior knowledge of programming. Using some motivating examples, the course quickly builds up basic concepts such as conditionals, loops, functions, lists, strings and tuples. It goes on to cover searching and sorting algorithms, dynamic programming and backtracking, as well as topics such as exception handling and using files. As far as data structures are concerned, the course covers Python dictionaries as well as classes and objects for defining user defined datatypes such as linked lists and binary search trees.INTENDED AUDIENCE:Students in any branch of mathematics/science/engineering, 1st yearPREREQUISITES:     School level mathematics.INDUSTRY SUPPORT: This course should be of value to any company requiring programming skills. 
      


COURSE LAYOUT Week 1Informal introduction to programmin, algorithms and data structures viagcdDownloading and installing Pythongcd in Python: variables, operations, control flow - assignments, condition-als, loops, functionsWeek 2Python: types, expressions, strings, lists, tuplesPython memory model: names, mutable and immutable valuesList operations: slices etcBinary searchInductive function denitions: numerical and structural inductionElementary inductive sorting: selection and insertion sortIn-place sortingWeek 3Basic algorithmic analysis: input size, asymptotic complexity, O() notationArrays vs listsMerge sortQuicksortStable sortingWeek 4DictionariesMore on Python functions: optional arguments, default valuesPassing functions as argumentsHigher order functions on lists: map, lter, list comprehensionWeek 5Exception handlingBasic input/outputHandling filesString processingWeek 6Backtracking: N Queens, recording all solutionsScope in Python: local, global, nonlocal namesNested functionsData structures: stack, queueHeapsWeek 7Abstract datatypesClasses and objects in Python""Linked"" lists: find, insert, deleteBinary search trees: find, insert, deleteHeight-balanced binary search treesWeek 8Effcient evaluation of recursive denitions: memoizationDynamic programming: examplesOther programming languages: C and manual memory managementOther programming paradigms: functional programming","Programming, Data Structures And Algorithms Using Python"
https://www.classcentral.com/course/software-design-methods-tools-9652,"Since many software developers are compulsive coders, they have created software over the years to help them do their job.  There are tools which make design and its associated tasks easier.  The course introduces some basic tools and techniques to help you with design.  Tools aren’t always tangible, however.  The last two lessons of this course discuss questions of Ethics in software development. The purpose here is, as with tools, to equip you to better carry our your responsibilities as a designer. Students will be required to have a prior knowledge of writing and delivering software and some programming knowledge in java.
      


          General Design Notions
    -What is in a design and an introduction to hierarchical design representations.

Dynamic and Algebraic Designs
    -Hierarchical design which shows data flow, and rigorous, formally provable methods of design representation.

UML Tools
    -An introduction to IBM Rhapsody, a UML modeling tool.

Unit Testing
    -An introduction to the use of JUnit which performs unit testing for Java software.

Ethics
    -Unusual situations in a project in which you may find yourself, and what to do about them.

Final Exam
    -A comprehensive course assessment comprising of 5 quizzes. Each assessment contains a randomized set of questions from different modules of the course.",Software Design Methods and Tools
https://www.classcentral.com/course/business-analytics-7184,"The explosion in digital media - web, social and now mobile - represents a departure from how things were like in the last century. This proliferation of digital media is both a threat and an opportunity for many businesses. Business Analytics can be leveraged to process data, sentiment, buzz, contacts, context and other aspects of business interest in real time, for business performance and impact. The course picks and uses use-cases from a variety of industries and geographies, to showcase the potential and impact that business analytics done properly (or not) can have on business performance.
      


          Introduction to Business Analytics
    -An overview of the what and the why
Learning outcomes by the end of week 1 should normatively be that (a) Students grasp what is business analytics from the perspective of a business manager, (b) identify areas of interest, overlap, co-ordination and conflict with other business functions and processes in the firm, (c) and, develop an appreciation for the value of data, of analyses and of the components of analytics.


Toolscape
    -An overview of the broad tools available for business analytics and the leveraging of digital media. 
Learning outcomes by the end of week 2 should normatively be that (a) Students have an understanding of the broad classes of analytics tools and platforms that currently dominate the market, (b) and, develop an appreciation for the pros and cons of the major groups of tools. 


Customer Analytics 
    -Introduction to and the application of some important analytical processes in Marketing Analytics
Learning outcomes by the end of week 3 should normatively be that  (a) Students have an understanding of the major processes and procedures typically used in a customer analytics setting, in particular factor and cluster analyses (b) and, develop an appreciation for the possibilities that emerge from recombining procedures, data, algorithms and problem formulation perspectives in open source environments.


Digital Media 
    -An overview of the big questions, possibilities and challenges.
Learning outcomes by the end of week 4 should normatively be that 
(a) Students have an understanding of the major types of digital media in use currently by people and firms,  (b) and, develop an appreciation for the types of problem solving, data collection, prediction and optimization that can be enabled using digital media tools.",Business Analytics and Digital Media
https://www.classcentral.com/course/data-driven-decision-making-18277,"Data becomes valuable when it allows us to make a decision or take action in the real world.
On this microcredential, you’ll work through practical programming exercises in R language to learn the process of tidying, harvesting and wrangling data and applying statistical models to simulate complex functions that solve a broad range of problems.
Using data visualisation techniques, you’ll learn to interpret and explain data to inform your decision-making process and communicate your message to others.
You’ll also explore the essential ethical, legal and organisational issues of data collection and management.



Courses under this program:Course 1: Wrangling and Workflow-Get an introduction to data science and learn how to make the most of your data through effective data wrangling and storytelling.Course 2: Modelling and Visualisation-Explore the role of data visualisation in data science, and learn how to use and apply data modelling techniques.Course 3: Formats, Ethics, and Storytelling-Evaluate the challenges of data variety, ethics, and privacy on this course in Monash University's data science microcredential.",Data Science: Data-Driven Decision Making
https://www.classcentral.com/course/survey-analysis-marketing-insights-6915,"How do consumers see your brand relative to your competitors? How should a new product be positioned when it’s launched? Which customer segments are most interested in our current offerings? For these questions and many others, surveys remain the tried and true method for gaining marketing insights. From one-off customer satisfaction surveys to brand tracking surveys that are administered on a continuous basis, they provide the information that marketers need to understand how their products, services and brands are seen by consumers. In Analytic Methods for Survey Data, learners will become familiar with established statistical methods for converting survey responses to insights that can support marketing decisions. Techniques discussed include factor analytics, cluster analysis, discriminant analysis and multi-dimensional scaling. These techniques are presented within the STP (Segmentation, Positioning, Targeting) Framework, enabling learners to apply the analytic techniques to develop a marketing strategy. It is recommended that you complete the Meaningful Marketing Insights course offered by Coursera before taking this course. 

Note: This course would require using XL Stat, an Excel Add-on that students would need to purchase. XL Stat offers a 30-day free trial, so students could complete this course without incurring additional expense.
      


          Introduction to Factor Analysis
    -This module will provide readings and discussions to provide an introduction to the topic of Factor Analysis.  It is recommended that you complete the Meaningful Marketing Insights course offered by Coursera before taking this course.

Implementing Factor Analysis
    -This module will provide lectures and exercises that will inform students on how to determine the number of factors to consider in your analysis and to evaluate the fit of the data.

Customer Segmentation
    -This module will introduce components of customer segmentation to students.  Students will use this knowledge to be able to analyze data and make more informed business decisions.

Perceptual Maps
    -This module will explain and describe perceptual maps.  Students will be able to create perceptual maps and also analyze data from perceptual maps.",Survey analysis to Gain Marketing Insights
https://www.classcentral.com/course/edx-big-data-for-smart-cities-6323,"Cities run on a stream of data. In the smart city, the innovative use of data helps provide better and more inventive services to improve people’s lives and make the entire city run more smoothly. But the data our cities collect nowadays is more massive and varied, and is accessed at higher speeds than ever before. This is Big Data. New technologies are constantly being developed to better manage Big Data. This computer science course, from the IEEE Smart Cities initiative and the University of Trento, helps students understand and use these new technologies to help improve a city.
Our international team of instructors and content experts discuss the fundamental concepts of Big Data and how it has changed Data Management. They provide a vision for managing Big Data today, and how we can make Big Data work for the smart city.
Verified students are eligible to earn Continuing Education Units (CEUs) and Professional Development Hours (PDHs), valid toward continuing education requirements for many professional certifications.",Big Data for Smart Cities
https://www.classcentral.com/course/symmetric-crypto-9534,"Welcome to Symmetric Cryptography! 

Symmetric cryptography relies on shared secret key to ensure message confidentiality, so that the unauthorized attackers cannot retrieve the message. The course describes substitution and transposition techniques, which were the bases for classical cryptography when the message is encoded in natural language such as English. Then, we build on product ciphers (using both substitution and transposition/permutation) to describe modern block ciphers and review the widely used cipher algorithms in DES, 3-DES, and AES. Lastly, we enable the use of block ciphers to support variable data length by introducing different modes of block cipher operations in ECB, CBC, CFB, OFB, and CTR modes.

This course is cross-listed and is a part of the two specializations, the Applied Cryptography specialization and the Introduction to Applied Cryptography specialization.
      


          Classical Cipher: Substitution
    -This module defines substitution cipher technique and describes multiple examples for substitution-based classical algorithms: Caesar Cipher, Monoalphabetic Cipher, and Vigenere Cipher (which is a type of Polyalphabetic Cipher). We will also discuss the mathematical concepts in Modulo Operations to use them to describe the cipher algorithms. 

Classical Cipher: Transposition
    -This module studies transposition cipher which, along with substitution cipher, provides a base technique for symmetric ciphers. We define transposition cipher and product cipher and discuss transposition examples in Rail Fence and Permutation Cipher.

Block Cipher and DES
    -This module is about modern ciphers based on product ciphers. We will first define block cipher and contrast it with stream cipher. We will then describe the ideal block cipher, which maximizes the number of transformations, and Feistel Cipher, which is a practical structure framework approximating the ideal block cipher. As a widely used cipher example based on the Feistel Cipher structure; we will study Data Encryption Standard (DES).


3-DES and AES
    -To provide stronger security than DES, modern symmetric ciphers can either use multiple ciphers or use an entirely different algorithm. This module reviews examples of each in Triple-DES and AES. 

Block Cipher Operation Modes
    -Given a cipher and a key, this module reviews how to use block cipher operation modes when the data spans across multiple blocks. The module describes five popular operation modes: ECB, CBC, CFB, OFB, and CTR mode.",Symmetric Cryptography
https://www.classcentral.com/course/swayam-introduction-to-industry-4-0-and-industrial-internet-of-things-12941,"Industry 4.0 concerns the transformation of industrial processes through the integration of modern technologies such as sensors, communication, and computational processing. Technologies such as Cyber Physical Systems (CPS), Internet of Things (IoT), Cloud Computing, Machine Learning, and Data Analytics are considered to be the different drivers necessary for the transformation. Industrial Internet of Things (IIoT) is an application of IoT in industries to modify the various existing industrial systems. IIoT links the automation system with enterprise, planning and product lifecycle.This course has been organized into the following modules:INTENDED AUDIENCE : CSE, IT, ECE, EE, Instrumentation Engg, Industrial Engineering, Industry ProfessionalsPRE-REQUISITES   :  Basic knowledge of computer and internetINDUSTRY SUPPORT : All Industrial Sectors 
      


COURSE LAYOUT Week 1: Introduction: Sensing & actuation, Communication-Part I, Part II, Networking-Part I, Part IIWeek 2: Industry 4.0: Globalization and Emerging Issues, The Fourth Revolution, LEAN Production Systems, Smart and Connected Business Perspective, Smart FactoriesWeek 3: Industry 4.0: Cyber Physical Systems and Next Generation Sensors, Collaborative Platform and Product Lifecycle Management, Augmented Reality and Virtual Reality, Artifical Intelligence, Big Data and Advanced AnalysisWeek 4: Cybersecurity in Industry 4.0, Basics of Industrial IoT: Industrial Processes-Part I, Part II, Industrial Sensing & Actuation, Industrial Internet Systems.Week 5: IIoT-Introduction, Industrial IoT: Business Model and Referece Architerture: IIoT-Business Models-Part I, Part II, IIoT Reference Architecture-Part I, Part II.Week 6: Industrial IoT- Layers: IIoT Sensing-Part I, Part II, IIoT Processing-Part I, Part II, IIoT Communication-Part I.Week 7: Industrial IoT- Layers: IIoT Communication-Part II, Part III, IIoT Networking-Part I, Part II, Part III.Week 8:  Industrial IoT: Big Data Analytics and Software Defined Networks: IIoT Analytics - Introduction, Machine Learning and Data Science - Part I, Part II, R and Julia Programming, Data Management with Hadoop.Week 9: Industrial IoT: Big Data Analytics and Software Defined Networks: SDN in IIoT-Part I, Part II, Data Center Networks, Industrial IoT: Security and Fog Computing: Cloud Computing in IIoT-Part I, Part II.Week 10: Industrial IoT: Security and Fog Computing - Fog Computing in IIoT, Security in IIoT-Part I, Part II, Industrial IoT- Application Domains: Factories and Assembly Line, Food Industry.Week 11: Industrial IoT- Application Domains: Healthcare, Power Plants, Inventory Management & Quality Control, Plant Safety and Security (Including AR and VR safety applications), Facility Management.Week 12: Industrial IoT- Application Domains: Oil, chemical and pharmaceutical industry, Applications of UAVs in Industries, Real case studies :Case study - I : Milk Processing and Packaging IndustriesCase study - II: Manufacturing Industries - Part ICase study - III : Manufacturing Industries - Part IICase study - IV : Student Projects - Part ICase study - V : Student Projects - Part IICase study - VI : Virtual Reality LabCase study - VII : Steel Technology Lab",Introduction to Industry 4.0 and Industrial Internet of Things
https://www.classcentral.com/course/edx-introduction-to-theoretical-computer-science--2436,"点击上方绿色按钮报名。
本课程的 教学内容包括：形式语言与自动机理论、可计算性理论、计算复杂性理论等三个部分。这些内容分别回答下列问题：（1）有哪些计算装置？它们的能力如何？ （2）什么是计算？哪些问题是（不）可计算的？（3）什么是有效计算？哪些问题是（不）可有效计算的？通过这门课程的学习，学生将了解计算理论的基础知 识，掌握有效计算的概念。
本课程的教学方式包括教学录像片段（每段录像8-20分钟，内含1-2个测验问题），教学录像之外的书面作业，以及（必须参加的）期末考试。
本课程课程的总长度为8周，每周教学录像长度大约120分钟。需要的预备知识是离散数学（集合论、数理逻辑、图论等）的基本概念。
本课程需要哪些资源才能进行学习？
答：一台联网的电脑，纸和笔，以及最重要的好奇心。
本课程最有趣的内容是什么？
答：本课程将告诉你计算机不可能做到的一些事情。
本课程需要什么先修课程？
答：离散数学的基础知识，包括集合、关系、函数、逻辑、图等。",Introduction to Theoretical Computer Science 理论计算机科学基础
https://www.classcentral.com/course/ibm-ai-workflow-data-analysis-hypothesis-testing-17096,"This is the second course in the IBM AI Enterprise Workflow Certification specialization.  You are STRONGLY encouraged to complete these courses in order as they are not individual independent courses, but part of a workflow where each course builds on the previous ones.  

In this course you will begin your work for a hypothetical streaming media company by doing exploratory data analysis (EDA).  Best practices for data visualization, handling missing data, and hypothesis testing will be introduced to you as part of your work.  You will learn techniques of estimation with probability distributions and extending these estimates to apply null hypothesis significance tests. You will apply what you learn through two hands on case studies: data visualization and multiple testing using a simple pipeline.
 
By the end of this course you should be able to:
1.  List several best practices concerning EDA and data visualization
2.  Create a simple dashboard in Watson Studio
3.  Describe strategies for dealing with missing data
4.  Explain the difference between imputation and multiple imputation
5.  Employ common distributions to answer questions about event probabilities
6.  Explain the investigative role of hypothesis testing in EDA
7.  Apply several methods for dealing with multiple testing
 
Who should take this course?
This course targets existing data science practitioners that have expertise building machine learning models, who want to deepen their skills on building and deploying AI in large enterprises. If you are an aspiring Data Scientist, this course is NOT for you as you need real world expertise to benefit from the content of these courses.

What skills should you have?
It is assumed that you have completed Course 1 of the IBM AI Enterprise Workflow specialization and have a solid understanding of the following topics prior to starting this course: Fundamental understanding of Linear Algebra; Understand sampling, probability theory, and probability distributions; Knowledge of descriptive and inferential statistical concepts; General understanding of machine learning techniques and best practices; Practiced understanding of Python and the packages commonly used in data science: NumPy, Pandas, matplotlib, scikit-learn; Familiarity with IBM Watson Studio; Familiarity with the design thinking process.
      


            Read more
          



          Data Analysis
    -Exploratory data analysis is mostly about gaining insight through visualization and hypothesis testing.  This unit looks at EDA, data visualization, and missing values. One missing value strategy may be better for some models, but for others another strategy may show better predictive performance.

Data Investigation
    -Data scientists employ a broad range of statistical tools to analyze data and reach conclusions from data. This unit focuses on the foundational techniques of estimation with probability distributions and extending these estimates to apply null hypothesis significance tests.",AI Workflow: Data Analysis and Hypothesis Testing
https://www.classcentral.com/course/edx-the-data-science-method-17899,"Despite and influx in computing power and access to data over the last couple of decades, our ability to use data within the decision-making process is either lost or not maximized all too often. We do not have a strong grasp of the questions asked and how to apply the data correctly to resolve the issues at hand.
The purpose of this course is to share the methods, models and practices that can be applied within data science, to ensure that the data used in problem-solving is relevant and properly manipulated to address business and real-world challenges.
You will learn how to identify a problem, collect and analyze data, build a model, and understand the feedback after model deployment.
Advancing your ability to manage, decipher and analyze new and big data is vital to working in data science. By the end of this course, you will have a better understanding of the various stages and requirements of the data science method and be able to apply it to your own work.",The Data Science Method
https://www.classcentral.com/course/analytics-capstone-5108,"In this final course you will complete a Capstone Project using data analysis to recommend a method for improving profits for your company, Watershed Property Management, Inc. Watershed is responsible for managing thousands of residential rental properties throughout the United States. Your job is to persuade Watershed’s management team to pursue a new strategy for managing its properties that will increase their profits. To do this, you will: (1) Elicit information about important variables relevant to your analysis; (2) Draw upon your new MySQL database skills to extract relevant data from a real estate database; (3) Implement data analysis in Excel to identify the best opportunities for Watershed to increase revenue and maximize profits, while managing any new risks; (4) Create a Tableau dashboard to show Watershed executives the results of a sensitivity analysis; and (5) Articulate a significant and innovative business process change for Watershed based on your data analysis, that you will recommend to company executives. 

Airbnb, our Capstone’s official Sponsor, provided input on the project design. The top 10 Capstone completers each year will have the opportunity to present their work directly to senior data scientists at Airbnb live for feedback and discussion.

""Note: Only learners who have passed the four previous courses in the specialization are eligible to take the Capstone.""
      


          Introduction
    -The goal for this week is to learn about the Capstone Project you are tasked with, acquire background about the business problem, and begin to outline the steps of your analysis.

Data Extraction and Visualization
    -The goal of this week is for you to extract the relevant data from the MySQL database you are given access to, and to look at it briefly in Tableau to get sense of what data you have.  

Modeling
    -The goal of this week is for you to create a financial model using Excel to analyze the data you extracted from the database, and to start to predict short-term rents for some of Watershed's existing properties. 

Cash Flow and Profits
    -The goal for this week is for you to use your projections about the Watershed properties to estimate cash flows and profits Watershed would experience if it converted properties to short-term rentals. 

Data Dashboard
    -The goal of this week and next week is to build an analytical dashboard in Tableau using the data models and assumptions you have discovered in prior weeks. 

Dashboard for Decision-makers
    -This week complete your dashboard and add design elements so the dashboard is ready for stakeholders (Watershed executives, for example) to use it to test your model's assumptions. 

Final Project
    -This week, design and give a presentation for Watershed executives with your business recommendations, and complete a white paper template. Evaluate 3 peer's dashboards, white papers and presentations.",Increasing Real Estate Management Profits: Harnessing Data Analytics
https://www.classcentral.com/course/competitive-programming-core-skills-11713,"During the course, you’ll learn everything needed to participate in real competitions — that’s the main goal. Along the way you’ll also gain useful skills for which competitive programmers are so highly valued by employers: ability to write efficient, reliable, and compact code, manage your time well when it’s limited, apply basic algorithmic ideas to real problems, etc.

We start from the very beginning by teaching you what competitions there are, what are their rules, what specifics problems have, how to read problem statements, how to organize your work, and what you should and shouldn’t do. So it’s fine if you’ve never taken part in programming competitions before.

We’ll focus on skills essential to competitive programming: inventing solutions and proving their correctness, estimating their running time, testing and debugging programs, how to benefit from structuring code. We’ll also cover basic algorithmic ideas: brute force search, dynamic programming, greedy algorithms, segment trees.

On competitions, there are a lot of specific pitfalls, perilous to beginners — but that’s not to worry, as we’ll go through the most common of them: integer overflow and issues with fractional numbers, troubles of particular programming languages, how to get unstuck in general.

And, you’ll hone all these skills by solving practice problems, which are just like problems on real competitions. You could use any of the following programming languages: C, C++, C#, Haskell, Java, JavaScript, Python 2, Python 3, Ruby, Rust, Scala. We assume that you already know how to write simplest programs in one of these.
      


            Read more
          



          Programming Competitions
    -We'll begin with introduction to the world of competitive programming — the rules, specialties and helpful tips on taking part in competitions in general. In a separate lesson, we'll learn how to test programs: what kinds of test cases there are, how to organize the search for a bugtest, and particularly a method of automating testing called stress-testing.

CORRECTNESS FIRST
    -In this module, we'll start with the most basic things you need to actually solve algorithmic problems. First, we'll talk about structuring your code and intuition behind it — why it's very important, how to manage dependencies between parts of different purpose, how intuitive rules are enforced through formal invariants and conditions. We'll also identify a special class of solutions — brute force solutions — which are always correct, but often very slow. And we'll learn how to estimate running time of our solutions by using a powerful concept of big-O notation.

COMMON STRUGGLES
    -In competitive programming, there are a lot of things to stumble upon — if you don't know them first! We'll delve into how numbers are represented in computers, identify the most common issues with integer and floating point arithmetic, and learn to overcome them. We'll also discuss how to get stuck less in general, especially when debugging solutions.

COMMON STRUGGLES 2
    -We continue considering common struggles arising in competitive programming. We start by learning how to prove that a natural greedy algorithm is correct. We also discuss programming languages: what features are most helpful on competitions, and what are the advantages and pitfalls of several frequently used languages. Finally, we study an essential and easy-to-implement data structure: the segment tree.

Dynamic Programming
    -Dynamic programming is a powerful algorithmic paradigm with lots of applications in areas like optimisation, scheduling, planning, bioinformatics, and others. For this reason, it is not surprising that it is the most popular type of problems in competitive programming. A common feature of such problems is that a solution is usually easy to implement. This does not however mean that it is also easy to find a solution! Therefore, it is important to practice solving such problems. And this is exactly what we are going to do in this module!

Dynamic Programming 2
    -We continue applying dynamic programming technique to various problems.",Competitive Programmer's Core Skills
https://www.classcentral.com/course/swayam-soil-science-and-technology-12886,"This core course is aimed to provide a basic understanding of various aspects of soil science along with some state-of-the-art technologies. The objective is to provide knowledge of different physical and chemical properties of soil. Most importantly this course will impart different preparatory and exploratory data analysis approaches for unconventional digital soil mapping, modeling and mapping of continuous and categorical soil attributes, hyperspectral and proximal soil sensors and their applications for modeling of soil properties, soil pollution and remediation which are not covered in the traditional courses of soil science.



Week 1Lec1: BASIC OVERVIEW OF SOILLec 2: ECOSYSTEM SERVICES OF SOILSLec 3: WEATHERINGLec 4: SOIL FORMATIONLec 5: SOIL PROFILEWeek 2Lec 6: SOIL TAXONOMYLec 7: SOIL ORDERS-1Lec 8: SOIL ORDERS-2Lec 9: SOIL COLOUR AND SOIL TEXTURELec 10: SOIL STRUCTUREWeek 3Lec 11: SOIL TILLAGE AND SOIL DENSITYLec 12: SOIL POROSITY AND CONSISTENCYLec 13: SOIL WATER ENERGY CONCEPTSLec 14: MEASUREMENT OF SOIL WATERLec 15: TUTORIALWeek 4Lec 16: THE FLOW OF LIQUID WATER INTO SOILLec 17: QUALITATIVE DESCRIPTION OF SOIL WETNESSLec 18: SOIL AIRLec 19: SOIL TEMPRATURELec 20: TUTORIALWeek 5Lec 21: SILICATE CLAYS-1Lec 22: SILICATE CLAYS -2Lec 23: SOURCES OF CHARGES ON SOIL COLLOIDSLec 24: CATION EXCHANGE CAPACITYLec 25: SORPTION OF PESTICIDES IN SOILWeek 6Lec 26: DIFFUSE DOUBLE LAYER THEORIESLec 27: ADSORPTION ISOTHERMSLec 28: SOIL ACIDITYLec 29: SOIL ALKALINITY AND SALINITYLec 30: SUBMERGED SOILSWeek 7Lec 31: ESSENTIAL PLANT NUTRIENTSLec 32: SOIL NITROGENLec 33: BIOLOGICAL NITROGEN FIXATIONLec 34: SOIL PHOSPHORUS AND POTASSIUMLec 35: FERTILIZERSWeek 8Lec 36: SOIL TESTING-1Lec 37: SOIL TESTING-2Lec 38: SOIL ORGANIC MATTER AND CLIMATE CHANGELec 39: SOIL ORGANISMSLec 40: COMPOSTWeek 9Lec 41: SOIL EROSION AND LAND DEGRADATIONLec 42: THE UNIVERSAL SOIL-LOSS EQUATIONLec 43: CONSERVATION TILLAGELec 44: WIND AND TILLAGE EROSIONLec 45: TOXIC ORGANIC CHEMICALS IN SOILSWeek 10Lec 46: REMEDIATION OF SOIL ORGANIC POLLUTIONLec 47: SOIL CONTAMINATION WITH TOXIC INORGANIC SUBSTANCESLec 48: REMEDIATION OF SOIL INORGANIC POLLUTIONLec 49: SOIL SURVEYLec 50: REMOTE SENSING IN SOIL SURVEYWeek 11Lec 51: GIS AND GPSLec 52: GEOSTATISTICSLec 53: BASICS OF DIFFUSE REFLECTANCE SPECTROSCOPYLec 54: DIFFUSE REFLECTANCE SPECTROSCOPY FOR SOILSLec 55: PXRF SOIL APPLICATIONSWeek 12Lec 56: OVERVIEW OF DIGITAL SOIL MAPPINGLec 57: MODELING AND MAPPING OF CONTINUOUOS VARIABLESLec 58: MODELING AND MAPPING OF CATEGORICAL VARIABLESLec 59: PEDOTRASNFER FUNCTIONSLec 60: ACCURACY AND UNCERTAINITY OF DSM",Soil Science and Technology
https://www.classcentral.com/course/independent-spatial-data-science-the-new-frontier-in-analytics-17227,"Use location to find patterns and tackle complex problems.
Spatial data science allows analysts to extract deeper insight from data using a comprehensive set of analytical methods and spatial algorithms, including machine learning and deep learning techniques. This course explores the application of spatial data science to uncover hidden patterns and improve predictive modeling. You'll work with powerful analytical tools in Esri's ArcGIS software and learn how to integrate popular open data science packages into your analyses.",Spatial Data Science: The New Frontier in Analytics
https://www.classcentral.com/course/mongodb-university-m233-getting-started-with-spark-and-mongodb-6837,"This course provides an introduction to Spark and helps students get started using the MongoDB Spark connector to build data analytics applications. We provide an overview of the Spark Scala and Java APIs with plenty of sample code and demonstrations. 



Chapter 1: Spark and MongoDB",M233: Getting Started with Spark and MongoDB
https://www.classcentral.com/course/finance-quantitative-modeling-analysts-18634,"The role of an Analyst is dynamic, complex, and driven by a variety of skills. These skills range from a basic understanding of financial statement data and non-financial metrics that can be linked to financial performance, to a deeper dive into business and financial modeling. Analysts also utilize spreadsheet models, modeling techniques, and common investment analysis application as part of their toolkit to make informed financial decisions and investments. This multifaceted specialization will equip a learner who might be interested in entering the dynamic world of data and business analysis, and/or is interested gaining deeper technical knowledge in Finance and Quantitative Modeling. Starting from the fundamentals of quantitative modeling, you will learn how to put data to work by using spreadsheets and leverage spreadsheets as a powerful, accessible data analysis tool. You will also be introduced to the world of corporate finance, and gain a better understanding of finance fundamentals, including a variety of real-world situations spanning personal finance, corporate decision-making and financial intermediation.



          Course 1: Fundamentals of Quantitative Modeling- How can you put data to work for you? Specifically, how can numbers in a spreadsheet tell us about present and past business activities, and how can we use them to forecast the future? The answer is in building quantitative models, and this course is designed to help you understand the fundamentals of this critical, foundational, business skill. Through a series of short lectures, demonstrations, and assignments, you’ll learn the key ideas and process of quantitative modeling so that you can begin to create your own models for your own business or enterprise. By the end of this course, you will have seen a variety of practical commonly used quantitative models as well as the building blocks that will allow you to start structuring your own models. These building blocks will be put to use in the other courses in this Specialization.Course 2: Introduction to Spreadsheets and Models- The simple spreadsheet is one of the most powerful data analysis tools that exists, and it’s available to almost anyone. Major corporations and small businesses alike use spreadsheet models to determine where key measures of their success are now, and where they are likely to be in the future. But in order to get the most out of a spreadsheet, you have the know-how to use it. This course is designed to give you an introduction to basic spreadsheet tools and formulas so that you can begin harness the power of spreadsheets to map the data you have now and to predict the data you may have in the future. Through short, easy-to-follow demonstrations, you’ll learn how to use Excel or Sheets so that you can begin to build models and decision trees in future courses in this Specialization. Basic familiarity with, and access to, Excel or Sheets is required.Course 3: Financial Acumen for Non-Financial Managers- In this course, you’ll explore how financial statement data and non-financial metrics can be linked to financial performance. Professors Rick Lambert and Chris Ittner of the Wharton School have designed this course to help you gain a practical understanding of how data is used to assess what drives financial performance and forecast future financial scenarios. You’ll learn more about the frameworks of financial reporting, income statements, and cash reporting, and apply different approaches to analyzing financial performance using real-life examples to see the concepts in action. By the end of this course, you’ll have honed your skills in understanding how financial data and non-financial data interact to forecast events and be able to determine the best financial strategy for your organization.Course 4: Introduction to Corporate Finance- This course provides a brief introduction to the fundamentals of finance, emphasizing their application to a wide variety of real-world situations spanning personal finance, corporate decision-making, and financial intermediation. Key concepts and applications include: time value of money, risk-return tradeoff, cost of capital, interest rates, retirement savings, mortgage financing, auto leasing, capital budgeting, asset valuation, discounted cash flow (DCF) analysis, net present value, internal rate of return, hurdle rate, payback period.",Finance & Quantitative Modeling for Analysts
https://www.classcentral.com/course/introduction-to-psychology-18270,"Psychology is the scientific study of the human mind and behaviour.  The principles of psychology are critical to a range of industries from counselling and teaching to human resource management and marketing.  This program will introduce fascinating psychology theories and ask you to apply them to issues in the world around you.  The program also introduces key research skills and will challenge you to develop critical thinking skills.



Courses under this program:Course 1: Introduction to Psychology: The History and Science of Psychology-Investigate the history and science of psychology while mastering the basic principles of the scientific method.Course 2: Introduction to Psychology: Biological Psychology-Understand the link between behaviour and human biology, and learn how genes and the environment influence our behaviour.Course 3: Introduction to Psychology: The Psychology of Learning-Explore how new behaviours are learnt by examining different types of psychological conditioning.Course 4: Introduction to Psychology: Developmental Psychology-Examine the physical, cognitive and social development we undergo throughout our lives.Course 5: Introduction to Psychology: The Psychology of Personality-Explore the complex factors and influences that help shape our personality and examine what makes us different, and why.Course 6: Introduction to Psychology: Sensation and Perception-Learn how our sensory systems work together to help us to perceive and respond to the world around us.",Introduction to Psychology
https://www.classcentral.com/course/edx-sql-for-data-science-17900,"Much of the world's data lives in databases. SQL (or Structured Query Language) is a powerful programming language that is used for communicating with and extracting various data types from databases. A working knowledge of databases and SQL is necessary to advance as a data scientist or a machine learning specialist. The purpose of this course is to introduce relational database concepts and help you learn and apply foundational knowledge of the SQL language. It is also intended to get you started with performing SQL access in a data science environment.
The emphasis in this course is on hands-on, practical learning. As such, you will work with real databases, real data science tools, and real-world datasets. You will create a database instance in the cloud. Through a series of hands-on labs, you will practice building and running SQL queries. You will also learn how to access databases from Jupyter notebooks using SQL and Python.
No prior knowledge of databases, SQL, Python, or programming is required.",SQL for Data Science
https://www.classcentral.com/course/edx-practical-learning-analytics-5975,"Everyone involved in higher education has questions. Students want to know how they’re doing and which classes they should take. Faculty members want to understand their students’ backgrounds and to learn whether their teaching techniques are effective. Staff members want to be sure the advice they provide is appropriate and find out whether college requirements accomplish their goals. Administrators want to explore how all of their students and faculty are doing and to anticipate emerging changes. The public wants to know what happens in college and why.
Everyone has questions. We have the chance to help them find answers.
Practical Learning Analytics has a specific goal: to help us collectively ponder learning analytics in a concrete way. To keep it practical, we will focus on using traditional student record data, the kinds of data every campus already has. To make it interesting, we will address questions raised by an array of different stakeholders, including campus leaders, faculty, staff, and especially students. To provide analytic teeth, each analysis we discuss will be supported by both realistic data and sample code.",Practical Learning Analytics
https://www.classcentral.com/course/optimizing-web-search-5512,"Learn the ins and outs of optimizing a website, from conducting an initial audit to presenting your findings and recommendations. Hands-on activities include learning how to select and apply appropriate keywords throughout a website, incorporating keyword research in a content marketing strategy, and optimizing a site for local search. You will also learn strategies for setting goals and client/stakeholder expectations, building effective analytics and reports, and communicating SEO improvements.
      


          Introduction
    -Welcome to week 1! As you may remember from Module 4 within the last course, Search Engine Optimization Fundamentals, keywords are an extremely important tool for helping your customers find you in an often crowded field. Effective use of keywords on your optimized website can result in free targeted traffic to your site, helping you to reach your business goals. In this module, you will use the keyword research you conducted in the last course and you will learn a process for selecting the best keywords to optimize your website in search results. We will look at concepts like relevancy to the site, keyword intent, how competitive the keyword is in organic search, and how well that term might convert once it receives traffic. We’ll also discuss how to identify and evaluate competitors, how to map keywords to pages, and how to create a keyword map for your clients and your own site.  There is a lot to discuss in our first module, so if you are taking this course without learning the materials of module 4 within the SEO Fundamentals course, I highly recommend you complete that module before diving into this one. So, let’s get started learning how to apply keyword research!

Advanced On-Page SEO
    -Welcome to week 2! While keywords help users locate relevant web pages, it’s the content itself that determines whether  a click converts to a sale or increased site traffic. In many corners of the SEO world, the expression “Content is King” is a generally accepted rule, and in this module we’ll examine content from many perspectives: how to analyze it, organize it, create it, make it great and build it into our strategies. You’ll also learn how to conduct effective competitive content analysis and internal content audits. And finally, you’ll learn how to create a site-wide content strategy building on the data we uncover in our study and analysis of content. 

Local SEO
    -Welcome to week 3! In the lessons that follow, you will take a close look at local SEO strategy. You will see how to optimize your Google business pages, on-site content and external references such as citations, backlinks, and reviews to help your local business have higher visibility in the local search landscape. By the end of this module, you should be able to not only describe a bit of the history of how Google displays local searches but also utilize best practices to develop a high quality local SEO approach. 

Creating an SEO Campaign
    -Welcome to week 4! In this module, we are going to discuss the human factor of SEO - how to manage your relationship with clients. We’ll talk about what should be discussed in the critical first meetings, how to manage your client’s expectations, and how to track and report on progress toward your client’s goals. By the end of this module, you’ll have developed a solid approach for achieving a productive and successful relationship with your client.",Optimizing a Website for Search
https://www.classcentral.com/course/executive-data-science-capstone-5088,"The Executive Data Science Capstone, the specialization’s culminating project, is an opportunity for people who have completed all four EDS courses to apply what they've learned to a real-world scenario developed in collaboration with Zillow, a data-driven online real estate and rental marketplace, and DataCamp, a web-based platform for data science programming. Your task will be to lead a virtual data science team and make key decisions along the way to demonstrate that you have what it takes to shepherd a complex analysis project from start to finish.  For the final project, you will prepare and submit a presentation, which will be evaluated and graded by your fellow capstone participants.

Course cover image by Luckey_sun. Creative Commons BY-SA https://flic.kr/p/bx1jvU
      


          Executive Data Science Capstone
    -It's time to put your skills to the test managing a data science project at Zillow, a data-driven online real estate and rental marketplace. Along the way, you'll make important decisions as you lead your team through the project.",Executive Data Science Capstone
https://www.classcentral.com/course/healthcare-data-models-12787,"Career prospects are bright for those qualified to work in healthcare data analytics. Perhaps you work in data analytics, but are considering a move into healthcare where your work can improve people’s quality of life. If so, this course gives you a glimpse into why this work matters, what you’d be doing in this role, and what takes place on the Path to Value where data is gathered from patients at the point of care, moves into data warehouses to be prepared for analysis, then moves along the data pipeline to be transformed into valuable insights that can save lives, reduce costs, to improve healthcare and make it more accessible and affordable. Perhaps you work in healthcare but are considering a transition into a new role. If so, this course will help you see if this career path is one you want to pursue. You’ll get an overview of common data models and their uses. You’ll learn how various systems integrate data, how to ensure clear communication, measure and improve data quality. Data analytics in healthcare serves doctors, clinicians, patients, care providers, and those who carry out the business of improving health outcomes. This course of study will give you a clear picture of data analysis in today’s fast-changing healthcare field and the opportunities it holds for you.
      


          Introduction to Healthcare Data Models
    -In this module, you will be able to define the foundational terms used in discussing and building healthcare data models. You'll be able to describe the conceptual model showing how data flows from operations to analysis. You will compare and contrast common data models used in healthcare data systems. You will also be able to identify common measures used in healthcare data analysis. 

Data Models and Use Cases They Support
    -In this module, you'll be able to describe the Star Schema Data Model, distinguish it from the hierarchical and relational model, list some pros and cons and explain situations in which it could be appropriately used. You should also recognize when another type of data model might be better suited to a particular use case.

Working with Data across Systems
    -In this module, you'll be able to explain how information is stored in data models and how we assemble relevant information to analyze an interesting problem that can improve our healthcare systems. We'll review how we normalize data and how that facilitates analysis. We'll go on to discuss how to bring together information from different sources and across various functional systems. We will also consider how to measure it accurately. 

Improving the Quality of Healthcare Data
    -In this module, you will be able to examine the data that goes into these models and explain how we work with the information that comes from the practice and business of medicine. We will transition from raising the data quality to focusing on finding and correcting data errors by validation and verification. You will also be able to describe several ways data is checked to eliminate errors and improve data quality.",Healthcare Data Models
https://www.classcentral.com/course/discrete-mathematics-8133,"Discrete mathematics forms the mathematical foundation of computer and information science. It is also a fascinating subject in itself.

Learners will become familiar with a broad range of mathematical objects like sets, functions, relations, graphs, that are omnipresent in computer science. Perhaps more importantly, they will reach a certain level of mathematical maturity - being able to  understand formal statements and their proofs; coming up with rigorous proofs themselves; and coming up with interesting results.

This course attempts to be rigorous without being overly formal. This means, for every concept we introduce we will show at least one interesting and non-trivial result and give a full proof. However, we will do so without too much formal notation, employing examples and figures whenever possible.

The main topics of this course are (1) sets, functions, relations, (2) enumerative combinatorics, (3) graph theory, (4) network flow and matchings. It does not cover modular arithmetic, algebra, and logic, since these topics have a slightly different flavor and because there are already several courses on Coursera specifically on these topics.
      


          Introduction - Basic Objects in Discrete Mathematics
    -This module gives the learner a first impression of what discrete mathematics is about, and in which ways its ""flavor"" differs from other fields of mathematics. It introduces basic objects like sets, relations, functions, which form the foundation of discrete mathematics.

Partial Orders
    -Even without knowing, the learner has seen some orderings in the past. Numbers are ordered by",Discrete Mathematics
https://www.classcentral.com/course/executive-data-science-18529,"Assemble the right team, ask the right questions, and avoid the mistakes that derail data science projects.

In four intensive courses, you will learn what you need to know to begin assembling and leading a data science enterprise, even if you have never worked in data science before. You’ll get a crash course in data science so that you’ll be conversant in the field and understand your role as a leader. You’ll also learn how to recruit, assemble, evaluate, and develop a team with complementary skill sets and roles. You’ll learn the structure of the data science pipeline, the goals of each stage, and how to keep your team on target throughout. Finally, you’ll learn some down-to-earth practical skills that will help you overcome the common challenges that frequently derail data science projects.
      


          Course 1: A Crash Course in Data Science- By now you have definitely heard about data science and big data. In this one-week class, we will provide a crash course in what these terms mean and how they play a role in successful organizations. This class is for anyone who wants to learn what all the data science action is about, including those who will eventually need to manage data scientists. The goal is to get you up to speed as quickly as possible on data science without all the fluff. We've designed this course to be as convenient as possible without sacrificing any of the essentials. This is a focused course designed to rapidly get you up to speed on the field of data science. Our goal was to make this as convenient as possible for you without sacrificing any essential content. We've left the technical information aside so that you can focus on managing your team and moving it forward. After completing this course you will know. 1. How to describe the role data science plays in various contexts 2. How statistics, machine learning, and software engineering play a role in data science 3. How to describe the structure of a data science project 4. Know the key terms and tools used by data scientists 5. How to identify a successful and an unsuccessful data science project 3. The role of a data science manager Course cover image by r2hox. Creative Commons BY-SA: https://flic.kr/p/gdMuhTCourse 2: Building a Data Science Team- Data science is a team sport. As a data science executive it is your job to recruit, organize, and manage the team to success. In this one-week course, we will cover how you can find the right people to fill out your data science team, how to organize them to give them the best chance to feel empowered and successful, and how to manage your team as it grows. This is a focused course designed to rapidly get you up to speed on the process of building and managing a data science team. Our goal was to make this as convenient as possible for you without sacrificing any essential content. We've left the technical information aside so that you can focus on managing your team and moving it forward. After completing this course you will know. 1. The different roles in the data science team including data scientist and data engineer 2. How the data science team relates to other teams in an organization 3. What are the expected qualifications of different data science team members 4. Relevant questions for interviewing data scientists 5. How to manage the onboarding process for the team 6. How to guide data science teams to success 7. How to encourage and empower data science teams Commitment: 1 week of study, 4-6 hours Course cover image by JaredZammit. Creative Commons BY-SA. https://flic.kr/p/5vuWZzCourse 3: Managing Data Analysis- This one-week course describes the process of analyzing data and how to manage that process. We describe the iterative nature of data analysis and the role of stating a sharp question, exploratory data analysis, inference, formal statistical modeling, interpretation, and communication. In addition, we will describe how to direct analytic activities within a team and to drive the data analysis process towards coherent and useful results. This is a focused course designed to rapidly get you up to speed on the process of data analysis and how it can be managed. Our goal was to make this as convenient as possible for you without sacrificing any essential content. We've left the technical information aside so that you can focus on managing your team and moving it forward. After completing this course you will know how to…. 1. Describe the basic data analysis iteration 2. Identify different types of questions and translate them to specific datasets 3. Describe different types of data pulls 4. Explore datasets to determine if data are appropriate for a given question 5. Direct model building efforts in common data analyses 6. Interpret the results from common data analyses 7. Integrate statistical findings to form coherent data analysis presentations Commitment: 1 week of study, 4-6 hours Course cover image by fdecomite. Creative Commons BY https://flic.kr/p/4HjmvDCourse 4: Data Science in Real Life- Have you ever had the perfect data science experience? The data pull went perfectly. There were no merging errors or missing data. Hypotheses were clearly defined prior to analyses. Randomization was performed for the treatment of interest. The analytic plan was outlined prior to analysis and followed exactly. The conclusions were clear and actionable decisions were obvious. Has that every happened to you? Of course not. Data analysis in real life is messy. How does one manage a team facing real data analyses? In this one-week course, we contrast the ideal with what happens in real life. By contrasting the ideal, you will learn key concepts that will help you manage real life analyses. This is a focused course designed to rapidly get you up to speed on doing data science in real life. Our goal was to make this as convenient as possible for you without sacrificing any essential content. We've left the technical information aside so that you can focus on managing your team and moving it forward. After completing this course you will know how to: 1, Describe the “perfect” data science experience 2. Identify strengths and weaknesses in experimental designs 3. Describe possible pitfalls when pulling / assembling data and learn solutions for managing data pulls. 4. Challenge statistical modeling assumptions and drive feedback to data analysts 5. Describe common pitfalls in communicating data analyses 6. Get a glimpse into a day in the life of a data analysis manager. The course will be taught at a conceptual level for active managers of data scientists and statisticians. Some key concepts being discussed include: 1. Experimental design, randomization, A/B testing 2. Causal inference, counterfactuals, 3. Strategies for managing data quality. 4. Bias and confounding 5. Contrasting machine learning versus classical statistical inference Course promo: https://www.youtube.com/watch?v=9BIYmw5wnBI Course cover image by Jonathan Gross. Creative Commons BY-ND https://flic.kr/p/q1vudbCourse 5: Executive Data Science Capstone- The Executive Data Science Capstone, the specialization’s culminating project, is an opportunity for people who have completed all four EDS courses to apply what they've learned to a real-world scenario developed in collaboration with Zillow, a data-driven online real estate and rental marketplace, and DataCamp, a web-based platform for data science programming. Your task will be to lead a virtual data science team and make key decisions along the way to demonstrate that you have what it takes to shepherd a complex analysis project from start to finish. For the final project, you will prepare and submit a presentation, which will be evaluated and graded by your fellow capstone participants. Course cover image by Luckey_sun. Creative Commons BY-SA https://flic.kr/p/bx1jvU",Executive Data Science
https://www.classcentral.com/course/detecting-cyber-attacks-9419,"Computer attacks and data breaches are inevitable.  It seems like every day a data breach occurs and the victims of the data breach suffer.  Their information is stolen or posted online.  The company’s or businesses who had the breach go on, learn a little from the attack, and just give credit monitoring out as if nothing happened.  What if you could help prevent a data breach in your organization?  This is the third course in the Practical Computer Security specialization.  This course looks at detection and mitigation of threats and attack vectors and discusses how to use tools and principles to protect information.  By the end of the course you should be able to make suggestions on what type of detection and mitigation strategy is right for your systems or business given the known threats and attack vectors.  You should be able to discuss what features you want in a firewall, or how cash registers or sensitive data systems should be secured.  The project at the end of the course will allow you to apply what you have learned to argue what type of detection and mitigation strategies should have been employed by companies and businesses that have suffered a data breach.
      


          Introduction and Firewalls
    -Welcome!  This week we'll explore firewalls as they are usually the first line of defense against a threat or attack.

Intrusion Detection and Prevention
    -This module will cover intrusion detection and prevention, which is one of the most essential concepts in looking at how threats and attacks are detected and mitigated.

Detection and Prevention tools
    -This module covers intrusion detection and prevention tools used for both networks and systems.  There will be demos of the tools so that you can understand how they might protect your network or systems better.

Attacks are Inevitable - Case Study
    -This module will focus on attacks and how detection and response makes the world of difference when responding to an attack.

Understanding detection and mitigation
    -This module is the course project.  You will review data breaches and understand how they were detected and mitigated.",Detecting and Mitigating Cyber Threats and Attacks
https://www.classcentral.com/course/independent-intro-to-r-for-journalists-how-to-find-great-stories-in-data-11701,"Welcome to the massive open online course (MOOC) “Intro to R for Journalists: How to Find Great Stories in Data,” from the Knight Center for Journalism in the Americas at the University of Texas at Austin. This is a free course open to anyone interested in quickly asking questions of and assessing data. It is meant for journalists, editors, journalism professors and students, but anyone from anywhere in the world who has an interest in data analysis and visualization is welcome to enroll.
 
 



Introduction Module: R
In this introductory module, you will learn how to configure your computer to work with R. Before you can use it analyze data, your computer needs the following tools installed:

A command-line interface to interact with your computer
The git version control software and a GitHub account
The latest version of R
The latest version of RStudio
An API key from Census.gov (https://api.census.gov/data/key_signup.html)
 

 
Module 1: Programming in R
This week you will be introduced to RStudio and learn how to start a new analysis project. You will learn the basics of how to import and explore data with R.
This module will cover:

A tour of the RStudio IDE
Syntax for coding in R
Creating R scripts
Importing packages
Good habits for workflow and documentation habits
How to import data like CSVs, Excel spreadsheets, XML
Exploring the data’s structure

 
Module 2: Wrangling data
This week you will learn how to transform and analyze data the tidy way using the dplyr package.
This module will cover:

Filtering, selecting, arranging, mutating, summarizing data
How to join two data sets for more insight
Chaining analyses functions with pipes for efficiency and readability

 
Module 3: Visualizing data
This week, you’ll learn about the grammar of graphics and how to use the ggplot2 package to make quick exploratory data visualizations.
This module will cover:

The aesthetics of data visualizations
How to create different charts like, bar, box, line, scatterplots
Grouping for charts
How to create facets or small multiples with the data
Labels and titles for visualizations

 
Module 4: Spatial analysis
This week you will learn how to visualize geographical data and look for neighborhood racial profiling disparities using Census data and traffic stop data from Connecticut.
This module will cover:

Creating interactive maps with the R Leaflet package
How to geolocate addresses in R
Importing and visualizing shapefiles
Points in a polygon analysis that merges location data and boundaries for deeper insights

 
Module 5: Publishing for reproducibility
This week you will learn how to use RMarkdown to present your analysis in a narrative format. You’ll also learn how to log changes to your project with version-control software and publish your analysis on the Internet.
This module will cover:

The git version control software and its integration with Github
How data journalists use GitHub and RMarkdown and other notebooks to publish their work
How to use the Markdown markup language to annotate RMarkdown
How to create a new git code repository and start tracking code
How to connect the repository to GitHub and publish to Github Pages",Intro to R for Journalists: How to Find Great Stories in Data
https://www.classcentral.com/course/beneath-the-blue-13604,"Discover fascinating seafloor habitats and learn how humans affect them
Exactly what lies beneath our oceans? Why is the sea floor, and its marine sediments, so important? And how are humans affecting them? On this course you’ll answer these questions and more.
You will consider the importance of the seafloor and learn about its part in global ecological, chemical and physical processes. You will learn about the vital role that the seafloor plays in providing ecosystem services to society, the current rate at which humans are exploiting seafloor habitats and the need to conserve these systems.
This course is for students from pre-A level to undergraduate who have a passion for, or are studying, marine science, biodiversity, earth systems, global change, ecosystem services or human interaction with marine environment.
It will also be of interest to teachers in these areas, or those with a general interest in ocean science.",Beneath the Blue: The Importance of Marine Sediments
https://www.classcentral.com/course/data-science-healthcare-13154,"Understand real world evidence (RWE) and learn how to use it
Real world data (RWD) is the huge quantity of data that falls outside the boundaries of controlled clinical trials, data that is increasingly used to inform decisions in healthcare. Real world evidence (RWE), is the conclusions drawn from this data.
On this course you will learn how real world evidence can be used in healthcare, exploring current trends and existing methodologies for using it. You will consider ethics, design thinking, commercial applications, and the limitations of RWE.
You will also practice using RWE, applying a user-friendly business intelligence tool to examine RWD.
This course is for anyone with an interest in the relationship between ICT and healthcare, especially those interesting in data analysis. You might be an undergraduate student in data science, an analyst or commercial manager working in life sciences pharmaceuticals, healthcare regulation, biotech and medical devices. This course focuses on UK health data, however the course is relevant to learners in other countries.
To take part in this course, you will need a computer with high-speed access to the internet.",Data Science for Healthcare: Using Real World Evidence
https://www.classcentral.com/course/edx-structure-of-materials-part-1-fundamentals-of-materials-structure-12687,"Structure – or the arrangement of materials’ internal components – determines virtually everything about a material:  its properties, its potential applications, and its performance within those applications.  This course is the first in a three-part series from MIT’s Department of Materials Science and Engineering that explores the structure of a wide variety of materials with current-day engineering applications. Taken together, these three courses provide similar content to MIT’s sophomore-level materials structure curriculum.Part 1 begins with an introduction to amorphous materials.  We explore glasses and polymers, learn about the factors that influence their structure, and learn how materials scientists measure and describe the structure of these materials. Then we begin a discussion of the crystalline state, exploring what it means for a material to be crystalline, how we describe periodic arrangement of atoms in a crystal, and how we can determine the structure of crystals through x-ray diffraction.If you would like to explore the structure of materials further, we encourage you to enroll in Part 2 and Part 3 of the course.Photo by User: Bill Burris on Flickr. (CC BY-SA) 2.0



          Part 1: An Introduction to Materials Science

Structure of materials roadmap
States of matter and bonding

Part 2: Descriptors

Descriptors: concept and function
Free volume
Pair distribution function

Part 3: Glasses

Glass processing methods
Continuous network model
Network modifiers

Part 4: Polymers

Random walk model
Chain-to-chain end distance
Order and disorder in polymers

Part 5: An Introduction to the Crystalline State

Translational symmetry
The crystalline state in 2D
The crystalline state in 3D

Part 6: Real and Reciprocal Space

Miller indices
Real space
Reciprocal space

Part 7: X-Ray Diffraction

Bragg’s Law
Diffraction examples","Structure of Materials, Part 1: Fundamentals of Materials Structure"
https://www.classcentral.com/course/edx-scripting-and-programming-foundations-17972,"Computer programs are abundant in many people's lives today, carrying out applications on smartphones, tablets, and laptops, powering businesses, helping cars drive and planes fly, and much more. The course introduces computational thinking and algorithms, a sequence of instructions that solves a problem. Computational or mathematical thinking became increasingly important throughout the industrial age to enable people to successfully live and work. In the information age, computational thinking and algorithms will continue to be increasingly critical for work and everyday life. 
Beyond business and personal computing devices such as PCs, tablets, and smartphones, embedded computers exist invisibly in nearly anything electrical today (e.g., TVs, cars, printers, thermostats, satellites, etc.) and require scripting and programming of instructions to perform efficiently.",Scripting and Programming Foundations
https://www.classcentral.com/course/edx-ap-computer-science-a-java-programming-6541,"In this computer science course, you will learn the basics of programming in the Java language, and cover topics relevant to the AP Computer Science A course and exam.
This course includes a broad view of computer operation, the global impact of computing, and then introduces Java programming concepts including variables, selection and object-oriented design.
This course is for anyone interested in taking a first-level computer-programming course, particularly those who attend a school that does not provide a similar class.
No previous programming knowledge is needed. We are looking forward to helping you explore this exciting new world!



Unit Name or Timeframe: Computer Programming Fundamentals (2 weeks)
Discussion of the objectives of good programmers (correctness, design, style, efficiency)
Problem solving and computer science
The ethics of computer use, social networking, and engineering for the greater good.
Computer hardware and memory
Number representations and conversions
Overflow and underflow
Introduction to Java IDE and debugger (DrJava, IntelliJ)
Building a first Java class and simple program
The main method
I/O in Java
Unit Name or Timeframe: Primitive data types, variables, arithmetic (2 weeks)
Data types and variables
Constants
ASCII and Unicode representation of characters
Assignment
Primitive types vs reference types
Binary arithmetic operators
Static methods and the Math class
String class and functions
Wrapper classes for integer and double type
Unit Name or Timeframe: Selection (2 weeks)
Boolean type
Relational operators
Selection statements (if, else, else-if, switch)
Short-circuit execution
Code blocks
Dangling else
Compound relational operators and truth tables
DeMorgan’s Laws",AP Computer Science A: Java Programming
https://www.classcentral.com/course/edx-big-data-analytics-using-spark-8221,"In data science, data is called ""big"" if it cannot fit into the memory of a single standard laptop or workstation.
The analysis of big datasets requires using a cluster of tens, hundreds or thousands of computers. Effectively using such clusters requires the use of distributed files systems, such as the Hadoop Distributed File System (HDFS) and corresponding computational models, such as Hadoop, MapReduce and Spark.
In this course, part of the Data Science MicroMasters program, you will learn what the bottlenecks are in massive parallel computation and how to use spark to minimize these bottlenecks.
You will learn how to perform supervised an unsupervised machine learning on massive datasets using the Machine Learning Library (MLlib).
In this course, as in the other ones in this MicroMasters program, you will gain hands-on experience using PySpark within the Jupyter notebooks environment.",Big Data Analytics Using Spark
https://www.classcentral.com/course/classical-cryptosystems-9532,"Welcome to Introduction to Applied Cryptography.  Cryptography is an essential component of cybersecurity. The need to protect sensitive information and ensure the integrity of industrial control processes has placed a premium on cybersecurity skills in today’s information technology market.  Demand for cybersecurity jobs is expected to rise 6 million globally by 2019, with a projected shortfall of 1.5 million, according to Symantec, the world’s largest security software vendor. According to Forbes, the cybersecurity market is expected to grow from $75 billion in 2015 to $170 billion by 2020. In this specialization, you will learn basic security issues in computer communications, classical cryptographic algorithms, symmetric-key cryptography, public-key cryptography, authentication, and digital signatures. These topics should prove especially useful to you if you are new to cybersecurity Course 1, Classical Cryptosystems, introduces you to basic concepts and terminology related to cryptography and cryptanalysis. It is recommended that you have a basic knowledge of computer science and basic math skills such as algebra and probability.
      


          Specialization Introduction
    -This module covers an introduction of the specialization and instructors, covers what to expect from this educational experience and also, an introduction to the course Classical Cryptosystems and Core Concepts.

Cryptographic Tidbits
    -In this module we present an introduction to cryptography, differentiate between codes and ciphers, describe cryptanalysis, and identify the guiding principles of modern cryptography.  After completing this course you will be able to read material related to cryptographic systems, understanding the basic terminology and concepts. You will also have an appreciation for the historical framework of modern cryptography and the difficulty of achieving its aims.

Cryptanalysis
    -Delving deeper into cryptanalysis, in this module we will discuss different types of attacks, explain frequency analysis and different use cases, explain the significance of polyalphabetical ciphers, and discuss the Vigenere Cipher.  When you have completed this module, you will have an appreciation of the different types of attacks  and under what kinds of situations each might be applicable.

Hash Functions
    -Continuing on our exploration of the fundamental concept of cryptography, this module will explain the Hash Function, its purpose and application, potential attack vectors, and the importance of hash functions on cryptographic design.  Upon completion you will be able to understand the role that hash functions play in cryptography and how cryptographic hash functions differ from other types of hash functions.",Classical Cryptosystems and Core Concepts
https://www.classcentral.com/course/edx-improvement-science-in-education-7244,"With roots in industry and in health care, improvement science is a disciplined approach to educational innovation that supports teachers, leaders, and researchers in collaborating to solve specific problems of practice. Improvement science brings discipline and methods to different logics of innovation by integrating:

Problem analysis
Use of research
Development of solutions
Measurement of processes and outcomes
Rapid refinement through plan-do-study-act cycles.

For teachers, school leaders, and system leaders, improvement science moves educational innovation out of the realm of “fad” and into the realm of research-based, evidence-driven continuous improvement, with the goal of increasing the effectiveness of educational practice.
That, in turn, will support schools and systems in responding to calls to improve opportunities to learn and student performance and calls to reduce achievement gaps by improving the day-to-day work students, teachers, and leaders.
In this introduction to improvement science, developed in collaboration with the Carnegie Foundation for the Advancement of Teaching, learners will explore:

Problem-specific and user-centered design and analysis
Differences in implementation and outcomes as resources for improvement
Improving systems to improve practice
Driving improvement through measurement, evidence, and disciplined inquiry

This course is part of the Leading Educational Innovation and Improvement MicroMasters Program offered by MichiganX.



            Read more
          



          Lesson 1: Introduction to Improvement Science Lesson 2: Understanding the Problem and the System that Produces It Lesson 3: Focusing Collective Efforts Lesson 4: Testing and Building Evidence Lesson 5: Achieving Quality at Scale Lesson 6: Putting it All Together",Improvement Science in Education
https://www.classcentral.com/course/classical-cryptosystems-9532,"Welcome to Introduction to Applied Cryptography.  Cryptography is an essential component of cybersecurity. The need to protect sensitive information and ensure the integrity of industrial control processes has placed a premium on cybersecurity skills in today’s information technology market.  Demand for cybersecurity jobs is expected to rise 6 million globally by 2019, with a projected shortfall of 1.5 million, according to Symantec, the world’s largest security software vendor. According to Forbes, the cybersecurity market is expected to grow from $75 billion in 2015 to $170 billion by 2020. In this specialization, you will learn basic security issues in computer communications, classical cryptographic algorithms, symmetric-key cryptography, public-key cryptography, authentication, and digital signatures. These topics should prove especially useful to you if you are new to cybersecurity Course 1, Classical Cryptosystems, introduces you to basic concepts and terminology related to cryptography and cryptanalysis. It is recommended that you have a basic knowledge of computer science and basic math skills such as algebra and probability.
      


          Specialization Introduction
    -This module covers an introduction of the specialization and instructors, covers what to expect from this educational experience and also, an introduction to the course Classical Cryptosystems and Core Concepts.

Cryptographic Tidbits
    -In this module we present an introduction to cryptography, differentiate between codes and ciphers, describe cryptanalysis, and identify the guiding principles of modern cryptography.  After completing this course you will be able to read material related to cryptographic systems, understanding the basic terminology and concepts. You will also have an appreciation for the historical framework of modern cryptography and the difficulty of achieving its aims.

Cryptanalysis
    -Delving deeper into cryptanalysis, in this module we will discuss different types of attacks, explain frequency analysis and different use cases, explain the significance of polyalphabetical ciphers, and discuss the Vigenere Cipher.  When you have completed this module, you will have an appreciation of the different types of attacks  and under what kinds of situations each might be applicable.

Hash Functions
    -Continuing on our exploration of the fundamental concept of cryptography, this module will explain the Hash Function, its purpose and application, potential attack vectors, and the importance of hash functions on cryptographic design.  Upon completion you will be able to understand the role that hash functions play in cryptography and how cryptographic hash functions differ from other types of hash functions.",Classical Cryptosystems and Core Concepts
https://www.classcentral.com/course/toxicology-21-10478,"This course familiarizes students with the novel concepts being used to revamp regulatory toxicology in response to a breakthrough National Research Council Report “Toxicity Testing in the 21st Century: A Vision and a Strategy.” We present the latest developments in the field of toxicology—the shift from animal testing toward human relevant, high content, high-throughput integrative testing strategies. Active programs from EPA, NIH, and the global scientific community illustrate the dynamics of safety sciences.
      


          Module 1
    -This model will give you a broad introduction to the Toxicology 21st century (Tox21c) field and familiarize you with the main document, which summarize the main ideas and principles of Tox21c.

Module 2
    -This module will discuss how ToxCast and Tox21 technologies can be used in practice. The US EPA Endocrine Disruptor Screening Program will be discussed in detail and we will demonstrate how the ToxCast platform replaced in vivo tiered approaches in EDSP and, thus, acelerate the process of .  In the second lesson of this module, the development of in silico models for toxicity testing will be discussed.

Module 3
    -This module will familiarize you with the Human Toxome Project run by Johns Hopkins University in collaboration with several university, industry, and research agencies. Omics technologies, their advantages and disadvantages, as well as concepts of Adverse Outcome Pathways (AOP) and Pathways of Toxicity (PoT) will be discussed.

Module 4
    -The first lesson in this module will explain the concept of read-across, why it is important for regulatory risk assessment, and how it can be implemented by industry in response to REACH legislation. The organotypic cultures lesson will teach you about existing in vitro cell-based models starting from simple monolayer cultures of cell lines and ending with complex combined organ-on-a-chip and human-on-a-chip approaches. 

Module 5
    -This module will teach you the role of miRNA and epigenetics in toxicology and environmental health. 

Module 6
    -In this module you will learn about important component of in vitro toxicology such as in vitro to in vivo extrapolation (IVIVE) and physiologically based biokinetic modeling. You will learn why it is important to consider biokinetics in vitro and see some example of biokinetics modeling in vitro. This lesson will also give you a biometry prospective of in vitro toxicology. You will learn which methods can be used to analyze big data. 

Module 7
    -In this lesson you will learn about integrated testing strategies and how they differ from individual tests or test batteries. Also a wrap-up lesson ""beyond chemical"" will summaries your knowledge from this course and give a out-look for further directions in the field of alternatives to animal testing.",Toxicology 21: Scientific Applications
https://www.classcentral.com/course/edx-data-science-tools-17908,"In this course, you'll learn about Data Science tools like Jupyter Notebooks, RStudio IDE, and Watson Studio. You will learn what each tool is used for, what programming languages they can execute, their features and limitations and how data scientists use these tools today.
With the tools hosted in the cloud, you will be able to test each tool and follow instructions to run simple code in Python or R. To complete the course, you will create a final project with a Jupyter Notebook on IBM Watson Studio on Cloud and demonstrate your proficiency in preparing a notebook, writing Markdown, and sharing your work with your peers.
This hands-on course will get you up and running with some of the latest and greatest data science tools.",Data Science Tools
https://www.classcentral.com/course/edx-quantum-information-science-i-part-2-10259,"This course is part of a three-course series that provides an introduction to the theory and practice of quantum computation. This second course builds on the foundational introduction provided in the first course, 8.370.1x, and explores simple quantum protocols and algorithms, including:

Quantum teleportation and superdense coding
The Deutsch-Jozsa and Simon's algorithms
Grover's quantum search algorithm
Shor's quantum factoring algorithm

This course will help you understand what quantum computers can do and how they work. You'll learn how you can contribute to discovering new things and solving problems in quantum information science and engineering.

The complete three-course series includes:

8.370.1x: Foundations of quantum and classical computing – quantum mechanics, reversible computation, and quantum measurement
8.370.2x: Simple quantum protocols and algorithms – teleportation and superdense coding, the Deutsch-Jozsa and Simon’s algorithm, Grover’s quantum search algorithm, and Shor’s quantum factoring algorithm
8.370.3x: Foundations of quantum communication – noise and quantum channels, and quantum key distribution

This course has been authored by one or more members of the Faculty of the Massachusetts Institute of Technology. Its educational objectives, methods, assessments, and the selection and presentation of its content are solely the responsibility of MIT. MIT gratefully acknowledges major support for this course, provided by IBM Research. This course on quantum information science is a collective effort to further advance knowledge and understanding in quantum information and quantum computing.

For more information about MIT’s Quantum Curriculum, visit quantumcurriculum.mit.edu.



            Read more","Quantum Information Science I, Part 2"
https://www.classcentral.com/course/advanced-machine-learning-10341,"Discover and apply advanced statistical machine learning techniques
This online course explores advanced statistical machine learning.
You will discover where machine learning techniques are used in the data science project workflow. You will then look in detail at supervised learning statistical modeling algorithms for classification and regression problems, examining how these algorithms are related, and how models generated by them can be tuned and evaluated.
You will also look at feature engineering and how to analyse sufficiency of data.
This is an advanced course and some experience with machine learning, data science or statistical modeling is expected. Links will be provided to basic resources about assumed knowledge.
Sections of the course make use of advanced mathematics, including statistics, linear algebra, calculus and information theory. If you have prior knowledge of these areas, particularly the first two, you will obtain additional insights into the methods used. If you do not have this prior knowledge, you will still be able to achieve the learning outcomes of the course.
The course uses R. If you have not programmed with R before, you should consider taking a quick introductory course, such as Try R.",Advanced Machine Learning
https://www.classcentral.com/course/edx-the-beauty-and-joy-of-computing-ap-cs-principles-part-2-2532,"Discover the big ideas and thinking practices in computer science plus learn how to code using one of the friendliest programming languages, Snap! (based on Scratch).
Computing has profoundly changed the world, opening up wonderful new ways for people to connect, design, research, play, create, and express themselves. However, just using a computer is only a small part of the picture. The real transformative and empowering experience comes when one learns how to program the computer, to translate ideas into code.
This course teaches students how to do exactly that, using Snap! (based on Scratch), one of the friendliest programming languages ever invented. It's purely graphical, which means programming involves simply dragging blocks around, and building bigger blocks out of smaller blocks. But this course is far more than just learning to program. We focus on seven big ideas (creativity, abstraction, data and information, algorithms, programming, the Internet, and global impact), and six computational thinking practices (connecting computing, creating computational artifacts, abstracting, analyzing problems and artifacts, communicating, and collaborating). Throughout the course, relevance is emphasized: relevance to the student and to society.
Topics include:

Data and Information
Complexity Theory
Recursion, Lambda and Higher Order Functions
Artificial Intelligence
Human Computer Interaction
Lab-based Topics: Algorithms and Data, Trees and Fractals, Recursion and Higher Order Functions

This fun, introductory course is not just for computer science majors, it’s for everyone… join us!



            Read more",The Beauty and Joy of Computing - AP® CS Principles Part 2
https://www.classcentral.com/course/programming-for-data-science-nanodegree-with-R--n-18204,"In this program, you’ll learn the most valuable programming tools and languages used by data scientists today. You’ll learn how to manipulate large datasets, perform version control, and access modern databases. You’ll be programming with R, one of the most popular programming languages used by Data Scientists today. This program is an ideal way to launch a career in data, and for experienced analysts, it’s an excellent opportunity to augment your existing skill set with in-demand programming skills.
Prepare for a data science career by learning the fundamental data programming tools: R, SQL, command line, and git.
      


           Prerequisite Knowledge There are no prerequisites for this program, aside from basic computer skills.See detailed requirements.Introduction to SQLLearn SQL fundamentals such as JOINs, Aggregations, and Subqueries. Learn how to use SQL to answer complex business problems. Investigate a DatabaseIntroduction to R ProgrammingLearn R programming fundamentals such as data structures, variables, loops, and functions. Learn to visualize data in the popular data visualization library ggplot2.Explore US Bikeshare DataIntroduction to Version ControlLearn how to use version control and share your work with other people in the data science industry.Post your work on Github",Programming for Data Science with R
https://www.classcentral.com/course/edx-leading-organizational-change-in-healthcare-11567,"This course is part of the Certified Lifestyle Medicine Executive MicroMasters program which consists of 9 courses and a capstone exam. After completing the program, you can also apply to Doane University to complete your MBA online for approximately $10,500 (learn more about the program here).________________________________________________________________Healthcare practitioners often best understand the intricacies of healthcare, and when equipped with the appropriate leadership skills, can become change agents within their health care delivery systems.A focus on performance is vital for any organization.  However, understanding the culture and health of your organization is equally, and if not, more important.  This course examines key change management constructs, theories and practice associated with leading organizational change.  Learners will be introduced to methods for assessing key features of organization’s cultural environment. Learners will be able to apply social, behavioral, and organizational science to the diagnosis, development, and implementation of an effective organizational culture change.This course is part of the Certified Lifestyle Medicine Executive MicroMasters program. For an introduction to lifestyle medicine, see the Lifestyle Medicine Competencies Professional Certificate program.",Leading Organizational Change in Healthcare
https://www.classcentral.com/course/edx-analytics-for-the-classroom-teacher-7213,"Do you want to be more reflective in your teaching practice and wonder if there are technologies that can help? Are you curious about how data-driven, evidence-based teaching practices can improve your students’ learning? This is the course for you!
Analytics for the Classroom Teacher is an introduction to the emerging field of teaching and learning analytics from the perspective of a classroom teacher.
Experts from all over the world will provide an overview of the current state-of-the-art in teaching and learning analytics. You’ll learn how teachers, curriculum developers and policy makers are collecting and analysing data from the classroom to help guide decisions at all levels.
The course will then focus on the school teacher, and how data analytics can help you to make improvements in your classroom.
You’ll learn to use analytics to improve your lesson plans and your delivery of those plans, and discover more about your students' learning.
No previous knowledge in data-driven instruction, teaching and learning analytics is needed. Join us and a large community of innovative teachers from around the globe and become a pioneer of teaching and learning analytics in your school.



Module 0 - Orientation
Familiarisation of participants with the course structure, policies and outline.
Module 1 - Introduction to educational data for supporting data-driven decision making in school education
This module will:

Introduce the concept of educational data
Discuss how educational data can be used to inform data-driven decision-making at various levels of school operations, strengthening school autonomy
Identify data literacy for teachers as a core competency for supporting not only school accountability and compliance to (national) regulatory standards, but also continuous school self-evaluation and improvement
Introduce the need for data analytics technologies for efficient and effective educational data-driven decision-making, and highlight learning analytics and teaching analytics, which will be further discussed in the course

Module 2 - Teaching analytics: Analyse your lesson plans to improve them
This module will:

Introduce the need to capture and document teaching designs using lesson plans
Define the concept of teaching analytics as a way to enable the analysis of a teaching design and reflection upon it
Present the current state-of-the-art in teaching analytics tools that can be used by classroom teachers
Demonstrate how to use teaching analytics tools to analyse a lesson plan

Module 3 - Learning analytics: Analyse the classroom delivery of your lesson plans and discover more about your students
This module will:

Discuss the concept of personalisation in 21st century school education and the need for generating, updating and maintaining accurate student profiles
Define the concept of learning analytics as the means for supporting personalised teaching and learning, through the measurement, collection, analysis and reporting of students’ educational data generated during the learning process
Present the current state-of-the-art in learning analytics methods and tools that can be used by classroom teachers
Demonstrate how to use learning analytics tools to analyse the classroom delivery of a lesson plan, identify individual student needs and better support the individual student

Module 4 - Teaching and learning analytics to support teacher inquiry
This module will:

Introduce the concept of reflective practice as an important instrument for practice-based professional development as well as organisational learning and improvement
Define the concept of teacher inquiry as a key method for data-driven reflection on-action, related to the process where teachers build useful knowledge about teaching and learning through the deliberate and systematic study of their own practice 
Present indicative teaching and learning analytics tools that can support teacher inquiry
Demonstrate how to use teaching and learning analytics tools to reflect on your teaching practice.

Module 5 – Conclusion
This concluding module will allow participants to:

Finalise their assignments
Discuss their overall MOOC learning experience with their peers, and
Reflect on their learning experience by submitting a course review and feedback survey.",Analytics for the Classroom Teacher
https://www.classcentral.com/course/application-systems-programming-11853,"Welcome to Application Systems Programming, the second course in the Unity Certified Programmer Specialization from Unity Technologies.

This course will help you prepare for the Unity Certified Programmer exam, the professional certification for entry to mid-level Unity programmers. Unity is used to create real-time 3D applications for many industries, including video games, automotive, film, training, and more. In this course, you will be challenged to solve realistic Unity programming problems that are aligned to topics covered on the exam. Throughout the second course, you will expand upon the development of a 2D action video game that was started in the first course: AsteraX. In doing so, you will practice many of the skills covered in the exam, including adding particles effects, implementing user customizations, managing user and application data, and optimizing for different platforms. 

This is an intermediate course, intended for people who are ready for their first paying roles as Unity programmers, or enthusiasts who would like to verify their skills against a professional standard. To succeed, you should have at least 1-2 years of experience programming interactive applications in Unity. You should be proficient at programming in the C# language and familiar with Unity's scripting APIs. You should have experience in the full product development lifecycle, from concept to launch (and beyond). And you should understand multi-platform development, including deploying applications to XR (AR and VR) platforms.
      


            Read more
          



          Particle and Effects Systems
    -For the first part of the course, you'll get an introduction to the course and its Challenge/Solution format, then launch right into challenges that will take the AsteraX game to the next level. Games and other software applications can strongly benefit from user feedback systems that provide a lot of impact and interest. Unity's particle systems can create powerful visual effects, and in the first challenge of this course, you'll implement particle systems to create satisfying explosions and other effects to add excitement to the game.

User Progress and Reward Systems
    -In the following two lessons, you'll continue to add important application systems to the game. First, you'll implement multiple level support with progressively increasing difficulty, as well as the ability for the user to pause the game. Then you'll create a popular type of user reward system: a set of achievements that the player can earn for reaching defined milestones.

Data Management and User Customization Systems
    -What's the use of user progression systems if application data doesn't persist between sessions? In this week's lesson, you'll implement a way to save the user's data to the local device. After setting up Unity Analytics in preparation for a later lesson, you'll implement user customization functionality: allowing users to unlock new ship parts and build their own custom ship from the menu.

Optimizing for Performance and Platforms
    -Let's assume this week that the application is relatively complete and you're ready to launch it to the public. Instead of releasing it blindly, however, you're going to wire it up to Unity Analytics and RemoteSettings, which will allow you to track user progression and update the game difficulty in an agile fashion without releasing a new version. For your final challenge of this course, you'll prepare a mobile version of the game with the appropriate inputs and optimizations.",Application Systems Programming
https://www.classcentral.com/course/probabilistic-graphical-models-3-learnin-7293,"Probabilistic graphical models (PGMs) are a rich framework for encoding probability distributions over complex domains: joint (multivariate) distributions over large numbers of random variables that interact with each other. These representations sit at the intersection of statistics and computer science, relying on concepts from probability theory, graph algorithms, machine learning, and more. They are the basis for the state-of-the-art methods in a wide variety of applications, such as medical diagnosis, image understanding, speech recognition, natural language processing, and many, many more. They are also a foundational tool in formulating many machine learning problems. 

This course is the third in a sequence of three. Following the first course, which focused on representation, and the second, which focused on inference, this course addresses the question of learning: how a PGM can be learned from a data set of examples. The course discusses the key problems of parameter estimation in both directed and undirected models, as well as the structure learning task for directed models. The (highly recommended) honors track contains two hands-on programming assignments, in which key routines of two commonly used learning algorithms are implemented and applied to a real-world problem.
      


          Learning: Overview
    -This module presents some of the learning tasks for probabilistic graphical models that we will tackle in this course.

Review of Machine Learning Concepts from Prof. Andrew Ng's Machine Learning Class (Optional)
    -This module contains some basic concepts from the general framework of machine learning, taken from Professor Andrew Ng's Stanford class offered on Coursera. Many of these concepts are highly relevant to the problems we'll tackle in this course.

Parameter Estimation in Bayesian Networks
    -This module discusses the simples and most basic of the learning problems in probabilistic graphical models: that of parameter estimation in a Bayesian network. We discuss maximum likelihood estimation, and the issues with it. We then discuss Bayesian estimation and how it can ameliorate these problems.

Learning Undirected Models
    -In this module, we discuss the parameter estimation problem for Markov networks - undirected graphical models. This task is considerably more complex, both conceptually and computationally, than parameter estimation for Bayesian networks, due to the issues presented by the global partition function.

Learning BN Structure
    -This module discusses the problem of learning the structure of Bayesian networks. We first discuss how this problem can be formulated as an optimization problem over a space of graph structures, and what are good ways to score different structures so as to trade off fit to data and model complexity. We then talk about how the optimization problem can be solved: exactly in a few cases, approximately in most others.

Learning BNs with Incomplete Data
    -In this module, we discuss the problem of learning models in cases where some of the variables in some of the data cases are not fully observed. We discuss why this situation is considerably more complex than the fully observable case. We then present the Expectation Maximization (EM) algorithm, which is used in a wide variety of problems.

Learning Summary and Final
    -This module summarizes some of the issues that arise when learning probabilistic graphical models from data. It also contains the course final.

PGM Wrapup
    -This module contains an overview of PGM methods as a whole, discussing some of the real-world tradeoffs when using this framework in practice. It refers to topics from all three of the PGM courses.",Probabilistic Graphical Models 3: Learning
https://www.classcentral.com/course/communicating-business-analytics-results-7031,"The analytical process does not end with models than can predict with accuracy or prescribe the best solution to business problems. Developing these models and gaining insights from data do not necessarily lead to successful implementations. This depends on the ability to communicate results to those who make decisions. Presenting findings to decision makers who are not familiar with the language of analytics presents a challenge. In this course you will learn how to communicate analytics results to  stakeholders who do not understand the details of analytics but want evidence of analysis and data. You will be able to choose the right vehicles to present quantitative information, including those based on principles of data visualization. You will also learn how to develop and deliver data-analytics stories that provide context, insight, and interpretation.
      


          Introduction to the Course
    -In this module we’ll briefly review the Information-Action Value Chain we introduced in Course 1.  Then we’ll see how analytical techniques are applied in business problems, first by looking at some “classic” business problems that have been around for a long time, then by looking at some “emergent” business problems that have resulted from more recent advances in technology.

Best  Practices in Data Visualization
    -In this module we’ll learn about a variety of visualizations used to illustrate and communicate data. We will start with the different vehicles used  to present quantitative information. We will then look at a set of examples of data visualizations and discuss what makes them effective or ineffective.  Finally, we discuss Excel charts and why most of them should be avoided.  After completing this module, you will be able to better understand the characteristics of good data visualization and avoid common mistakes when creating your own graphs.


Interpreting, Telling, and Selling
    -In this module we’ll cover a number of topics around interpreting data, gathering additional data, and pitching our recommendations based on our analysis.  First, we’ll discuss ways in which we misinterpret or misrepresent data and how to avoid them, such as mistaking correlation with causation, allowing cognitive biases to influence how we see data, and visualizing data in misleading ways.  We’ll also learn how experimentation can help us obtain more data, including compromises we may need to make in measurement.  Finally, we’ll discuss how we communicate our results and recommendations, with a focus on knowing our audience, telling compelling stories, and creating clear and effective communication materials.


Acting on Data
    -In our final module we’ll walk through two case studies and illustrate the ideas we’ve covered in the course and in the specialization as a whole.  The first case shows how experimentation can be used to create data, sometimes with surprising results.  The second case presents a comprehensive analysis that illustrates the entire analytic lifecycle, and shows how different methods and both quantitative and qualitative analysis can be brought together to solve one strategically important analytical problem.",Communicating Business Analytics Results
https://www.classcentral.com/course/swayam-sociology-of-science-9918,"This course aims to stimulate inspire and provoke awareness of science and technology impact on society and vice versa The course will also discuss the various theoretical underpinnings of science and technology in society The course will also focus on the impact of science and technology on international relations social institutions social groups and on everyday life One of the learning outcome upon completion of the course would be that students will have a better understanding of the complex relationship between science and technology and between science technology and society When you have finished this course you will be able to explain developments in science and technology in terms of their interactions with social cultural environmental and other issues



Week 1: Introduction to Sociology, History of Science, Role of Social Sciences in Technology InstitutesWeek 2: Sociology of Science: Social Shaping of Science, Ethos of Science, Matthew Effect in Science Week 3: Structure & Methodology of Science: Structure of Scientific Revolution, Science as Falsification, Scientist as Indexical ReasonerWeek 4: Science and Technology in India: Science & Technology in Colonial India, Development of Indian Science, Peer Review in Indian Science",Sociology of Science
https://www.classcentral.com/course/canvas-network-data-science-en-agricultura-2618,"El curso ""Data Science en Agricultura"" dotrará a los alumnos de los conocimientos esenciales sobre Data Science, de forma que estos puedan ser capaces de avanzar por sí mismos. La orientación del curso es hacia el ámbito de la agricultura, dado que los casos prácticos que se emplearán están relacionados con este área. En cualquier caso, no se requiere ningún conocimiento específico sobre agricultura y los conocimientos adquiridos son inmediatamente aplicables a cualquier otro área.
Los temas principales serán:

La importancia de ""Data Science"". El rol del ""Data Scientist"" y sus habilidades.
Las herramientas y fuentes de datos empleadas en ""Data Science"".
Casos de estudio: exploratorio, predictivo y descriptivo.
El futuro de ""Data Science"".

English translation:This course introduces the fundamentals of data science, using agriculture as the common thread. Concepts, tools, methods, processes, and data sources will be explored through lectures, readings, quizzes, and case study applications. Main topics will include:

The importance of data science
Skills and roles of data scientists
Data science tools and data sources
How to identify and analyze case studies
The outlook for data science",Data Science en Agricultura
https://www.classcentral.com/course/iversity-hiv-pre-exposure-prophylaxis-prep-8931,"Major advances have been achieved in the treatment of HIV infection but the number of new HIV-infections remains high worldwide, around 2.1 million in 2015 according to the latest UNAIDS report. Data strongly support the need to strengthen HIV prevention and to implement new effective prevention methods. Pre-exposure prophylaxis, PrEP has in several studies been proven to prevent sexual transmission of HIV infection. This course offers an introduction to the principles of PrEP and clinical considerations related to PrEP e.g. prescription, monitoring and adherence. In 2016 PrEP was approved by the European Commision and will in the years to come be implemented in Europe. This course provides information of how to engage community and key stakeholders for the implementation of PrEP and what impact PrEP could have on the HIV epidemic. The course also include examples of how PrEP was implemented in France and the UK.



Chapter 1: Introduction to the course
Chapter 2: Basic information on PrEPIn this chapter you will be introduced to the principles of PrEP and the current studies supporting the use of oral PrEP.
Chapter 3: Clinical considerations in relation to PrEP.In this chapter you will learn how to define key populations for PrEP and how to prescribe and monitor PrEP in patients. Furthermore you will learn how you can ensure adherence to PrEP, how to assess overall risk for STIs and finally how to manage seroconversion in a person on PrEP.
Chapter 4: Implementation of PrEPIn this chapter you will be presented to how PrEP was implemented in France and the United Kingdom. You will learn how to engage community and key stakeholders for implementation of PrEP. Finally you will learn how PrEP can impact the HIV epidemic.
Study time for those who will participate in the exam (= upgraded to the Certificate of Accomplishment)",HIV: Pre-exposure Prophylaxis - PrEP
https://www.classcentral.com/course/oceans-from-space-6952,"##
This free online course will provide an introduction to ocean monitoring Earth Observation (EO) satellite data, and its uses, types and challenges. It will explain how the data is acquired and used, the range of data types available, and the terminology and techniques involved.
The course is presented by physicist, oceanographer and broadcaster Dr Helen Czerski from University College London, remote sensing specialist Dr Hayley Evers-King from the Plymouth Marine Laboratory, and the lead educator Dr Mark Higgins from EUMETSAT.
The course is run by EUMETSAT in support of the Copernicus Programme.
Explore ocean monitoring EO data using real-world examples
You will look at practical examples of using ocean monitoring EO data - in real-world case-studies and in a range of areas of policy and decision-making - and will explore emerging technologies and trends.
The course will introduce you to the operational marine data stream from EUMETSAT in the context of the ‘Copernicus’ programme. It will highlight the role of the Sentinel-3, Sentinel-6 and Jason-3 ocean monitoring satellites and the contributing missions providing marine data for Copernicus – such as Metop and Meteosat. You will also explore the role of the Copernicus Marine Environment Service (CMEMS), focussing on the applications of its data for users and its wider benefits to society.
Examine different areas of ocean monitoring week by week
The course consists of five themed weeks:
Week 1 - Oceans and Climate
How do the oceans play a key role in the Earth’s climate system? How are the oceans set to be affected by changes in climate and why is satellite data so valuable for addressing multiple challenges in the marine environment?
Weeks 2 & 3 - Oceans, Weather and Hazards
What role do our oceans play in weather forecasting? How does monitoring our oceans from space play a key role in this and how is satellite data used in weather models? How can we use satellite data to understand ocean hazards?
Week 4 - Living Oceans
How do satellites help to monitor, quantify and preserve ocean biodiversity?
Week 5 - Oceans and Us
How does Earth observation help us to set international policy, manage ocean resources and biodiversity? How can the oceans be used for renewable energy? How can the public get involved in ocean science?
Learn with ocean monitoring experts from EUMETSAT and major research centres
Throughout the course, you will learn with experts from EUMETSAT - one of the key global organisations involved in ocean monitoring using satellite data - and from its research partners including Plymouth Marine Laboratory, National Oceanography Centre, CLS, Mercator Ocean, and the NASA Jet Propulsion Laboratory.
(Animations, data visualisations and imagery from ESA, NASA and CMEMS are provided courtesy of ESA, NASA and CMEMS. This course is produced for EUMETSAT by Imperative Space).
This course is designed for people who want to learn and explore more about Earth observation and ocean monitoring from space. It is ideal for new potential EO marine data users as well as existing professionals working in other areas of EO, oceanography or environmental science.
It will also help policy-makers, decision-makers, communicators, educators and the general public gain a better insight into the use of satellite data in environmental and ocean monitoring.



            Read more",Monitoring the Oceans from Space
https://www.classcentral.com/course/udacity-data-science-interview-prep-11458,"Data science job interviews  can be daunting. Technical interviewers often ask you to design an experiment or model. You may need to solve problems using Python and SQL. You will likely need to show how you connect data skills to business decisions and strategy.In this course, you'll review the common questions asked in data science, data analyst, and machine learning interviews. You'll learn how to answer machine learning questions about predictions, underfitting and overfitting. You'll walk through typical data analyst questions about statistics and probability. Then, you'll dive deeper into the data structures and algorithms you need to know. You'll also learn tips for answering questions like, ""Tell me about one of your recent projects."" At the end of the course, you'll have a chance to practice what you've learned. You'll receive a link for unlimited mock interviews on Pramp. Practice the skills you need to show up for your data science interview with confidence!Why Take This Course?Knowing what to expect and practicing are keys to technical interview success. But, knowing the right answer is only part of the process. You also need to show how you tackle problems and communicate your thinking. In this course, you'll learn how to approach an interview not as a test, but a showcase. You'll learn to prepare not through memorization, but through process. You'll learn tips for remaining calm so you can answer with confidence to show your expertise.This course will help you prepare and practice for your data science interview. Experienced data scientists will walk you through clear steps for answering tough questions. They'll share their tips for how to respond when you are nervous or don't know the answer. Then, you'll have an opportunity to practice what you've learned in mock interviews.Udacity partners with tech industry leaders to bring you the most comprehensive resources for your job search. Join this course if you want to be in the driver’s seat of your job search where you decide which roles to interview for and land those interviews!



            Read more",Data Science Interview Prep
https://www.classcentral.com/course/stem-learning-5912,"This eight-week course prepares science, technology, engineering, and mathematics (STEM) instructors to develop and implement teaching practices that advance the learning experiences and outcomes of both students and teachers.

About the Course
This course will provide graduate students and post-doctoral fellows in the STEM disciplines (science, technology, engineering, and mathematics) who are planning college and university faculty careers with an introduction to “teaching as research”—the deliberate, systematic, and reflective use of research methods to develop and implement teaching practices that advance the learning experiences and outcomes of both students and teachers.  Participants will learn about effective teaching strategies and the research that supports them, and they will learn how to collect, analyze, and act upon their own evidence of student learning. 

The course will draw on the expertise of experienced STEM faculty, educational researchers, and staff from university teaching centers, many of them affiliated with the Center for the Integration of Research, Teaching, and Learning (CIRTL), a network of 21 research universities collaborating in the preparation of STEM graduate students and post-docs as future faculty members. The eight-week course will be highly interactive, with many opportunities for peer-to-peer learning. Learning communities are at the heart of CIRTL’s activities, and this open, online course is intended to foster a large, healthy learning community of those interested in undergraduate STEM teaching—including current STEM faculty. 

“Advancing Learning through Evidence-Based STEM Teaching” has been developed by faculty, staff, and students at Vanderbilt University, Michigan State University, Boston University, and the University of Wisconsin-Madison. The course is based on work supported by the National Science Foundation under Grant No. 1347605.

For a complete syllabus and more information about the course, please visit http://stemteachingcourse.org/introduction/about-course-2/
      


            Read more",Advancing Learning through Evidence-Based STEM Teaching
https://www.classcentral.com/course/annual-campaigns-10806,"In this comprehensive overview of annual giving programs, you’ll gain an introduction to the basic terminology and concepts of annual giving as well as the various solicitation channels and donor types. Learn how to write a direct mail appeal, craft an impactful email appeal, and develop a script for phone solicitation. You’ll learn how to build a leadership annual giving portfolio and maximize the impact of memberships and events in annual campaigns. You’ll complete the course with the knowledge and skills to build and implement a multi-channel solicitation strategy that achieves the goals of an annual campaign.
      


          The Science and Practice of Annual Giving
    -In this module, you will be able to define and describe common annual giving terminology. You will be able to identify the channels for annual giving and define your audience and build strategies based on data. You will be able to examine and analyze the fundamentals of successful direct mail and email programs and write impactful solicitations. You will be able to identify the fundamentals of telephone outreach and solicitation and develop scripts and ask ladders. You will be able to examine pledge fulfillment strategies and how to use them.

Leadership Annual Giving
    -In this module, you will be able to develop a portfolio of annual giving donors. You'll be able to discuss ideas and best practices for securing a face-to-face donor visit. You will be able to demonstrate how to successfully qualify and solicit a high-value annual donor. You will be able to apply strategies to build relationships with donors to help them achieve their philanthropic goals.

Memberships and Events
    -In this module, you will be able to compare the fundraising techniques of dues-based membership organizations. You will be able to examine the keys to successful fundraising events, and you will be able to create a plan to engage members and donors throughout the year.

Bringing it All Together - The Multi-Channel Approach
    -In this module, you will be able to examine the fundamentals of a multi-channel approach to fundraising. You will be able to develop a multi-channel strategy and you will be able to consider the feedback you have received throughout the course and put together a final portfolio piece.",Annual Campaigns: Building a Case for Support
https://www.classcentral.com/course/startup-entrepreneurship-innovation-care-5516,"This course, which is Part Three in the series of Startup Entrepreneurship specialization, offers Life Lessons from a Master Innovator, with proven achievements. During this course you will listen to conversations and interviews with Mr. David (Dadi) Perlmutter, who until recently was Executive VP of Intel corporate. Dadi will talk about 10 life lessons, based on his 34 years as a rebel innovator and entrepreneur. 

We will share with you the following lessons: 
Love and Knowledge are infinite: grow and share; 
Learn from Failures and Successes; 
Nothing Moves without a Vision; 
Have a Differentiated Market Transforming Strategy; 
Dare to Take Action; 
Fight Resistance; 
It is All About the Ecosystem; 
Build a Team; 
Keep it Simple and Work Hard.

By the end of the course the learner will:
* Know how to lead a process of innovation and implement ideas through all its phases from discovery to delivery in your own field of choice.
* Know how to apply creativity to  generate creative ideas in a wide range of strategic management issues.
* Know how to solve problems in general, with a high degree of innovative creative thinking, to widen the range of possible choices
* Identify new and unfamiliar challenges and needs, reflect on them from a creative point of view (zoom in), decide on the   
action they require (zoom out)  and generate a novel and useful solution
* Transform ideas into real value-creating products, services and processes.
* Be able to analyze both success and failure  and draw conclusions from both, for improving future innovative efforts.
* Be able to identify and create key features of innovative products and services and in doing so,  generate strategically differentiated innovations that are unique
* Be able to present your  ideas persuasively and overcome resistance.
* Know how to simplify a complex product and make it user friendly.


Course assignments will include participation in two discussion groups and four assignments. In each assignment you will be asked to deal with a question relating to an interview you have seen.
      


            Read more
          



          Introduction
    -A science has laws and rules. But art has no laws or rules.  In fact, art is about breaking the rules, to create wonderful new works.  Innovation is an art, not a science;   it is about breaking the rules intelligently,  to create value through novel, useful ideas. The best way to learn the art of innovation, or indeed to learn any art, is from those who have mastered it at the highest level and are willing and able to share their wisdom.  In this course, a master innovator,  Dadi Perlmutter, shares with Coursera learners what he has learned during 34 years of world-changing innovation at Intel Corp., where he served until recently as Executive Vice President.  Perlmutter summarizes over three decades of innovation in ten key lessons, recounted in conversation with Prof. Shlomo Maital.   Our hope is that these ten lessons will significantly improve your chances of success as an entrepreneur.  At the end of this module you will be able to analyze situations of failure and success, and to draw conclusions for future situations.

Strategy, Action & Resistance
    -       Many highly creative people never get beyond vaguely talking about their ideas.  Don’t be like them, Perlmutter counsels.  Take action to implement at least some of your ideas.   The bigger your idea, the more resistance you will likely encounter.  Perlmutter explains how he overcame such resistance, in order to help you do the same.  At the end of this module you will be able to define key features of your product or service in order to differentiate it. You will also be able to focus on key ideas in order to fight resistance. 

Ecosystem, Team & Simplicity
    -Innovators and their innovations rarely stand alone.  Most innovations are part of large complex ecosystems.  Perlmutter counsels you to design your ecosystem to enhance your innovation and offers examples of how he himself did this with the Centrino chipset.  He then discusses how innovators can build powerful, effective teams.   At the end of this module you will be able to  design an ecosystem and build a powerful and effective team. You will also be able to simplify a complex product or service.

Summary & Final Assignment
    -We began by observing that innovation is about breaking the rules.  Nonetheless,  experience shows that there are some basic lessons that can be learned from long years of experience,  lessons that can help young startup entrepreneurs improve their chances of ultimate success.  We hope and trust that Coursera learners have integrated these ten lessons, adapted and expanded them to fit their needs and personalities, and will make them part of their personal toolbox as they set out to use their creativity to change the world.   The capstone project, the fourth of four courses in this specialization, will help them learn how to do this.",Innovation Career Lessons from a Master
https://www.classcentral.com/course/swayam-an-introduction-to-probability-in-computing-10029,"With the advent of machine learning, data mining, and many other modern applications of computer science, we are increasingly seeing the influence of probability theory on computer science. This course is aimed at providing a brief introduction to probability theory to CS students so that they can grasp recent CS trends more easily.



Week 1 : A brief axiomatic introduction to discrete probability theory – Karger’s Mincut Week 2 : Random Variables – QuicksortWeek 3 : Markov’s and Chebyshev’s Inequalities – Randomized MedianWeek 4 : Chernoff Bounds – Parameter Estimation & Quicksort Revisited",An Introduction to Probability in Computing
https://www.classcentral.com/course/feature-engineering-matlab-17127,"In this course, you will build on the skills learned in Exploratory Data Analysis with MATLAB to lay the foundation required for predictive modeling.  This intermediate-level course is useful to anyone who needs to combine data from multiple sources or times and has an interest in modeling.  

These skills are valuable for those who have domain knowledge and some exposure to computational tools, but no programming background. To be successful in this course, you should have some background in basic statistics (histograms, averages, standard deviation, curve fitting, interpolation) and have completed Exploratory Data Analysis with MATLAB. 

Throughout the course, you will merge data from different data sets and handle common scenarios, such as missing data.  In the last module of the course, you will explore special techniques for handling textual, audio, and image data, which are common in data science and more advanced modeling.   By the end of this course, you will learn how to visualize your data, clean it up and arrange it for analysis, and identify the qualities necessary to answer your questions.  You will be able to visualize the distribution of your data and use visual inspection to address artifacts that affect accurate modeling.
      


          Surveying Your Data
    -In this module you'll apply the skills gained in Exploratory Data Analysis with MATLAB on a new dataset. You'll explore different types of distributions and calculate quantities like the skewness and interquartile range. You'll also learn about more types of plots for visualizing multi-dimensional data.

Organizing Your Data
    -In this module you'll learn to prepare data for analysis. Often data is not recorded as required. You'll learn to manipulate string variables to extract key information. You'll create a single datetime variable from date and time information spread across multiple columns in a table. You'll efficiently load and combine data from multiple files to create a final table for analysis.

Cleaning Your Data
    -In this module you'll clean messy data. Missing data, outliers, and variables with very different scales can obscure trends in the data. You'll find and address missing data and outliers in a data set. You'll compare variables with different scales by normalizing variables.

Finding Features that Matter
    -In this module you'll create new features to better understand your data. You'll evaluate features to determine if a feature is potentially useful for making predictions.

Domain-Specific Feature Engineering
    -In this module you'll apply the concepts from Modules 1 through 4 to different domains. You'll create and evaluate features using time-based signals such as accelerometer data from a cell phone. You'll use Apps in MATLAB to perform image processing and create features based on segmented images. You'll also use text processing techniques to find features in unstructured text.",Data Processing and Feature Engineering with MATLAB
https://www.classcentral.com/course/biology-basic-concepts-9208,"Explore the biology behind the complex issues you read about in the news
To be able to properly engage with complex issues in today’s society we often need a basic knowledge of biology. Any consideration of issues like genetic determinism, cloning, genetic engineering, the fight against ageing, eugenics, artificial selection or intelligence inheritance requires an understanding of biology we might not all have.
This online biology course can help. You’ll get a basic introduction to the biology behind big issues - using lessons and interviews with experts - so that you can understand the implications of them for the fields of the social sciences and humanities.
This biology course is for people curious about science, students and professionals in the social sciences and humanities, who want to learn more about the scientific basis of humanity, people with a general interest in biology or the social sciences and humanities.",Why Biology Matters: Basic Concepts
https://www.classcentral.com/course/swayam-descriptive-statistics-with-r-software-13007,"Any data analysis is incomplete without statistics. After getting the data, any statistical analysis starts with descriptive statistics which aims to extract the information hidden inside the data. The tools of descriptive statistics are based on mathematical and statistical functions which are to be evaluated using the software. The statistical software are paid as well as free. Most of the statistical software are paid software. A popular free statistical software is R. What are the basic tools of descriptive statistics and how to use the R software for descriptive statistical analysis is the objective of the course to be taught.



Descriptive Statistics with R Software
 
ABOUT THE COURSE:
Any data analysis is incomplete without statistics. After getting the data, any statistical analysis starts with descriptive statistics which aims to extract the information hidden inside the data. The tools of descriptive statistics are based on mathematical and statistical functions which are to be evaluated using the software. The statistical software are paid as well as free. Most of the statistical software are paid software. A popular free statistical software is R. What are the basic tools of descriptive statistics and how to use the R software for descriptive statistical analysis is the objective of the course to be taught.INTENDED AUDIENCE:UG students of Science and Engineering. Students of humanities with basic mathematical and statistical background can also do it. Working professionals in analytics can also do it.CORE/ELECTIVE: Core/ElectiveUG/PG: UG and PGPREREQUISITES: Mathematics background up to class 12 is needed. Some minor statistics background is desirable.lINDUSTRY SUPPORT: All industries having R & D set up will use this course.
 




COURSE LAYOUT:
Week 1: Calculations with R Software
Week 2: Introduction to Descriptive Statistics, frequency distribution
Week 3: Graphics and Plots
Week 4: Central Tendency of Data
Week 5: Variation in Data
Week 6: Moments, Association of Variables
Week 7: Association of Variables
Week 8: Association of Variables, Fitting of Linear Models",Descriptive Statistics with R Software
https://www.classcentral.com/course/swayam-an-introduction-to-programming-through-c-13892,"This course provides an introduction to problem solving and programming using the C++ programming language. The topics include:Basic programming notions. Control flow, variables and assignments statements, conditional execution, looping, function calls including recursion. Arrays and structures. Elementary aspects of classes. Heap memory.Program design. How human beings solve problems manually. Strategies for translating manual strategies to computer programs. Organizing large programs into units such as functions and classes. Introduction to assertions and invariants.Programming applications. Arithmetic on polynomials, matrices. Root finding. Sorting and searching. Design of editors and simulators, including graphical editors. Elementary animation. A rudimentary graphics system will be discussed.Standard Library of C++. The string, vector and map classes.INTENDED AUDIENCE: First and second year students in degree programs including Engineering and Science degree programsPRE-REQUISITES: Standard XII in the Science streamINDUSTRY SUPPORT: Basic programming is of value to all. C++ allows you to design very fast programs and access low level  machine features, but at the same time its libraries provide a very high level programming model. It can be  considered a modern, safer version of the C language



COURSE LAYOUT Week 1: Introduction to computers using graphics. Notions of program organization, control flow. Introduction to a repeat macro statement and its use for drawing interesting pictures.Basics of computer hardware and how numbers and  other information are represented and processed on computers.Week 2: Basic data types. Variables. Assignment statement. Introduction to program design using examples such as summing infinite series. Introduction to coordinate based graphics and elementary animation. The repeat macro is used for looping.Week 3-4:Statements of C++ for conditional execution and looping. Applications such as computing mathematical functions, root finding.WeeK 5: Functions. Parameter passing. Pointers and references. Recursion basics.WeeK 6: Recursive algorithms and recursive drawings. Breaking larger programs into functions. Passing functions as arguments to other functions.WeeK 7: Arrays. Basic array processing strategies including passing arrays to functions. Pointers. Applications illustrating use of arrays to store sets and sequences. Iterating over pairs of objects from an array. Selection sort.WeeK 8: Use of arrays to represent textual data. Multidimensional arrays. Command line arguments. Binary search. Mergesort.WeeK 9: Structures. Pointers with structures. Structure examples. Basics of classes: member functions, constructors, operator  overloading and access control.WeeK 10: Dynamic memory allocation. Basic mechanisms and pitfalls. Design of a \String"" class that has automated memory management. Copy constructors and destructors. Introduction to the standard library.WeeK 11-12: Use of the standard library in designing programs. Design of medium size programs. A miniature program for marks and ranks display. A program for gravitational simulation. A program for designing and solving resistive circuits with a graphical user interface.",An Introduction to Programming through C++
https://www.classcentral.com/course/edx-introduction-to-python-creating-scalable-robust-interactive-code-10040,"Ready to build on the experience you gained in the Introduction to Python: Absolute Beginner and Fundamentals courses? Continue to learn Python, step by step, as you create scalable, robust, and interactive code.Explore the power of importing Python Libraries into your code. Create Python (.py) files, and work within the file system. Increase the power and precision of your statements through better understanding of objects, operators, and formatting. Plus, make code with robust error handling methods, package your Python files for running in other programs or from the terminal, and provide standard Docstring documentation.When you finish the course, you’ll have code that will handle errors, you’ll have solid, standard documentation features, and you’ll be able to use more robust data structures. Start using your skills to solve problems and build code that lasts. As with the previous introduction to Python programming courses, you will get lots of hands-on practice working with sample code in Jupyter Notebooks on Azure, which require only a browser and an Internet connection (and, in this course, use the Jupiter Terminal).","Introduction to Python: Creating Scalable, Robust, Interactive Code"
https://www.classcentral.com/course/swayam-machine-learning-for-engineering-and-science-applications-12932,"Recent applications of machine learning have exploded due to cheaply available computational resources as well as wide availability of data. Machine Learning (ML) techniques provides a set of tools that can automatically detect patterns in data which can then be utilized for predictions and for developing models. Developments in ML algorithms and computational capabilities have now made it possible to scale engineering analysis, decision making and design rapidly. This, however, requires an engineer to understand the limits and applicability of the appropriate ML algorithms. This course aims to provide a broad overview of modern algorithms in ML, so that engineers may apply these judiciously. Towards this end, the course will focus on broad heuristics governing basic ML algorithms in the context of specific engineering applications. Students will also be trained to implement these methods utilizing open source packages such as TensorFlow.INTENDED AUDIENCE: Postgraduate students in all engineering and science disciplines. Mature seniorundergraduate students may also attempt the course.PREREQUISITES:Familiarity with Multivariable Calculus, Linear Algebra, Probability, Statistics. Comfortable with programming in PythonINDUSTRY SUPPORT: Should be of interest to companies trying to employ engineers familiar with Machine Learning 
      


COURSE LAYOUT Week 1: Mathematical Basics 1 – Introduction to Machine Learning, Linear AlgebraWeek 2: Mathematical Basics 2 - ProbabilityWeek 3: Computational Basics – Numerical computation and optimization, Introduction to Machine learning packagesWeek 4: Linear and Logistic Regression – Bias/Variance Tradeoff, Regularization, Variants of Gradient Descent, MLE, MAP, ApplicationsWeek 5: Neural Networks – Multilayer Perceptron, Backpropagation, ApplicationsWeek 6: Convolutional Neural Networks 1 – CNN Operations, CNN architecturesWeek 7: Convolutional Neural Networks 2 – Training, Transfer Learning, ApplicationsWeek 8: Recurrent Neural Networks RNN, LSTM, GRU, ApplicationsWeek 9: Classical Techniques 1 – Bayesian Regression, Binary Trees, Random Forests, SVM, Naïve Bayes, ApplicationsWeek 10: Classical Techniques 2 – k-Means, kNN, GMM, Expectation Maximization, ApplicationsWeek 11: Advanced Techniques 1 – Structured Probabilistic Models, Monte Carlo MethodsWeek 12: Advanced Techniques 2 – Autoencoders, Generative Adversarial Network",Machine Learning for Engineering and Science Applications
https://www.classcentral.com/course/independent-internet-of-things-foundation-series-12650,"The Internet of Things (IoT) Foundation Series comprises a set of courses that offer a broad experience across IoT Core and its associated services. Each class in the series is centered around a scenario where a fictitious customer has a business challenge. The information and activities in the class provide the knowledge and skills to overcome this challenge.
It is recommended that you complete the series in order. However, if you prefer to skip a topic or pick and choose topics, you may. Please understand that you might miss information that was presented in an earlier class.
Once you complete the series, you will have gained foundational knowledge and skills within AWS IoT and hands-on experience with a broad range of topics, such as Telemetry, Predictive Maintenance, and IoT Automation. Furthermore, by completing the IoT Foundation Series, you will be better prepared to dive deeply into more technical topics, such as IoT Security, MQTT, and the AWS IoT Rules Engine.
Intended Audience
This course is intended for:

Business decision-makers
Data engineers
Device engineers
Fleet managers
Line of business Developer
Operational analysts
Security architect
Security operations engineer

Series Prerequisites
We recommend that attendees of this course have the following prerequisites:

Introduction to AWS IoT

 



            Read more
          




IoT Foundation: Telemetry
IoT Foundation: Command and Control
IoT Foundation: Introduction to Fleet Management
IoT Foundation: Predictive Maintenance
IoT Foundation: Telemetry Demo
IoT Foundation: Fleet Management Demo",Internet of Things Foundation Series
https://www.classcentral.com/course/computational-phenotyping-12838,"This course teaches you the fundamentals of computational phenotyping, a biomedical informatics method for identifying patient populations. In this course you will learn how different clinical data types perform when trying to identify patients with a particular disease or trait. You will also learn how to program different data manipulations and combinations to increase the complexity and improve the performance of your algorithms. Finally, you will have a chance to put your skills to the test with a real-world practical application where you develop a computational phenotyping algorithm to identify patients who have hypertension. You will complete this work using a real clinical data set while using a free, online computational environment for data science hosted by our Industry Partner Google Cloud.
      


          Introduction: Identifying Patient Populations
    -Learn about computational phenotyping and how to use the technique to identify patient populations. 

Tools: Clinical Data Types
    -Understand how different clinical data types can be used to identify patient populations. Begin developing a computational phenotyping algorithm to identify patients with type II diabetes.

Techniques: Data Manipulations and Combinations
    -Learn how to manipulate individual data types and combine multiple data types in computational phenotyping algorithms. Develop a more sophisticated computational phenotyping algorithm to identify patients with type II diabetes.

Techniques: Algorithm Selection and Portability
    -Understand how to select a single ""best"" computational phenotyping algorithm. Finalize and justify a phenotyping algorithm for type II diabetes.

Practical Application: Develop a Computational Phenotyping Algorithm to Identify Patients with Hypertension
    -Put your new skills to the test - develop an computational phenotyping algorithm to identify patients with hypertension.",Identifying Patient Populations
https://www.classcentral.com/course/edx-computational-thinking-and-big-data-8161,"Computational thinking is an invaluable skill that can be used across every industry, as it allows you to formulate a problem and express a solution in such a way that a computer can effectively carry it out.
In this course, part of the Big Data MicroMasters program, you will learn how to apply computational thinking in data science. You will learn core computational thinking concepts including decomposition, pattern recognition, abstraction, and algorithmic thinking.
You will also learn about data representation and analysis and the processes of cleaning, presenting, and visualizing data. You will develop skills in data-driven problem design and algorithms for big data.
The course will also explain mathematical representations, probabilistic and statistical models, dimension reduction and Bayesian models.
You will use tools such as R and Java data processing libraries in associated language environments.



Section 1: Data in R 
Identify the components of RStudio; Identify the subjects and types of variables in R; Summarise and visualise univariate data, including histograms and box plots. 
Section 2: Visualising relationships 
Produce plots in ggplot2 in R to illustrate the relationship between pairs of variables; Understand which type of plot to use for different variables; Identify methods to deal with large datasets. 
Section 3: Manipulating and joining data 
Organise different data types, including strings, dates and times; Filter subjects in a data frame, select individual variables, group data by variables and calculate summary statistics; Join separate dataframes into a single dataframe; Learn how to implement these methods in mapReduce. 
Section 4: Transforming data and dimension reduction 
Transform data so that it is more appropriate for modelling; Use various methods to transform variables, including q-q plots and Box-Cox transformation, so that they are distributed normally Reduce the number of variables using PCA; Learn how to implement these techniques into modelling data with linear models. 
Section 5: Summarising data 
Estimate model parameters, both point and interval estimates; Differentiate between the statistical concepts or parameters and statistics; Use statistical summaries to infer population characteristics; Utilise strings; Learn about k-mers in genomics and their relationship to perfect hash functions as an example of text manipulation. 
Section 6: Introduction to Java 
Use complex data structures; Implement your own data structures to organise data; Explain the differences between classes and objects; Motivate object-orientation. 
Section 7: Graphs 
Encode directed and undirected graphs in different data structures, such as matrices and adjacency lists; Execute basic algorithms, such as depth-first search and breadth-first search. 
Section 8: Probability 
Determine the probability of events occurring when the probability distribution is discrete; How to approximate. 
Section 9: Hashing 
Apply hash functions on basic data structures in Java; Implement your own hash functions and execute, these as well as built-in ones; Differentiate good from bad hash functions based on the concept of collisions. 
Section 10: Bringing it all together 
Understand the context of big data in programming.",Computational Thinking and Big Data
https://www.classcentral.com/course/opensap-basics-of-design-research-6905,"In this course, you’ll get an overview from SAP’s design research experts that will help you get the most out of your field research experience. From identifying users through conducting a field visit to developing points of view, this course will provide you with a foundation for conducting design research in a people-centric way.



Week 1 – Introduction to the courseIntroducing the teaching team and an overview of design research, key terms, and roles.
Week 2 – Planning and preparing how to gain empathyHow to get ready for a field visit by agreeing on outcomes, defining and finding participants, creating a field visit guide, and also planning logistics.
Week 3 – Conducting a field visitHow to conduct a field visit, from building a connection with the participant to having an insightful conversation and capturing the field visit.
Week 4 – Analyzing your dataHow to analyze your data by sharing your findings with your team and making sense of your data through clustering.
Week 5 – Synthesizing your findingsHow to create a persona based on your clusters and extract insights from your data to create points of view.",Basics of Design Research
https://www.classcentral.com/course/climate-change-and-health-18852,"Climate change is arguably the greatest public health threat we face. To address it successfully, health and environmental professionals, advocates, and others need to acquire new skills and a deeper understanding of its challenges and solutions. This specialization is for those who wish to understand the impact of climate change on health and are committed to protecting the health of populations using the knowledge and skills they will acquire.
      


          Course 1: Introduction to Climate Change and Health- Climate change is one of the greatest threats to human health in the 21st century. Yet these impacts to health are still not well recognized. Since you can’t change what you don’t understand, this course is designed to equip health and environmental professionals, as well as other changemakers and the public, with critical and usable knowledge to take positive action. The course begins with an introduction to the science of climate change and how climate change affects human health. It takes a deep dive into climate change’s adverse health effects, including those related to extreme heat, waterborne infections, insect-borne diseases, and exposure to storms and floods. Throughout, the theme of health equity is interwoven by pointing to what factors make some populations more vulnerable than others to climate change’s negative health impacts. Finally, the course explains how measures to reduce greenhouse gas emissions can not only limit future climate change but can also generate substantial immediate health “co-benefits” over and above the benefit of reducing climate change. Following completion of the course, students will be able to: · At an introductory level, describe how the climate has changed, explain the role of greenhouse gases in climate change, and describe how the climate is predicted to change in the future. · Describe how climate change adversely impacts population health, with differing vulnerability across population sub-groups, through direct effects; through ecosystem transformation and degradation; and through the stress it places on political, economic, and social systems. · Explain how adaptation and mitigation strategies can reduce adverse health impacts of climate change and can generate substantial non-climate health benefits in a just and equitable manner.Course 2: Climate Adaptation for Human Health- The world’s climate is changing, and among the most significant negative consequences is to human health. While climate change is a global health issue, its health impacts vary across geographies and populations. In this course, you will learn why taking action to plan for and adapt to climate change is necessary for protecting human health, as well as what kinds of actions are most appropriate for a particular location and population. You also will learn tools and strategies to effectively plan for and enact adaptation actions that build resilience to climate change’s negative effects.Course 3: Communicating Climate Change and Health- How can you persuasively discuss the negative effects of climate change on human health to motivate change in your community? How do you encourage your friends, family, neighbors and community leaders to take meaningful action to address these impacts? In this course, you will learn to communicate the health-related risks of climate change effectively to the public and policymakers and motivate positive changes in climate-related behaviors. Starting with a review of best practices in health risk communication, the course examines the specific challenges of climate change communication and successful strategies to address these challenges. Throughout the course, you will build a step-by-step plan for developing and delivering a communications campaign.",Climate Change and Health: From Science to Action
https://www.classcentral.com/course/independent-data-science-essentials-for-sap-5707,"The purpose of this course is to introduce data science with practical assignments that can be solved in Excel, which is the tool most often used in the enterprise world. The topics and assignments have a focus on SAP data, which makes this course more interesting for professionals working with SAP tools.
 



Spreadsheet advanced topicsHow to extract data from SAPExploratory data analysisClusteringClassification",Data Science Essentials for SAP
https://www.classcentral.com/course/edx-human-population-dynamics-9202,"We are born, we usually move around during our lifetimes, and then, in time, we die. These three aspects of our daily lives – births, movements, and deaths – constitute the building blocks of population dynamics. Fertility, mortality, and migration, as they are more formally known respectively, comprise the central processes of population studies or demography.

The composition of the population in which we live as characterized by its age-sex structure, and especially changes in it over time, shape many of our life-chances and have important socio-economic and political consequences for the societies that we have and what they can and are likely to become. These facts about our intimate personal lives combine to form a sum that is truly greater than its individual parts. In this course we will (a) explore how these population variables are defined, (b) examine some very elementary tools that we have to measure them, both directly and indirectly, (c) discuss the ways in which these demographic variables relate to each other, (d) investigate their significance for the ways in which societies are, and have been, affected by them and effect them, and (e) discover how they can be understood both at the individual level and at the societal level.

Special attention will be given to the significant ways in which these three population variables are linked to other aspects of social structure both cross-sectional (at a given point in time) and longitudinally (over long periods of time), with special reference to the social changes that have defined our world today. We will also situate these population or demographic variables as factors that explain, and in turn can be explained by, other features of the human experience such as urban-rural residence, educational attainment, labour force participation, minority status, family formation, retirement arrangements, and health care, among others. Further, as we expose various aspects of the three demographic variables, we will be in a position to assess the impact of human population dynamics on the Earth’s environment.

Most importantly, in this course we will discuss why population age-sex structures and the demographic variables themselves matter, and should matter, to all of us as citizens insofar as they constrain the options available to us and limit the choices we and our societies are asked to make.



            Read more
          



          The following topics will be covered:

Introduction to Population Studies
Data: the lifeblood of demography
Theorizing about population and its variables
Births and the study of fertility
Deaths and the study of mortality
Migration and the study of human population movements
The impact of the population variables on the Earth’s environment
Population policies and the effects",Human Population Dynamics
https://www.classcentral.com/course/genomic-data-science-project-5953,"In this culminating project, you will deploy the tools and techniques that you've mastered over the course of the specialization. You'll work with a real data set to perform analyses and prepare a report of your findings.
      


          Introduction
    -In this first week, we'll introduce the project and get you oriented to the tasks that you'll be performing over the next several weeks. 

Introduction to the Dataset - Andrew Jaffe
    -This week, we'll really dig into the dataset by providing an introduction from Andrew Jaffe, the lead scientist on the analysis. You should also be looking ahead to Task 2, which is due in Week 4; the alignment will take a long time to perform, so you should start early.

Understand the Problem
    -The purpose of genomic data science is to answer fundamental questions in biology. Before starting on the data analysis process, the first step is always to understand the scientific question you are trying to answer. Don't forget to stay on top of the alignment task due in Week 4; it will take a long time to accomplish and shouldn't be put off.

Alignment
    -Once you have understood the problem, the next step is to obtain the raw data so that you can perform your analysis. 

QC the Alignment
    -Now you have aligned the data, the next step is to do some quality control to make sure that the data are in good shape. 

Get Feature Counts 
    -Now that you have performed alignment and quality control, the next step is to calculate the abundance of every gene in every sample.

Exploratory Analysis 
    -After summarizing your genomic data the next step is to load the data into R for analysis with Bioconductor.

Statistical Analysis
    -The next step is to perform a statistical analysis to detect genes that are differentially expressed. 

Gene Set Analysis
    -In task 6, we have identified genes differentially expressed between fetal and adult brain. Now we will examine these results in a wider context. 

Describe Your Analysis 
    -The next step is to document your work. One of the major issues in genomic data science is that there are so many steps in the process. If these steps are not documented well the result can be major problems.",Genomic Data Science Capstone
https://www.classcentral.com/course/programming-for-data-science-nanodegree--nd104-18224,"In this program, you’ll learn the most valuable programming tools and languages used by data scientists today. You’ll learn how to manipulate large datasets, perform version control, and access modern databases. You’ll be programming with Python, one of the most popular programming languages used by Data Scientists today. This program is an ideal way to launch a career in data, and for experienced analysts, it’s an excellent opportunity to augment your existing skill set with in-demand programming skills.
Learn the fundamental programming tools for data professionals: Python, SQL, the Terminal and Git.
      


           Prerequisite Knowledge There are no prerequisites for this program, aside from basic computer skills.See detailed requirements.Introduction to SQLLearn SQL fundamentals such as JOINs, Aggregations, and Subqueries. Learn how to use SQL to answer complex business problems. Investigate a DatabaseIntroduction to Python ProgrammingLearn Python programming fundamentals such as data structures, variables, loops, and functions. Learn to work with data using libraries like NumPy and Pandas.Explore US Bikeshare DataIntroduction to Version ControlLearn how to use version control and share your work with other people in the data science industry.Post your work on Github",Programming for Data Science with Python
https://www.classcentral.com/course/edx-hospitality-and-tourism-technology-and-innovation-7324,"Gain an in-depth understanding of the strategic applications of ICT (information and communication technologies) innovations in the hospitality and tourism industry.
You will learn about the roles of ICT infrastructures and tools in shaping business environment, business models, marketing practices, revenue strategies, and customer services.
We will also discuss the dynamics that is generated in the development of ICTs and its impact on hospitality and tourism organizations.
Note that this course is priced at USD $198.



Week 1: An Introduction to IT in Hospitality & Tourism Industry 
Develop a holistic view of the impact of ICT in the hospitality and tourism industry.  
Week 2: InformationTechnology Adoption & Applications 
Introduce the theoretical perspectives on technology adoption and innovation diffusion.  
Week 3: Value Creation through IT and Innovation 
Discuss the IT-based value creation in hospitality and tourism organizations.  
Week 4: IT-based Innovation in Marketing and Operation 
Understand why digital advertising matters and how to devise a digital advertising plan.  
Evaluate digital advertising applications, create search advertising and display advertising via a certain platform.  
Week 5: Business Analytics for Data-based Decision Making in Hospitality and Tourism Organizations 
Introduce the concept of data-based decision making and the principles and tools for business analytics.  
Discuss data sources and big data applications for decisions in hospitality & tourism organizations.  
Week 6: Technology Development and the Future of Hospitality and Tourism Organizations 
Discuss destination competitiveness based on IT strategy.",Hospitality and Tourism Technology and Innovation
https://www.classcentral.com/course/edx-data-science-readiness-assessment-7995,"Are you interested in pursuing a degree in Data Science, but unsure whether you have the necessary Math and Programming skills? This assessment will help you identify your current readiness in three core areas required for the study of Data Science; Calculus, Linear Algebra, and Programming.
You can take this assessment at your own pace and receive a private score report that identifies your readiness in each specific area. We will also provide, when necessary, recommendations for additional free online study.
This assessment is free, unproctored, and not offered for credit; it is designed for enrichment and self-assessment for anyone interested in pursuing data science as a career.​",Data Science Readiness Assessment
https://www.classcentral.com/course/edx-systematic-innovation-for-life-science-11698,"How can we improve the innovation process without sacrificing creativity? For most people and organizations, the actual problem solving phase is still very much a random process usually consisting of brain storming, trial-and-error and guesswork. Using structured and systematic innovation methodology allows for solving difficult problems in a shorter amount of time and with better results. Systematic innovation is a cornerstone for innovation strategies in some large multinational companies. The Theory of Inventive Problem Solving (TRIZ) has gained a reputation for systematic problem analysis, problem-solving and system forecasting. TRIZ was developed in Russia based on decades of research. However, TRIZ is considered to be underutilized and not very well known internationally, especially within the life science sector. The course targets students, professionals and citizens with interest in innovation and entrepreneurship. Innovation essentials in the life science sector context will be presented, as well as TRIZ methods and principles. The aim of this course is to learn when, and how, to use all the tools in the “tool box”. Case studies will be shared, reviewed and discussed. Participants who complete and pass the course will be able to use structured and systematic innovation methodology in their projects. Many may be highly motivated to continue developing their skills in additional courses to gain deeper knowledge and potentially gain certification.This course is offered in collaboration with RISE, Oxford AHSN and EIT Health.
      


            Read more
          



Week 1 - Course welcome and introduction

What is Innovation?

The history of innovation and the need to innovate
Innovation vs R&D and inventions


Innovation in Life Science

Characteristics compared to other technological and scientific areas



Week 2 - Tools for innovation

Design Thinking
Ideation
Open Innovation
Innovation Contests

Week 3 TRIZ: Structured and Systematic Innovation 

Introduction to TRIZ and Inventive problem solving
The five levels of Innovation
Problem description
Ideal final result

Week 4 TRIZ: Structured and Systematic Innovation 

Thinking in time and scale
Resolving contradictions
How to apply solution principles
Applying TRIZ thinking to real world problems

Week 5 Rules and Regulations

Implementation and differences in legislation
Regional differences within EU

Week 6 Summary & Conclusions",Systematic Innovation for Life Science
https://www.classcentral.com/course/edx-global-health-informatics-to-improve-quality-of-care-7886,"Disease has no respect for country borders and increased global travel has fueled the spread of infectious disease, as evidenced by the Ebola virus epidemic. Chronic diseases such as diabetes and heart disease, initially confined to the developed world, now exist side by side with malnutrition in low- and middle-income countries (LMIC). Global warming is widening the endemicity of vector-borne diseases.
In this course, we will explore ways to leverage information technology to combat disease and promote health, especially in resource-constrained settings. Technology is a driving force that sweeps across nations even faster than disease and with the spread of mobile phones, which bring computational power and data to our fingertips, new paradigms in tracking and battling disease have been discovered.
This course will explore innovations in information systems in developing countries, and focus not only on the importance of technology, but also on broader issues necessary for its success, such as quality improvement, project management, and leadership skills. Ultimately, health care delivery systems require fundamental and sound operations, such as physical infrastructure and supply-chain management, to deliver high-quality care. Technology is simply a tool to help facilitate this process.
The quality of care theme is critical to this course. The first step stakeholders in health systems should focus on prior to introducing an innovation is to establish a culture of quality improvement and patient safety. An information system can then play a facilitative role by enabling care coordination, tracking processes and outcomes, informing decision making, and fostering learning through data analysis.
An information system without an accompanying organizational transformation risks reinforcing the same failed processes. Using technology to improve access to care without any other quality improvement elements will yield the same and not necessarily better results, but more of them. Innovations need to address gaps in quality and demonstrate improvement in health outcomes, otherwise they won’t sustain or scale.
Lastly, we will discuss our attempts to leverage troves of data to define best practice and how we must keep the patient perspective and health at the center of everything we do.
This course is targeted toward individuals interested in designing or implementing a health information and communication technology (ICT) solution in the developing world. Implementing a health information technology project requires multidisciplinary teams. Thus, with this course, we hope to bring together individuals from a variety of disciplines—computer science, medicine, engineering, public health, policy, and business.



            Read more",Global Health Informatics to Improve Quality of Care
https://www.classcentral.com/course/independent-data-plane-programming-12778,"Traditionally, network equipment has been seen as a closed box with little opportunity to invent. With the recent support of new programming languages such as P4, compiler and runtime support, the next generation of network equipment will be programmable, enabling new use cases. The course is divided into three modules. In the first module, we will introduce the concept of programmable data planes, including P4. In the second part, we will look into how we can use programmable data planes for data-center loadbalancing. Finally, part three covers techniques that enable network monitoring, in-network caching and facilitate simple computing operations with programmable data planes.",Data Plane Programming
https://www.classcentral.com/course/swayam-engineering-thermodynamics-7904,"This course provides an introduction to the most powerful engineering principles -Thermodynamics: the science of energy and its transformation from one form to another form. The subject is widely applicable in several branches of engineering and science. The objective of this course is to introduce systematic different tools needed to analyze energy systems from various daily lives to large scale engineering applications. More specifically, we will cover the topics of mass and energy conservation principles; first law analysis of closed and open systems; understanding second law of thermodynamics and entropy; exergy; properties of pure substances; power generation and refrigeration on thermodynamic cycles; thermodynamic relation, combustion and reaction. 



Week 1: Introduction Energy and Energy transferWeek 2: Properties of Pure SubstancesWeek 3: Energy analysis of closed systemWeek 4: Mass and Energy Analysis of open systems Week 5: The second law of thermodynamics and entropyWeek 6: Exergy  AnalysisWeek 7: Power & Refrigeration CyclesWeek 8: Thermodynamic Potentials I Law Application to Chemically Reacting Systems",Engineering Thermodynamics
https://www.classcentral.com/course/swayam-problem-solving-through-programming-in-c-10090,"This course is aimed at enabling the students toFormulate simple algorithms for arithmetic and logical problemsTranslate the algorithms to programs (in C language)Test and execute the programs and correct syntax and logical errorsImplement conditional branching, iteration and recursionDecompose a problem into functions and synthesize a complete program using divide and conquer approachUse arrays, pointers and structures to formulate algorithms and programsApply programming to solve matrix addition and multiplication problems and searching and sorting problemsApply programming to solve simple numerical method problems, namely rot finding of function, differentiation of function and simple integrationINTENDED AUDIENCE: BE/BTech in all disciplines BCA/MCA/M. ScINDUSTRY SUPPORT : All IT Industries 
      


COURSE LAYOUT Week 1 :Introduction to Problem Solving through programs, Flowcharts/Pseudo codes, the compilation process, Syntax and Semantic errors, Variables and Data TypesWeek 2 :Arithmetic expressions, Relational Operations, Logical expressions; Introduction to Conditional BranchingWeek 3 :Conditional Branching and Iterative LoopsWeek 4 :Arranging things : ArraysWeek 5 :2-D arrays, Character Arrays and StringsWeek 6 :Basic Algorithms including Numerical AlgorithmsWeek 7 :Functions and Parameter Passing by ValueWeek 8 :Passing Arrays to Functions, Call by ReferenceWeek 9 :RecursionWeek 10 :Structures and PointersWeek 11 :Self-Referential Structures and Introduction to ListsWeek 12 :Advanced Topics",Problem Solving through Programming in C
https://www.classcentral.com/course/edx-compliance-in-office-365-data-governance-5754,"In this computer science course you will examine how to plan, implement, and manage Data Governance. As organizational data stored in email and documents continues to grow, Office 365 makes it easy to control the information that you want to keep, as well as control the flow of information out of your organization. This course covers all the steps to effectively plan and manage data retention and data leakage.
This is the second in a series of courses concerning Compliance in Office 365. By completing this course, you will gain an understanding of the archiving and data retention capabilities of Office 365 and data leakage prevention.",Compliance in Office 365: Data Governance
https://www.classcentral.com/course/java-programming-recommender-5113,"Ever wonder how Netflix decides what movies to recommend for you? Or how Amazon recommends books? We can get a feel for how it works by building a simplified recommender of our own!

In this capstone, you will show off your problem solving and Java programming skills by creating recommender systems. You will work with data for movies, including ratings, but the principles involved can easily be adapted to books, restaurants, and more. You will write a program to answer questions about the data, including which items should be recommended to a user based on their ratings of several movies. Given input files on users ratings and movie titles, you will be able to:

1. Read in and parse data into lists and maps;
2. Calculate average ratings;
3. Calculate how similar a given rater is to another user based on ratings; and
4. Recommend movies to a given user based on ratings. 
5. Display recommended movies for a given user on a webpage.
      


          Introducing the Recommender
    -You will start out the capstone project by taking a look at the features of a recommender engine. Then you will choose how to read in and organize user, ratings, and movie data in your program. The programming exercise will provide a check on your progress before moving on to the next step.

Simple Recommendations
    -Your second step in building a recommender will focus on making simple recommendations based on the average ratings that a movie receives. You'll also make sure that each recommended movie has a least a minimal number of user ratings before including it in your recommendations. Throughout this step you are encouraged you use your knowledge of the seven step process to design useful algorithms and successful programs to solve the challenges you will face.

Interfaces, Filters, Database
    -In your third step, you will be encouraged to use interfaces to rewrite your existing code, making it more flexible and more efficient. You will also add filters to select a desired subset of movies that you want to recommend, such as 'all movies under two hours long' or 'all movies made in 2012'. You'll also make your recommendation engine more efficient as you practice software design principles such as refactoring.

Weighted Averages
    -In your fourth step, you will complete your recommendation engine by finding users in the database that have similar ratings and weighting their input to provide a more personal recommendation for the users of your program. Once you complete this step, you could request ratings of movies from those you know, run your program, and give them recommendations tailored to their own interests and tastes!

Farewell
    -Congratulations on completing your recommender programming project! As we conclude this capstone course, our instructors have a few parting words as you embark in future learning and work in computer science!",Java Programming: Build a Recommendation System
https://www.classcentral.com/course/formal-concept-analysis-7769,"This course is an introduction into formal concept analysis (FCA), a mathematical theory oriented at applications in knowledge representation, knowledge acquisition, data analysis and visualization. It provides tools for understanding the data by representing it as a hierarchy of concepts or, more exactly, a concept lattice. FCA can help in processing a wide class of data types providing a framework in which various data analysis and knowledge acquisition techniques can be formulated. In this course, we focus on some of these techniques, as well as cover the theoretical foundations and algorithmic issues of FCA.
Upon completion of the course, the students will be able to use the mathematical techniques and computational tools of formal concept analysis in their own research projects involving data processing. Among other things, the students will learn about FCA-based approaches to clustering and dependency mining.
The course is self-contained, although basic knowledge of elementary set theory, propositional logic, and probability theory would help.
End-of-the-week quizzes include easy questions aimed at checking basic understanding of the topic, as well as more advanced problems that may require some effort to be solved.

Do you have technical problems? Write to us: coursera@hse.ru
      


          Formal concept analysis in a nutshell
    -This week we will learn the basic notions of formal concept analysis (FCA). We'll talk about some of its typical applications, such as conceptual clustering and search for implicational dependencies in data. We'll see a few examples of concept lattices and learn how to interpret them. The simplest data structure in formal concept analysis is the formal context. It is used to describe objects in terms of attributes they have. Derivation operators in a formal context link together object and attribute subsets; they are used to define formal concepts. They also give rise to closure operators, and we'll talk about what these are, too. We'll have a look at software called Concept Explorer, which is good for basic processing of formal contexts. We'll also talk a little bit about many-valued contexts, where attributes may have many values. Conceptual scaling is used to transform many-valued contexts into ""standard"", one-valued, formal contexts.

Concept lattices and their line diagrams
    -This week we'll talk about some mathematical properties of concepts. We'll define a partial order on formal concepts, that of ""being less general"". Ordered in this way, the concepts of a formal concept constitute a special mathematical structure, a complete lattice. We'll learn what these are, and we'll see, through the basic theorem on concept lattices, that any complete lattice can, in a certain sense, be modelled by a formal context. We'll also discuss how a formal context can be simplified without loosing the structure of its concept lattice.

Constructing concept lattices
    -We will consider a few algorithms that build the concept lattice of a formal context: a couple of naive approaches, which are easy to use if one wants to build the concept lattice of a small context; a more sophisticated approach, which enumerates concepts in a specific order; and an incremental strategy, which can be used to update the concept lattice when a new object is added to the context. We will also give a formal definition of implications, and we'll see how an implication can logically follow from a set of other implications.

Implications
    -This week we'll continue talking about implications. We'll see that implication sets can be redundant, and we'll learn to summarise all valid implications of a formal context by its canonical (Duquenne–Guigues) basis. We'll study one concrete algorithm that computes the canonical basis, which turns out to be a modification of the Next Closure algorithm from the previous week. We'll also talk about what is known in database theory as functional dependencies, and we'll show how they are related to implications.

Interactive algorithms for learning implications
    -What if we don't have a direct access to a formal context, but still want to compute its concept lattice and its implicational theory? This can be done if there is a domain expert (or an oracle) willing to answer our queries about the domain. We'll study an approach known as learning with queries that addresses this setting. We'll get to know a few standard types of queries, and we'll see how an implication set can be learnt in time polynomial of its size with so called membership and equivalence queries. We'll then introduce attribute exploration, a method from formal concept analysis, which may require exponential time, but which uses different queries, more suitable for building implicational theories and representative samples of subject domains.

Working with real data
    -A concept lattice can be exponentially large in the size of its formal context. Sometimes this can be due to noise in data. We'll study a few heuristics to filter out noisy concepts or select the most interesting concepts in a large lattice built from real data: stability and separation indices, concept probability, iceberg lattices. We will also talk about association rules, which is a name for implications that are supported by strong evidence, but may still have counterexamples in data.",Introduction to Formal Concept Analysis
https://www.classcentral.com/course/edx-introduction-to-apache-hadoop-8392,"Everywhere you look today, enterprises are embracing big data-driven customer relationships and building innovative solutions based on insights gained from data. According to IBM, every day we create 2.5 quintillion bytes of data — so much that 90% of the data in the world today has been created in the last two years. This data comes from everywhere: sensors used to gather climate information, posts to social media sites, digital pictures and videos, purchase transaction records, and cell phone GPS signals, just to name a few. This data is big data.
The demand for storing this unprecedented amount of information is enough of a challenge, but when you add the need for analytics, the technology requirements truly start pushing the envelope on state-of-the-art IT infrastructures. Fortunately, the Open Source community has stepped up to this challenge and developed a storage and processing layer called Apache Hadoop. Add the dozens of other projects integrating with Apache Hadoop and you have the whole Hadoop ecosystem.
The Hadoop ecosystem, along with the data management architectures it enables, is growing at an unprecedented rate, with 73% of Hadoop cluster deployments now in production — a number which continues to rise.
The demand for individuals who have experience managing this platform is also accelerating. According to the IT Skills and Certifications Pay Index research from Foote Partners, “the need for big data skills also continues to lead to pay increases — about 8% over the last year.” Now is exactly the right time to build an exciting and rewarding career managing big data with Apache Hadoop.
This introductory course is taught by Hadoop experts from The Linux Foundation’s ODPi collaborative project. As host to some of the world's leading open source projects, The Linux Foundation provides training and networking opportunities to help you advance your career.
This course is perfect for IT professionals seeking a high-level overview of Hadoop, and who want to find out if a Hadoop-driven big data strategy is the right solution to meet their data retention and analytics needs. This course will also help anyone who wants to set up a small-scale Hadoop test environment to gain experience working with this exciting open source technology.



            Read more
          



Welcome and Introduction
Enterprise Data Management: From Relational Databases to Hadoop “Data Lakes”
Understanding Hadoop
Deploying Hadoop
Using Your Hadoop Cluster for Data Management and Analytics
Securing Hadoop
Where to Go from Here
Final Exam",Introduction to Apache Hadoop
https://www.classcentral.com/course/edx-social-network-analysis-sna-9134,"In this course, you will learn how relationships between people, artifacts, and ideas within learning settings can be analyzed and interpreted through social network analysis (SNA). You will learn how to prepare data and map these relationships to help you understand how people communicate and exchange information.
The course will review foundational concepts and applications of social network analysis in learning analytics. You will also learn how to use igraph and statnet R packages to manipulate, analyze, and visualize network data.



Week 1: Navigating the Language of Networks
Introduction to networks including the basic concepts in social network analysis, i.e. nodes, edges, adjacency matrix, one and two-mode networks, node degree, connected components, average shortest path, diameter, preferential attachment, network centrality. The week will involve a hands-on task showing students how to calculate basic metrics in R.
Week 2: Applying Network Analysis in Educational Research
Overview of educational research and evidence produced using SNA applications, including differentiation between self-reported and digitally collected network data; ethical considerations; interpretation of basic metrics. The week’s task will include exploratory analysis of the selected dataset, and interpretation of results.
Week 3: The Use of Network Analytic Techniques in Learning Analytics
Introduction to the analysis of socio-technical networks, and applications of network analytic techniques in LA, i.e. community detection, bipartite network analysis, network clustering, integration with text analysis. Presentation of community detection, information flow analysis, and statistical approaches in network analysis. The students will be expected to select one approach out of those presented, and implement it on one of the suggested datasets in R.",Social Network Analysis (SNA)
https://www.classcentral.com/course/swayam-introduction-to-nonlinear-dynamics-4441,"What is common between the motion of planets, mechanical vibrations, chemical oscillators, biological rhythms and love affairs? They can all be modelled as dynamical systems, and more often than not these systems are nonlinear!
This course is an introduction to nonlinear dynamics.  The style of the lectures will be friendly: we will focus on geometric intuition and examples, rather than on rigorous proofs and abstract algebra. Also, the concepts will be illustrated by application to science and engineering. The theory will be developed systematically. We will cover 1 and 2 dimensional flows, with a focus on stability and bifurcations.",Introduction to Nonlinear Dynamics
https://www.classcentral.com/course/udacity-google-analytics-for-android-3700,"This course is deprecated. We recommend taking Firebase Analytics instead.Where in the world are people using your app? Which activities do they use most? How do they navigate through your app? Take this course to learn how to add code to your mobile app to send usage data to Google Analytics, and get answers to questions like these.This course also covers how to use Google Tag Manager to send updated information to your app without needing to redeploy the APK, and to manage all your Google Analytics tags.This course is part of the Google Play Services series, which features a  variety of different Google APIs. Designed as standalone short courses, you can take any course on its own, or take them all!Google Location Services on Android Google Analytics for Android [this course]App Monetization with Display Advertising Add Google Maps to your Android AppWhy Take This Course?If you want to be a professional Android developer, it's critical to understand who your users are, where they are, and how they're using your app. To do this, you need to know how to access and manage your app's analytics. Take this course to learn how to use Google Analytics in your apps, and how to use Tag Manager to send updated information to your app and manage your Google Analytics tags.



IntroductionOverview of Google Play services and an introduction to the goals and structure of this series.Lesson 1 - Getting Started with AnalyticsGet a Google Analytics account ID, and update your app to track all screen views. Lesson 2 - Beyond Auto Activity TrackingSend tracking data for events, and track how your users move through the shopping process.Lesson 3 - Intro to Tag ManagerUse Tag Manager to update values in your app without having to redeploy any code. Cool, huh?Lesson 4 - Integrating Google Analytics and Tag ManagerUse Tag Manager to organize the Analytics tags in your app.Capstone Project (2 Stages)This project assumes that you have completed Developing Android Apps,  Advanced Android App Development and  Google Play Services: Location and Context, in addition to this course.Design, then build, your own Android app.",Google Analytics for Android
https://www.classcentral.com/course/effective-communication-in-the-globalise-5602,"The Capstone Project for this Specialisation requires you to demonstrate your understanding of the courses and integrate the knowledge and skills learned in real workplace scenarios. In particular, you will be given a choice of a few projects based on scenarios and case studies drawn from different workplaces.  

The project outcome is a handbook or a practical guide, which could be a blend of text and multi-media.  In completing the project, you will be required to use and/or collect relevant primary data from people in the workplace through emails, face-to-face chats, Skype discussions and incorporate the data into the handbook/guide as support.  

In addition, there will be a component on critical reflection on your learning journey. 

The Capstone Project is to be completed within six weeks.  
Evaluation will be done via a combination of peer and tutor assessment.
      


          Capstone: An overview

Capstone: E-guide
    -Introduction to e-guide

Capstone: Data Collection 1
    -Basic principles in constructing survey questions

Capstone: Data Collection 2

Capstone: Putting it altogether
    -Putting it altogether

Final Submission and Peer Critique
    -Putting all the information that you have prepared into the e-guide.",Effective Communication in the Globalised Workplace - The Capstone
https://www.classcentral.com/course/edx-feeding-a-hungry-planet-agriculture-nutrition-and-sustainability-8498,"Agriculture is more than waving fields of wheat; our ability to grow food from existing natural resources – and without decimating those resources – is key to sustainably feeding the world. In this course, learn about food security worldwide, the effects of malnutrition, how we manage ecosystems that provide food resources and more. You’ll emerge from this course with a clear answer to the question: What can I do to make food consumption and production more sustainable? This course is for:

Graduate students and advanced undergraduate students in agriculture, economics, international development and other fields who are learning about the intersectional factors impacting agriculture and food production/consumption
Nutritionists, agriculture professionals and other practitioners interested in the latest developments in the field
Sustainable development practitioners – including those who work for international aid organizations and nonprofits in the realms of poverty, nutrition and agriculture – who want to understand the lifecycle of food production and food security
Private actors, such as those engaging in or investing in social entrepreneurship and the support of local agriculture

Partners:This course is supported by faculty based at Cornell University, Johns Hopkins University, Rothamsted Research, Tufts University, and Wageningen University and Research.
      


            Read more
          



          Module 1: The global challenges around food 

1.1 Introduction to this MOOC
1.2 Global challenges around food
1.3 Case study 1: Rice
1.4 Case study 2: Smallholder farming
1.5 Case study 3: Livestock
1.6 Case study 4: Aquaculture

Module 2: Agriculture at the center of sustainable development 

2.1 Emergence of modern agriculture
2.2 Risks under a Business-As-Usual scenario
2.3 Agriculture & the Sustainable Development Goals

Module 3: Food systems for nutritional security and better health 

3.1 What is food security?
3.2 Nutrition and health
3.3 Consumption and diets
3.4 Food losses and waste
3.5 Socio-economic dynamics of food systems
3.6 Pathways towards food security

Module 4: Sustainable intensification of agricultural systems – Part 1

4.1 Sustainable agriculture intensification
4.2 The importance of productivity growth
4.3 Climate change adaptation and mitigation
4.4 Breeding and genetics
4.5 Nutrient management
4.6 Soil fertility management

Module 5: Sustainable intensification of agricultural systems – Part 2 

5.1 Water management
5.2 Crop protection
5.3 Good agronomy
5.4 Sustainable livestock systems
5.5 & 5.6 Functional diversity I & II

Module 6: Rural development for poverty alleviation

6.1 Rural economies and urban linkages
6.2 Rural development
6.3 Markets and supply chains
6.4 International trade
6.5 Development enhancing investments
6.6 Food governance

Module 7: Action for change

7.1 Pathways to change
7.2 Monitoring change
7.3 Mechanisms to stimulate change
7.4 Investing in science
7.5 What can I do?","Feeding a Hungry Planet: Agriculture, Nutrition and Sustainability"
https://www.classcentral.com/course/mooc-ed-teaching-the-beauty-and-joy-of-computing-curriculum-12218,"The Teaching the Beauty and Joy of Computing (BJC) Curriculum Massive Open Online Course for Educators (MOOC-Ed) provides professional development and support for teachers of the BJC high school computer science curriculum.
The BJC curriculum is endorsed by the College Board as an Advanced Placement Computer Science Principles (AP CSP) course for high school students. While this MOOC-Ed will help prepare you to teach BJC, the online course alone does not meet the requirements to become a College Board certified AP teacher; attending a summer BJC Professional Development workshop is required for that certification. Information about those workshops is available at https://bjc.berkeley.edu/summer-pd. Ideally, BJC teachers will be able to both attend a BJC Institute and use this MOOC-Ed to further their preparation.
Much of this MOOC-Ed is built around short videos of pairs of students working together to solve BJC curriculum programming challenges. These videos demonstrate students' — often very clever — problem solving, while also highlighting some common mistakes your students may make, misconceptions they may have, and misdirections they may take. These student videos serve several important purposes in this course for teachers, including to:

Provide you with a concrete sense of what BJClooks like in practice;
Help you learn about the specific BJClabs used in the videos to inform your own teaching;
Show how different student pairs work together and learn as they develop, test, and debug their ideas;
Learn how the curriculum incorporates the Big Ideas and Computational Thinking Practices that are at the core of BJC(and other CSP curriculum) through seeing students actively engage with them;
Demonstrate how Snap!provides an easy-to-use and powerful tool for students' learning and creativity; and
Seed discussions among you and your peers in this MOOC-Ed about teaching the BJCcurriculum and guiding your students' learning.

 
We build upon the student videos to provide programming insights materials about the Snap! language and to discuss effective teaching practices to help you develop your pedagogical content knowledge and be a successful BJC teacher. In addition, you will hear computer science experts discuss the central ideas of the curriculum and experienced BJC teachers discuss what they have learned and their recommendations for teaching BJC. Throughout this course, you will have opportunities to learn with and from your peers, and to help them learn, through the discussion forum.
The MOOC-Ed focuses on the early units of the curriculum to help you begin to teach it successfully and to prepare your students for the Advanced Placement Computer Science Principles exam; the content of the full BJC curriculum goes well beyond the AP requirements. This course also introduces you to the Snap!programming language. Many who have not programmed before are surprised at how easy and enjoyable it is to create simple programs with this visual programming language that was designed to support teaching and learning.
The MOOC-Ed is designed to be flexible to allow you to select the resources and activities that best serve your professional learning needs — whether you are a computer science expert or a novice at computer programing, and whether you are experienced at guiding project-based, student-driven activities or new to those approaches. You can use it in the following ways:

As an online coursethat you work through in sequence, on your own or with local or online colleagues. By completing a required set of activities, you can earn a certificate of completion that most teachers can submit to their local agency to obtain continuing education units (CEUs).
As a set of on-demand resourcesfrom which you can select as needed to support your own BJC
As resources to enhance other BJC professional development activities, which may, for example, use the student videos to stimulate discussions about how teachers can best facilitate students' learning.

 



            Read more
          



Session 1: Welcome to the BJC Curriculum: Student and Teacher Perspectives
In this session, you will be introduced to the MOOC-Ed and the BJCcurriculum through the perspectives of students and teachers. Videos of pairs of students working on different parts of a BJC programming lab and of expert teachers sharing their approaches to teaching BJC will provide insights into what BJC looks like in practice and how you can successfully guide your students' learning. Expert teacher panels discuss strategies for facilitating both the programming labs and teaching students about the global impact of computing through the social implications labs and Computing in the News activities.
Session 2: Introducing the Snap! Programming Language
In this session, you will explore coding concepts central to all programming languages and begin to learn about the Snap! programming language and environment, from learning how to set up an account to experimenting by revising or extending a starting script. As a self-directed learning experience, this session should be approached differently by those who are new to computer programming, those who have programming experience but are new to the Snap! language, and those who already know Snap!
Session 3: Getting Started: Creating the Click Alonzo Game
This session invites you to delve into a simple programming project and then to view examples of ways to extend the lab to give students opportunities to develop their own variations, learning more about programming as they do so. You will have an opportunity to observe videos of students, discuss your observations with other MOOC-Ed participants, and learn more about Snap! programming and specific computer science concepts in the process. A panel of expert teachers offer insights into pair programming and effectively managing it in your classroom.
Session 4: Programming with Text: Lists and List Processing
In this session, you will explore a lab in which students learn how to create lists of data, select data from those lists, and combine data in new ways. As in the previous session, you will observe pair programming through student videos and discuss your observations with other participants. You will also observe videos of students working on a more advanced lab using lists of data and list processing programming commands. A panel of expert teachers offers suggestions about teaching the first few labs to help your students establish a strong foundation for the rest of the BJC curriculum.
Session 5: Polygons and Patterns: Abstracting by Creating Blocks
In this session, you will explore a lab that is designed to help students understand important programming concepts such as variables, loops, and inputs while they explore creating shapes on the screen. They learn to create new blocks (e.g., for drawing a polygon with any number of sides) that can then be used within their programs, thereby learning about the concept and process of abstraction. As in previous sessions, you will observe pair programming through student videos and discuss your observations with other MOOC-Ed participants. A panel of expert teachers offers suggestions for helping students understand the difference between local and global variables, and the related Big Idea of abstraction and Computational Thinking Practice of abstracting.
Session 6: Multiple Sprites and Types of Variables: The Number Guessing Game
In this session, you will explore labs that expand students' understanding of local and global variables and engage them in more complex programming challenges. As in previous sessions, you will observe videos of students engaged in pair programming with both a simple and a more complex programming challenge, and discuss your observations with other participants. A panel of expert teachers offers suggestions for helping students debug programs and for engaging more advanced students in both their own projects and in helping their classmates.
Session 7: Wrapping Up
In the final session, you will look toward the Advanced Placement Computer Science Principles exam and its ""Explore"" and ""Create"" performance tasks. Additional resources are provided to help you prepare students for the AP exam. You will hear advice from both teachers and students about preparing students for the written exam and the performance tasks. A final online discussion with your peers focuses on how you can best prepare students for this assessment focused on application to ideas and the impact of computer innovations.",Teaching the Beauty and Joy of Computing Curriculum
https://www.classcentral.com/course/edx-computer-networks-and-the-internet-8665,"The Internet has become integral to our daily lives. Despite its importance to users, most have only a general idea of how it works. If you’re eager to learn more about the Internet and computer networks in general, this course is for you! This course was created in collaboration with the Lübeck University of Applied Sciences with support from the German Federal Ministry of Education and Research (BMBF).
In this course, you will learn about technologies that you use at home like Wireless LAN. We will also illustrate how the Internet works on a global scale and investigate the role of major protocols; in particular the Internet Protocol (version 4 and version 6) and its helper protocols (e.g., ICMP, ARP, DHCP).
You’ll learn how the protocols TCP and UDP are used to realize applications. Out of the many applications that the Internet has, the Hypertext Transfer Protocol is focused on as the lead example since it is the main protocol for the Web.
Key tools will be introduced and used, including the network protocol analyzer Wireshark, the network emulators eNSP and WANem, command line tools ping and traceroute, Firefox browser Add-Ons like IPvFox, and many test web pages.
This course uses videos and texts to provide an overarching foundation, augmented with practical exercises so that you can experiment and explore on your own.
A portion of the profit from verified certificates in this course will go toward Kiron Open Higher Education. Kiron enables access to higher education and successful learning for refugees through digital solutions.



            Read more
          



Week 1: Introduction and Network Topologies

Importance of computer networks
Network topologies
Standardization bodies

Week 2: OSI Reference Model

Layers of the OSI Reference Model
Internet Model / Hybrid Model

Week 3-4: Data Link Layer

Ethernet - Wireless LAN
Point-to-Point Protocol

Week 5-7: Network Layer

Circuit Switching, Packet Switching
Internet Protocol (version 4, version 6)
Helper protocols (ICMP, DHCP, ARP)
Network Address Translation
Routing Basics

Week 8-9: Transport Layer

User Datagram Protocol
Transmission Control Protocol

Week 10-11: Application Layer

Hypertext Transfer Protocol
Electronic Mail
Domain Name System

Week 12: Computer Networks History

Important historic milestones",Computer Networks and the Internet
https://www.classcentral.com/course/weobserve-the-earth-16933,"Learn to capture and analyse data and use the findings to take action
Would you like to understand the environment and help create change? A citizen science project or observatory is the ideal way to explore environmental issues, take action and become a changemaker.
On this course, you’ll discover the type of citizen science projects available around the world and how to get involved. You’ll find out how to lead a citizen science project, including the best practices for community building, question forming and data collecting.
You’ll also learn how to interpret the data you collect and use your findings to educate others about environmental concerns.
This course is for anyone interested in citizen science and citizen observatories, and learning about how to design a citizen science project.",Citizen Science Projects: How to Make a Difference
https://www.classcentral.com/course/edx-quantum-information-science-i-part-3-10276,"This course is the final part of a three-course series that provides an introduction to the theory and practice of quantum computation. This third course builds on the foundational introduction provided in the first course, and the simple quantum protocols provided in the second course, and explores quantum communication, including:

Models of quantum noise and quantum channels
Quantum error correction
Quantum key distribution
Distributed quantum protocols

This course will help you establish a foundation of knowledge for understanding what quantum computers can do, how they work, and how you can contribute to discovering new things and solving problems in quantum information science and engineering.
The three-course series comprise:

8.370.1x: Foundations of quantum and classical computing – quantum mechanics, reversible computation, and quantum measurement
8.370.2x: Simple quantum protocols and algorithms – teleportation and superdense coding, the Deutsch-Jozsa and Simon’s algorithm, Grover’s quantum search algorithm, and Shor’s quantum factoring algorithm
8.370.3x: Foundations of quantum communication – noise and quantum channels, and quantum key distribution

Prior knowledge of quantum mechanics is helpful but not required. It is best if you know some linear algebra.
This course has been authored by one or more members of the Faculty of the Massachusetts Institute of Technology. Its educational objectives, methods, assessments, and the selection and presentation of its content are solely the responsibility of MIT. MIT gratefully acknowledges major support for this course, provided by IBM Research. This course on quantum information science is a collective effort to further advance knowledge and understanding in quantum information and quantum computing.
For more information about MIT’s Quantum Curriculum, visit quantumcurriculum.mit.edu.



            Read more","Quantum Information Science I, Part 3"
https://www.classcentral.com/course/edx---data-structures-and-algorithm-design-part-i-1646,"Data structures play a central role in computer science and are the cornerstones of efficient algorithms. Knowledge in this area has been at the kernel of related curriculums. This course aims at exploring the principles and methods in the design and implementation of various data structures and providing students with main tools and skills for algorithm design and performance analysis. Topics covered by this course range from fundamental data structures to recent research results. ""Data Structures and Algorithm Design Part I"" is an introductory course focusing on basic data structures, including vectors, lists, stacks, queues, binary trees, and graphs. They are important in programming practice, as well as fundamental to our advanced course: ""Part II.""
数据结构是计算机科学的关键内容，也是构建高效算法的必要基础。其覆盖的知识，在相关专业的课程体系中始终处于核心位置。本课程旨在围绕各类数据结构的设 计与实现，揭示其中的规律原理与方法技巧；同时针对算法设计及其性能分析，使学生了解并掌握主要的套路与手法。讲授的主题从基础的数据结构，一直延伸至新 近的研究成果。本学期的数据结构（上），是数据结构的入门课程，着重讲解向量、列表、栈、队列、二叉树、图等基本的数据结构，它们不仅本身具有重要实用价值，而且为学习后续课程“数据结构（下）""提供了基础。更多介绍详见：http://dsa.cs.tsinghua.edu.cn/~deng/ds/mooc/，或加入本课之后查看FAQ栏目。",数据结构与算法设计(上) | Data Structures and Algorithm Design Part I
https://www.classcentral.com/course/professional-epidemiology-18759,"This specialization is intended for people working or aspiring to work in the field of public health at the local, regional, and national level. Over five courses taught by faculty from the preeminent school of public health, you'll learn to use the core epidemiologic toolset to measure the health of populations, assess interventions, collect and analyze data, and investigate outbreaks and epidemics.



          Course 1: Essential Epidemiologic Tools for Public Health Practice- In order to make a difference in the health and well-being of a population, we must understand the burden of all problems and conditions that affect the population, as well as how well our efforts to mitigate these problems are actually working. This course provides you with some essential skills and tools that will enhance your ability to describe and understand the health of your community. The tools that epidemiologists use are in fact useful for all public health practitioners, including data scientists, program officials, agency leaders, and policymakers. Whether you are deeply enmeshed in your career and looking to augment your skills, or are looking to change career paths into the field of public health, this course will give you some of the practical knowledge and skills that we hope you can apply in your professional endeavors.Course 2: Data and Health Indicators in Public Health Practice- Epidemiology is often described as the cornerstone science in public health. Epidemiology in public health practice uses study design and analyses to identify causes in an outbreak situation, guides interventions to improve population health, and evaluates programs and policies. In this course, we'll define the role of the professional epidemiologist as it relates to public health services, functions, and competencies. With that foundation in mind, we'll introduce you to the problem solving methodology and demonstrate how it can be used in a wide variety of settings to identify problems, propose solutions, and evaluate interventions. This methodology depends on the use of reliable data, so we'll take a deep dive into the routine and public health data systems that lie at the heart of epidemiology and then conclude with how you can use that data to calculate measures of disease burden in populations.Course 3: Surveillance Systems: The Building Blocks- Epidemiology is often described as the cornerstone science and public health and public health surveillance is a cornerstone of epidemiology. This course will help you build your technical awareness and skills for working with a variety of surveillance systems. Along the way, we'll focus on system objectives, data reporting, the core surveillance attributes, and performance assessment. This course is designed for public health practitioners and anyone who wants to learn more about the basics of public health surveillance. If you develop or implement surveillance systems or aspire to do so or use the data resulting from surveillance, then this course is for you. It's s also for people who are interested in understanding more about this fundamental epidemiologic tool and public health practice.Course 4: Surveillance Systems: Analysis, Dissemination, and Special Systems- In this course, we'll build on the previous lessons in this specialization to focus on some very specific skills related to public health surveillance. We'll learn how to get the most out of surveillance data analysis, focusing specifically on interpreting time trend data to detect temporal aberrations as well as person, place, and time in the context of surveillance data. We'll also explore strategies for the presentation of surveillance data and some of the complex legal elements that affect its use. We'll then turn our attention to surveillance of non-communicable chronic diseases and how the data can be used to support prevention efforts. Finally, we'll explore special surveillance systems, such as syndromic surveillance, antimicrobial resistance, and event-related surveillance. This course is designed for public health practitioners with a focus on those working on health surveillance in municipal, regional, state, provincial, or even national public health agencies. We really think that this course will help those with an interest in health surveillance to see which approaches are used in actual practice of public health.Course 5: Outbreaks and Epidemics- Professional epidemiologists are often called on to investigate outbreaks and epidemics. This course serves as an introduction to the essentials of investigation, identifying pathogens, figuring out what's going on, reporting, and responding. You'll learn how to ask precise epidemiologic questions and apply epidemiologic tools to uncover the answers. You'll also learn about basic epidemic dynamics and the terrible law that cause them to grow, as well as the reasons why they recede and eventually go away. The course concludes with deep dives into some real outbreaks from Ebola, in West Africa, to the opioid epidemic in the United States.",Epidemiology in Public Health Practice
https://www.classcentral.com/course/industrial-iot-markets-security-12056,"This course can also be taken for academic credit as ECEA 5385, part of CU Boulder’s Master of Science in Electrical Engineering degree.

Developing tomorrow's industrial infrastructure is a significant challenge. This course goes beyond the hype of consumer IoT to emphasize a much greater space for potential embedded system applications and growth: The Industrial Internet of Things (IIoT), also known as Industry 4.0. Cisco’s CEO stated: “IoT overall is a $19 Trillion market. IIoT is a significant subset including digital oilfield, advanced manufacturing, power grid automation, and smart cities”.

This is part 1 of the specialization. The primary objective of this specialization is to closely examine emerging markets, technology trends, applications and skills required by engineering students, or working engineers, exploring career opportunities in the IIoT space. The structure of the course is intentionally wide and shallow: We will cover many topics, but will not go extremely deep into any one topic area, thereby providing a broad overview of the immense landscape of IIoT. There is one exception: We will study security in some depth as this is the most important topic for all ""Internet of Things"" product development.

In this course students will learn :
  * What Industry 4.0 is and what factors have enabled the IIoT
  * Key skills to develop to be employed in the IIoT space
  * What platforms are, and also market information on Software and Services
  * What the top application areas are (examples include manufacturing and oil & gas)
  * What the top operating systems are that are used in IIoT deployments
  * About networking and wireless communication protocols used in IIoT deployments
  * About computer security; encryption techniques and secure methods for insuring data integrity and authentication
      


            Read more
          



          Market Overview, Key Skills to Develop
    -In this module you will see a specialization (all 3 courses) overview, learn what Industry 4.0 is all about, learn about the enabling factors that made it possible for the IIoT to come into existence, and become aware of what key skills to learn in order to be employed in the IIoT market segment.

Platforms, Software and Services
    -In this module we will take a look at what a platform is and the leading suppliers of platforms. I'll give you a quick look at an example building automation deployment and how a platform forms the ""glue"" that ties the entire system together. We will also take a look at the software and services market.

Top 5 application areas, Realtime Operating Systems
    -In this module we will look at the top 5 application areas and considerations involved in selecting a real-time operating system for an IIoT node (think: a single board computer attached to a manufacturing machine like a lathe).

Networking, wireless communication providers and protocols
    -In this module we look at networking concepts and two important developments: Network Functions Virtualization and Software Defined Networks. We then move on to take a quick survey of long-range and short-range wireless protocols.

Security
    -This is probably the most important module in the entire specialization. With billions of devices connected to the internet, security is of paramount importance. I will share with you the bulk of my experience in developing security solutions for end-node type devices. For me the products were hard drives and solid state drives. However, the principles that ""work"" for storage devices also apply to any IIoT device. I have a colleague guest speaker (Don Matthews) come in to talk to you about his experience with security which he has been doing for 25+ years.",Industrial IoT Markets and Security
https://www.classcentral.com/course/business-analytics-executive-overview-13373,"Businesses run on data, and data offers little value without analytics. The ability to process data to make predictions about the behavior of individuals or markets, to diagnose systems or situations, or to prescribe actions for people or processes drives business today. Increasingly many businesses are striving to become “data-driven”, proactively relying more on cold hard information and sophisticated algorithms than upon the gut instinct or slow reactions of humans. 

This course will focus on understanding key analytics concepts and the breadth of analytic possibilities. Together, the class will explore dozens of real-world analytics problems and solutions across most major industries and business functions. The course will also touch on analytic technologies, architectures, and roles from business intelligence to data science, and from data warehouses to data lakes. And the course will wrap up with a discussion of analytics trends and futures.
      


          Course Overview & Module 1 Analytics Beyond the Spreadsheet
    -This first module exposes and explains key data and analytics concepts from Big Data to data warehousing to natural language query, and everything in-between. Next we will explore various analytic techniques, types of visualizations, and types of analytics solutions. The course will continue with identifying and learning about key data and analytics roles and organization structures, including chief data and analytics officers, data scientists, and analytics centers of excellence. Alternatives to direct hiring, such as outsourcing and crowdsourcing, will also be covered. Finally, the course will scrutinize analytic trends and futures. 

Module 2 Industry and Business Function Analytics 
    -Over the course of the module, you will also see how data and analytics in each of these organizations can be used in similar ways, in similar business functions. Accordingly, you will appreciate that to be truly data-driven, you need not only look to examples in your own industry, but, also learn and apply analytics concepts from organizations in other fields.

Module 3 Staffing and Organizing for Analytics 
    -In this module you will learn a bunch of crucial analytical roles and the emergence of new roles in organizations from the C-suite down to various analyst roles. You will take a brief look at the job descriptions and the responsibilities. You will also put yourself in either a job seeker’s or a recruiter’s shoes to see what kind of skill sets are the most important and which position fits you the best. For example, it will introduce you to the three core skills of the data scientist and the crucial soft skills required to be a successful data scientist. 

Module 4 Analytics Success Today and Tomorrow
    -This module explores telling stories, through data, that connect emotionally with your audience. It will also review examples and figures that make the concept easy to understand. You will learn the major do’s and don’ts of creating dataviz and rules that lead to the clear depiction of your findings. This unit specifically focuses on Dona Wong’s guidelines for good data visualization and charts. The last leg of Module 4 teaches the three tests that help you improve your visualization. In the final step of dataviz execution, you will learn the McCandless Method for presenting visualizations. This five-step process produces the most effective communication of the graphics to your audience.",Business Analytics Executive Overview
https://www.classcentral.com/course/social-science-18629,"Identify interesting questions, analyze data sets, and correctly interpret results to make solid, evidence-based decisions.

This Specialization covers research methods, design and statistical analysis for social science research questions. In the final Capstone Project, you’ll apply the skills you learned by developing your own research question, gathering data, and analyzing and reporting on the results using statistical methods.
      


          Course 1: Quantitative Methods- Discover the principles of solid scientific methods in the behavioral and social sciences. Join us and learn to separate sloppy science from solid research! This course will cover the fundamental principles of science, some history and philosophy of science, research designs, measurement, sampling and ethics. The course is comparable to a university level introductory course on quantitative research methods in the social sciences, but has a strong focus on research integrity. We will use examples from sociology, political sciences, educational sciences, communication sciences and psychology.Course 2: Qualitative Research Methods- In this course you will be introduced to the basic ideas behind the qualitative research in social science. You will learn about data collection, description, analysis and interpretation in qualitative research. Qualitative research often involves an iterative process. We will focus on the ingredients required for this process: data collection and analysis. You won't learn how to use qualitative methods by just watching video's, so we put much stress on collecting data through observation and interviewing and on analysing and interpreting the collected data in other assignments. Obviously, the most important concepts in qualitative research will be discussed, just as we will discuss quality criteria, good practices, ethics, writing some methods of analysis, and mixing methods. We hope to take away some prejudice, and enthuse many students for qualitative research.Course 3: Basic Statistics- Understanding statistics is essential to understand research in the social and behavioral sciences. In this course you will learn the basics of statistics; not just how to calculate them, but also how to evaluate them. This course will also prepare you for the next course in the specialization - the course Inferential Statistics. In the first part of the course we will discuss methods of descriptive statistics. You will learn what cases and variables are and how you can compute measures of central tendency (mean, median and mode) and dispersion (standard deviation and variance). Next, we discuss how to assess relationships between variables, and we introduce the concepts correlation and regression. The second part of the course is concerned with the basics of probability: calculating probabilities, probability distributions and sampling distributions. You need to know about these things in order to understand how inferential statistics work. The third part of the course consists of an introduction to methods of inferential statistics - methods that help us decide whether the patterns we see in our data are strong enough to draw conclusions about the underlying population we are interested in. We will discuss confidence intervals and significance tests. You will not only learn about all these statistical concepts, you will also be trained to calculate and generate these statistics yourself using freely available statistical software.Course 4: Inferential Statistics- Inferential statistics are concerned with making inferences based on relations found in the sample, to relations in the population. Inferential statistics help us decide, for example, whether the differences between groups that we see in our data are strong enough to provide support for our hypothesis that group differences exist in general, in the entire population. We will start by considering the basic principles of significance testing: the sampling and test statistic distribution, p-value, significance level, power and type I and type II errors. Then we will consider a large number of statistical tests and techniques that help us make inferences for different types of data and different types of research designs. For each individual statistical test we will consider how it works, for what data and design it is appropriate and how results should be interpreted. You will also learn how to perform these tests using freely available software. For those who are already familiar with statistical testing: We will look at z-tests for 1 and 2 proportions, McNemar's test for dependent proportions, t-tests for 1 mean (paired differences) and 2 means, the Chi-square test for independence, Fisher’s exact test, simple regression (linear and exponential) and multiple regression (linear and logistic), one way and factorial analysis of variance, and non-parametric tests (Wilcoxon, Kruskal-Wallis, sign test, signed-rank test, runs test).Course 5: Methods and Statistics in Social Science - Final Research Project- The Final Research Project consists of a research study that you will perform in collaboration with fellow learners. Together you will formulate a research hypothesis and design, come up with operationalizations, create manipulation and measurement instruments, collect data, perform statistical analyses and document the results. In this course you will go through the entire research process and will be able to help determine what research question we will investigate and how we design and perform the research. This is an invaluable experience if you want to be able to critically evaluate scientific research in the social and behavioral sciences or design and perform your own studies in the future.",Methods and Statistics in Social Sciences
https://www.classcentral.com/course/edx-big-data-capstone-project-8159,"The Big Data Capstone Project will allow you to apply the techniques and theory you have gained from the four courses in this Big Data MicroMasters program to a medium-scale data science project.
Working with organisations and stakeholders of your choice on a real-world dataset, you will further develop your data science skills and knowledge.
This project will give you the opportunity to deepen your learning by giving you valuable experience in evaluating, selecting and applying relevant data science techniques, principles and theory to a data science problem.
This project will see you plan and execute a reasonably substantial project and demonstrate autonomy, initiative and accountability.
You’ll deepen your learning of social and ethical concerns in relation to data science, including an analysis of ethical concerns and ethical frameworks in relation to data selection and data management.
By communicating the knowledge, skills and ideas you have gained to other learners through online collaborative technologies, you will learn valuable communication skills, important for any career. You’ll also deliver a written presentation of your project design, plan, methodologies, and outcomes.



Dataset overview, data selection and ethicsUnderstand ethical issues and concerns around big data projects; Describe how ethical issues apply to the sample dataset; Describe up to three ethical approaches; Apply ethical analysis to scenarios.Exam (timed, proctored)The exam will cover content from the first four courses in the Big Data MicroMasters program, including the Ethics section of this capstone course, DataCapX. It will include questions on topics such as code structure and testing, variable types, graphs, big data algorithms, regression and ethics. Project Task 1: Data cleaning and RegressionUnderstand the basic data cleaning and preprocessing steps required in the analysis of a real data set; Create computer code to read data and perform data cleaning and preprocessing; Judge the appropriateness of a fitted regression model to the data; Determine whether simplification of a regression model is appropriate; Apply a fitted regression model to obtain predictions for new observations.Project Task 2: ClassificationBuild classifiers to predict the output of a desired factor; Analyse learned classifiers; Design a feature selection scheme; Design a scheme for evaluating the performance of classifiers.",Big Data Capstone Project
https://www.classcentral.com/course/udacity-firebase-in-a-weekend-android-7464,"In this course, you’ll learn how to use Firebase. Firebase is app development platform that provides developers a variety of tools and a scalable infrastructure to build high quality apps. We’ll begin by showing you how easy it is to read and write almost any data to Firebase. After that, we’ll teach you how to allow users to login, have data associated with them and send them notifications. You’ll learn how to use Firebase’s Security and Rules language to secure and add permissions to your data.Firebase Remote Config gives you the ability to tune and customize your app without having to publish a new version. Finally we’ll give you a brief overview of Firebase Analytics so you can collect data from the start. Got extra time this weekend? As a bonus, you will write your own Cloud Function for Firebase that makes chat more fun by adding emojis to FriendlyChat conversations. Cloud Functions for Firebase integrates the Firebase platform by letting you write code that responds to events and invokes functionality exposed by other Firebase features.By the end of this course you will have an Android application that can store and share data between different users in real time as well as authenticate and authorize those users.Why Take This Course?If you are an Android developer and your app needs any of the following features:Online data storageReal-time synchronization between many usersAuthentication for Email/Password as well as OAuth providersData permissions and securityOffline access to dataThis is the course for you!Firebase is a gentle but very powerful introduction to storing and managing data. With just a few lines of code, you can read and write almost any data you could dream up from your own custom Firebase backend.Furthermore, Firebase has a generous free plan that lets you start making hosted apps with multiple users immediately.



            Read more
          



Lesson 1 - Saturday: Why Choose Firebase, Creating a Firebase Project, Reading and Writing using Firebase Realtime Database, Firebase Security Rules, Firebase AuthenticationLesson 2 - Sunday Funday: Firebase Storage for user uploaded files, Securing uploaded files with Firebase's Storage rules, Leveraging Firebase Analytics to Improve User Engagement, Sending Notifications, Using Firebase Remote Config",Firebase in a Weekend: Android
https://www.classcentral.com/course/ibm-ai-workflow-machine-learning-vr-nlp-17101,"This is the fourth course in the IBM AI Enterprise Workflow Certification specialization.    You are STRONGLY encouraged to complete these courses in order as they are not individual independent courses, but part of a workflow where each course builds on the previous ones. 

Course 4 covers the next stage of the workflow, setting up models and their associated data pipelines for a hypothetical streaming media company.  The first topic covers the complex topic of evaluation metrics, where you will learn best practices for a number of different metrics including regression metrics, classification metrics, and multi-class metrics, which you will use to select the best model for your business challenge.  The next topics cover best practices for different types of models including linear models, tree-based models, and neural networks.  Out-of-the-box Watson models for natural language understanding and visual recognition will be used.  There will be case studies focusing on natural language processing and on image analysis to provide realistic context for the model pipelines.
 
By the end of this course you will be able to:
Discuss common regression, classification, and multilabel classification metrics
Explain the use of linear and logistic regression in supervised learning applications
Describe common strategies for grid searching and cross-validation
Employ evaluation metrics to select models for production use
Explain the use of tree-based algorithms in supervised learning applications
Explain the use of Neural Networks in supervised learning applications
Discuss the major variants of neural networks and recent advances
Create a neural net model in Tensorflow
Create and test an instance of Watson Visual Recognition
Create and test an instance of Watson NLU

Who should take this course?
This course targets existing data science practitioners that have expertise building machine learning models, who want to deepen their skills on building and deploying AI in large enterprises. If you are an aspiring Data Scientist, this course is NOT for you as you need real world expertise to benefit from the content of these courses.
 
What skills should you have?
It is assumed that you have completed Courses 1 through 3 of the IBM AI Enterprise Workflow specialization and you have a solid understanding of the following topics prior to starting this course: Fundamental understanding of Linear Algebra; Understand sampling, probability theory, and probability distributions; Knowledge of descriptive and inferential statistical concepts; General understanding of machine learning techniques and best practices; Practiced understanding of Python and the packages commonly used in data science: NumPy, Pandas, matplotlib, scikit-learn; Familiarity with IBM Watson Studio; Familiarity with the design thinking process.
      


            Read more
          



          Model Evaluation and Performance Metrics
    -This week covers model selection, evaluation and performance metrics.  The focus is on evaluating models iteratively for improvements. You will survey the landscape of evaluation metrics and linear models in order to ensure you are comfortable using implementing baseline models. The materials build up to the case study where you will use natural language processing in a classification setting. When you are done iterating on your model you will connect its model performance to business metrics as an approach to better understand model utility.

Building Machine Learning and Deep Learning Models
    -This week is primarily focused on building supervised learning models. We will survey available methods in two popular and effective areas of machine learning: tree-based algorithms and deep-learning algorithms. We will cover the use of tree-based methods like random forests and boosting along with other ensemble approaches. Many of these approaches serve as an important middle layer between interpretable linear models and difficult to interpret deep-learning models. For deep-learning we will use a pre-built visual recognition model and use TensorFlow to demonstrate how to build, turn and iterate on neural networks. We will also make sure that you understand popular neural network architectures. In the case study you will implement a convolutional neural network and ready it for deployment.","AI Workflow: Machine Learning, Visual Recognition and NLP"
https://www.classcentral.com/course/big-data-r-hadoop-8056,"You will experience how to use RHadoop tool to manage and analyse big data.
This course will give you access to a virtual environment with installations of Hadoop, R and Rstudio to get hands-on experience with big data management. Several unique examples from statistical learning and related R code for map-reduce operations will be available for testing and learning.
Those with basic knowledge in statistical learning and R will better understand the methods behind and how to run them in parallel using map-reduce functions and Hadoop data storage. At the end of the course you will get access to RHadoop on a supercomputer at University of Ljubljana.
This course is designed for people interested in data science, computational statistics and machine learning and have basic experiences with them. It will be also useful for advanced undergraduate students and first year PhD students in data analysis, statistics or bioinformatics, who wish to understand how to manage big data with Hadoop using R programming language.
We expect that the learners will also have basic experiences with linux and bash and working experiences with R and matrix operations. They should be also capable to download and run virtual machine.
All software needed to actively participate the course is provided within the virtual machine that the followers are supposed to download and run on the local machine. No extra software is needed.
You will need a modest local machine with 15GB free disk space and 2GB RAM.



            Read more",Managing Big Data with R and Hadoop
https://www.classcentral.com/course/leds-semiconductor-lasers-12228,"This course can also be taken for academic credit as ECEA 5605, part of CU Boulder’s Master of Science in Electrical Engineering degree.

LEDs and Semiconductor Lasers Course Introduction
You will learn about semiconductor light emitting diodes (LEDs) and lasers, and the important rules for their analysis, planning, design, and implementation. You will also apply your knowledge through challenging homework problem sets to cement your understanding of the material and prepare you to apply in your career. 

Course Learning Outcomes
At the end of this course you will be able to…
  (1) Design a semiconductor light emitting diode and analyze efficiency
  (2) Design a semiconductor laser
  (3) Choose suitable semiconductor materials for light emitting devices
      


          Semiconductor fundamentals
    -Light emitting diodes and semiconductor lasers is a really special course, and probably one of my favorite.  In it, you will learn the fundamental operating principles, design, fabrication techniques and applications of two of the most widely used light emitting devices in the world today - light emitting diodes and semiconductor lasers.   For module 1, I am really looking forward to introducing you to the magical world of semiconductors. In this module, we will review the basics of semiconductor physics and you will learn how we can manipulate the materials to tailor electrical and optical properties.

Radiative recombination in semiconductors
    -In the last module, we learned about the basics of semiconductor physics. In this module, we will apply this knowledge to understand how semiconductors emit light, and the basis for optoelectronic devices such as lasers and light emitting diodes.

Light Emitting Diode (LED)
    -In the last module, we learned about how semiconductors can emit light. In this module, we will apply this knowledge to learn about the basics of light emitting diodes. These devices are everywhere you turn and you now have the tools to develop a complete understanding of their operation.

Fundamentals of semiconductor lasers
    -In the last module, we learned about light emitting diodes or LEDs. Now, we will use our knowledge of semiconductors and in particular, radiative recombination, to tackle an even more powerful device, the semiconductor laser. This technology is probably the most successful laser technology of our time, with every compact disc player incorporating a 6-cent semiconductor laser. I hope you enjoy this unit as much as I do.

semiconductor laser design principles
    -In the last module, we learned about the basics of semiconductor lasers. Now, we will extend this knowledge to understand the design principles behind this very successful technology. After the module, you will wonder, as I do, how it is possible to produce a semiconductor laser for 6 cents!

advanced semiconductor laser design principles
    -In the last module, we learned about basic design principles for semiconductor lasers. In this module, we will take this one step further and learn about advanced concepts that have enabled the current generation of semiconductor lasers. Stay tuned for the magic!",Light Emitting Diodes and Semiconductor Lasers
https://www.classcentral.com/course/opensap-introduction-to-sap-enterprise-architecture-designer-11867,"Enterprise architecture is more important than ever in today’s dynamic business environment to provide a blueprint for executing digital transformation. By building an enterprise architecture, organizations can deliver a common knowledge base of easy-to-consume documentation that explains the relationships between the business and technical guiding principles and structures with which to develop a plan of action for change to drive growth.
In today’s world, it is a challenge for most customers to gain a cohesive business and system view of the enterprise.
SAP Enterprise Architecture Designer provides a single solution for you to create, document, and integrate the organization’s business, data, landscape, and requirements models to design and plan how to achieve this heterogeneous cohesive view.
This course starts with an introduction to the tool itself. After explaining the use of the tool with user/group rights, import, export, and common functions such as repository browsing, we’ll look at the 3 main functional areas. The second week will cover business modeling with business capability and BPMN models, including support for SAP Solution Manager. In the third week, we’ll discuss information modeling. This covers conceptual data models and 2 different SAP HANA styles, with Data Definition Language (DDL) as well as SAP HANA Deployment Infrastructure (HDI). We’ll also briefly touch on data warehousing foundation (DWF) support, data movement models, and other databases like Oracle, DB2, and MS SQL. The last week will cover enterprise architecture, with landscape and location models.
 



            Read more
          



Week 1:
Overview of SAP EA Designer
Week 2:
Business Architecture
Week 3:
Information Architecture
Week 4:
Landscape and System Architecture",Introduction to SAP Enterprise Architecture Designer
https://www.classcentral.com/course/smart-analytics-machine-learning-ai-gcp-17945,"Incorporating machine learning into data pipelines increases the ability of businesses to extract insights from their data. This course covers several ways machine learning can be included in data pipelines on Google Cloud Platform depending on the level of customization required. For little to no customization, this course covers AutoML. For more tailored machine learning capabilities, this course introduces AI Platform Notebooks and BigQuery Machine Learning. Also, this course covers how to productionalize machine learning solutions using Kubeflow. Learners will get hands-on experience building machine learning models on Google Cloud Platform using QwikLabs.
      


          Introduction
    -This module introduces the course and agenda

Introduction to Analytics and AI
    -This modules talks about ML options on GCP

Prebuilt ML model APIs for Unstructured Data	
    -This module focuses on using pre-built ML APIs on your unstructured data

Big Data Analytics with Cloud AI Platform Notebooks	
    -This module covers how to use AI Platform Notebooks

Productionizing Custom ML Models	
    -This module covers building custom ML models and introduces Kubeflow and AI Hub

Custom Model building with SQL in BigQuery ML	
    -This module covers BigQuery ML

Custom Model Building with Cloud AutoML 	
    -This module introduces Cloud AutoML to build powerful models without coding

Summary	
    -This module recaps the topics covered in the course","Smart Analytics, Machine Learning, and AI on GCP"
https://www.classcentral.com/course/edx-medical-genomics-101-7826,"Medical Genomics 101 (CME) is for Physicians, Physician Assistants, and Nurse Practitioners seeking CME credit. You must be registered with the Charlotte Area Healthcare Education Center to receive credit.If you are taking this course for CME credit, please CLICK HERE to register and you will be directed to that version of the course.This continuing medical education course includes six modules which cover various areas of medical genomics including: Introduction to Genomics, Variation, Microbiome,   Pharmacogenomics, in vitro (IVF) and Fetal medicine, and Oncology.
Each module defines common terms, shows examples of data, and how healthcare is changing due to genomic insights. Each module also contains ethical, legal, and social implications of genomics in medical treatment. All modules contain five multiple choice questions to assess learning gains.
Interspersed in each module are multiple interviews with practicing healthcare workers who have first hand experience with medical genomics and how the standards of care are changing. This continuing medical education course contains information that satisfies the American Board of Medical Specialties six core competencies: Practice-based learning and improvement; Patient care and procedural skills; Systems-based practice; Medical knowledge; Interpersonal and communication skills; and Professionalism.This course has been created in joint partnership with the Charlotte AHEC.



            Read more",Medical Genomics 101
https://www.classcentral.com/course/machine-learning-business-professionals-13415,"This course is intended to be an introduction to machine learning for non-technical business professionals. There is a lot of hype around machine learning and many people are concerned that in order to use machine learning in business, you need to have a technical background. For reasons that are covered in this course, that's not the case. In actuality, your knowledge of your business is far more important than your ability to build an ML model from scratch.

By the end of this course, you will have learned how to:
• Formulate machine learning solutions to real-world problems
• Identify whether the data you have is sufficient for ML
• Carry a project through various ML phases including training, evaluation, and deployment
• Perform AI responsibly and avoid reinforcing existing bias
• Discover ML use cases
• Be successful at ML

You'll need a desktop web browser to run this course's interactive labs via Qwiklabs and Google Cloud Platform.

>>> By enrolling in this course you agree to the Qwiklabs Terms of Service as set out in the FAQ and located at: https://qwiklabs.com/terms_of_service 
      


          Introduction
    -This module reviews the learning objectives for the course and introduces technology that will be important for completing labs.

What is Machine Learning?
    -This module defines what machine learning is, provides examples of how businesses are using it, contextualizes recent advances in machine learning, and reviews how artificial intelligence raises important ethical questions.

Employing ML
    -This module reviews how to do machine learning, including how to label data, train and evaluate models and avoid reinforcing bias.

Discovering ML Use Cases
    -This module reviews broad categories of ML use cases in order to jump start your ideation.

How to be successful at ML
    -This module reviews what your business must do in order to be successful at ML, including how to acquire data, how to appropriately govern that data, and how to create a culture of innovation.

Summary
    -This module reviews the content in the course.",Machine Learning for Business Professionals
https://www.classcentral.com/course/nanophotonics-detectors-12231,"This course can also be taken for academic credit as ECEA 5606, part of CU Boulder’s Master of Science in Electrical Engineering degree.

Nanophotonics and Detectors Introduction
This course dives into nanophotonic light emitting devices and optical detectors, including metal semiconductors, metal semiconductor insulators, and pn junctions. We will also cover photoconductors, avalanche photodiodes, and photomultiplier tubes. Weekly homework problem sets will challenge you to apply the principles of analysis and design we cover in preparation for real-world problems.

Course Learning Outcomes
At the end of this course you will be able to…
  (1) Use nanophotonic effects (low dimensional structures) to engineer lasers
  (2) Apply  low dimensional structures to photonic device design
  (3) Select and design optical detector for given system and application
      


          Quantum Cascade Lasers
    -The course covers the basics of nanophotonic light emitting devices and optical detectors, including metal semiconductor, metal semiconductor insulator, and pn junctions, photoconductors, avalanche photodiodes and photomultiplier tubes. Low dimensional structures enable an entirely new class of devices. Join me on a journey to understand how this happens and explore powerful examples of successful technologies such as the quantum cascade laser.Module 1 will cover the quantum cascade laser, a laser design based on intersub-band transitions, that enables very long wavelength lasers.  It will also talk about lasers that operate on intraband transitions, using low dimensional structures, which enable further control over carrier concentrations.

Confined photons 
    -In this unit, we will learn how to confine photons just as we do with electrons. This gives us power over the allowed modes of emission, allowing us to enhance the performance of lasers as well as develop 'threshold-less' lasers. I hope you enjoy this exciting topic as much as I do.

photonic detection
    -In this module, you will learn about the basics of detection and the key performance metrics that are used to evaluate detectors including noise equivalent power and detectivity. This lays the building blocks for fundamental understanding, design, and use of different photonic detection technology. This is core information that should be in the wheelhouse of any photonics researcher or engineer.

metal insulator semiconductor structures 
    -In this unit, you will learn about the fundamentals of how metal insulator semiconductor devices operate, their advantages and challenges they face. This information is particularly useful for understanding the operation of charge-coupled devices, discussed in the next section.

Charge Coupled Devices (CCDs) and Photoconductors
    -In this module, you will learn about two powerful detection technologies: charge coupled devices (CCDs) based on metal insulator semiconductor structures and photoconductors. These technologies are very useful for photonic systems.

P/N Junctions and Avalanche photodiodes (APDs)
    -In this module, you will learn about another very important detector technology: p-n junctions. These junctions can be used to be photodiodes as well as avalanche photodiodes. We will learn these important technologies function, with applications ranging from microscopy to light detection and ranging (LIDAR).",Nanophotonics and Detectors
https://www.classcentral.com/course/swayam-introduction-to-learning-analytics-14137,"Learning analytics is a method to collect, measure, analysis and reporting of data about learners and their interactions with a learning environment. Learning analytics is applying analytics on educational data to infer the student learning process and to provide support. This is an introduction and a first course in the series of learning analytics courses that will be offered in coming semesters. Learning analytics is important course in the data era and it will help the learner to apply analytics on data from education domain and also in other relevant domain.INTENDED AUDIENCE: Computer Science, ECE, Electrical Engg, Biotechnology   PREREQUISITES:Basics in Probability, Beginner level programming skill



COURSE LAYOUT Week 1:  What is LA! Definition and how it relates to Academic Analytics and EDM Learning Analytics Big-Picture.How it is related to ML, EDM Four Levels of Learning AnalyticsOverviewWeek 2:  Data Collection – How Big is Education data Data Collection from Learning Environments Pre-Processing Ethics in Learning Analytics Student PrivacyWeek 3:  Descriptive Analytics, Data Visualization, Example Dashboard Analytics,Week 4:  Predictive Analytics, Linear Regression, Analytics Tools, Demo of Weka/Rapidminer,Demo of Linear Regression using Weka",Introduction To Learning Analytics
https://www.classcentral.com/course/edx-data-analytics-and-visualization-in-health-care-13785,"Big data is transforming the health care industry relative to improving quality of care and reducing costs--key objectives for most organizations. Employers are desperately searching for professionals who have the ability to extract, analyze, and interpret data from patient health records, insurance claims, financial records, and more to tell a compelling and actionable story using health care data analytics. 
The course begins with a study of key components of the U.S. health care system as they relate to data and analytics. While we will be looking through a U.S. lens, the topics will be familiar to global learners, who will be invited to compare/contrast with their country's system. 
With that essential industry context, we'll explore the role of health informatics and health information technology in evidence-based medicine, population health, clinical process improvement, and consumer health. 
Using that as a foundation, we'll outline the components of a successful data analytics program in health care, establishing a ""virtuous cycle"" of data quality and standardization required for clinical improvement and innovation. 
The course culminates in a study of how visualizations harness data to tell a powerful, actionable story. We'll build an awareness of visualization tools and their features, as well as gain familiarity with various analytic tools.



Module 1: Introduction to Health Care 
Components of Health Care
Stakeholders
Care Settings
Financing
Public Health
Regulatory/Research 
Challenges and Opportunities
The Triple Aim
Quality and Cos
Patient Experience/Access 
Systems Approach
Evidence-Based Medicine
Quality Improvement
Value-Based Reimbursement 
Health Care Trends
Demographics/Population Health
Consumerism/Personalized Medicine
Emerging Trends in Health Care 
Module 2: Introduction to Health Informatics 
Overview of Health IT
What is Health Informatics?
How Health Informatics Supports Triple Aim 
Health IT Systems and Components
EMR/EHR Modules and Ancillary Data Systems
Enterprise Systems vs. Best of Breed
Structured Versus Unstructured Data 
EHR Adoption
EHR Regulations
Barriers to EHR Adoption 
Interoperability and HIT Standards
Health IT Standards
Data Exchange
Clinical Decision Support
HIPAA Security 
Public Health IT and Consumer Engagement 
Module 3: Introduction to Data Analytics 
Data Terms and Concepts
Why Data Analytics?
Virtuous Cycle in Analytics
Data Terminology
Big Data Terminology 
Getting Data Ready for Analysis
Considerations Before Analyzing
Integrating Data Across Data Sets 
Data Governance, Privacy, and Security
Data Governance Within the Organization
Patient Identification
Regulatory Considerations and Data Security 
Analysis with Artificial Intelligence
Machine Learning in Health Care
Natural Language Processing in Health Care 
Making Data Usable to Others
Finalizing Data for Analysis
Communicating Data 
Module 4: Introduction to Visualizations 
Value of Visualization 
Visualization Best Practices
What Not to Do
Types Based on Use Case
Visualizations of Complex Data
Dashboard Design 
Analyzing Visuals
Exploratory vs. Explanatory Visualization
Quantitative vs. Qualitative Visualization
Uses in Health Care 
Tools for Analysis and Visualization
Gartner Software Benchmarking
Current Tools",Data Analytics and Visualization in Health Care
https://www.classcentral.com/course/dsalgo-1267,"介绍视频若无法正常播放，请看这里。 

计算机是现代社会中用于解决问题的重要工具。利用计算机解决实际问题需要将问题抽象，并对数据进行操作，最后通过计算机程序求解问题。而本门课程主要内容就是对以上内容进行研究。
图灵奖获得者N.Wirth写了一本经典著作“程序=算法+数据结构”。数据结构，是抽象的表示数据的方式；算法，则是计算的一系列有效、通用的步骤。算法与数据结构是程序设计中相辅相成的两个方面。
我们会围绕着“算法+数据结构=程序”的思路，以问题求解为导向进行学习。希望能够帮助大家提高理论、抽象、设计的能力。在扎实的经典理论基础上，运用问题抽象、数据抽象、算法抽象来分析问题，应用适当的数据结构和算法来设计和实现相应的程序。通过课程学习，大家的抽象思维能力、问题求解能力将得到较大提升，编程能力和代码质量会有质的飞跃！
在求解实际问题方面，我们会学习到通过权衡时空和其他资源开销，利用数据结构来组织数据、设计高效的算法、完成高质量的程序以满足错综复杂的实际应用需要。
此外，课程所学到的内容会被利用到计算机科学后续的各个课程中，如操作系统、软件工程、数据库概论、编译技术、计算机图形学、人机交互等。希望可以为大家将来从事计算机相关的学习、研究和开发工作打下扎实的基础。
本课程采用张铭主编的国家“十一五”规划教材《数据结构与算法》（高等教育出版社）。适合计算机以及相关理工专业的大二本科生学习，需要先修过计算概论等课程，具有结构化和面向对象的程序设计基础。
课程主要包括的内容有：线性表，栈与队列，字符串，二叉树，树，图，排序（内排序，外排序），检索，索引、以及高级数据结构。课程持续14周，学习者每周在本课程上需要投入4－8小时。作为完成课程学习的要求，学生需要熟悉教材有关章节的内容，独立正确地完成作业和考试，达到60%的成绩就能获得北大的课程结业证书（获得80%以上的成绩，能得到优秀证书）。该课程是“北大-德稻网络公开课程”中的一门，由北京大学与德稻教育联合提供。

Computer, as an important tool for problem solving, has been deeply involved in every aspect of people’s daily lives. Data are the quantities on which operations are performed on computers. What is the logical relationship among data?
    How are the data stored in computers? What algorithms should be operated to solve the problems on the data? These are the questions that will be answered in “Data Structures and Algorithms”, one of the most important core courses in Computer Science.
    The course also covers fundamental data structures and classical algorithms which are widely used in the succeeding specialized courses, such as Operating Systems, Software Engineering, Database Systems, Compiler Principles, Computer
    Graphics and Human Computer Interaction.

What is the combination of data structures and algorithms? Niklaus Wirth wrote a book titled ""Algorithms + Data Structures = Programs"", which points out their important roles in computing discipline: algorithm and data structure are two closely linked
    and indivisible parts of programming.
The course will follow the idea of  “Algorithms + Data Structures = Programs”, aimed at improving  students’ knowledge and skills of theory, abstraction and design in problem solving. On a solid basis of the fundamental theory, the students will
    analyze the problems using problem, data and algorithm abstraction. Making a tradeoff between space and time complexity, the students will learn how to organize data reasonably, design efficient and effective algorithms, and implement high quality
    programs, so that they can solve real-world complex problems. After studying this course, students should be well prepared for further study, engineering and research in computer related areas.
The course uses the textbook “Data Structures and Algorithms” written by Prof. Ming Zhang and two other  coauthors. The course is appropriate for sophomore students majoring in computer science or other science/engineering disciplines. Students should have
    learned ""introduction to computing"", with the knowledge of structured and object-oriented programming.

The course will last for 14 weeks and requires the students to study for 4-8 hours per week. After studying the course, the students’ ability of abstract thinking and problem solving should have improved considerably. Their programming skills
    and the quality of their codes would have increased as well.


To be qualified for graduation in Peking University, the students need to be familiar about the materials in the textbook, do homework and exam independently, and obtain the score of 60% or more (80% for A score).
The course is one of the PKU-DeTao MOOCs, which is a joint effort by Peking University and DeTao Masters Academy.



            Read more
          



时间安排• 第一周：数据结构和算法简介以及线性表• 第二周：栈和队列• 第三周：字符串• 第四周：二叉树（1）• 第五周：二叉树（2）• 第六周：树与森林• 第七周：图• 第八周：内排序（1）• 第九周：内排序（2）• 第十周：文件管理和外排序• 第十一周：检索• 第十二周：索引技术• 第十三周：高级数据结构（1）• 第十四周：高级数据结构（2）任务安排（作业及考试）考试分为期中考试（11.25-12.8）和期末考试（1.13-1.26课程关闭时间）评分方案评分按照日常作业的完成情况和期中期末考试的答题情况进行。平时（课程参与）10 %，作业30 % ，POJ 20 %，期中 15 %，期末 25
%。POJ作业在程序自动评测网站发布：http://dsalgo.openjudge.cn/课程参与度较高的同学（Meetup讨论会、论坛问答），可以得到加分。高级数据结构的内容不作考核要求，如果学生主动完成高级数据结构的作业，也可以得到一定加分。 证书














设置“合格”（达到60%成绩）、""优秀""（达到80%成绩）两档课程标准，由任课教师签发北大统一的课程结业证书。",数据结构与算法  Data Structures and Algorithms
https://www.classcentral.com/course/edx-semiconductor-fundamentals-11697,"This course provides the essential foundations required to understand the operation of semiconductor devices such as transistors, diodes, solar cells, light-emitting devices, and more. The material will primarily appeal to electrical engineering students whose interests are in applications of semiconductor devices in circuits and systems. The treatment is physical and intuitive, and not heavily mathematical.
Technology users will gain an understanding of the semiconductor physics that is the basis for devices. Semiconductor technology developers may find it a useful starting point for diving deeper into condensed matter physics, statistical mechanics, thermodynamics, and materials science. The course presents an electrical engineering perspective on semiconductors, but those in other fields may find it a useful introduction to the approach that has guided the development of semiconductor technology for the past 50+ years.
Students taking this course will be required to complete two (2) proctored exams using the edX online Proctortrack software. 
Completed exams will be scanned and sent using Gradescope for grading by Professor Lundstrom.
Semiconductor Fundamentals is one course in a growing suite of unique, 1-credit-hour short courses being developed in an edX/Purdue University collaboration. Students may elect to pursue a verified certificate for this specific course alone or as one of the six courses needed for the edX/Purdue MicroMasters program in Nano-Science and Technology. For further information and other courses offered and planned, please see the Nano-Science and Technology page. Courses like this can also apply toward a Purdue University MSECE degree for students accepted into the full master’s program.



            Read more
          



Week 1: Materials Properties and Doping

Energy levels to energy bands
Crystalline, polycrystalline, and amorphous semiconductors
Miller indices
Properties of common semiconductors
Free carriers in semiconductors

Week 2: Rudiments of Quantum Mechanics

The wave equation
Quantum confinement
Quantum tunneling and reflection
Electron waves in crystals
Density of states

Week 3: Equilibrium Carrier Concentration

The Fermi function
Fermi-Dirac integrals
Carrier concentration vs. Fermi level
Carrier concentration vs. doping density
Carrier concentration vs. temperature

Week 4: Carrier Transport, Generation, and Recombination

The Landauer approach
Current from the nanoscale to the macroscale
Drift-diffusion equation
Carrier recombination
Carrier generation

Week 5: The Semiconductor Equations

Mathematical formulation
Energy band diagrams
Quasi-Fermi levels
Minority carrier diffusion equation",Semiconductor Fundamentals
https://www.classcentral.com/course/swayam-introduction-to-cryptology-6700,"Cryptology is employed to communicate securely, authenticate messages and sign digitally. This four-week course “Introduction to Cryptology” is designed for both computer science and mathematics students, touching upon the most important ideas and techniques of the present day cryptology. All the pre-requisite topics are revised during the lectures making this course self-contained and accessible to a wider audience. It is hoped that this course will prepare interested students for a more extensive course on Information Security.



Week-1: Classical Cryptography, Shannon’s Theory. Week-2: Block Ciphers.Week-3: Public Key Cryptography. Week-4: Cryptographic Hash Functions.",Introduction to Cryptology
https://www.classcentral.com/course/edx-structure-of-materials-15175,"Structure determines so much about a material:  its properties, its potential applications, and its performance within those applications.  This course from MIT’s Department of Materials Science and Engineering explores the structure of a wide variety of materials with current-day engineering applications.  The course begins with an introduction to amorphous materials.  We explore glasses and polymers, learn about the factors that influence their structure, and learn how materials scientists measure and describe the structure of these materials.Then we begin a discussion of the crystalline state, exploring what it means for a material to be crystalline, how we describe directions in a crystal, and how we can determine the structure of crystal through x-ray diffraction. We explore the underlying crystalline structures that underpin so many of the materials that surround us.  Finally, we look at how tensors can be used to represent the properties of three-dimensional materials, and we consider how symmetry places constraints on the properties of materials.We move on to an exploration of quasi-, plastic, and liquid crystals.  Then, we learn about the point defects that are present in all crystals, and we will learn how the presence of these defects lead to diffusion in materials. Next, we will explore dislocations in materials.  We will introduce the descriptors that we use to describe dislocations, we will learn about dislocation motion, and will consider how dislocations dramatically affect the strength of materials.  Finally, we will explore how defects can be used to strengthen materials, and we will learn about the properties of higher-order defects such as stacking faults and grain boundaries.
      


            Read more
          



          Part 1: An Introduction to Materials Science

Structure of materials roadmap
States of matter and bonding

Part 2: Descriptors

Descriptors: concept and function
Free volume
Pair distribution function

Part 3: Glasses

Glass processing methods
Continuous network model
Network modifiers

Part 4: Polymers 

Random walk model
Chain-to-chain end distance
Order and disorder in polymers

Part 5: An Introduction to the Crystalline State

Translational symmetry
The crystalline state in 2D
The crystalline state in 3D

Part 6: Real and Reciprocal Space

Miller indices
Real space
Reciprocal space

Part 7: X-Ray Diffraction

Bragg’s Law
Diffraction examples

Part 8: Symmetry in 2D Crystals

Translation, mirror, glide and rotation symmetry

Part 9: Point groups in 2D

Allowed rotational symmetries in crystals

The 10 2D point groups

An introduction to crystallographic notation

Part 10: Plane groups in 2D

The five 2D lattice types
The 17 plane groups in 2D

Part 11: Symmetry in 3D Crystals

Inversion, Roto-Inversion, and Roto-reflection
Screw symmetry

Part 12: 3D Space Point groups

Space point groups
Stereographic projection

Part 13: 3D Space Groups

Crystal lattices
Space groups

Part 14: An Introduction to Tensors

Symmetry constraints on materials properties
Coordinate transformation

Part 15: Quasi, Plastic, and Liquid Crystals

Quasi crystals
An introduction to plastic and liquid crystals
Liquid crystal descriptors
Liquid crystal applications

Part 16: Introduction to Point Defects

Thermodynamics of point defects
Vacancies, interstitials, solid solutions and nonequilibrium defects

Part 17: Ionic Point Defects & Diffusion

Kröger-Vink notation
Extrinsic defects
Diffusion

Part 18: Dislocations and Deformation 

Intro d shear stress

Part 19: Strengthening & Surface Energy

Strengthening Mechanisms
Surface free energy
Wulff shape

Part 20: 2-Dimensional Defects

Surface defects
Stacking faults
Grain boundaries
Surface reconstruction
Linear defects in liquid crystals",Structure of Materials
https://www.classcentral.com/course/ibm-data-science-18394,"Data science and machine learning skills continue to be in highest demand across industries, and the need for data practitioners is booming. Upon completing this Professional Certificate program, you will be armed with the skills and experience you need to start your career in data science and machine learning.
Through hands-on assignments and high-quality instruction, you will build a portfolio using real data science tools and real-world problems and data sets. The curriculum will cover a wide range of data science topics including: open source tools and libraries, methodologies, Python, databases, SQL, data visualization, data analysis, and machine learning. There is no requirement for prior computer science or programming knowledge in order to take this program.
Anyone with some computer skills and a passion for self-learning can succeed as we begin small and build up to more complex problems and topics.
With the tremendous need for data science and data analyst professionals in the market today, this program will jumpstart your path in data science and prepare you with a portfolio of data science deliverables to give you the confidence to take the plunge and start your data science career.



Courses under this program:Course 1: Introduction to Data Science
Learn about the would of data science first-hand from real data scientists.
Course 2: Data Science Tools
Learn about the most popular data science tools, including how to use them and what their features are.
Course 3: The Data Science Method
Learn about the methodology, practices and requirements behind data science to better understand how to problem solve with data and ensure data is relevant and properly manipulated to address a variety of real-world projects and business scenarios.
Course 4: SQL for Data Science
Learn how to use and apply the powerful language of SQL to better communicate and extract data from databases - a must for anyone working in the data science field.
Course 5: Python Basics for Data Science
This Python course provides a beginner-friendly introduction to Python for Data Science. Practice through lab exercises, and you'll be ready to create your first Python scripts on your own!
Course 6: Analyzing Data with Python
In this course, you will learn how to analyze data in Python using multi-dimensional arrays in numpy, manipulate DataFrames in pandas, use SciPy library of mathematical routines, and perform machine learning using scikit-learn!
Course 7: Visualizing Data with Python
Data visualization is the graphical representation of data in order to interactively and efficiently convey insights to clients, customers, and stakeholders in general.
Course 8: Machine Learning with Python: A Practical Introduction
Machine Learning can be an incredibly beneficial tool to uncover hidden insights and predict future trends. This Machine Learning with Python course will give you all the tools you need to get started with supervised and unsupervised learning.
Course 9: Data Science and Machine Learning Capstone Project
Create a project that you can use to showcase your Data Science skills to prospective employers. Apply various data science and machine learning techniques to analyze and visualize a data set involving a real life business scenario and build a predictive model.",IBM Data Science
https://www.classcentral.com/course/swayam-linear-algebra-7928,"Linear Algebra is a foundational subject in Mathematics which is of fundamental importance in the development of almost every branch of Mathematics, Theoretical Physics and Computer Science. A good understanding of the subject is also crucial to the study of most Engineering disciplines and many problems in Social Sciences. Linear Algebra can be succinctly described as the study of Linear Transformations and its algebraic properties. This course is an introduction to Linear AlgebraINTENDED AUDIENCE :  Undergraduate students in various universities.PREREQUISITES :  NilINDUSTRY SUPPORT :  Almost all engineering based companies 
      


COURSE LAYOUT Week 1 : Vectors, vector spaces, span, linear independence, basesWeek 2 : Dimension, linear transformationsWeek 3 : Null spaces, range, coordinate basesWeek 4 : Matrix multiplication, Invertibility, IsomorphismsWeek 5 : Coordinate change, products and quotients of vector spaces, dualityWeek 6 : Review of elementary row operations, rank, determinantsWeek 7 : Eigenvalues, EigenvectorsWeek 8 : DiagonalizationWeek 9 : Characteristic polynomials, inner products and normsWeek 10 : Orthogonal bases, orthognalization, orthogonal complementsWeek 11 : Adjoints, normal and self-adjoint operatorsWeek 12 : Spectral theorem for normal and self-adjoint operators",Linear Algebra
https://www.classcentral.com/course/data-mining-18266,"This flexible program of online courses is aimed at anyone who deals in data and is seriously concerned about obtaining information from it.
You’ll begin with a practical introduction to data mining and learn to mine your own data using the popular Weka workbench. You’ll go on to discover more advanced data mining techniques, including how to mine large datasets.
Finally, you’ll look at a variety of popular packages that can be used to extend Weka’s functionality, and gain the skills you need to become a data mining wizard.



Courses under this program:Course 1: Data Mining with Weka-Discover practical data mining and learn to mine your own data using the popular Weka workbench.Course 2: More Data Mining with Weka-Learn more about practical data mining, including how to deal with large data sets. Use advanced techniques to mine your own data.Course 3: Advanced Data Mining with Weka-Learn how to use popular packages that extend Weka's functionality and areas of application. Use them to mine your own data!",Practical Data Mining
https://www.classcentral.com/course/swayam-principles-of-modern-cdma-mimo-ofdm-wireless-communications-3980,"The field of wireless communications has witnessed revolutionary technology developments in the last decade. While previously there existed only 2G GSM based communication systems which supported a data rate of around 10 Kbps, several radical wireless technologies have been developed in the last 10 years to enable broadband wireless access with rates in excess of 100 Mbps. These have subsequently led to the development of 3G and 4G wireless technologies such as HSDPA (High Speed Downlink Packet Access), LTE (Long Term Evolution) and WiMAX (Worldwide Interoperability for Microwave Access). This has been made possible through breakthrough wireless technologies such as Code Division for Multiple Access (CDMA), Orthogonal Frequency Division Multiplexing (OFDM), Multiple Input Multiple Output (MIMO).These techniques form the basis of understanding the world of 3G/4G wireless communication systems. This course will present an elaborate introduction to the principles and performance of these fundamental 3G/ 4G wireless technologies.",Principles of Modern CDMA/ MIMO/ OFDM Wireless Communications
https://www.classcentral.com/course/udacity-google-play-services-3583,"Google offers APIs that allow you to access many of its popular services, including Location, Maps, Analytics, Advertising, Identity, and more. In this course, you’ll learn how to access these services, and build better apps!Why Take This Course?If you want to be a professional Android developer, you'll need to know how to enhance, tailor and monetize your apps, and to track their performance.

This course includes lessons on:

**Location and Context**: Vitally important for building the best possible mobile app, Location and Context allows your app behavior to change based on location. In this course, you’ll learn how to do this with the Fused Location Provider, which gives you much more than simple GPS. You’ll also learn about Activity recognition, which allows you to tailor your app to what the user is doing. Finally, you’ll learn about Geofencing, and how location services work alongside geofences to allow you to build apps that could be used for augmented reality!

**Analytics**: Where in the world are people using your app? Which activities do they use most? How do they navigate through your app? Take this course to learn how to add code to your mobile app to send usage data to Google Analytics, and answer questions like these. This course also covers how to use Google Tag Manager to send updated information to your app without needing to redeploy the APK, and how to use Tag Manager to manage all your Google Analytics tags.

**Ads**: Learn how to monetize apps using Google's AdMob to display banner and interstitial ads! 

**Mapping**: Everybody uses maps, and many people love them. Maps on mobile devices have changed the world over the last few years. They not only provide a local map in your pocket, but also a map of the entire world, down to street level, and even a 3D flyaround of many major cities. In this course, you’ll learn everything from how to add maps to your app, to how to build a virtual hike down the Grand Canyon!

**Identity**: Many apps need to establish the user’s Identity in order to customize the app to the user’s desires, save their data, allow them to identify themselves in social circles and countless other scenarios. Learn how to use Google’s Identity Platform to allow users to sign-in using their Google credentials, and access the data that they grant you permission to access.
      


            Read more
          



          ### Introduction
Overview of Google Play services and an introduction to the goals and structure of the course.

### Location and Context 

#### Part 1 - Getting Started
Learn about Location Services and Fused Location Provider, then create an app to get the current location. 
#### Part 2 - Going Deeper
Learn about continuous updates to your app, and then extend this to understand different user activities.
#### Part 3 - Advanced Topics: Geofencing 
Learn about geofencing, how it works, and how to build and monitor them.

### Analytics/Tag Manager
Where in the world are people using your app? Which activities do they use most? How do they navigate through your app? Take this course to learn how to add code to your mobile app to send usage data to Google Analytics, to get answers to questions like these.

This course also covers how to use Google Tag Manager to send updated information to your app without needing to redeploy the APK. The final lesson explains how to use Tag Manager to manage all your Google Analytics tags.

#### Part 1 - Getting Started with Analytics
Get a Google Analytics account ID, and update your app to track all screen views. 

#### Part 2 - Beyond Auto Activity Tracking
Send tracking data for events, and track how your users move through the shopping process.

#### Part 3 - Intro to Tag Manager 
Use Tag Manager to update values in your app without having to redeploy any code. Cool, huh?

#### Part 4 - Integrating Google Analytics and Tag Manager 
Use Tag Manager to organize the Analytics tags in your app.

### AdMob
#### Part 1 - Using Ads to Monetize Your App 
Introduction to models to make money from an app and Google AdMob.

#### Part 2 - Displaying Ads in an App 
Create code to display Banner and Interstitial ads in an app.

#### Part 3 - Using Real Ads
How to go from a test app to an app that shows real ads.

### Mapping 
Maps. Everybody uses them, and many people love them. Maps on mobile devices have changed the world over the last few years. Learn how to build a rich map experience in this section.

#### Part 1 - Getting Started
Add maps to your app, understand the different map types, and learn how to use the Google Developers console to get an API key. Even create a map that flies around the world!

#### Part 2 - Going Deeper 
Understand the Camera, and how it's used to project a map. Learn about zooming to different locations, and changing the camera tilt and direction. Learn about Markers, and how to place them on a map, as well as drawing shapes that are correctly geographically projected -- including lines, polylines and circles.

#### Part 3 - Advanced Topics: Street View
Learn about StreetView and how you can look at various locations around the globe as if you were there. Build a virtual hike down the Grand Canyon, and learn how to modify this to make it perfect for your app.

### Identity 
Learn how to use Google’s Identity Platform to allow users to sign-in using their Google credentials, and access the data that they grant you permission to access. 

#### Part 1 - Getting Started 
Build a basic Android App that signs your users in with Profile access. From this, you can get metadata about your users such as their full name.

####Part 2 - Going Deeper 
Learn about the Google design styles for sign-in buttons, and how to get them to use in your own app. Customize your app with these styles, and learn about different scopes, including email scope, which only allows apps access to the signed-in user’s email address for identification.",Google Play Services
https://www.classcentral.com/course/edx-graph-algorithms-10247,"If you have ever used a navigation service to find the optimal route and estimate time to destination, you've used algorithms on graphs.
Graphs arise in various real-world situations, as there are road networks, water and electricity supply networks, computer networks and, most recently, social networks! If you're looking for the fastest time to get to work, cheapest way to connect set of computers into a network or efficient algorithm to automatically find communities and opinion leaders in Facebook, you're going to work with graphs and algorithms on graphs.
In this course, part of the Algorithms and Data Structures MicroMasters program, you will learn what a graph is and its most important properties. You’ll learn several ways to traverse graphs and how you can do useful things while traversing the graph in some order. We will also talk about shortest paths algorithms. We will finish with minimum spanning trees, which are used to plan road, telephone and computer networks and also find applications in clustering and approximate algorithms.



Modules 1 and 2: Decomposition of Graphs Graphs arise in various real-world situations as there are road networks, computer networks and, most recently, social networks! If you're looking for the fastest time to get to work, cheapest way to connect set of computers into a network or efficient algorithm to automatically find communities and opinion leaders hot in Facebook, you're going to work with graphs and algorithms on graphs. In this module, you will learn ways to represent a graph as well as basic algorithms for decomposing graphs into parts. In the programming assignment of this module, you will apply the algorithms that you’ve learned to implement efficient programs for exploring mazes, analyzing Computer Science curriculum, and analyzing road networks. In the first week of the module, we focus on undirected graphs.
Modules 3 and 4: Shortest Paths  In this module you will study algorithms for finding Shortest Paths in Graphs. These algorithms have lots of applications. When you launch a navigation app on your smartphone like Google Maps or Yandex.Navi, it uses these algorithms to find you the fastest route from work to home, from home to school, etc. When you search for airplane tickets, these algorithms are used to find a route with the minimum number of plane changes. Unexpectedly, these algorithms can also be used to determine the optimal way to do currency exchange, sometimes allowing to earn huge profit! We will cover all these applications, and you will learn Breadth-First Search, Dijkstra's Algorithm and Bellman-Ford Algorithm. These algorithms are efficient and lay the foundation for even more efficient algorithms which you will learn and implement in the Shortest Paths Capstone Project to find best routes on real maps of cities and countries, find distances between people in Social Networks. In the end you will be able to find Shortest Paths efficiently in any Graph.
Module 5: Minimum Spanning Trees  In this module, we study the minimum spanning tree problem. We will cover two elegant greedy algorithms for this problem: the first one is due to Kruskal and uses the disjoint sets data structure, the second one is due to Prim and uses the priority queue data structure. In the programming assignment for this module you will be computing an optimal way of building roads between cities and an optimal way of partitioning a given set of objects into clusters (a fundamental problem in data mining).
Module 6: Flows in Networks  Network flows show up in many real-world situations in which a good needs to be transported across a network with limited capacity. You can see it when shipping goods across highways and routing packets across the internet. In this unit, we will discuss the mathematical underpinnings of network flows and some important flow algorithms. We will also give some surprising examples on seemingly unrelated problems that can be solved with our knowledge of network flows.",Graph Algorithms
https://www.classcentral.com/course/iversity-the-fascination-of-crystals-and-symmetry-984,"In this course, we will provide you with a basic introduction into crystallography. The focus is placed upon the symmetry elements, which occur in crystals. The arrangement of the atoms inside the crystal needs a more detailed description than the overall shape of the crystal (morphology). We want to show you how symmetry is classified in a hierarchical way. We want our students to gain the ability to discover symmetry on their own.
What will I learn?
At the end of the course you will be aware of the similarities between the patterns on wallpaper and the structures of crystals, be able to classify the innumerable appearances of crystals into the seven different crystal systems, know how to find crystallographic data and how to analyze it regarding symmetry, you will understand the International Tables for Crystallography and will be familiar with software for analyzing and drawing crystals structures.
What do I have to know?
Basic knowledge in chemistry (atoms, simple molecules).



Chapter    Topic



Chapter 1
       Introduction to Crystals and Crystal Systems


Chapter 2
       Crystal Systems, Fractional Coordinates, and Morphology of Crystals


Chapter 3
       The World of Symmetry, Crystal classes and Plane groups


Chapter 4
       Glide planes, Screw axes and Space groups


Chapter 5
       Quasicrystals and Real Crystal Structures (in 3D)


Chapter 6
       Metal-Organic Frameworks and Networks


Chapter 7
       Practising Topology Determination, Tilings",The Fascination of Crystals and Symmetry
https://www.classcentral.com/course/strategic-leadership-capstone-5257,"The capstone is a strategic leadership and management plan where you’ll apply what you will learn to an actual business situation with participation by one or more focal companies. The deliverable will be designed to create value from the perspective of potential employers while achieving pedagogical and experiential goals for learners.

This course is part of the iMBA offered by the University of Illinois, a flexible, fully-accredited online MBA at an incredibly competitive price. For more information, please see the Resource page in this course and onlinemba.illinois.edu.
      


          Module 1: Capstone Course Overview and Case Introduction
    -In this module you will become familiar with the Capstone course, your instructor, your classmates, and our learning environment. This Capstone course is based on an extended case study; through the module assignments you will have the opportunity to demonstrate learning gains from the courses that make up the Strategic Leadership and Management Specialization.

Module 2: Building a Leadership Team
    -In this module you will analyze performance and situational data to create the systems and processes used to lead a senior management team, applying what you have learned during completion of the Strategic Leadership and Management Specialization in two assignments.

Module 3: Identifying Opportunities
    -In this module you will analyze planning data to identify potential in-unit and division level opportunities and planning priorities, applying what you have learned during completion of the Strategic Leadership and Management Specialization in two assignments.

Module 4: Optimizing Support
    -In this module you will analyze planning data to identify modifications to support function organization and services, applying what you have learned during completion of the Strategic Leadership and Management Specialization in an assignment.

Module 5: Planning for Growth
    -In this module you will analyze planning data to identify modifications to goals, organization structure, metrics and division value propositions applying what you have learned during completion of the Strategic Leadership and Management specialization in an assignment.

Module 6: Leadership Development
    -In this module you will consider the opportunities and needs for leadership development within the Digital Dental division and your personal continued development applying what you have learned during completion of the Strategic Leadership and Management specialization in an assignment.",Strategic Leadership and Management Capstone
https://www.classcentral.com/course/futurelearn-data-tells-a-story-reading-data-in-the-social-sciences-and-humanities-6504,"##
How can we answer questions about the world around us?  How can we make decisions about what to do?  Over the past years, more and more people have turned to data for help.  Huge amounts of data are collected every day from millions of sources.  This data has a lot to tell us!  But data by itself is mute—it can only help us if we learn to make it speak and tell its story.
In this short free online course, we will introduce basic ideas about collecting data, and techniques for turning data into information we can use. Along the way, we will hear from researchers at Loughborough University about the ways they use data in their work.
Learn to answer questions with data
In the first week, we will start by considering some questions drawn from arts, political science, geography and sport that we want to answer.  We will think about what sort of data we might be able to use to answer these questions, and how we might go about finding this data.
Once we have data, we will start to explore it using some visual tools we can either create by hand or using apps online.  We will discuss how to understand these visualisations and begin to read what our data has to say.
In the second week, we will follow up with ways to summarise and present data.  You will learn how to choose the right summary for the type of data you have collected and the question you are trying to answer.
We will conclude with an article about how to make meaningful comparisons using data, and an explanation of the critical concept of significance.  We will look at the data we have collected and use these techniques to see what it has to say about our starting questions.
Throughout the course, we will be collecting, sharing, analysing and discussing our own data and learning what it has to say about some specific questions.
Improve your critical thinking skills
Although there exist very difficult and mathematically complicated methods of analysing data, the fundamentals of data analysis come from general critical thinking, and can be grasped with the basic examples and techniques we will cover.  By the end of this course, you will have learned about how data can help answer questions in a variety of disciplines, and have hands-on experience with data collection and analysis.
This course is open to anyone with a primary level education in maths and good critical thinking skills.  It is suitable if you are:

Starting or considering a course in arts, humanities, social sciences or sport
In a career where data analysis is becoming relevant
Curious about applications of data to a wide range of disciplines
Interested in learning about and experimenting with how data can be collected and studied to help answer questions




            Read more",Data Tells a Story: Reading Data in the Social Sciences and Humanities
https://www.classcentral.com/course/swayam-introduction-to-proteomics-7910,"This course introduces to the basic biology of proteins and the new advanced science called as proteomics which aims to look into the protein properties from a global perspective, i.e., not undertaking one protein at a time, but an entire set of proteins in the milieu. The course will cover in detail the two major aspects of proteomics i.e., Gel-based proteomics and Mass spectrometry-based proteomics. The gel-based module will cover different techniques like SDS-PAGE, 2-DE, 2D-DIGE etc. These techniques had a major contribution in transition from protein chemistry to proteomics. Mass spectrometry, on the other hand, is an advanced analytical technique for accurate mass measurement. In this module, we will discuss the basics of mass spectrometry, sample preparations, liquid chromatography, hybrid mass spectrometers and quantitative proteomics techniques such as iTRAQ, SILAC and TMT using mass spectrometry. The course will also provide the basic knowledge about sample preparation, mass spectrometry workflow, different chromatography technologies and quantitative proteomics.INTENDED AUDIENCE:It would be applied to B.Sc., M.Sc. and MS.PREREQUISITES: Any B.Sc. Or M.Sc.The target audiences of this course are required to have a basic introduction to biology.



COURSE LAYOUT Week 1 : Basics of Proteins and ProteomicsLecture 1 : Introduction to amino acidsLecture 2 : Introduction to ProteinsLecture 3 : Protein folding & misfoldingLecture 4 : Introduction to ProteomicsLecture 5 : Lab session – Protein-protein interaction using label-free biosensorsWeek 2 :  Gel-based proteomicsLecture 6: Sample preparation and pre-analytical factorsLecture 7 : Sample preparation: Pre-analytical factors (contd.)Lecture 8 : Sample preparation: Protein extraction and quantificationLecture 9 : One-dimensional electrophoresisLecture 10 : Introduction to 2-DEWeek 3 : Two-dimensional gel electrophoresis (2-DE)Lecture 11 : 2-DE: Second dimension, staining & destainingLecture 12 : 2-DE: Gel analysisLecture 13 : 2-DE ApplicationsLecture 14 : 2-DE Applications (contd.) & ChallengesLecture 15 : Lab session - Protein/peptide pre-fractionation using OFFGEL FRACTIONATOR & data analysisWeek 4 : Difference in gel electrophoresis (DIGE) & Systems BiologyLecture 16 : 2D-DIGE: BasicsLecture 17 : 2D-DIGE: Data analysisLecture 18 : 2D-DIGE: ApplicationsLecture 19 : Systems biology and proteomics – ILecture 20 : Systems biology and proteomics - IIWeek 5 : Basics of mass spectrometryLecture 21 : Fundamentals of mass spectrometryLecture 22 : Chromatography technologiesLecture 23 : Liquid chromatographyLecture 24 : Mass spectrometry: Ionization sourcesLecture 25 : Mass spectrometry: Mass analyzersWeek 6 : Basics of mass spectrometry and sample preparationLecture 26 : MALDI sample preparation and analysisLecture 27 : Hybrid mass spectrometry configurationsLecture 28 : Lab session - Demonstration of Q-TOF MS technologyLecture 29 : In-gel & in-solution digestionLecture 30 : Lab session - Sample preparation: tissue sample preservation technologyWeek 7 : Quantitative proteomicsLecture 31 : Introduction to quantitative proteomicsLecture 32 : SILAC: In vivo labellingLecture 33 : iTRAQ: In vitro labellingLecture 34 : TMT: In vitro labellingLecture 35 : Quantitative proteomics data analysisWeek 8  : Advancement in ProteomicsLecture 36 : Proteomics applicationsLecture 37 : Challenges in proteomicsLecture 38 : OMICS and translational researchLecture 39 : Lab session – Targeted proteomics using triple quadrupole mass spectrometryLecture 40 : Lab session – Targeted proteomics: multiple reaction monitoring",Introduction to Proteomics
https://www.classcentral.com/course/swayam-roadmap-for-patent-creation-13038,"For every science and technology individual, or for any inventive mind, there is a possibility of creating novel product or process. This course will help such intellectual minds to identify and protect their intellectual efforts.This course is an introduction to one of the important types of intellectual property, patent. The course is a good blend of theoretical and practical aspects of patenting activity. The course is focused on inventor/researcher perspective with an objective how to generate a patent. This course provides various guidelines to inventor/researcher to convert his research into patent. This includes various topics such as how to read a techno legal document (patent), how to use patent data for research gap analysis, how to identify potential patent, how to plan the patent filing activity, how to interact with patent attorney, how to use and maintain laboratory notebook and so on.INTENDED AUDIENCE : Any disciplinePREREQUISITES : NoneINDUSTRY SUPPORT : Almost all industry sectors need this course (Start ups, MSMEs, Corporate) 
      


COURSE LAYOUT Week 1: Introduction to patent: Definition, concepts, patentabilityWeek 2: Patentability Criteria:How to Identify whether my invention is patentable?Week 3: How to read a patent document?Week 4: Patentability check - various tools Week 5: Procedure for patent filingWeek 6: Research/project Planning IWeek 7: Research/project Planning IIWeek 8: Research/project Planning III",Roadmap for patent creation
https://www.classcentral.com/course/futurelearn-using-data-to-improve-student-outcomes-7655,"##
This free online course will help you to use data science to deliver better outcomes for your students.
Each week will focus on a different aspect of data. You will identify sources and interpret them, determine their implications and establish actions for improvement.
Week 1 – Improvement Science
We will consider:
 different sources and types of data;
 ways to improve student outcomes;
 improvement processes in your own context and professional experience;
 and real-world examples of improving student outcomes.
Week 2 – Findings
We will discuss:
 how to present and evaluate data effectively;
 the difference between data and findings;
 the role of ethics in data handling and sharing;
 and the relationship required between data, findings and actions, to achieve continuous improvement.
Week 3 – Actions
We will explore:
 different indicators for measuring improvement;
 how to collect sample data and select the appropriate indicator;
 and how to present indicators and actions to your students.
Learn with expert educators from AACTE
The course has been developed by the American Association of Colleges for Teacher Education (AACTE) – the premier voice on educator preparation in the United States.
This course is designed for professional educators, as well as those working in other professional services like health, who wish to use data science to improve outcomes.



            Read more",Using Data to Improve Student Outcomes
https://www.classcentral.com/course/python-data-science-18393,"Data is at the heart of our digital economy and Data Science has been ranked as the hottest profession of the 21st century. This 5 course Data Science with Python Professional Certificate program is aimed at preparing you for a career in Data Science and Machine Learning.
You will start by learning Python, the most popular language for Data Science. You will then develop skills for Data Analysis and Data Visualization and also get a practical introduction in Machine Learning. Finally you will apply and demonstrate your knowledge of Data Science and Machine Learning with a Capstone Project involving a real life business problem.
Taught by experts, the focus in this program is on hands-on learning and job readiness. As such you will work with real datasets and will be given no-charge access to tools like Jupyter notebooks in the IBM Cloud. You will utilize popular Python toolkits and libraries such as pandas, numpy, matplotlib, seaborn, folium, scipy, scikitlearn, etc.
Start developing data and analytical skills today and launch your career in Data Science, whether you are new to the job market or already in the workforce and looking to upskill yourself. No prior computer programming experience required.



Courses under this program:Course 1: Python Basics for Data Science
This Python course provides a beginner-friendly introduction to Python for Data Science. Practice through lab exercises, and you'll be ready to create your first Python scripts on your own!
Course 2: Analyzing Data with Python
In this course, you will learn how to analyze data in Python using multi-dimensional arrays in numpy, manipulate DataFrames in pandas, use SciPy library of mathematical routines, and perform machine learning using scikit-learn!
Course 3: Visualizing Data with Python
Data visualization is the graphical representation of data in order to interactively and efficiently convey insights to clients, customers, and stakeholders in general.
Course 4: Machine Learning with Python: A Practical Introduction
Machine Learning can be an incredibly beneficial tool to uncover hidden insights and predict future trends. This Machine Learning with Python course will give you all the tools you need to get started with supervised and unsupervised learning.
Course 5: Data Science and Machine Learning Capstone Project
Create a project that you can use to showcase your Data Science skills to prospective employers. Apply various data science and machine learning techniques to analyze and visualize a data set involving a real life business scenario and build a predictive model.",Python Data Science
https://www.classcentral.com/course/bayesian-methods-in-machine-learning-9604,"People apply Bayesian methods in many areas: from game development to drug discovery. They give superpowers to many machine learning algorithms: handling missing data, extracting much more information from small datasets. Bayesian methods also allow us to estimate uncertainty in predictions, which is a desirable feature for fields like medicine. 
When applied to deep learning, Bayesian methods allow you to compress your models a hundred folds, and automatically tune hyperparameters, saving your time and money.
In six weeks we will discuss the basics of Bayesian methods: from how to define a probabilistic model to how to make predictions from it. We will see how one can automate this workflow and how to speed it up using some advanced techniques. 
We will also see applications of Bayesian methods to deep learning and how to generate new images with it. We will see how new drugs that cure severe diseases be found with Bayesian methods.

Do you have technical problems? Write to us: coursera@hse.ru
      


          Introduction to Bayesian methods & Conjugate priors
    -Welcome to first week of our course! Today we will discuss what bayesian methods are and what are probabilistic models. We will see how they can be used to model real-life situations and how to make conclusions from them. We will also learn about conjugate priors — a class of models where all math becomes really simple.

Expectation-Maximization algorithm
    -This week we will about the central topic in probabilistic modeling: the Latent Variable Models and how to train them, namely the Expectation Maximization algorithm. We will see models for clustering and dimensionality reduction where Expectation Maximization algorithm can be applied as is. In the following weeks, we will spend weeks 3, 4, and 5 discussing numerous extensions to this algorithm to make it work for more complicated models and scale to large datasets.

Variational Inference & Latent Dirichlet Allocation
    -This week we will move on to approximate inference methods. We will see why we care about approximating distributions and see variational inference — one of the most powerful methods for this task. We will also see mean-field approximation in details. And apply it to text-mining algorithm called Latent Dirichlet Allocation

Markov chain Monte Carlo
    -This week we will learn how to approximate training and inference with sampling and how to sample from complicated distributions. This will allow us to build simple method to deal with LDA and with Bayesian Neural Networks — Neural Networks which weights are random variables themselves and instead of training (finding the best value for the weights) we will sample from the posterior distributions on weights.

Variational Autoencoder
    -Welcome to the fifth week of the course! This week we will combine many ideas from the previous weeks and add some new to build Variational Autoencoder -- a model that can learn a distribution over structured data (like photographs or molecules) and then sample new data points from the learned distribution, hallucinating new photographs of non-existing people. We will also the same techniques to Bayesian Neural Networks and will see how this can greatly compress the weights of the network without reducing the accuracy.

Gaussian processes & Bayesian optimization
    -Welcome to the final week of our course! This time we will see nonparametric Bayesian methods. Specifically, we will learn about Gaussian processes and their application to Bayesian optimization that allows one to perform optimization for scenarios in which each function evaluation is very expensive: oil probe, drug discovery and neural network architecture tuning.

Final project
    -In this module you will apply methods that you learned in this course to this final project",Bayesian Methods for Machine Learning
https://www.classcentral.com/course/edx-quantitative-methods-for-biology-17849,"Are you a biologist, health worker, or medical student who needs to learn how to program? Are you a programmer who wants a better understanding of the medical field? Are you looking for an introduction to MATLAB? 
For beginners, Quantitative Methods for Biology takes a unique approach, giving you an inside glimpse of a course and its learners. You'll study alongside students who are also learning to code. 
For expert programmers, this course has a will help you learn the MATLAB you need without getting slowed down by introductory concepts that you already know. Whether you're already comfortable with Python, Javascript, r, or some other language, we'll help you translate that knowledge to MATLAB. 
All learners will be able to access a copy of MATLAB that they can use during the run of the course, free of charge. There will also be opportunities to put code directly into assignments so that you can test your skills and work on authentic projects. 
In addition, this course uses an adaptive approach to its assignments. The more skilled you are, the fewer problems you'll need to complete in order to finish the course. If you're having difficulty, we'll make sure that you get the practice you need in order to succeed.



This course offers the following modules: 

Introduction to MATLAB
Arrays
Images
Loops
Functions and Scripts
Data Collection and Analysis
Arrays, pt 2
Special Topics
Yeast Showdown
Pro Tips
References and Tools",Quantitative Methods for Biology
https://www.classcentral.com/course/edx-introduction-to-predictive-analytics-using-python-14420,"This course provides you with the skills to build a predictive model from the ground up, using Python.
You will learn the full lifecycle of building the model. First, you'll understand the data discovery process and discover how to make connections between the predicting and predicted variables. You will also learn about key data transformation and preparation issues, which form the backdrop to an introduction in Python for data analytics.
Through the analysis of real-life data, you will also develop an approach to implement simple linear and logistic regression models. These real-life examples include assessments on customer credit card behavior and case studies on sales volume forecasting.
This course is the first in the MicroMasters program and will prepare you for modeling classification and regression problems with statistical and machine learning methods.



Week 1: Introduction to Predictive Modelling
Week 2: Python andPredictive Modelling
Week 3: Variables and the Modelling Process
Week 4: Transformation and Preparation of Data
Week 5: Data Quality Problems and Other Anomalies
Week 6: Regression and Case Study",Introduction to Predictive Analytics using Python
https://www.classcentral.com/course/edx-fundamentals-of-biomedical-imaging-ultrasounds-x-ray-positron-emission-tomography-pet-and-applications-7074,"This physics course covers the physical principles of major in vivo bio-imaging modalities and the different imaging techniques.
After a short study of ultrasound imaging, you will learn about the different X-ray imaging techniques. The understanding of the interaction of X-rays with tissue will lead to the study of three different techniques:

Computed Tomography (CT)
Emission Tomography
Positron Emission Tomography (PET)

This course shows how existing physical principles transcend into bio-imaging and establish an important link into life sciences, illustrating the contributions physics can make to life sciences. Practical examples will be shown to illustrate the respective imaging modality, its use, premise and limitations, and biological safety will be touched upon.
During this course, you will develop a good understanding of the mechanisms leading to tissue contrast of the bio-imaging modalities covered in this course, including the inner workings of the scanner and how they define the range of possible biomedical applications. You will be able to judge which imaging modality is adequate for specific life science needs and to understand the limits and promises of each modality.
To learn more about biomedical imaging, join us in the second part of this course Biomedical Imaging: Magnetic Resonance Imaging (MRI).




Introduction to the course, importance and essential elements of bio-imaging.
Ultrasound imaging; ionizing radiation and its generation.
X-ray imaging - when the photon bumps into living tissue, radioprotection primer.
Computed tomography - from projection to image.
Emission tomography - what are tracers and how to trace them in your body, x-ray detection, scintillation principle.
Positron emission tomography (PET) - imaging anti-matter annihilation.
Tracer kinetics - modeling of imaging data.","Fundamentals of Biomedical Imaging: Ultrasounds, X-ray, positron emission tomography (PET) and applications"
https://www.classcentral.com/course/edx-basics-of-computing-and-programming-17997,"This is a self-paced course that provides an Introduction to Computing and Programming. 
The course will address the following topics, using the Python programming language:

Positional number systems
Hello World
Numerical data types and arithmetic expressions
Branching statements
Iterative statements [Loops]
Strings
Functions
Lists [Array-based sequences]




Course Outline:

Week 1 - Positional number systems
Week 2 - Hello World
Week 3 - Numerical data types and arithmetic expressions
Week 4 - Branching statements
Week 5 - Iterative statements [Loops]
Week 6 - Strings
Week 7 - Functions
Week 8 - Lists [Array-based sequences]
Week 9 - Exam",Basics of Computing and Programming
https://www.classcentral.com/course/mitx-computational-thinking-using-python-18506,"The courses in the XSeries are designed to help people with no prior exposure to computer science or programming learn to think computationally and write programs to tackle useful problems. Some of the people taking the two courses will use them as a stepping stone to more advanced computer science courses, but for many it will be their first and last computer science courses. Since these courses may be the only formal computer science courses many of the students take, we have chosen to focus on breadth rather than depth. The goal is to provide students with a brief introduction to many topics so they will have an idea of what is possible when they need to think about how to use computation to accomplish some goal later in their career. That said, they are not “computation appreciation” courses. They are challenging and rigorous courses in which the students spend a lot of time and effort learning to bend the computer to their will.
Introduction to Computer Science and Programming Using Python covers the notion of computation, the Python programming language, some simple algorithms, testing and debugging, and informal introduction to algorithmic complexity, and some simple algorithms and data structures. Introduction to Computational Thinking and Data Science will teach you how to use computation to accomplish a variety of goals and provides you with a brief introduction to a variety of topics in computational problem solving.



Courses under this program:Course 1: Introduction to Computer Science and Programming Using Python
An introduction to computer science as a tool to solve real-world analytical problems using Python 3.5.
Course 2: Introduction to Computational Thinking and Data Science
6.00.2x is an introduction to using computation to understand real-world phenomena.",Computational Thinking using Python
https://www.classcentral.com/course/edx-demystifying-biomedical-big-data-a-user-s-guide-7871,"With the continuous generation of massive amounts of biomedical data on a daily basis, whether from research laboratories or clinical labs, we need to improve our ability to understand and analyze the data in order to take full advantage of its power in scientific discoveries and patient care. For non-bioinformaticians, “handling” big data remains a daunting task. This course was designed to facilitate the understanding, analysis, and interpretation of biomedical big data to those in the biomedical field with limited or no significant experience in bioinformatics. The goal of this course is to “demystify” the process of analyzing biomedical big data through a series of lectures and online hands-on training sessions and demos. You will learn how to use publicly available online resources and tools for genomic, transcriptomic, and proteomic data analysis, as well as other analytic tools and online resources. This course is funded by a research grant from the US National Institutes of Health (NIH)-Big Data to Knowledge (BD2K) Initiative.



Week 1: Introduction and Overview of Bioinformatics Platforms and Resources

Introduction to the Course -Interview with Bioinformatics at Georgetown University Medical Center. Dr. Robert Clarke, Dean for Research, at Georgetown University Medical Center
Biomedical Informatics: Enabling Research and Health Care. Interview with Dr. Subha Madhavan, Director of the Innovation Center for Biomedical Informatics (ICBI) at Georgetown University
Biomedical Big Data: Enabling Personalized Medicine. Interview with Dr. John Marshall, Chief, Hematology and Oncology, Lombardi Comprehensive Cancer Center, Georgetown University Medical Center internationally recognized medical oncologist

Week 2: Translational Research and Big Data

Translational Research
Translational Research Lecture, Part 1 Part I
Translational Research Lecture, Part 2 Part II
The Cancer Genome Atlas
The Cancer Genome Atlas Lecture
The Cancer Genome Atlas Demo
The Cancer Genome Atlas Exercise
Introduction to G-DOC
G-DOC Lecture
G-DOC Demo
G-DOC Exercise

Week 3: DNA and Big Data

DNA Copy Number
DNA Copy Number Lecture
DNA Copy Number Demo
DNA Copy Number Exercise
Genome Sequencing
Genome Sequencing Lecture, Part 1
Genome Sequencing Lecture, Part 2
Genome Sequencing Demo
Genome Sequencing Exercise

Week 4: RNA and Big Data

Gene Expression
Gene Expression Lecture
Gene Expression Demo
Gene Expression Exercise
MicroRNA
MicroRNA Lecture
MicroRNA Demo
MicroRNA Exercise

Week 5: Proteins and Big Data Part I

Proteomics
Protein Sequences Lecture
Protein Interactions Lecture
Mass Spec Proteomics, Lecture
Proteomics Exercise

Week 6: Proteins and Big Data Part II

Proteomics (Continued)
Data Sharing, Metadata, Data Formats
Ontologies
Proteomics Demo, Part 1
Proteomics Demo, Part 2
Proteomics Demo, Part 3
Proteomics Exercise

Week 7: Systems Biology and Big Data

Systems Biology
Systems Biology Lecture, Part 1
Systems Biology Lecture, Part 2
Systems Biology and Data Analysis Demo
Systems Biology Exercise

Week 8: Perspectives from the Field and Course Conclusion

Perspectives from the Field
Regulatory issues Issues related Related to biomedical Biomedical big Big dataData. Sheila Zimmet, JD, Senior Associate Vice President for Regulatory Affairs, and Ashley Carver, JD, Deputy Conflicts Officer and Regulatory Affairs Associate, Georgetown University Medical Center.
Enabling Everyone to Share and Use Public Datasets. Interview with Dr. Ben Busby, genomics Genomics outreach Outreach coordinator Coordinator at the National Center for Biotechnology Information (NCBI)
Interview withCancer Moonshot. Dr. Jerry Lee, Deputy Director, Center for Strategic Scientific Initiatives, Office of the Director, National Cancer Institute, National Institutes of Health",Demystifying Biomedical Big Data: A User’s Guide
https://www.classcentral.com/course/edx-circular-fashion-design-science-and-value-in-a-sustainable-clothing-industry-17080,"The fashion industry has a large influence on the global economy and is more and more known for its social and environmental impact. Everywhere, new sustainable initiatives are arising from recycling, upcycling to creating clothes from compostable materials. Circularity tough, is a complex phenomenon. What will the future bring us? Are we indeed going to decompose our clothes in our own garden?
This online course brings you a comprehensive introduction in circular fashion brought to you by roughly thirty different experts from both academia and practice. You will learn about the versatile task of transitioning towards circular fashion, from the unique collaboration between Wageningen University & Research, ArtEZ University of the Arts and many other experts.
After the course you will know the core concepts and tools to help better understand circular economy in the fashion industry. Some of the topics that are covered focus on understanding the challenge of recycling, design for circularity, alternative textiles through biobased innovation and circular business modelling to help bring innovations to the market.
For whom?
This course will provide designers, retailers, scientists, engineers and all working at the industry or with an interest in fashion with holistic insights in the complex challenges of circular fashion, while engaging you to start the transition to circularity within your personal and/or professional practices. We will bring together art, design and science to move beyond an ego-centric approach of fashion and start from an ecosystems perspective.
Learn the theory, understand the practice and start your own circular fashion journey. Join the movement towards a circular fashion industry!



            Read more
          



Module 1: Translation and interpretations
Introduction to terms and concepts such as sustainability and circularity, understanding the role of eco in fashion. First introduction to design for circularity. 
Module 2: Ecosystem circularity
Understanding the role of ecosystems in fashion. How to disrupt current thinking and mindset in the fashion industry and govern this transition. 
Module 3: Closing the loop
Introduction to the complexity of materials and recycling of textiles. Understand the importance of design for disassembly and recycling. 
Module 4: Biobased innovation & new materialism 
Learn about new biobased materials for textiles, understand the change in production processes and reflect on the future influence of biobased materials in fashion. 
Module 5: Business as crafting value
Introduction to economic paradigms and new forms of value creation for circularity in the fashion industry. Understand investment and acceleration and circular retail models.","Circular Fashion: Design, Science and Value in a Sustainable Clothing Industry"
https://www.classcentral.com/course/teachengineering-868,"This is a hands-on workshop that explores various strategies that middle and high school teachers can use to integrate engineering practices into science lessons and laboratory
investigations that they already do. We will start by comparing and contrasting the research methods employed by scientists and engineers, then demonstrate ways that teachers can facilitate, sequence, and assess lessons designed to help students understand and apply engineering principles. These principles include learning to (1) design within constraints, (2) analyze and interpret data, (3) construct models, and (4) conduct iterative tests. Upon completing this course, teachers will possess a deeper understanding of engineering and be able to effectively teach engineering processes to their students.
      


Week One: Learning from FailureOne of the best ways to introduce and understand engineering practices is by studying real-life examples, including what went wrong. We'll look at some famous engineering failures (and successes) and explore teaching applications.Week Two: Science and Engineering ThinkingThe Next Generation Science Standards explicitly call out the differences between science and engineering. We'll use exhibits from the Exploratorium museum floor to illustrate some of these differences, and ask you to re-imagine your own science activity from an engineering perspective.Week Three: Modeling ActivitiesA hallmark of the Exploratorium Teacher Institute is that we have developed lots of ""snacks"" over the years: hands-on teaching activities (thoroughly tested by students and teachers) that explore scientific phenomena using easy-to-obtain materials. This week, we'll share some of our favorites and ask you to try them out at home. Week Four: Develop Your Own Engineering ActivityIt's your turn! Take what you've learned in the class and create your own mini-lesson. You can adapt one of our activities or come up with your own and get feedback and tips from other students in the class.",Re-Engineering Your Science Curriculum
https://www.classcentral.com/course/edx-build-your-very-first-ios-app-coming-2020-13066,"In this course you will learn the tools, techniques and concepts needed to build a basic iOS app, from scratch. You will be introduced to the Swift programming language and learn how to utilise the Apple developer tools to build an app.



Lesson 1: Starting App Development 

Explain where programming is used and especially where Swift is used;
Explain the terminal, playgrounds;
Use Xcode to build an App for iOS; and
Use and explain variables and data types.

Lesson 2: Control Flow and Advanced Variables and Data Types 

Make decisions within your programs using if-then-else statements;
Use the different logical operators NOT, AND and OR to verify the truth of something;
Use the switch statement to control what is executed next; and
Use arrays and dictionaries to store data.

Lesson 3: Xcode and Interface Builder 

Navigate through Xcode projects;
Use the following areas of Xcode: project navigator, the debug area, the assistant and version editors; and
Use interface builder to build interfaces and be able to preview interfaces outside of a running App.

Lesson 4: Functions, Classes and Structures 

Understand the benefits of abstraction when writing code;
Create functions, classes and structures to improve program quality;
Use classes and structures to create custom datatypes;
Understand relationships and inheritance between classes.

Lesson 5: Introduction to User Interface Development 

Build Apps using common user interface views and controls;
Use Interface Builder to configure common user interface views and controls;
Connect Swift code to common user interface controls;
Use AutoLayout to ensure Apps adapt to different devices.

Lesson 6: View Controllers and Navigation 

Develop Apps with multiple scenes;
Use tab bar controllers to move between scenes within Apps;
Create and utilise event handlers on view controllers;
Design an appropriate navigation hierarchy for your app.

Lesson 7: Introduction to TableViews 

Use the Model View Controller design pattern for App development;
Use a ScrollView to control content display;
Use tables to display data within your App;
Respond to user input within a table.",Build your very first iOS app (COMING 2020)
